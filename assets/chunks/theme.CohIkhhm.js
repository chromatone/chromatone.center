const __vite__fileDeps=["assets/chunks/virtual_pwa-register.BehibTvg.js","assets/chunks/framework.C7hFoqOj.js","assets/chunks/index.DqdnRQKP.js"],__vite__mapDeps=i=>i.map(i=>__vite__fileDeps[i]);
import{i as Jy,c as H,a as Fl,t as sa,r as ee,b as De,u as ue,o as bn,w as dn,s as zo,d as de,e as Zy,f as Lm,g as Ti,h as Gm,n as rn,_ as Ua,j as Yy,m as xi,k as qr,l as Yc,p as $m,q as Fe,v as _,x as T,y as ae,z as v,F as ke,A as Me,B as F,C as bt,D as f,E as K,G as se,H as U,I as En,J as mt,K as pt,L as At,M as Ge,N as xo,O as Ro,P as Xy,Q as Fr,R as Qy,S as eb,T as tb,U as nb,V as pn,W as Q,X as nr,Y as ab,Z as ib,$ as ar,a0 as dc,a1 as uc,a2 as Lr,a3 as ob,a4 as Jn,a5 as Vm,a6 as Hm,a7 as sb,a8 as rb,a9 as lb,aa as cb,ab as Wm,ac as Ta,ad as Od,ae as hb,af as Ka,ag as db,ah as ub,ai as mb,aj as Um,ak as Oo,al as So,am as pb,an as fb,ao as gb,ap as yb,aq as bb,ar as vb}from"./framework.C7hFoqOj.js";const Km="15.0.4",qd=(n,e,t)=>({endTime:e,insertTime:t,type:"exponentialRampToValue",value:n}),Fd=(n,e,t)=>({endTime:e,insertTime:t,type:"linearRampToValue",value:n}),mc=(n,e)=>({startTime:e,type:"setValue",value:n}),Jm=(n,e,t)=>({duration:t,startTime:e,type:"setValueCurve",values:n}),Zm=(n,e,{startTime:t,target:a,timeConstant:i})=>a+(e-a)*Math.exp((t-n)/i),Ai=n=>n.type==="exponentialRampToValue",ir=n=>n.type==="linearRampToValue",ca=n=>Ai(n)||ir(n),Xc=n=>n.type==="setValue",Vn=n=>n.type==="setValueCurve",or=(n,e,t,a)=>{const i=n[e];return i===void 0?a:ca(i)||Xc(i)?i.value:Vn(i)?i.values[i.values.length-1]:Zm(t,or(n,e-1,i.startTime,a),i)},Ld=(n,e,t,a,i)=>t===void 0?[a.insertTime,i]:ca(t)?[t.endTime,t.value]:Xc(t)?[t.startTime,t.value]:Vn(t)?[t.startTime+t.duration,t.values[t.values.length-1]]:[t.startTime,or(n,e-1,t.startTime,i)],pc=n=>n.type==="cancelAndHold",fc=n=>n.type==="cancelScheduledValues",ia=n=>pc(n)||fc(n)?n.cancelTime:Ai(n)||ir(n)?n.endTime:n.startTime,Gd=(n,e,t,{endTime:a,value:i})=>t===i?i:0<t&&0<i||t<0&&i<0?t*(i/t)**((n-e)/(a-e)):0,$d=(n,e,t,{endTime:a,value:i})=>t+(n-e)/(a-e)*(i-t),wb=(n,e)=>{const t=Math.floor(e),a=Math.ceil(e);return t===a?n[t]:(1-(e-t))*n[t]+(1-(a-e))*n[a]},_b=(n,{duration:e,startTime:t,values:a})=>{const i=(n-t)/e*(a.length-1);return wb(a,i)},Ps=n=>n.type==="setTarget";class kb{constructor(e){this._automationEvents=[],this._currenTime=0,this._defaultValue=e}[Symbol.iterator](){return this._automationEvents[Symbol.iterator]()}add(e){const t=ia(e);if(pc(e)||fc(e)){const a=this._automationEvents.findIndex(o=>fc(e)&&Vn(o)?o.startTime+o.duration>=t:ia(o)>=t),i=this._automationEvents[a];if(a!==-1&&(this._automationEvents=this._automationEvents.slice(0,a)),pc(e)){const o=this._automationEvents[this._automationEvents.length-1];if(i!==void 0&&ca(i)){if(o!==void 0&&Ps(o))throw new Error("The internal list is malformed.");const s=o===void 0?i.insertTime:Vn(o)?o.startTime+o.duration:ia(o),r=o===void 0?this._defaultValue:Vn(o)?o.values[o.values.length-1]:o.value,l=Ai(i)?Gd(t,s,r,i):$d(t,s,r,i),c=Ai(i)?qd(l,t,this._currenTime):Fd(l,t,this._currenTime);this._automationEvents.push(c)}if(o!==void 0&&Ps(o)&&this._automationEvents.push(mc(this.getValue(t),t)),o!==void 0&&Vn(o)&&o.startTime+o.duration>t){const s=t-o.startTime,r=(o.values.length-1)/o.duration,l=Math.max(2,1+Math.ceil(s*r)),c=s/(l-1)*r,h=o.values.slice(0,l);if(c<1)for(let d=1;d<l;d+=1){const u=c*d%1;h[d]=o.values[d-1]*(1-u)+o.values[d]*u}this._automationEvents[this._automationEvents.length-1]=Jm(h,o.startTime,s)}}}else{const a=this._automationEvents.findIndex(s=>ia(s)>t),i=a===-1?this._automationEvents[this._automationEvents.length-1]:this._automationEvents[a-1];if(i!==void 0&&Vn(i)&&ia(i)+i.duration>t)return!1;const o=Ai(e)?qd(e.value,e.endTime,this._currenTime):ir(e)?Fd(e.value,t,this._currenTime):e;if(a===-1)this._automationEvents.push(o);else{if(Vn(e)&&t+e.duration>ia(this._automationEvents[a]))return!1;this._automationEvents.splice(a,0,o)}}return!0}flush(e){const t=this._automationEvents.findIndex(a=>ia(a)>e);if(t>1){const a=this._automationEvents.slice(t-1),i=a[0];Ps(i)&&a.unshift(mc(or(this._automationEvents,t-2,i.startTime,this._defaultValue),i.startTime)),this._automationEvents=a}}getValue(e){if(this._automationEvents.length===0)return this._defaultValue;const t=this._automationEvents.findIndex(s=>ia(s)>e),a=this._automationEvents[t],i=(t===-1?this._automationEvents.length:t)-1,o=this._automationEvents[i];if(o!==void 0&&Ps(o)&&(a===void 0||!ca(a)||a.insertTime>e))return Zm(e,or(this._automationEvents,i-1,o.startTime,this._defaultValue),o);if(o!==void 0&&Xc(o)&&(a===void 0||!ca(a)))return o.value;if(o!==void 0&&Vn(o)&&(a===void 0||!ca(a)||o.startTime+o.duration>e))return e<o.startTime+o.duration?_b(e,o):o.values[o.values.length-1];if(o!==void 0&&ca(o)&&(a===void 0||!ca(a)))return o.value;if(a!==void 0&&Ai(a)){const[s,r]=Ld(this._automationEvents,i,o,a,this._defaultValue);return Gd(e,s,r,a)}if(a!==void 0&&ir(a)){const[s,r]=Ld(this._automationEvents,i,o,a,this._defaultValue);return $d(e,s,r,a)}return this._defaultValue}}const Tb=n=>({cancelTime:n,type:"cancelAndHold"}),xb=n=>({cancelTime:n,type:"cancelScheduledValues"}),Sb=(n,e)=>({endTime:e,type:"exponentialRampToValue",value:n}),Ab=(n,e)=>({endTime:e,type:"linearRampToValue",value:n}),Cb=(n,e,t)=>({startTime:e,target:n,timeConstant:t,type:"setTarget"}),Mb=()=>new DOMException("","AbortError"),Ib=n=>(e,t,[a,i,o],s)=>{n(e[i],[t,a,o],r=>r[0]===t&&r[1]===a,s)},Eb=n=>(e,t,a)=>{const i=[];for(let o=0;o<a.numberOfInputs;o+=1)i.push(new Set);n.set(e,{activeInputs:i,outputs:new Set,passiveInputs:new WeakMap,renderer:t})},Db=n=>(e,t)=>{n.set(e,{activeInputs:new Set,passiveInputs:new WeakMap,renderer:t})},Oi=new WeakSet,Ym=new WeakMap,Qc=new WeakMap,Xm=new WeakMap,eh=new WeakMap,Gr=new WeakMap,Qm=new WeakMap,gc=new WeakMap,yc=new WeakMap,bc=new WeakMap,ep={construct(){return ep}},Pb=n=>{try{const e=new Proxy(n,ep);new e}catch{return!1}return!0},Vd=/^import(?:(?:[\s]+[\w]+|(?:[\s]+[\w]+[\s]*,)?[\s]*\{[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?(?:[\s]*,[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?)*[\s]*}|(?:[\s]+[\w]+[\s]*,)?[\s]*\*[\s]+as[\s]+[\w]+)[\s]+from)?(?:[\s]*)("([^"\\]|\\.)+"|'([^'\\]|\\.)+')(?:[\s]*);?/,Hd=(n,e)=>{const t=[];let a=n.replace(/^[\s]+/,""),i=a.match(Vd);for(;i!==null;){const o=i[1].slice(1,-1),s=i[0].replace(/([\s]+)?;?$/,"").replace(o,new URL(o,e).toString());t.push(s),a=a.slice(i[0].length).replace(/^[\s]+/,""),i=a.match(Vd)}return[t.join(";"),a]},Wd=n=>{if(n!==void 0&&!Array.isArray(n))throw new TypeError("The parameterDescriptors property of given value for processorCtor is not an array.")},Ud=n=>{if(!Pb(n))throw new TypeError("The given value for processorCtor should be a constructor.");if(n.prototype===null||typeof n.prototype!="object")throw new TypeError("The given value for processorCtor should have a prototype.")},Nb=(n,e,t,a,i,o,s,r,l,c,h,d,u)=>{let m=0;return(p,g,y={credentials:"omit"})=>{const b=h.get(p);if(b!==void 0&&b.has(g))return Promise.resolve();const x=c.get(p);if(x!==void 0){const w=x.get(g);if(w!==void 0)return w}const S=o(p),k=S.audioWorklet===void 0?i(g).then(([w,C])=>{const[M,A]=Hd(w,C),I=`${M};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${A}
})})(window,'_AWGS')`;return t(I)}).then(()=>{const w=u._AWGS.pop();if(w===void 0)throw new SyntaxError;a(S.currentTime,S.sampleRate,()=>w(class{},void 0,(C,M)=>{if(C.trim()==="")throw e();const A=yc.get(S);if(A!==void 0){if(A.has(C))throw e();Ud(M),Wd(M.parameterDescriptors),A.set(C,M)}else Ud(M),Wd(M.parameterDescriptors),yc.set(S,new Map([[C,M]]))},S.sampleRate,void 0,void 0))}):Promise.all([i(g),Promise.resolve(n(d,d))]).then(([[w,C],M])=>{const A=m+1;m=A;const[I,D]=Hd(w,C),j=`${I};((AudioWorkletProcessor,registerProcessor)=>{${D}
})(${M?"AudioWorkletProcessor":"class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}"},(n,p)=>registerProcessor(n,class extends p{${M?"":"__c = (a) => a.forEach(e=>this.__b.add(e.buffer));"}process(i,o,p){${M?"":"i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));"}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${A}',class extends AudioWorkletProcessor{process(){return !1}})`,W=new Blob([j],{type:"application/javascript; charset=utf-8"}),L=URL.createObjectURL(W);return S.audioWorklet.addModule(L,y).then(()=>{if(r(S))return S;const z=s(S);return z.audioWorklet.addModule(L,y).then(()=>z)}).then(z=>{if(l===null)throw new SyntaxError;try{new l(z,`__sac${A}`)}catch{throw new SyntaxError}}).finally(()=>URL.revokeObjectURL(L))});return x===void 0?c.set(p,new Map([[g,k]])):x.set(g,k),k.then(()=>{const w=h.get(p);w===void 0?h.set(p,new Set([g])):w.add(g)}).finally(()=>{const w=c.get(p);w!==void 0&&w.delete(g)}),k}},fn=(n,e)=>{const t=n.get(e);if(t===void 0)throw new Error("A value with the given key could not be found.");return t},$r=(n,e)=>{const t=Array.from(n).filter(e);if(t.length>1)throw Error("More than one element was found.");if(t.length===0)throw Error("No element was found.");const[a]=t;return n.delete(a),a},tp=(n,e,t,a)=>{const i=fn(n,e),o=$r(i,s=>s[0]===t&&s[1]===a);return i.size===0&&n.delete(e),o},os=n=>fn(Qm,n),qi=n=>{if(Oi.has(n))throw new Error("The AudioNode is already stored.");Oi.add(n),os(n).forEach(e=>e(!0))},np=n=>"port"in n,ss=n=>{if(!Oi.has(n))throw new Error("The AudioNode is not stored.");Oi.delete(n),os(n).forEach(e=>e(!1))},vc=(n,e)=>{!np(n)&&e.every(t=>t.size===0)&&ss(n)},Bb=(n,e,t,a,i,o,s,r,l,c,h,d,u)=>{const m=new WeakMap;return(p,g,y,b,x)=>{const{activeInputs:S,passiveInputs:k}=o(g),{outputs:w}=o(p),C=r(p),M=A=>{const I=l(g),D=l(p);if(A){const P=tp(k,p,y,b);n(S,p,P,!1),!x&&!d(p)&&t(D,I,y,b),u(g)&&qi(g)}else{const P=a(S,p,y,b);e(k,b,P,!1),!x&&!d(p)&&i(D,I,y,b);const E=s(g);if(E===0)h(g)&&vc(g,S);else{const O=m.get(g);O!==void 0&&clearTimeout(O),m.set(g,setTimeout(()=>{h(g)&&vc(g,S)},E*1e3))}}};return c(w,[g,y,b],A=>A[0]===g&&A[1]===y&&A[2]===b,!0)?(C.add(M),h(p)?n(S,p,[y,b,M],!0):e(k,b,[p,y,M],!0),!0):!1}},jb=n=>(e,t,[a,i,o],s)=>{const r=e.get(a);r===void 0?e.set(a,new Set([[i,t,o]])):n(r,[i,t,o],l=>l[0]===i&&l[1]===t,s)},zb=n=>(e,t)=>{const a=n(e,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:0});t.connect(a).connect(e.destination);const i=()=>{t.removeEventListener("ended",i),t.disconnect(a),a.disconnect()};t.addEventListener("ended",i)},Rb=n=>(e,t)=>{n(e).add(t)},Ob={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",fftSize:2048,maxDecibels:-30,minDecibels:-100,smoothingTimeConstant:.8},qb=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=i(r),h={...Ob,...l},d=a(c,h),u=o(c)?e():null;super(r,!1,d,u),this._nativeAnalyserNode=d}get fftSize(){return this._nativeAnalyserNode.fftSize}set fftSize(r){this._nativeAnalyserNode.fftSize=r}get frequencyBinCount(){return this._nativeAnalyserNode.frequencyBinCount}get maxDecibels(){return this._nativeAnalyserNode.maxDecibels}set maxDecibels(r){const l=this._nativeAnalyserNode.maxDecibels;if(this._nativeAnalyserNode.maxDecibels=r,!(r>this._nativeAnalyserNode.minDecibels))throw this._nativeAnalyserNode.maxDecibels=l,t()}get minDecibels(){return this._nativeAnalyserNode.minDecibels}set minDecibels(r){const l=this._nativeAnalyserNode.minDecibels;if(this._nativeAnalyserNode.minDecibels=r,!(this._nativeAnalyserNode.maxDecibels>r))throw this._nativeAnalyserNode.minDecibels=l,t()}get smoothingTimeConstant(){return this._nativeAnalyserNode.smoothingTimeConstant}set smoothingTimeConstant(r){this._nativeAnalyserNode.smoothingTimeConstant=r}getByteFrequencyData(r){this._nativeAnalyserNode.getByteFrequencyData(r)}getByteTimeDomainData(r){this._nativeAnalyserNode.getByteTimeDomainData(r)}getFloatFrequencyData(r){this._nativeAnalyserNode.getFloatFrequencyData(r)}getFloatTimeDomainData(r){this._nativeAnalyserNode.getFloatTimeDomainData(r)}},kt=(n,e)=>n.context===e,Fb=(n,e,t)=>()=>{const a=new WeakMap,i=async(o,s)=>{let r=e(o);if(!kt(r,s)){const c={channelCount:r.channelCount,channelCountMode:r.channelCountMode,channelInterpretation:r.channelInterpretation,fftSize:r.fftSize,maxDecibels:r.maxDecibels,minDecibels:r.minDecibels,smoothingTimeConstant:r.smoothingTimeConstant};r=n(s,c)}return a.set(s,r),await t(o,s,r),r};return{render(o,s){const r=a.get(s);return r!==void 0?Promise.resolve(r):i(o,s)}}},sr=n=>{try{n.copyToChannel(new Float32Array(1),0,-1)}catch{return!1}return!0},Rn=()=>new DOMException("","IndexSizeError"),th=n=>{n.getChannelData=(e=>t=>{try{return e.call(n,t)}catch(a){throw a.code===12?Rn():a}})(n.getChannelData)},Lb={numberOfChannels:1},Gb=(n,e,t,a,i,o,s,r)=>{let l=null;return class ap{constructor(h){if(i===null)throw new Error("Missing the native OfflineAudioContext constructor.");const{length:d,numberOfChannels:u,sampleRate:m}={...Lb,...h};l===null&&(l=new i(1,1,44100));const p=a!==null&&e(o,o)?new a({length:d,numberOfChannels:u,sampleRate:m}):l.createBuffer(u,d,m);if(p.numberOfChannels===0)throw t();return typeof p.copyFromChannel!="function"?(s(p),th(p)):e(sr,()=>sr(p))||r(p),n.add(p),p}static[Symbol.hasInstance](h){return h!==null&&typeof h=="object"&&Object.getPrototypeOf(h)===ap.prototype||n.has(h)}}},Nt=-34028234663852886e22,Ct=-Nt,Un=n=>Oi.has(n),$b={buffer:null,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",loop:!1,loopEnd:0,loopStart:0,playbackRate:1},Vb=(n,e,t,a,i,o,s,r)=>class extends n{constructor(c,h){const d=o(c),u={...$b,...h},m=i(d,u),p=s(d),g=p?e():null;super(c,!1,m,g),this._audioBufferSourceNodeRenderer=g,this._isBufferNullified=!1,this._isBufferSet=u.buffer!==null,this._nativeAudioBufferSourceNode=m,this._onended=null,this._playbackRate=t(this,p,m.playbackRate,Ct,Nt)}get buffer(){return this._isBufferNullified?null:this._nativeAudioBufferSourceNode.buffer}set buffer(c){if(this._nativeAudioBufferSourceNode.buffer=c,c!==null){if(this._isBufferSet)throw a();this._isBufferSet=!0}}get loop(){return this._nativeAudioBufferSourceNode.loop}set loop(c){this._nativeAudioBufferSourceNode.loop=c}get loopEnd(){return this._nativeAudioBufferSourceNode.loopEnd}set loopEnd(c){this._nativeAudioBufferSourceNode.loopEnd=c}get loopStart(){return this._nativeAudioBufferSourceNode.loopStart}set loopStart(c){this._nativeAudioBufferSourceNode.loopStart=c}get onended(){return this._onended}set onended(c){const h=typeof c=="function"?r(this,c):null;this._nativeAudioBufferSourceNode.onended=h;const d=this._nativeAudioBufferSourceNode.onended;this._onended=d!==null&&d===h?c:d}get playbackRate(){return this._playbackRate}start(c=0,h=0,d){if(this._nativeAudioBufferSourceNode.start(c,h,d),this._audioBufferSourceNodeRenderer!==null&&(this._audioBufferSourceNodeRenderer.start=d===void 0?[c,h]:[c,h,d]),this.context.state!=="closed"){qi(this);const u=()=>{this._nativeAudioBufferSourceNode.removeEventListener("ended",u),Un(this)&&ss(this)};this._nativeAudioBufferSourceNode.addEventListener("ended",u)}}stop(c=0){this._nativeAudioBufferSourceNode.stop(c),this._audioBufferSourceNodeRenderer!==null&&(this._audioBufferSourceNodeRenderer.stop=c)}},Hb=(n,e,t,a,i)=>()=>{const o=new WeakMap;let s=null,r=null;const l=async(c,h)=>{let d=t(c);const u=kt(d,h);if(!u){const m={buffer:d.buffer,channelCount:d.channelCount,channelCountMode:d.channelCountMode,channelInterpretation:d.channelInterpretation,loop:d.loop,loopEnd:d.loopEnd,loopStart:d.loopStart,playbackRate:d.playbackRate.value};d=e(h,m),s!==null&&d.start(...s),r!==null&&d.stop(r)}return o.set(h,d),u?await n(h,c.playbackRate,d.playbackRate):await a(h,c.playbackRate,d.playbackRate),await i(c,h,d),d};return{set start(c){s=c},set stop(c){r=c},render(c,h){const d=o.get(h);return d!==void 0?Promise.resolve(d):l(c,h)}}},Wb=n=>"playbackRate"in n,Ub=n=>"frequency"in n&&"gain"in n,Kb=n=>"offset"in n,Jb=n=>!("frequency"in n)&&"gain"in n,Zb=n=>"detune"in n&&"frequency"in n,Yb=n=>"pan"in n,It=n=>fn(Ym,n),rs=n=>fn(Xm,n),wc=(n,e)=>{const{activeInputs:t}=It(n);t.forEach(i=>i.forEach(([o])=>{e.includes(n)||wc(o,[...e,n])}));const a=Wb(n)?[n.playbackRate]:np(n)?Array.from(n.parameters.values()):Ub(n)?[n.Q,n.detune,n.frequency,n.gain]:Kb(n)?[n.offset]:Jb(n)?[n.gain]:Zb(n)?[n.detune,n.frequency]:Yb(n)?[n.pan]:[];for(const i of a){const o=rs(i);o!==void 0&&o.activeInputs.forEach(([s])=>wc(s,e))}Un(n)&&ss(n)},ip=n=>{wc(n.destination,[])},Xb=n=>n===void 0||typeof n=="number"||typeof n=="string"&&(n==="balanced"||n==="interactive"||n==="playback"),Qb=(n,e,t,a,i,o,s,r,l)=>class extends n{constructor(h={}){if(l===null)throw new Error("Missing the native AudioContext constructor.");let d;try{d=new l(h)}catch(p){throw p.code===12&&p.message==="sampleRate is not in range"?t():p}if(d===null)throw a();if(!Xb(h.latencyHint))throw new TypeError(`The provided value '${h.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);if(h.sampleRate!==void 0&&d.sampleRate!==h.sampleRate)throw t();super(d,2);const{latencyHint:u}=h,{sampleRate:m}=d;if(this._baseLatency=typeof d.baseLatency=="number"?d.baseLatency:u==="balanced"?512/m:u==="interactive"||u===void 0?256/m:u==="playback"?1024/m:Math.max(2,Math.min(128,Math.round(u*m/128)))*128/m,this._nativeAudioContext=d,l.name==="webkitAudioContext"?(this._nativeGainNode=d.createGain(),this._nativeOscillatorNode=d.createOscillator(),this._nativeGainNode.gain.value=1e-37,this._nativeOscillatorNode.connect(this._nativeGainNode).connect(d.destination),this._nativeOscillatorNode.start()):(this._nativeGainNode=null,this._nativeOscillatorNode=null),this._state=null,d.state==="running"){this._state="suspended";const p=()=>{this._state==="suspended"&&(this._state=null),d.removeEventListener("statechange",p)};d.addEventListener("statechange",p)}}get baseLatency(){return this._baseLatency}get state(){return this._state!==null?this._state:this._nativeAudioContext.state}close(){return this.state==="closed"?this._nativeAudioContext.close().then(()=>{throw e()}):(this._state==="suspended"&&(this._state=null),this._nativeAudioContext.close().then(()=>{this._nativeGainNode!==null&&this._nativeOscillatorNode!==null&&(this._nativeOscillatorNode.stop(),this._nativeGainNode.disconnect(),this._nativeOscillatorNode.disconnect()),ip(this)}))}createMediaElementSource(h){return new i(this,{mediaElement:h})}createMediaStreamDestination(){return new o(this)}createMediaStreamSource(h){return new s(this,{mediaStream:h})}createMediaStreamTrackSource(h){return new r(this,{mediaStreamTrack:h})}resume(){return this._state==="suspended"?new Promise((h,d)=>{const u=()=>{this._nativeAudioContext.removeEventListener("statechange",u),this._nativeAudioContext.state==="running"?h():this.resume().then(h,d)};this._nativeAudioContext.addEventListener("statechange",u)}):this._nativeAudioContext.resume().catch(h=>{throw h===void 0||h.code===15?e():h})}suspend(){return this._nativeAudioContext.suspend().catch(h=>{throw h===void 0?e():h})}},ev=(n,e,t,a,i,o,s,r)=>class extends n{constructor(c,h){const d=o(c),u=s(d),m=i(d,h,u),p=u?e(r):null;super(c,!1,m,p),this._isNodeOfNativeOfflineAudioContext=u,this._nativeAudioDestinationNode=m}get channelCount(){return this._nativeAudioDestinationNode.channelCount}set channelCount(c){if(this._isNodeOfNativeOfflineAudioContext)throw a();if(c>this._nativeAudioDestinationNode.maxChannelCount)throw t();this._nativeAudioDestinationNode.channelCount=c}get channelCountMode(){return this._nativeAudioDestinationNode.channelCountMode}set channelCountMode(c){if(this._isNodeOfNativeOfflineAudioContext)throw a();this._nativeAudioDestinationNode.channelCountMode=c}get maxChannelCount(){return this._nativeAudioDestinationNode.maxChannelCount}},tv=n=>{const e=new WeakMap,t=async(a,i)=>{const o=i.destination;return e.set(i,o),await n(a,i,o),o};return{render(a,i){const o=e.get(i);return o!==void 0?Promise.resolve(o):t(a,i)}}},nv=(n,e,t,a,i,o,s,r)=>(l,c)=>{const h=c.listener,d=()=>{const w=new Float32Array(1),C=e(c,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:9}),M=s(c);let A=!1,I=[0,0,-1,0,1,0],D=[0,0,0];const P=()=>{if(A)return;A=!0;const W=a(c,256,9,0);W.onaudioprocess=({inputBuffer:L})=>{const z=[o(L,w,0),o(L,w,1),o(L,w,2),o(L,w,3),o(L,w,4),o(L,w,5)];z.some((V,J)=>V!==I[J])&&(h.setOrientation(...z),I=z);const Y=[o(L,w,6),o(L,w,7),o(L,w,8)];Y.some((V,J)=>V!==D[J])&&(h.setPosition(...Y),D=Y)},C.connect(W)},E=W=>L=>{L!==I[W]&&(I[W]=L,h.setOrientation(...I))},O=W=>L=>{L!==D[W]&&(D[W]=L,h.setPosition(...D))},j=(W,L,z)=>{const Y=t(c,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",offset:L});Y.connect(C,0,W),Y.start(),Object.defineProperty(Y.offset,"defaultValue",{get(){return L}});const V=n({context:l},M,Y.offset,Ct,Nt);return r(V,"value",J=>()=>J.call(V),J=>ie=>{try{J.call(V,ie)}catch(ge){if(ge.code!==9)throw ge}P(),M&&z(ie)}),V.cancelAndHoldAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.cancelAndHoldAtTime),V.cancelScheduledValues=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.cancelScheduledValues),V.exponentialRampToValueAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.exponentialRampToValueAtTime),V.linearRampToValueAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.linearRampToValueAtTime),V.setTargetAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.setTargetAtTime),V.setValueAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.setValueAtTime),V.setValueCurveAtTime=(J=>M?()=>{throw i()}:(...ie)=>{const ge=J.apply(V,ie);return P(),ge})(V.setValueCurveAtTime),V};return{forwardX:j(0,0,E(0)),forwardY:j(1,0,E(1)),forwardZ:j(2,-1,E(2)),positionX:j(6,0,O(0)),positionY:j(7,0,O(1)),positionZ:j(8,0,O(2)),upX:j(3,0,E(3)),upY:j(4,1,E(4)),upZ:j(5,0,E(5))}},{forwardX:u,forwardY:m,forwardZ:p,positionX:g,positionY:y,positionZ:b,upX:x,upY:S,upZ:k}=h.forwardX===void 0?d():h;return{get forwardX(){return u},get forwardY(){return m},get forwardZ(){return p},get positionX(){return g},get positionY(){return y},get positionZ(){return b},get upX(){return x},get upY(){return S},get upZ(){return k}}},rr=n=>"context"in n,ls=n=>rr(n[0]),ai=(n,e,t,a)=>{for(const i of n)if(t(i)){if(a)return!1;throw Error("The set contains at least one similar element.")}return n.add(e),!0},Kd=(n,e,[t,a],i)=>{ai(n,[e,t,a],o=>o[0]===e&&o[1]===t,i)},Jd=(n,[e,t,a],i)=>{const o=n.get(e);o===void 0?n.set(e,new Set([[t,a]])):ai(o,[t,a],s=>s[0]===t,i)},Vi=n=>"inputs"in n,lr=(n,e,t,a)=>{if(Vi(e)){const i=e.inputs[a];return n.connect(i,t,0),[i,t,0]}return n.connect(e,t,a),[e,t,a]},op=(n,e,t)=>{for(const a of n)if(a[0]===e&&a[1]===t)return n.delete(a),a;return null},av=(n,e,t)=>$r(n,a=>a[0]===e&&a[1]===t),sp=(n,e)=>{if(!os(n).delete(e))throw new Error("Missing the expected event listener.")},rp=(n,e,t)=>{const a=fn(n,e),i=$r(a,o=>o[0]===t);return a.size===0&&n.delete(e),i},cr=(n,e,t,a)=>{Vi(e)?n.disconnect(e.inputs[a],t,0):n.disconnect(e,t,a)},Be=n=>fn(Qc,n),qo=n=>fn(eh,n),Ja=n=>gc.has(n),Ks=n=>!Oi.has(n),Zd=(n,e)=>new Promise(t=>{if(e!==null)t(!0);else{const a=n.createScriptProcessor(256,1,1),i=n.createGain(),o=n.createBuffer(1,2,44100),s=o.getChannelData(0);s[0]=1,s[1]=1;const r=n.createBufferSource();r.buffer=o,r.loop=!0,r.connect(a).connect(n.destination),r.connect(i),r.disconnect(i),a.onaudioprocess=l=>{const c=l.inputBuffer.getChannelData(0);Array.prototype.some.call(c,h=>h===1)?t(!0):t(!1),r.stop(),a.onaudioprocess=null,r.disconnect(a),a.disconnect(n.destination)},r.start()}}),Ll=(n,e)=>{const t=new Map;for(const a of n)for(const i of a){const o=t.get(i);t.set(i,o===void 0?1:o+1)}t.forEach((a,i)=>e(i,a))},hr=n=>"context"in n,iv=n=>{const e=new Map;n.connect=(t=>(a,i=0,o=0)=>{const s=hr(a)?t(a,i,o):t(a,i),r=e.get(a);return r===void 0?e.set(a,[{input:o,output:i}]):r.every(l=>l.input!==o||l.output!==i)&&r.push({input:o,output:i}),s})(n.connect.bind(n)),n.disconnect=(t=>(a,i,o)=>{if(t.apply(n),a===void 0)e.clear();else if(typeof a=="number")for(const[s,r]of e){const l=r.filter(c=>c.output!==a);l.length===0?e.delete(s):e.set(s,l)}else if(e.has(a))if(i===void 0)e.delete(a);else{const s=e.get(a);if(s!==void 0){const r=s.filter(l=>l.output!==i&&(l.input!==o||o===void 0));r.length===0?e.delete(a):e.set(a,r)}}for(const[s,r]of e)r.forEach(l=>{hr(s)?n.connect(s,l.output,l.input):n.connect(s,l.output)})})(n.disconnect)},ov=(n,e,t,a)=>{const{activeInputs:i,passiveInputs:o}=rs(e),{outputs:s}=It(n),r=os(n),l=c=>{const h=Be(n),d=qo(e);if(c){const u=rp(o,n,t);Kd(i,n,u,!1),!a&&!Ja(n)&&h.connect(d,t)}else{const u=av(i,n,t);Jd(o,u,!1),!a&&!Ja(n)&&h.disconnect(d,t)}};return ai(s,[e,t],c=>c[0]===e&&c[1]===t,!0)?(r.add(l),Un(n)?Kd(i,n,[t,l],!0):Jd(o,[n,t,l],!0),!0):!1},sv=(n,e,t,a)=>{const{activeInputs:i,passiveInputs:o}=It(e),s=op(i[a],n,t);return s===null?[tp(o,n,t,a)[2],!1]:[s[2],!0]},rv=(n,e,t)=>{const{activeInputs:a,passiveInputs:i}=rs(e),o=op(a,n,t);return o===null?[rp(i,n,t)[1],!1]:[o[2],!0]},nh=(n,e,t,a,i)=>{const[o,s]=sv(n,t,a,i);if(o!==null&&(sp(n,o),s&&!e&&!Ja(n)&&cr(Be(n),Be(t),a,i)),Un(t)){const{activeInputs:r}=It(t);vc(t,r)}},ah=(n,e,t,a)=>{const[i,o]=rv(n,t,a);i!==null&&(sp(n,i),o&&!e&&!Ja(n)&&Be(n).disconnect(qo(t),a))},lv=(n,e)=>{const t=It(n),a=[];for(const i of t.outputs)ls(i)?nh(n,e,...i):ah(n,e,...i),a.push(i[0]);return t.outputs.clear(),a},cv=(n,e,t)=>{const a=It(n),i=[];for(const o of a.outputs)o[1]===t&&(ls(o)?nh(n,e,...o):ah(n,e,...o),i.push(o[0]),a.outputs.delete(o));return i},hv=(n,e,t,a,i)=>{const o=It(n);return Array.from(o.outputs).filter(s=>s[0]===t&&(a===void 0||s[1]===a)&&(i===void 0||s[2]===i)).map(s=>(ls(s)?nh(n,e,...s):ah(n,e,...s),o.outputs.delete(s),s[0]))},dv=(n,e,t,a,i,o,s,r,l,c,h,d,u,m,p,g)=>class extends c{constructor(b,x,S,k){super(S),this._context=b,this._nativeAudioNode=S;const w=h(b);d(w)&&t(Zd,()=>Zd(w,g))!==!0&&iv(S),Qc.set(this,S),Qm.set(this,new Set),b.state!=="closed"&&x&&qi(this),n(this,k,S)}get channelCount(){return this._nativeAudioNode.channelCount}set channelCount(b){this._nativeAudioNode.channelCount=b}get channelCountMode(){return this._nativeAudioNode.channelCountMode}set channelCountMode(b){this._nativeAudioNode.channelCountMode=b}get channelInterpretation(){return this._nativeAudioNode.channelInterpretation}set channelInterpretation(b){this._nativeAudioNode.channelInterpretation=b}get context(){return this._context}get numberOfInputs(){return this._nativeAudioNode.numberOfInputs}get numberOfOutputs(){return this._nativeAudioNode.numberOfOutputs}connect(b,x=0,S=0){if(x<0||x>=this._nativeAudioNode.numberOfOutputs)throw i();const k=h(this._context),w=p(k);if(u(b)||m(b))throw o();if(rr(b)){const A=Be(b);try{const D=lr(this._nativeAudioNode,A,x,S),P=Ks(this);(w||P)&&this._nativeAudioNode.disconnect(...D),this.context.state!=="closed"&&!P&&Ks(b)&&qi(b)}catch(D){throw D.code===12?o():D}if(e(this,b,x,S,w)){const D=l([this],b);Ll(D,a(w))}return b}const C=qo(b);if(C.name==="playbackRate"&&C.maxValue===1024)throw s();try{this._nativeAudioNode.connect(C,x),(w||Ks(this))&&this._nativeAudioNode.disconnect(C,x)}catch(A){throw A.code===12?o():A}if(ov(this,b,x,w)){const A=l([this],b);Ll(A,a(w))}}disconnect(b,x,S){let k;const w=h(this._context),C=p(w);if(b===void 0)k=lv(this,C);else if(typeof b=="number"){if(b<0||b>=this.numberOfOutputs)throw i();k=cv(this,C,b)}else{if(x!==void 0&&(x<0||x>=this.numberOfOutputs)||rr(b)&&S!==void 0&&(S<0||S>=b.numberOfInputs))throw i();if(k=hv(this,C,b,x,S),k.length===0)throw o()}for(const M of k){const A=l([this],M);Ll(A,r)}}},uv=(n,e,t,a,i,o,s,r,l,c,h,d,u)=>(m,p,g,y=null,b=null)=>{const x=g.value,S=new kb(x),k=p?a(S):null,w={get defaultValue(){return x},get maxValue(){return y===null?g.maxValue:y},get minValue(){return b===null?g.minValue:b},get value(){return g.value},set value(C){g.value=C,w.setValueAtTime(C,m.context.currentTime)},cancelAndHoldAtTime(C){if(typeof g.cancelAndHoldAtTime=="function")k===null&&S.flush(m.context.currentTime),S.add(i(C)),g.cancelAndHoldAtTime(C);else{const M=Array.from(S).pop();k===null&&S.flush(m.context.currentTime),S.add(i(C));const A=Array.from(S).pop();g.cancelScheduledValues(C),M!==A&&A!==void 0&&(A.type==="exponentialRampToValue"?g.exponentialRampToValueAtTime(A.value,A.endTime):A.type==="linearRampToValue"?g.linearRampToValueAtTime(A.value,A.endTime):A.type==="setValue"?g.setValueAtTime(A.value,A.startTime):A.type==="setValueCurve"&&g.setValueCurveAtTime(A.values,A.startTime,A.duration))}return w},cancelScheduledValues(C){return k===null&&S.flush(m.context.currentTime),S.add(o(C)),g.cancelScheduledValues(C),w},exponentialRampToValueAtTime(C,M){if(C===0)throw new RangeError;if(!Number.isFinite(M)||M<0)throw new RangeError;const A=m.context.currentTime;return k===null&&S.flush(A),Array.from(S).length===0&&(S.add(c(x,A)),g.setValueAtTime(x,A)),S.add(s(C,M)),g.exponentialRampToValueAtTime(C,M),w},linearRampToValueAtTime(C,M){const A=m.context.currentTime;return k===null&&S.flush(A),Array.from(S).length===0&&(S.add(c(x,A)),g.setValueAtTime(x,A)),S.add(r(C,M)),g.linearRampToValueAtTime(C,M),w},setTargetAtTime(C,M,A){return k===null&&S.flush(m.context.currentTime),S.add(l(C,M,A)),g.setTargetAtTime(C,M,A),w},setValueAtTime(C,M){return k===null&&S.flush(m.context.currentTime),S.add(c(C,M)),g.setValueAtTime(C,M),w},setValueCurveAtTime(C,M,A){const I=C instanceof Float32Array?C:new Float32Array(C);if(d!==null&&d.name==="webkitAudioContext"){const D=M+A,P=m.context.sampleRate,E=Math.ceil(M*P),O=Math.floor(D*P),j=O-E,W=new Float32Array(j);for(let z=0;z<j;z+=1){const Y=(I.length-1)/A*((E+z)/P-M),V=Math.floor(Y),J=Math.ceil(Y);W[z]=V===J?I[V]:(1-(Y-V))*I[V]+(1-(J-Y))*I[J]}k===null&&S.flush(m.context.currentTime),S.add(h(W,M,A)),g.setValueCurveAtTime(W,M,A);const L=O/P;L<D&&u(w,W[W.length-1],L),u(w,I[I.length-1],D)}else k===null&&S.flush(m.context.currentTime),S.add(h(I,M,A)),g.setValueCurveAtTime(I,M,A);return w}};return t.set(w,g),e.set(w,m),n(w,k),w},mv=n=>({replay(e){for(const t of n)if(t.type==="exponentialRampToValue"){const{endTime:a,value:i}=t;e.exponentialRampToValueAtTime(i,a)}else if(t.type==="linearRampToValue"){const{endTime:a,value:i}=t;e.linearRampToValueAtTime(i,a)}else if(t.type==="setTarget"){const{startTime:a,target:i,timeConstant:o}=t;e.setTargetAtTime(i,a,o)}else if(t.type==="setValue"){const{startTime:a,value:i}=t;e.setValueAtTime(i,a)}else if(t.type==="setValueCurve"){const{duration:a,startTime:i,values:o}=t;e.setValueCurveAtTime(o,i,a)}else throw new Error("Can't apply an unknown automation.")}});class lp{constructor(e){this._map=new Map(e)}get size(){return this._map.size}entries(){return this._map.entries()}forEach(e,t=null){return this._map.forEach((a,i)=>e.call(t,a,i,this))}get(e){return this._map.get(e)}has(e){return this._map.has(e)}keys(){return this._map.keys()}values(){return this._map.values()}}const pv={channelCount:2,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:1,numberOfOutputs:1,parameterData:{},processorOptions:{}},fv=(n,e,t,a,i,o,s,r,l,c,h,d,u,m)=>class extends e{constructor(g,y,b){var x;const S=r(g),k=l(S),w=h({...pv,...b});u(w);const C=yc.get(S),M=C==null?void 0:C.get(y),A=k||S.state!=="closed"?S:(x=s(S))!==null&&x!==void 0?x:S,I=i(A,k?null:g.baseLatency,c,y,M,w),D=k?a(y,w,M):null;super(g,!0,I,D);const P=[];I.parameters.forEach((O,j)=>{const W=t(this,k,O);P.push([j,W])}),this._nativeAudioWorkletNode=I,this._onprocessorerror=null,this._parameters=new lp(P),k&&n(S,this);const{activeInputs:E}=o(this);d(I,E)}get onprocessorerror(){return this._onprocessorerror}set onprocessorerror(g){const y=typeof g=="function"?m(this,g):null;this._nativeAudioWorkletNode.onprocessorerror=y;const b=this._nativeAudioWorkletNode.onprocessorerror;this._onprocessorerror=b!==null&&b===y?g:b}get parameters(){return this._parameters===null?this._nativeAudioWorkletNode.parameters:this._parameters}get port(){return this._nativeAudioWorkletNode.port}};function dr(n,e,t,a,i){if(typeof n.copyFromChannel=="function")e[t].byteLength===0&&(e[t]=new Float32Array(128)),n.copyFromChannel(e[t],a,i);else{const o=n.getChannelData(a);if(e[t].byteLength===0)e[t]=o.slice(i,i+128);else{const s=new Float32Array(o.buffer,i*Float32Array.BYTES_PER_ELEMENT,128);e[t].set(s)}}}const cp=(n,e,t,a,i)=>{typeof n.copyToChannel=="function"?e[t].byteLength!==0&&n.copyToChannel(e[t],a,i):e[t].byteLength!==0&&n.getChannelData(a).set(e[t],i)},ur=(n,e)=>{const t=[];for(let a=0;a<n;a+=1){const i=[],o=typeof e=="number"?e:e[a];for(let s=0;s<o;s+=1)i.push(new Float32Array(128));t.push(i)}return t},gv=(n,e)=>{const t=fn(bc,n),a=Be(e);return fn(t,a)},yv=async(n,e,t,a,i,o,s)=>{const r=e===null?Math.ceil(n.context.length/128)*128:e.length,l=a.channelCount*a.numberOfInputs,c=i.reduce((y,b)=>y+b,0),h=c===0?null:t.createBuffer(c,r,t.sampleRate);if(o===void 0)throw new Error("Missing the processor constructor.");const d=It(n),u=await gv(t,n),m=ur(a.numberOfInputs,a.channelCount),p=ur(a.numberOfOutputs,i),g=Array.from(n.parameters.keys()).reduce((y,b)=>({...y,[b]:new Float32Array(128)}),{});for(let y=0;y<r;y+=128){if(a.numberOfInputs>0&&e!==null)for(let b=0;b<a.numberOfInputs;b+=1)for(let x=0;x<a.channelCount;x+=1)dr(e,m[b],x,x,y);o.parameterDescriptors!==void 0&&e!==null&&o.parameterDescriptors.forEach(({name:b},x)=>{dr(e,g,b,l+x,y)});for(let b=0;b<a.numberOfInputs;b+=1)for(let x=0;x<i[b];x+=1)p[b][x].byteLength===0&&(p[b][x]=new Float32Array(128));try{const b=m.map((S,k)=>d.activeInputs[k].size===0?[]:S),x=s(y/t.sampleRate,t.sampleRate,()=>u.process(b,p,g));if(h!==null)for(let S=0,k=0;S<a.numberOfOutputs;S+=1){for(let w=0;w<i[S];w+=1)cp(h,p[S],w,k+w,y);k+=i[S]}if(!x)break}catch(b){n.dispatchEvent(new ErrorEvent("processorerror",{colno:b.colno,filename:b.filename,lineno:b.lineno,message:b.message}));break}}return h},bv=(n,e,t,a,i,o,s,r,l,c,h,d,u,m,p,g)=>(y,b,x)=>{const S=new WeakMap;let k=null;const w=async(C,M)=>{let A=h(C),I=null;const D=kt(A,M),P=Array.isArray(b.outputChannelCount)?b.outputChannelCount:Array.from(b.outputChannelCount);if(d===null){const E=P.reduce((L,z)=>L+z,0),O=i(M,{channelCount:Math.max(1,E),channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:Math.max(1,E)}),j=[];for(let L=0;L<C.numberOfOutputs;L+=1)j.push(a(M,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:P[L]}));const W=s(M,{channelCount:b.channelCount,channelCountMode:b.channelCountMode,channelInterpretation:b.channelInterpretation,gain:1});W.connect=e.bind(null,j),W.disconnect=l.bind(null,j),I=[O,j,W]}else D||(A=new d(M,y));if(S.set(M,I===null?A:I[2]),I!==null){if(k===null){if(x===void 0)throw new Error("Missing the processor constructor.");if(u===null)throw new Error("Missing the native OfflineAudioContext constructor.");const z=C.channelCount*C.numberOfInputs,Y=x.parameterDescriptors===void 0?0:x.parameterDescriptors.length,V=z+Y;k=yv(C,V===0?null:await(async()=>{const ie=new u(V,Math.ceil(C.context.length/128)*128,M.sampleRate),ge=[],ot=[];for(let Te=0;Te<b.numberOfInputs;Te+=1)ge.push(s(ie,{channelCount:b.channelCount,channelCountMode:b.channelCountMode,channelInterpretation:b.channelInterpretation,gain:1})),ot.push(i(ie,{channelCount:b.channelCount,channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:b.channelCount}));const Ee=await Promise.all(Array.from(C.parameters.values()).map(async Te=>{const Je=o(ie,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",offset:Te.value});return await m(ie,Te,Je.offset),Je})),le=a(ie,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:Math.max(1,z+Y)});for(let Te=0;Te<b.numberOfInputs;Te+=1){ge[Te].connect(ot[Te]);for(let Je=0;Je<b.channelCount;Je+=1)ot[Te].connect(le,Je,Te*b.channelCount+Je)}for(const[Te,Je]of Ee.entries())Je.connect(le,0,z+Te),Je.start(0);return le.connect(ie.destination),await Promise.all(ge.map(Te=>p(C,ie,Te))),g(ie)})(),M,b,P,x,c)}const E=await k,O=t(M,{buffer:null,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",loop:!1,loopEnd:0,loopStart:0,playbackRate:1}),[j,W,L]=I;E!==null&&(O.buffer=E,O.start(0)),O.connect(j);for(let z=0,Y=0;z<C.numberOfOutputs;z+=1){const V=W[z];for(let J=0;J<P[z];J+=1)j.connect(V,Y+J,J);Y+=P[z]}return L}if(D)for(const[E,O]of C.parameters.entries())await n(M,O,A.parameters.get(E));else for(const[E,O]of C.parameters.entries())await m(M,O,A.parameters.get(E));return await p(C,M,A),A};return{render(C,M){r(M,C);const A=S.get(M);return A!==void 0?Promise.resolve(A):w(C,M)}}},vv=(n,e,t,a,i,o,s,r,l,c,h,d,u,m,p,g,y,b,x,S)=>class extends p{constructor(w,C){super(w,C),this._nativeContext=w,this._audioWorklet=n===void 0?void 0:{addModule:(M,A)=>n(this,M,A)}}get audioWorklet(){return this._audioWorklet}createAnalyser(){return new e(this)}createBiquadFilter(){return new i(this)}createBuffer(w,C,M){return new t({length:C,numberOfChannels:w,sampleRate:M})}createBufferSource(){return new a(this)}createChannelMerger(w=6){return new o(this,{numberOfInputs:w})}createChannelSplitter(w=6){return new s(this,{numberOfOutputs:w})}createConstantSource(){return new r(this)}createConvolver(){return new l(this)}createDelay(w=1){return new h(this,{maxDelayTime:w})}createDynamicsCompressor(){return new d(this)}createGain(){return new u(this)}createIIRFilter(w,C){return new m(this,{feedback:C,feedforward:w})}createOscillator(){return new g(this)}createPanner(){return new y(this)}createPeriodicWave(w,C,M={disableNormalization:!1}){return new b(this,{...M,imag:C,real:w})}createStereoPanner(){return new x(this)}createWaveShaper(){return new S(this)}decodeAudioData(w,C,M){return c(this._nativeContext,w).then(A=>(typeof C=="function"&&C(A),A),A=>{throw typeof M=="function"&&M(A),A})}},wv={Q:1,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",detune:0,frequency:350,gain:0,type:"lowpass"},_v=(n,e,t,a,i,o,s,r)=>class extends n{constructor(c,h){const d=o(c),u={...wv,...h},m=i(d,u),p=s(d),g=p?t():null;super(c,!1,m,g),this._Q=e(this,p,m.Q,Ct,Nt),this._detune=e(this,p,m.detune,1200*Math.log2(Ct),-1200*Math.log2(Ct)),this._frequency=e(this,p,m.frequency,c.sampleRate/2,0),this._gain=e(this,p,m.gain,40*Math.log10(Ct),Nt),this._nativeBiquadFilterNode=m,r(this,1)}get detune(){return this._detune}get frequency(){return this._frequency}get gain(){return this._gain}get Q(){return this._Q}get type(){return this._nativeBiquadFilterNode.type}set type(c){this._nativeBiquadFilterNode.type=c}getFrequencyResponse(c,h,d){try{this._nativeBiquadFilterNode.getFrequencyResponse(c,h,d)}catch(u){throw u.code===11?a():u}if(c.length!==h.length||h.length!==d.length)throw a()}},kv=(n,e,t,a,i)=>()=>{const o=new WeakMap,s=async(r,l)=>{let c=t(r);const h=kt(c,l);if(!h){const d={Q:c.Q.value,channelCount:c.channelCount,channelCountMode:c.channelCountMode,channelInterpretation:c.channelInterpretation,detune:c.detune.value,frequency:c.frequency.value,gain:c.gain.value,type:c.type};c=e(l,d)}return o.set(l,c),h?(await n(l,r.Q,c.Q),await n(l,r.detune,c.detune),await n(l,r.frequency,c.frequency),await n(l,r.gain,c.gain)):(await a(l,r.Q,c.Q),await a(l,r.detune,c.detune),await a(l,r.frequency,c.frequency),await a(l,r.gain,c.gain)),await i(r,l,c),c};return{render(r,l){const c=o.get(l);return c!==void 0?Promise.resolve(c):s(r,l)}}},Tv=(n,e)=>(t,a)=>{const i=e.get(t);if(i!==void 0)return i;const o=n.get(t);if(o!==void 0)return o;try{const s=a();return s instanceof Promise?(n.set(t,s),s.catch(()=>!1).then(r=>(n.delete(t),e.set(t,r),r))):(e.set(t,s),s)}catch{return e.set(t,!1),!1}},xv={channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:6},Sv=(n,e,t,a,i)=>class extends n{constructor(s,r){const l=a(s),c={...xv,...r},h=t(l,c),d=i(l)?e():null;super(s,!1,h,d)}},Av=(n,e,t)=>()=>{const a=new WeakMap,i=async(o,s)=>{let r=e(o);if(!kt(r,s)){const c={channelCount:r.channelCount,channelCountMode:r.channelCountMode,channelInterpretation:r.channelInterpretation,numberOfInputs:r.numberOfInputs};r=n(s,c)}return a.set(s,r),await t(o,s,r),r};return{render(o,s){const r=a.get(s);return r!==void 0?Promise.resolve(r):i(o,s)}}},Cv={channelCount:6,channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:6},Mv=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=a(r),h=o({...Cv,...l}),d=t(c,h),u=i(c)?e():null;super(r,!1,d,u)}},Iv=(n,e,t)=>()=>{const a=new WeakMap,i=async(o,s)=>{let r=e(o);if(!kt(r,s)){const c={channelCount:r.channelCount,channelCountMode:r.channelCountMode,channelInterpretation:r.channelInterpretation,numberOfOutputs:r.numberOfOutputs};r=n(s,c)}return a.set(s,r),await t(o,s,r),r};return{render(o,s){const r=a.get(s);return r!==void 0?Promise.resolve(r):i(o,s)}}},Ev=n=>(e,t,a)=>n(t,e,a),Dv=n=>(e,t,a=0,i=0)=>{const o=e[a];if(o===void 0)throw n();return hr(t)?o.connect(t,0,i):o.connect(t,0)},Pv=n=>(e,t)=>{const a=n(e,{buffer:null,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",loop:!1,loopEnd:0,loopStart:0,playbackRate:1}),i=e.createBuffer(1,2,44100);return a.buffer=i,a.loop=!0,a.connect(t),a.start(),()=>{a.stop(),a.disconnect(t)}},Nv={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",offset:1},Bv=(n,e,t,a,i,o,s)=>class extends n{constructor(l,c){const h=i(l),d={...Nv,...c},u=a(h,d),m=o(h),p=m?t():null;super(l,!1,u,p),this._constantSourceNodeRenderer=p,this._nativeConstantSourceNode=u,this._offset=e(this,m,u.offset,Ct,Nt),this._onended=null}get offset(){return this._offset}get onended(){return this._onended}set onended(l){const c=typeof l=="function"?s(this,l):null;this._nativeConstantSourceNode.onended=c;const h=this._nativeConstantSourceNode.onended;this._onended=h!==null&&h===c?l:h}start(l=0){if(this._nativeConstantSourceNode.start(l),this._constantSourceNodeRenderer!==null&&(this._constantSourceNodeRenderer.start=l),this.context.state!=="closed"){qi(this);const c=()=>{this._nativeConstantSourceNode.removeEventListener("ended",c),Un(this)&&ss(this)};this._nativeConstantSourceNode.addEventListener("ended",c)}}stop(l=0){this._nativeConstantSourceNode.stop(l),this._constantSourceNodeRenderer!==null&&(this._constantSourceNodeRenderer.stop=l)}},jv=(n,e,t,a,i)=>()=>{const o=new WeakMap;let s=null,r=null;const l=async(c,h)=>{let d=t(c);const u=kt(d,h);if(!u){const m={channelCount:d.channelCount,channelCountMode:d.channelCountMode,channelInterpretation:d.channelInterpretation,offset:d.offset.value};d=e(h,m),s!==null&&d.start(s),r!==null&&d.stop(r)}return o.set(h,d),u?await n(h,c.offset,d.offset):await a(h,c.offset,d.offset),await i(c,h,d),d};return{set start(c){s=c},set stop(c){r=c},render(c,h){const d=o.get(h);return d!==void 0?Promise.resolve(d):l(c,h)}}},zv=n=>e=>(n[0]=e,n[0]),Rv={buffer:null,channelCount:2,channelCountMode:"clamped-max",channelInterpretation:"speakers",disableNormalization:!1},Ov=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=a(r),h={...Rv,...l},d=t(c,h),m=i(c)?e():null;super(r,!1,d,m),this._isBufferNullified=!1,this._nativeConvolverNode=d,h.buffer!==null&&o(this,h.buffer.duration)}get buffer(){return this._isBufferNullified?null:this._nativeConvolverNode.buffer}set buffer(r){if(this._nativeConvolverNode.buffer=r,r===null&&this._nativeConvolverNode.buffer!==null){const l=this._nativeConvolverNode.context;this._nativeConvolverNode.buffer=l.createBuffer(1,1,l.sampleRate),this._isBufferNullified=!0,o(this,0)}else this._isBufferNullified=!1,o(this,this._nativeConvolverNode.buffer===null?0:this._nativeConvolverNode.buffer.duration)}get normalize(){return this._nativeConvolverNode.normalize}set normalize(r){this._nativeConvolverNode.normalize=r}},qv=(n,e,t)=>()=>{const a=new WeakMap,i=async(o,s)=>{let r=e(o);if(!kt(r,s)){const c={buffer:r.buffer,channelCount:r.channelCount,channelCountMode:r.channelCountMode,channelInterpretation:r.channelInterpretation,disableNormalization:!r.normalize};r=n(s,c)}return a.set(s,r),Vi(r)?await t(o,s,r.inputs[0]):await t(o,s,r),r};return{render(o,s){const r=a.get(s);return r!==void 0?Promise.resolve(r):i(o,s)}}},Fv=(n,e)=>(t,a,i)=>{if(e===null)throw new Error("Missing the native OfflineAudioContext constructor.");try{return new e(t,a,i)}catch(o){throw o.name==="SyntaxError"?n():o}},Lv=()=>new DOMException("","DataCloneError"),Yd=n=>{const{port1:e,port2:t}=new MessageChannel;return new Promise(a=>{const i=()=>{t.onmessage=null,e.close(),t.close(),a()};t.onmessage=()=>i();try{e.postMessage(n,[n])}catch{}finally{i()}})},Gv=(n,e,t,a,i,o,s,r,l,c,h)=>(d,u)=>{const m=s(d)?d:o(d);if(i.has(u)){const p=t();return Promise.reject(p)}try{i.add(u)}catch{}return e(l,()=>l(m))?m.decodeAudioData(u).then(p=>(Yd(u).catch(()=>{}),e(r,()=>r(p))||h(p),n.add(p),p)):new Promise((p,g)=>{const y=async()=>{try{await Yd(u)}catch{}},b=x=>{g(x),y()};try{m.decodeAudioData(u,x=>{typeof x.copyFromChannel!="function"&&(c(x),th(x)),n.add(x),y().then(()=>p(x))},x=>{b(x===null?a():x)})}catch(x){b(x)}})},$v=(n,e,t,a,i,o,s,r)=>(l,c)=>{const h=e.get(l);if(h===void 0)throw new Error("Missing the expected cycle count.");const d=o(l.context),u=r(d);if(h===c){if(e.delete(l),!u&&s(l)){const m=a(l),{outputs:p}=t(l);for(const g of p)if(ls(g)){const y=a(g[0]);n(m,y,g[1],g[2])}else{const y=i(g[0]);m.connect(y,g[1])}}}else e.set(l,h-c)},Vv={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",delayTime:0,maxDelayTime:1},Hv=(n,e,t,a,i,o,s)=>class extends n{constructor(l,c){const h=i(l),d={...Vv,...c},u=a(h,d),m=o(h),p=m?t(d.maxDelayTime):null;super(l,!1,u,p),this._delayTime=e(this,m,u.delayTime),s(this,d.maxDelayTime)}get delayTime(){return this._delayTime}},Wv=(n,e,t,a,i)=>o=>{const s=new WeakMap,r=async(l,c)=>{let h=t(l);const d=kt(h,c);if(!d){const u={channelCount:h.channelCount,channelCountMode:h.channelCountMode,channelInterpretation:h.channelInterpretation,delayTime:h.delayTime.value,maxDelayTime:o};h=e(c,u)}return s.set(c,h),d?await n(c,l.delayTime,h.delayTime):await a(c,l.delayTime,h.delayTime),await i(l,c,h),h};return{render(l,c){const h=s.get(c);return h!==void 0?Promise.resolve(h):r(l,c)}}},Uv=n=>(e,t,a,i)=>n(e[i],o=>o[0]===t&&o[1]===a),Kv=n=>(e,t)=>{n(e).delete(t)},Jv=n=>"delayTime"in n,Zv=(n,e,t)=>function a(i,o){const s=rr(o)?o:t(n,o);if(Jv(s))return[];if(i[0]===s)return[i];if(i.includes(s))return[];const{outputs:r}=e(s);return Array.from(r).map(l=>a([...i,s],l[0])).reduce((l,c)=>l.concat(c),[])},Ns=(n,e,t)=>{const a=e[t];if(a===void 0)throw n();return a},Yv=n=>(e,t=void 0,a=void 0,i=0)=>t===void 0?e.forEach(o=>o.disconnect()):typeof t=="number"?Ns(n,e,t).disconnect():hr(t)?a===void 0?e.forEach(o=>o.disconnect(t)):i===void 0?Ns(n,e,a).disconnect(t,0):Ns(n,e,a).disconnect(t,0,i):a===void 0?e.forEach(o=>o.disconnect(t)):Ns(n,e,a).disconnect(t,0),Xv={attack:.003,channelCount:2,channelCountMode:"clamped-max",channelInterpretation:"speakers",knee:30,ratio:12,release:.25,threshold:-24},Qv=(n,e,t,a,i,o,s,r)=>class extends n{constructor(c,h){const d=o(c),u={...Xv,...h},m=a(d,u),p=s(d),g=p?t():null;super(c,!1,m,g),this._attack=e(this,p,m.attack),this._knee=e(this,p,m.knee),this._nativeDynamicsCompressorNode=m,this._ratio=e(this,p,m.ratio),this._release=e(this,p,m.release),this._threshold=e(this,p,m.threshold),r(this,.006)}get attack(){return this._attack}get channelCount(){return this._nativeDynamicsCompressorNode.channelCount}set channelCount(c){const h=this._nativeDynamicsCompressorNode.channelCount;if(this._nativeDynamicsCompressorNode.channelCount=c,c>2)throw this._nativeDynamicsCompressorNode.channelCount=h,i()}get channelCountMode(){return this._nativeDynamicsCompressorNode.channelCountMode}set channelCountMode(c){const h=this._nativeDynamicsCompressorNode.channelCountMode;if(this._nativeDynamicsCompressorNode.channelCountMode=c,c==="max")throw this._nativeDynamicsCompressorNode.channelCountMode=h,i()}get knee(){return this._knee}get ratio(){return this._ratio}get reduction(){return typeof this._nativeDynamicsCompressorNode.reduction.value=="number"?this._nativeDynamicsCompressorNode.reduction.value:this._nativeDynamicsCompressorNode.reduction}get release(){return this._release}get threshold(){return this._threshold}},ew=(n,e,t,a,i)=>()=>{const o=new WeakMap,s=async(r,l)=>{let c=t(r);const h=kt(c,l);if(!h){const d={attack:c.attack.value,channelCount:c.channelCount,channelCountMode:c.channelCountMode,channelInterpretation:c.channelInterpretation,knee:c.knee.value,ratio:c.ratio.value,release:c.release.value,threshold:c.threshold.value};c=e(l,d)}return o.set(l,c),h?(await n(l,r.attack,c.attack),await n(l,r.knee,c.knee),await n(l,r.ratio,c.ratio),await n(l,r.release,c.release),await n(l,r.threshold,c.threshold)):(await a(l,r.attack,c.attack),await a(l,r.knee,c.knee),await a(l,r.ratio,c.ratio),await a(l,r.release,c.release),await a(l,r.threshold,c.threshold)),await i(r,l,c),c};return{render(r,l){const c=o.get(l);return c!==void 0?Promise.resolve(c):s(r,l)}}},tw=()=>new DOMException("","EncodingError"),nw=n=>e=>new Promise((t,a)=>{if(n===null){a(new SyntaxError);return}const i=n.document.head;if(i===null)a(new SyntaxError);else{const o=n.document.createElement("script"),s=new Blob([e],{type:"application/javascript"}),r=URL.createObjectURL(s),l=n.onerror,c=()=>{n.onerror=l,URL.revokeObjectURL(r)};n.onerror=(h,d,u,m,p)=>{if(d===r||d===n.location.href&&u===1&&m===1)return c(),a(p),!1;if(l!==null)return l(h,d,u,m,p)},o.onerror=()=>{c(),a(new SyntaxError)},o.onload=()=>{c(),t()},o.src=r,o.type="module",i.appendChild(o)}}),aw=n=>class{constructor(t){this._nativeEventTarget=t,this._listeners=new WeakMap}addEventListener(t,a,i){if(a!==null){let o=this._listeners.get(a);o===void 0&&(o=n(this,a),typeof a=="function"&&this._listeners.set(a,o)),this._nativeEventTarget.addEventListener(t,o,i)}}dispatchEvent(t){return this._nativeEventTarget.dispatchEvent(t)}removeEventListener(t,a,i){const o=a===null?void 0:this._listeners.get(a);this._nativeEventTarget.removeEventListener(t,o===void 0?null:o,i)}},iw=n=>(e,t,a)=>{Object.defineProperties(n,{currentFrame:{configurable:!0,get(){return Math.round(e*t)}},currentTime:{configurable:!0,get(){return e}}});try{return a()}finally{n!==null&&(delete n.currentFrame,delete n.currentTime)}},ow=n=>async e=>{try{const t=await fetch(e);if(t.ok)return[await t.text(),t.url]}catch{}throw n()},sw={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",gain:1},rw=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=i(r),h={...sw,...l},d=a(c,h),u=o(c),m=u?t():null;super(r,!1,d,m),this._gain=e(this,u,d.gain,Ct,Nt)}get gain(){return this._gain}},lw=(n,e,t,a,i)=>()=>{const o=new WeakMap,s=async(r,l)=>{let c=t(r);const h=kt(c,l);if(!h){const d={channelCount:c.channelCount,channelCountMode:c.channelCountMode,channelInterpretation:c.channelInterpretation,gain:c.gain.value};c=e(l,d)}return o.set(l,c),h?await n(l,r.gain,c.gain):await a(l,r.gain,c.gain),await i(r,l,c),c};return{render(r,l){const c=o.get(l);return c!==void 0?Promise.resolve(c):s(r,l)}}},cw=(n,e)=>t=>e(n,t),hw=n=>e=>{const t=n(e);if(t.renderer===null)throw new Error("Missing the renderer of the given AudioNode in the audio graph.");return t.renderer},dw=n=>e=>{var t;return(t=n.get(e))!==null&&t!==void 0?t:0},uw=n=>e=>{const t=n(e);if(t.renderer===null)throw new Error("Missing the renderer of the given AudioParam in the audio graph.");return t.renderer},mw=n=>e=>n.get(e),lt=()=>new DOMException("","InvalidStateError"),pw=n=>e=>{const t=n.get(e);if(t===void 0)throw lt();return t},fw=(n,e)=>t=>{let a=n.get(t);if(a!==void 0)return a;if(e===null)throw new Error("Missing the native OfflineAudioContext constructor.");return a=new e(1,1,44100),n.set(t,a),a},gw=n=>e=>{const t=n.get(e);if(t===void 0)throw new Error("The context has no set of AudioWorkletNodes.");return t},Vr=()=>new DOMException("","InvalidAccessError"),yw=n=>{n.getFrequencyResponse=(e=>(t,a,i)=>{if(t.length!==a.length||a.length!==i.length)throw Vr();return e.call(n,t,a,i)})(n.getFrequencyResponse)},bw={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers"},vw=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=a(r),h=i(c),d={...bw,...l},u=e(c,h?null:r.baseLatency,d),m=h?t(d.feedback,d.feedforward):null;super(r,!1,u,m),yw(u),this._nativeIIRFilterNode=u,o(this,1)}getFrequencyResponse(r,l,c){return this._nativeIIRFilterNode.getFrequencyResponse(r,l,c)}},hp=(n,e,t,a,i,o,s,r,l,c,h)=>{const d=c.length;let u=r;for(let m=0;m<d;m+=1){let p=t[0]*c[m];for(let g=1;g<i;g+=1){const y=u-g&l-1;p+=t[g]*o[y],p-=n[g]*s[y]}for(let g=i;g<a;g+=1)p+=t[g]*o[u-g&l-1];for(let g=i;g<e;g+=1)p-=n[g]*s[u-g&l-1];o[u]=c[m],s[u]=p,u=u+1&l-1,h[m]=p}return u},ww=(n,e,t,a)=>{const i=t instanceof Float64Array?t:new Float64Array(t),o=a instanceof Float64Array?a:new Float64Array(a),s=i.length,r=o.length,l=Math.min(s,r);if(i[0]!==1){for(let p=0;p<s;p+=1)o[p]/=i[0];for(let p=1;p<r;p+=1)i[p]/=i[0]}const c=32,h=new Float32Array(c),d=new Float32Array(c),u=e.createBuffer(n.numberOfChannels,n.length,n.sampleRate),m=n.numberOfChannels;for(let p=0;p<m;p+=1){const g=n.getChannelData(p),y=u.getChannelData(p);h.fill(0),d.fill(0),hp(i,s,o,r,l,h,d,0,c,g,y)}return u},_w=(n,e,t,a,i)=>(o,s)=>{const r=new WeakMap;let l=null;const c=async(h,d)=>{let u=null,m=e(h);const p=kt(m,d);if(d.createIIRFilter===void 0?u=n(d,{buffer:null,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",loop:!1,loopEnd:0,loopStart:0,playbackRate:1}):p||(m=d.createIIRFilter(s,o)),r.set(d,u===null?m:u),u!==null){if(l===null){if(t===null)throw new Error("Missing the native OfflineAudioContext constructor.");const y=new t(h.context.destination.channelCount,h.context.length,d.sampleRate);l=(async()=>{await a(h,y,y.destination);const b=await i(y);return ww(b,d,o,s)})()}const g=await l;return u.buffer=g,u.start(0),u}return await a(h,d,m),m};return{render(h,d){const u=r.get(d);return u!==void 0?Promise.resolve(u):c(h,d)}}},kw=(n,e,t,a,i,o)=>s=>(r,l)=>{const c=n.get(r);if(c===void 0){if(!s&&o(r)){const h=a(r),{outputs:d}=t(r);for(const u of d)if(ls(u)){const m=a(u[0]);e(h,m,u[1],u[2])}else{const m=i(u[0]);h.disconnect(m,u[1])}}n.set(r,l)}else n.set(r,c+l)},Tw=(n,e)=>t=>{const a=n.get(t);return e(a)||e(t)},xw=(n,e)=>t=>n.has(t)||e(t),Sw=(n,e)=>t=>n.has(t)||e(t),Aw=(n,e)=>t=>{const a=n.get(t);return e(a)||e(t)},Cw=n=>e=>n!==null&&e instanceof n,Mw=n=>e=>n!==null&&typeof n.AudioNode=="function"&&e instanceof n.AudioNode,Iw=n=>e=>n!==null&&typeof n.AudioParam=="function"&&e instanceof n.AudioParam,Ew=(n,e)=>t=>n(t)||e(t),Dw=n=>e=>n!==null&&e instanceof n,Pw=n=>n!==null&&n.isSecureContext,Nw=(n,e,t,a)=>class extends n{constructor(o,s){const r=t(o),l=e(r,s);if(a(r))throw TypeError();super(o,!0,l,null),this._nativeMediaElementAudioSourceNode=l}get mediaElement(){return this._nativeMediaElementAudioSourceNode.mediaElement}},Bw={channelCount:2,channelCountMode:"explicit",channelInterpretation:"speakers"},jw=(n,e,t,a)=>class extends n{constructor(o,s){const r=t(o);if(a(r))throw new TypeError;const l={...Bw,...s},c=e(r,l);super(o,!1,c,null),this._nativeMediaStreamAudioDestinationNode=c}get stream(){return this._nativeMediaStreamAudioDestinationNode.stream}},zw=(n,e,t,a)=>class extends n{constructor(o,s){const r=t(o),l=e(r,s);if(a(r))throw new TypeError;super(o,!0,l,null),this._nativeMediaStreamAudioSourceNode=l}get mediaStream(){return this._nativeMediaStreamAudioSourceNode.mediaStream}},Rw=(n,e,t)=>class extends n{constructor(i,o){const s=t(i),r=e(s,o);super(i,!0,r,null)}},Ow=(n,e,t,a,i,o)=>class extends t{constructor(r,l){super(r),this._nativeContext=r,Gr.set(this,r),a(r)&&i.set(r,new Set),this._destination=new n(this,l),this._listener=e(this,r),this._onstatechange=null}get currentTime(){return this._nativeContext.currentTime}get destination(){return this._destination}get listener(){return this._listener}get onstatechange(){return this._onstatechange}set onstatechange(r){const l=typeof r=="function"?o(this,r):null;this._nativeContext.onstatechange=l;const c=this._nativeContext.onstatechange;this._onstatechange=c!==null&&c===l?r:c}get sampleRate(){return this._nativeContext.sampleRate}get state(){return this._nativeContext.state}},Fo=n=>{const e=new Uint32Array([1179011410,40,1163280727,544501094,16,131073,44100,176400,1048580,1635017060,4,0]);try{const t=n.decodeAudioData(e.buffer,()=>{});return t===void 0?!1:(t.catch(()=>{}),!0)}catch{}return!1},qw=(n,e)=>(t,a,i)=>{const o=new Set;return t.connect=(s=>(r,l=0,c=0)=>{const h=o.size===0;if(e(r))return s.call(t,r,l,c),n(o,[r,l,c],d=>d[0]===r&&d[1]===l&&d[2]===c,!0),h&&a(),r;s.call(t,r,l),n(o,[r,l],d=>d[0]===r&&d[1]===l,!0),h&&a()})(t.connect),t.disconnect=(s=>(r,l,c)=>{const h=o.size>0;if(r===void 0)s.apply(t),o.clear();else if(typeof r=="number"){s.call(t,r);for(const u of o)u[1]===r&&o.delete(u)}else{e(r)?s.call(t,r,l,c):s.call(t,r,l);for(const u of o)u[0]===r&&(l===void 0||u[1]===l)&&(c===void 0||u[2]===c)&&o.delete(u)}const d=o.size===0;h&&d&&i()})(t.disconnect),t},je=(n,e,t)=>{const a=e[t];a!==void 0&&a!==n[t]&&(n[t]=a)},nt=(n,e)=>{je(n,e,"channelCount"),je(n,e,"channelCountMode"),je(n,e,"channelInterpretation")},Xd=n=>typeof n.getFloatTimeDomainData=="function",Fw=n=>{n.getFloatTimeDomainData=e=>{const t=new Uint8Array(e.length);n.getByteTimeDomainData(t);const a=Math.max(t.length,n.fftSize);for(let i=0;i<a;i+=1)e[i]=(t[i]-128)*.0078125;return e}},Lw=(n,e)=>(t,a)=>{const i=t.createAnalyser();if(nt(i,a),!(a.maxDecibels>a.minDecibels))throw e();return je(i,a,"fftSize"),je(i,a,"maxDecibels"),je(i,a,"minDecibels"),je(i,a,"smoothingTimeConstant"),n(Xd,()=>Xd(i))||Fw(i),i},Gw=n=>n===null?null:n.hasOwnProperty("AudioBuffer")?n.AudioBuffer:null,He=(n,e,t)=>{const a=e[t];a!==void 0&&a!==n[t].value&&(n[t].value=a)},$w=n=>{n.start=(e=>{let t=!1;return(a=0,i=0,o)=>{if(t)throw lt();e.call(n,a,i,o),t=!0}})(n.start)},ih=n=>{n.start=(e=>(t=0,a=0,i)=>{if(typeof i=="number"&&i<0||a<0||t<0)throw new RangeError("The parameters can't be negative.");e.call(n,t,a,i)})(n.start)},oh=n=>{n.stop=(e=>(t=0)=>{if(t<0)throw new RangeError("The parameter can't be negative.");e.call(n,t)})(n.stop)},Vw=(n,e,t,a,i,o,s,r,l,c,h)=>(d,u)=>{const m=d.createBufferSource();return nt(m,u),He(m,u,"playbackRate"),je(m,u,"buffer"),je(m,u,"loop"),je(m,u,"loopEnd"),je(m,u,"loopStart"),e(t,()=>t(d))||$w(m),e(a,()=>a(d))||l(m),e(i,()=>i(d))||c(m,d),e(o,()=>o(d))||ih(m),e(s,()=>s(d))||h(m,d),e(r,()=>r(d))||oh(m),n(d,m),m},Hw=n=>n===null?null:n.hasOwnProperty("AudioContext")?n.AudioContext:n.hasOwnProperty("webkitAudioContext")?n.webkitAudioContext:null,Ww=(n,e)=>(t,a,i)=>{const o=t.destination;if(o.channelCount!==a)try{o.channelCount=a}catch{}i&&o.channelCountMode!=="explicit"&&(o.channelCountMode="explicit"),o.maxChannelCount===0&&Object.defineProperty(o,"maxChannelCount",{value:a});const s=n(t,{channelCount:a,channelCountMode:o.channelCountMode,channelInterpretation:o.channelInterpretation,gain:1});return e(s,"channelCount",r=>()=>r.call(s),r=>l=>{r.call(s,l);try{o.channelCount=l}catch(c){if(l>o.maxChannelCount)throw c}}),e(s,"channelCountMode",r=>()=>r.call(s),r=>l=>{r.call(s,l),o.channelCountMode=l}),e(s,"channelInterpretation",r=>()=>r.call(s),r=>l=>{r.call(s,l),o.channelInterpretation=l}),Object.defineProperty(s,"maxChannelCount",{get:()=>o.maxChannelCount}),s.connect(o),s},Uw=n=>n===null?null:n.hasOwnProperty("AudioWorkletNode")?n.AudioWorkletNode:null,Kw=n=>{const{port1:e}=new MessageChannel;try{e.postMessage(n)}finally{e.close()}},Jw=(n,e,t,a,i)=>(o,s,r,l,c,h)=>{if(r!==null)try{const d=new r(o,l,h),u=new Map;let m=null;if(Object.defineProperties(d,{channelCount:{get:()=>h.channelCount,set:()=>{throw n()}},channelCountMode:{get:()=>"explicit",set:()=>{throw n()}},onprocessorerror:{get:()=>m,set:p=>{typeof m=="function"&&d.removeEventListener("processorerror",m),m=typeof p=="function"?p:null,typeof m=="function"&&d.addEventListener("processorerror",m)}}}),d.addEventListener=(p=>(...g)=>{if(g[0]==="processorerror"){const y=typeof g[1]=="function"?g[1]:typeof g[1]=="object"&&g[1]!==null&&typeof g[1].handleEvent=="function"?g[1].handleEvent:null;if(y!==null){const b=u.get(g[1]);b!==void 0?g[1]=b:(g[1]=x=>{x.type==="error"?(Object.defineProperties(x,{type:{value:"processorerror"}}),y(x)):y(new ErrorEvent(g[0],{...x}))},u.set(y,g[1]))}}return p.call(d,"error",g[1],g[2]),p.call(d,...g)})(d.addEventListener),d.removeEventListener=(p=>(...g)=>{if(g[0]==="processorerror"){const y=u.get(g[1]);y!==void 0&&(u.delete(g[1]),g[1]=y)}return p.call(d,"error",g[1],g[2]),p.call(d,g[0],g[1],g[2])})(d.removeEventListener),h.numberOfOutputs!==0){const p=t(o,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:0});return d.connect(p).connect(o.destination),i(d,()=>p.disconnect(),()=>p.connect(o.destination))}return d}catch(d){throw d.code===11?a():d}if(c===void 0)throw a();return Kw(h),e(o,s,c,h)},dp=(n,e)=>n===null?512:Math.max(512,Math.min(16384,Math.pow(2,Math.round(Math.log2(n*e))))),Zw=n=>new Promise((e,t)=>{const{port1:a,port2:i}=new MessageChannel;a.onmessage=({data:o})=>{a.close(),i.close(),e(o)},a.onmessageerror=({data:o})=>{a.close(),i.close(),t(o)},i.postMessage(n)}),Yw=async(n,e)=>{const t=await Zw(e);return new n(t)},Xw=(n,e,t,a)=>{let i=bc.get(n);i===void 0&&(i=new WeakMap,bc.set(n,i));const o=Yw(t,a);return i.set(e,o),o},Qw=(n,e,t,a,i,o,s,r,l,c,h,d,u)=>(m,p,g,y)=>{if(y.numberOfInputs===0&&y.numberOfOutputs===0)throw l();const b=Array.isArray(y.outputChannelCount)?y.outputChannelCount:Array.from(y.outputChannelCount);if(b.some(Z=>Z<1))throw l();if(b.length!==y.numberOfOutputs)throw e();if(y.channelCountMode!=="explicit")throw l();const x=y.channelCount*y.numberOfInputs,S=b.reduce((Z,ce)=>Z+ce,0),k=g.parameterDescriptors===void 0?0:g.parameterDescriptors.length;if(x+k>6||S>6)throw l();const w=new MessageChannel,C=[],M=[];for(let Z=0;Z<y.numberOfInputs;Z+=1)C.push(s(m,{channelCount:y.channelCount,channelCountMode:y.channelCountMode,channelInterpretation:y.channelInterpretation,gain:1})),M.push(i(m,{channelCount:y.channelCount,channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:y.channelCount}));const A=[];if(g.parameterDescriptors!==void 0)for(const{defaultValue:Z,maxValue:ce,minValue:Xe,name:ze}of g.parameterDescriptors){const xe=o(m,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",offset:y.parameterData[ze]!==void 0?y.parameterData[ze]:Z===void 0?0:Z});Object.defineProperties(xe.offset,{defaultValue:{get:()=>Z===void 0?0:Z},maxValue:{get:()=>ce===void 0?Ct:ce},minValue:{get:()=>Xe===void 0?Nt:Xe}}),A.push(xe)}const I=a(m,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:Math.max(1,x+k)}),D=dp(p,m.sampleRate),P=r(m,D,x+k,Math.max(1,S)),E=i(m,{channelCount:Math.max(1,S),channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:Math.max(1,S)}),O=[];for(let Z=0;Z<y.numberOfOutputs;Z+=1)O.push(a(m,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:b[Z]}));for(let Z=0;Z<y.numberOfInputs;Z+=1){C[Z].connect(M[Z]);for(let ce=0;ce<y.channelCount;ce+=1)M[Z].connect(I,ce,Z*y.channelCount+ce)}const j=new lp(g.parameterDescriptors===void 0?[]:g.parameterDescriptors.map(({name:Z},ce)=>{const Xe=A[ce];return Xe.connect(I,0,x+ce),Xe.start(0),[Z,Xe.offset]}));I.connect(P);let W=y.channelInterpretation,L=null;const z=y.numberOfOutputs===0?[P]:O,Y={get bufferSize(){return D},get channelCount(){return y.channelCount},set channelCount(Z){throw t()},get channelCountMode(){return y.channelCountMode},set channelCountMode(Z){throw t()},get channelInterpretation(){return W},set channelInterpretation(Z){for(const ce of C)ce.channelInterpretation=Z;W=Z},get context(){return P.context},get inputs(){return C},get numberOfInputs(){return y.numberOfInputs},get numberOfOutputs(){return y.numberOfOutputs},get onprocessorerror(){return L},set onprocessorerror(Z){typeof L=="function"&&Y.removeEventListener("processorerror",L),L=typeof Z=="function"?Z:null,typeof L=="function"&&Y.addEventListener("processorerror",L)},get parameters(){return j},get port(){return w.port2},addEventListener(...Z){return P.addEventListener(Z[0],Z[1],Z[2])},connect:n.bind(null,z),disconnect:c.bind(null,z),dispatchEvent(...Z){return P.dispatchEvent(Z[0])},removeEventListener(...Z){return P.removeEventListener(Z[0],Z[1],Z[2])}},V=new Map;w.port1.addEventListener=(Z=>(...ce)=>{if(ce[0]==="message"){const Xe=typeof ce[1]=="function"?ce[1]:typeof ce[1]=="object"&&ce[1]!==null&&typeof ce[1].handleEvent=="function"?ce[1].handleEvent:null;if(Xe!==null){const ze=V.get(ce[1]);ze!==void 0?ce[1]=ze:(ce[1]=xe=>{h(m.currentTime,m.sampleRate,()=>Xe(xe))},V.set(Xe,ce[1]))}}return Z.call(w.port1,ce[0],ce[1],ce[2])})(w.port1.addEventListener),w.port1.removeEventListener=(Z=>(...ce)=>{if(ce[0]==="message"){const Xe=V.get(ce[1]);Xe!==void 0&&(V.delete(ce[1]),ce[1]=Xe)}return Z.call(w.port1,ce[0],ce[1],ce[2])})(w.port1.removeEventListener);let J=null;Object.defineProperty(w.port1,"onmessage",{get:()=>J,set:Z=>{typeof J=="function"&&w.port1.removeEventListener("message",J),J=typeof Z=="function"?Z:null,typeof J=="function"&&(w.port1.addEventListener("message",J),w.port1.start())}}),g.prototype.port=w.port1;let ie=null;Xw(m,Y,g,y).then(Z=>ie=Z);const ot=ur(y.numberOfInputs,y.channelCount),Ee=ur(y.numberOfOutputs,b),le=g.parameterDescriptors===void 0?[]:g.parameterDescriptors.reduce((Z,{name:ce})=>({...Z,[ce]:new Float32Array(128)}),{});let Te=!0;const Je=()=>{y.numberOfOutputs>0&&P.disconnect(E);for(let Z=0,ce=0;Z<y.numberOfOutputs;Z+=1){const Xe=O[Z];for(let ze=0;ze<b[Z];ze+=1)E.disconnect(Xe,ce+ze,ze);ce+=b[Z]}},te=new Map;P.onaudioprocess=({inputBuffer:Z,outputBuffer:ce})=>{if(ie!==null){const Xe=d(Y);for(let ze=0;ze<D;ze+=128){for(let xe=0;xe<y.numberOfInputs;xe+=1)for(let Le=0;Le<y.channelCount;Le+=1)dr(Z,ot[xe],Le,Le,ze);g.parameterDescriptors!==void 0&&g.parameterDescriptors.forEach(({name:xe},Le)=>{dr(Z,le,xe,x+Le,ze)});for(let xe=0;xe<y.numberOfInputs;xe+=1)for(let Le=0;Le<b[xe];Le+=1)Ee[xe][Le].byteLength===0&&(Ee[xe][Le]=new Float32Array(128));try{const xe=ot.map(($t,aa)=>{if(Xe[aa].size>0)return te.set(aa,D/128),$t;const ql=te.get(aa);return ql===void 0?[]:($t.every(Uy=>Uy.every(Ky=>Ky===0))&&(ql===1?te.delete(aa):te.set(aa,ql-1)),$t)});Te=h(m.currentTime+ze/m.sampleRate,m.sampleRate,()=>ie.process(xe,Ee,le));for(let $t=0,aa=0;$t<y.numberOfOutputs;$t+=1){for(let co=0;co<b[$t];co+=1)cp(ce,Ee[$t],co,aa+co,ze);aa+=b[$t]}}catch(xe){Te=!1,Y.dispatchEvent(new ErrorEvent("processorerror",{colno:xe.colno,filename:xe.filename,lineno:xe.lineno,message:xe.message}))}if(!Te){for(let xe=0;xe<y.numberOfInputs;xe+=1){C[xe].disconnect(M[xe]);for(let Le=0;Le<y.channelCount;Le+=1)M[ze].disconnect(I,Le,xe*y.channelCount+Le)}if(g.parameterDescriptors!==void 0){const xe=g.parameterDescriptors.length;for(let Le=0;Le<xe;Le+=1){const $t=A[Le];$t.disconnect(I,0,x+Le),$t.stop()}}I.disconnect(P),P.onaudioprocess=null,Ot?Je():tn();break}}}};let Ot=!1;const dt=s(m,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:0}),kn=()=>P.connect(dt).connect(m.destination),tn=()=>{P.disconnect(dt),dt.disconnect()},Hy=()=>{if(Te){tn(),y.numberOfOutputs>0&&P.connect(E);for(let Z=0,ce=0;Z<y.numberOfOutputs;Z+=1){const Xe=O[Z];for(let ze=0;ze<b[Z];ze+=1)E.connect(Xe,ce+ze,ze);ce+=b[Z]}}Ot=!0},Wy=()=>{Te&&(kn(),Je()),Ot=!1};return kn(),u(Y,Hy,Wy)},up=(n,e)=>{const t=n.createBiquadFilter();return nt(t,e),He(t,e,"Q"),He(t,e,"detune"),He(t,e,"frequency"),He(t,e,"gain"),je(t,e,"type"),t},e0=(n,e)=>(t,a)=>{const i=t.createChannelMerger(a.numberOfInputs);return n!==null&&n.name==="webkitAudioContext"&&e(t,i),nt(i,a),i},t0=n=>{const e=n.numberOfOutputs;Object.defineProperty(n,"channelCount",{get:()=>e,set:t=>{if(t!==e)throw lt()}}),Object.defineProperty(n,"channelCountMode",{get:()=>"explicit",set:t=>{if(t!=="explicit")throw lt()}}),Object.defineProperty(n,"channelInterpretation",{get:()=>"discrete",set:t=>{if(t!=="discrete")throw lt()}})},cs=(n,e)=>{const t=n.createChannelSplitter(e.numberOfOutputs);return nt(t,e),t0(t),t},n0=(n,e,t,a,i)=>(o,s)=>{if(o.createConstantSource===void 0)return t(o,s);const r=o.createConstantSource();return nt(r,s),He(r,s,"offset"),e(a,()=>a(o))||ih(r),e(i,()=>i(o))||oh(r),n(o,r),r},Hi=(n,e)=>(n.connect=e.connect.bind(e),n.disconnect=e.disconnect.bind(e),n),a0=(n,e,t,a)=>(i,{offset:o,...s})=>{const r=i.createBuffer(1,2,44100),l=e(i,{buffer:null,channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",loop:!1,loopEnd:0,loopStart:0,playbackRate:1}),c=t(i,{...s,gain:o}),h=r.getChannelData(0);h[0]=1,h[1]=1,l.buffer=r,l.loop=!0;const d={get bufferSize(){},get channelCount(){return c.channelCount},set channelCount(p){c.channelCount=p},get channelCountMode(){return c.channelCountMode},set channelCountMode(p){c.channelCountMode=p},get channelInterpretation(){return c.channelInterpretation},set channelInterpretation(p){c.channelInterpretation=p},get context(){return c.context},get inputs(){return[]},get numberOfInputs(){return l.numberOfInputs},get numberOfOutputs(){return c.numberOfOutputs},get offset(){return c.gain},get onended(){return l.onended},set onended(p){l.onended=p},addEventListener(...p){return l.addEventListener(p[0],p[1],p[2])},dispatchEvent(...p){return l.dispatchEvent(p[0])},removeEventListener(...p){return l.removeEventListener(p[0],p[1],p[2])},start(p=0){l.start.call(l,p)},stop(p=0){l.stop.call(l,p)}},u=()=>l.connect(c),m=()=>l.disconnect(c);return n(i,l),a(Hi(d,c),u,m)},i0=(n,e)=>(t,a)=>{const i=t.createConvolver();if(nt(i,a),a.disableNormalization===i.normalize&&(i.normalize=!a.disableNormalization),je(i,a,"buffer"),a.channelCount>2||(e(i,"channelCount",o=>()=>o.call(i),o=>s=>{if(s>2)throw n();return o.call(i,s)}),a.channelCountMode==="max"))throw n();return e(i,"channelCountMode",o=>()=>o.call(i),o=>s=>{if(s==="max")throw n();return o.call(i,s)}),i},mp=(n,e)=>{const t=n.createDelay(e.maxDelayTime);return nt(t,e),He(t,e,"delayTime"),t},o0=n=>(e,t)=>{const a=e.createDynamicsCompressor();if(nt(a,t),t.channelCount>2||t.channelCountMode==="max")throw n();return He(a,t,"attack"),He(a,t,"knee"),He(a,t,"ratio"),He(a,t,"release"),He(a,t,"threshold"),a},zt=(n,e)=>{const t=n.createGain();return nt(t,e),He(t,e,"gain"),t},s0=n=>(e,t,a)=>{if(e.createIIRFilter===void 0)return n(e,t,a);const i=e.createIIRFilter(a.feedforward,a.feedback);return nt(i,a),i};function r0(n,e){const t=e[0]*e[0]+e[1]*e[1];return[(n[0]*e[0]+n[1]*e[1])/t,(n[1]*e[0]-n[0]*e[1])/t]}function l0(n,e){return[n[0]*e[0]-n[1]*e[1],n[0]*e[1]+n[1]*e[0]]}function Qd(n,e){let t=[0,0];for(let a=n.length-1;a>=0;a-=1)t=l0(t,e),t[0]+=n[a];return t}const c0=(n,e,t,a)=>(i,o,{channelCount:s,channelCountMode:r,channelInterpretation:l,feedback:c,feedforward:h})=>{const d=dp(o,i.sampleRate),u=c instanceof Float64Array?c:new Float64Array(c),m=h instanceof Float64Array?h:new Float64Array(h),p=u.length,g=m.length,y=Math.min(p,g);if(p===0||p>20)throw a();if(u[0]===0)throw e();if(g===0||g>20)throw a();if(m[0]===0)throw e();if(u[0]!==1){for(let A=0;A<g;A+=1)m[A]/=u[0];for(let A=1;A<p;A+=1)u[A]/=u[0]}const b=t(i,d,s,s);b.channelCount=s,b.channelCountMode=r,b.channelInterpretation=l;const x=32,S=[],k=[],w=[];for(let A=0;A<s;A+=1){S.push(0);const I=new Float32Array(x),D=new Float32Array(x);I.fill(0),D.fill(0),k.push(I),w.push(D)}b.onaudioprocess=A=>{const I=A.inputBuffer,D=A.outputBuffer,P=I.numberOfChannels;for(let E=0;E<P;E+=1){const O=I.getChannelData(E),j=D.getChannelData(E);S[E]=hp(u,p,m,g,y,k[E],w[E],S[E],x,O,j)}};const C=i.sampleRate/2;return Hi({get bufferSize(){return d},get channelCount(){return b.channelCount},set channelCount(A){b.channelCount=A},get channelCountMode(){return b.channelCountMode},set channelCountMode(A){b.channelCountMode=A},get channelInterpretation(){return b.channelInterpretation},set channelInterpretation(A){b.channelInterpretation=A},get context(){return b.context},get inputs(){return[b]},get numberOfInputs(){return b.numberOfInputs},get numberOfOutputs(){return b.numberOfOutputs},addEventListener(...A){return b.addEventListener(A[0],A[1],A[2])},dispatchEvent(...A){return b.dispatchEvent(A[0])},getFrequencyResponse(A,I,D){if(A.length!==I.length||I.length!==D.length)throw n();const P=A.length;for(let E=0;E<P;E+=1){const O=-Math.PI*(A[E]/C),j=[Math.cos(O),Math.sin(O)],W=Qd(m,j),L=Qd(u,j),z=r0(W,L);I[E]=Math.sqrt(z[0]*z[0]+z[1]*z[1]),D[E]=Math.atan2(z[1],z[0])}},removeEventListener(...A){return b.removeEventListener(A[0],A[1],A[2])}},b)},h0=(n,e)=>n.createMediaElementSource(e.mediaElement),d0=(n,e)=>{const t=n.createMediaStreamDestination();return nt(t,e),t.numberOfOutputs===1&&Object.defineProperty(t,"numberOfOutputs",{get:()=>0}),t},u0=(n,{mediaStream:e})=>{const t=e.getAudioTracks();t.sort((o,s)=>o.id<s.id?-1:o.id>s.id?1:0);const a=t.slice(0,1),i=n.createMediaStreamSource(new MediaStream(a));return Object.defineProperty(i,"mediaStream",{value:e}),i},m0=(n,e)=>(t,{mediaStreamTrack:a})=>{if(typeof t.createMediaStreamTrackSource=="function")return t.createMediaStreamTrackSource(a);const i=new MediaStream([a]),o=t.createMediaStreamSource(i);if(a.kind!=="audio")throw n();if(e(t))throw new TypeError;return o},p0=n=>n===null?null:n.hasOwnProperty("OfflineAudioContext")?n.OfflineAudioContext:n.hasOwnProperty("webkitOfflineAudioContext")?n.webkitOfflineAudioContext:null,f0=(n,e,t,a,i,o)=>(s,r)=>{const l=s.createOscillator();return nt(l,r),He(l,r,"detune"),He(l,r,"frequency"),r.periodicWave!==void 0?l.setPeriodicWave(r.periodicWave):je(l,r,"type"),e(t,()=>t(s))||ih(l),e(a,()=>a(s))||o(l,s),e(i,()=>i(s))||oh(l),n(s,l),l},g0=n=>(e,t)=>{const a=e.createPanner();return a.orientationX===void 0?n(e,t):(nt(a,t),He(a,t,"orientationX"),He(a,t,"orientationY"),He(a,t,"orientationZ"),He(a,t,"positionX"),He(a,t,"positionY"),He(a,t,"positionZ"),je(a,t,"coneInnerAngle"),je(a,t,"coneOuterAngle"),je(a,t,"coneOuterGain"),je(a,t,"distanceModel"),je(a,t,"maxDistance"),je(a,t,"panningModel"),je(a,t,"refDistance"),je(a,t,"rolloffFactor"),a)},y0=(n,e,t,a,i,o,s,r,l,c)=>(h,{coneInnerAngle:d,coneOuterAngle:u,coneOuterGain:m,distanceModel:p,maxDistance:g,orientationX:y,orientationY:b,orientationZ:x,panningModel:S,positionX:k,positionY:w,positionZ:C,refDistance:M,rolloffFactor:A,...I})=>{const D=h.createPanner();if(I.channelCount>2||I.channelCountMode==="max")throw s();nt(D,I);const P={channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete"},E=t(h,{...P,channelInterpretation:"speakers",numberOfInputs:6}),O=a(h,{...I,gain:1}),j=a(h,{...P,gain:1}),W=a(h,{...P,gain:0}),L=a(h,{...P,gain:0}),z=a(h,{...P,gain:0}),Y=a(h,{...P,gain:0}),V=a(h,{...P,gain:0}),J=i(h,256,6,1),ie=o(h,{...P,curve:new Float32Array([1,1]),oversample:"none"});let ge=[y,b,x],ot=[k,w,C];const Ee=new Float32Array(1);J.onaudioprocess=({inputBuffer:te})=>{const Ot=[l(te,Ee,0),l(te,Ee,1),l(te,Ee,2)];Ot.some((kn,tn)=>kn!==ge[tn])&&(D.setOrientation(...Ot),ge=Ot);const dt=[l(te,Ee,3),l(te,Ee,4),l(te,Ee,5)];dt.some((kn,tn)=>kn!==ot[tn])&&(D.setPosition(...dt),ot=dt)},Object.defineProperty(W.gain,"defaultValue",{get:()=>0}),Object.defineProperty(L.gain,"defaultValue",{get:()=>0}),Object.defineProperty(z.gain,"defaultValue",{get:()=>0}),Object.defineProperty(Y.gain,"defaultValue",{get:()=>0}),Object.defineProperty(V.gain,"defaultValue",{get:()=>0});const le={get bufferSize(){},get channelCount(){return D.channelCount},set channelCount(te){if(te>2)throw s();O.channelCount=te,D.channelCount=te},get channelCountMode(){return D.channelCountMode},set channelCountMode(te){if(te==="max")throw s();O.channelCountMode=te,D.channelCountMode=te},get channelInterpretation(){return D.channelInterpretation},set channelInterpretation(te){O.channelInterpretation=te,D.channelInterpretation=te},get coneInnerAngle(){return D.coneInnerAngle},set coneInnerAngle(te){D.coneInnerAngle=te},get coneOuterAngle(){return D.coneOuterAngle},set coneOuterAngle(te){D.coneOuterAngle=te},get coneOuterGain(){return D.coneOuterGain},set coneOuterGain(te){if(te<0||te>1)throw e();D.coneOuterGain=te},get context(){return D.context},get distanceModel(){return D.distanceModel},set distanceModel(te){D.distanceModel=te},get inputs(){return[O]},get maxDistance(){return D.maxDistance},set maxDistance(te){if(te<0)throw new RangeError;D.maxDistance=te},get numberOfInputs(){return D.numberOfInputs},get numberOfOutputs(){return D.numberOfOutputs},get orientationX(){return j.gain},get orientationY(){return W.gain},get orientationZ(){return L.gain},get panningModel(){return D.panningModel},set panningModel(te){D.panningModel=te},get positionX(){return z.gain},get positionY(){return Y.gain},get positionZ(){return V.gain},get refDistance(){return D.refDistance},set refDistance(te){if(te<0)throw new RangeError;D.refDistance=te},get rolloffFactor(){return D.rolloffFactor},set rolloffFactor(te){if(te<0)throw new RangeError;D.rolloffFactor=te},addEventListener(...te){return O.addEventListener(te[0],te[1],te[2])},dispatchEvent(...te){return O.dispatchEvent(te[0])},removeEventListener(...te){return O.removeEventListener(te[0],te[1],te[2])}};d!==le.coneInnerAngle&&(le.coneInnerAngle=d),u!==le.coneOuterAngle&&(le.coneOuterAngle=u),m!==le.coneOuterGain&&(le.coneOuterGain=m),p!==le.distanceModel&&(le.distanceModel=p),g!==le.maxDistance&&(le.maxDistance=g),y!==le.orientationX.value&&(le.orientationX.value=y),b!==le.orientationY.value&&(le.orientationY.value=b),x!==le.orientationZ.value&&(le.orientationZ.value=x),S!==le.panningModel&&(le.panningModel=S),k!==le.positionX.value&&(le.positionX.value=k),w!==le.positionY.value&&(le.positionY.value=w),C!==le.positionZ.value&&(le.positionZ.value=C),M!==le.refDistance&&(le.refDistance=M),A!==le.rolloffFactor&&(le.rolloffFactor=A),(ge[0]!==1||ge[1]!==0||ge[2]!==0)&&D.setOrientation(...ge),(ot[0]!==0||ot[1]!==0||ot[2]!==0)&&D.setPosition(...ot);const Te=()=>{O.connect(D),n(O,ie,0,0),ie.connect(j).connect(E,0,0),ie.connect(W).connect(E,0,1),ie.connect(L).connect(E,0,2),ie.connect(z).connect(E,0,3),ie.connect(Y).connect(E,0,4),ie.connect(V).connect(E,0,5),E.connect(J).connect(h.destination)},Je=()=>{O.disconnect(D),r(O,ie,0,0),ie.disconnect(j),j.disconnect(E),ie.disconnect(W),W.disconnect(E),ie.disconnect(L),L.disconnect(E),ie.disconnect(z),z.disconnect(E),ie.disconnect(Y),Y.disconnect(E),ie.disconnect(V),V.disconnect(E),E.disconnect(J),J.disconnect(h.destination)};return c(Hi(le,D),Te,Je)},b0=n=>(e,{disableNormalization:t,imag:a,real:i})=>{const o=a instanceof Float32Array?a:new Float32Array(a),s=i instanceof Float32Array?i:new Float32Array(i),r=e.createPeriodicWave(s,o,{disableNormalization:t});if(Array.from(a).length<2)throw n();return r},hs=(n,e,t,a)=>n.createScriptProcessor(e,t,a),v0=(n,e)=>(t,a)=>{const i=a.channelCountMode;if(i==="clamped-max")throw e();if(t.createStereoPanner===void 0)return n(t,a);const o=t.createStereoPanner();return nt(o,a),He(o,a,"pan"),Object.defineProperty(o,"channelCountMode",{get:()=>i,set:s=>{if(s!==i)throw e()}}),o},w0=(n,e,t,a,i,o)=>{const r=new Float32Array([1,1]),l=Math.PI/2,c={channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete"},h={...c,oversample:"none"},d=(p,g,y,b)=>{const x=new Float32Array(16385),S=new Float32Array(16385);for(let I=0;I<16385;I+=1){const D=I/16384*l;x[I]=Math.cos(D),S[I]=Math.sin(D)}const k=t(p,{...c,gain:0}),w=a(p,{...h,curve:x}),C=a(p,{...h,curve:r}),M=t(p,{...c,gain:0}),A=a(p,{...h,curve:S});return{connectGraph(){g.connect(k),g.connect(C.inputs===void 0?C:C.inputs[0]),g.connect(M),C.connect(y),y.connect(w.inputs===void 0?w:w.inputs[0]),y.connect(A.inputs===void 0?A:A.inputs[0]),w.connect(k.gain),A.connect(M.gain),k.connect(b,0,0),M.connect(b,0,1)},disconnectGraph(){g.disconnect(k),g.disconnect(C.inputs===void 0?C:C.inputs[0]),g.disconnect(M),C.disconnect(y),y.disconnect(w.inputs===void 0?w:w.inputs[0]),y.disconnect(A.inputs===void 0?A:A.inputs[0]),w.disconnect(k.gain),A.disconnect(M.gain),k.disconnect(b,0,0),M.disconnect(b,0,1)}}},u=(p,g,y,b)=>{const x=new Float32Array(16385),S=new Float32Array(16385),k=new Float32Array(16385),w=new Float32Array(16385),C=Math.floor(16385/2);for(let z=0;z<16385;z+=1)if(z>C){const Y=(z-C)/(16384-C)*l;x[z]=Math.cos(Y),S[z]=Math.sin(Y),k[z]=0,w[z]=1}else{const Y=z/(16384-C)*l;x[z]=1,S[z]=0,k[z]=Math.cos(Y),w[z]=Math.sin(Y)}const M=e(p,{channelCount:2,channelCountMode:"explicit",channelInterpretation:"discrete",numberOfOutputs:2}),A=t(p,{...c,gain:0}),I=a(p,{...h,curve:x}),D=t(p,{...c,gain:0}),P=a(p,{...h,curve:S}),E=a(p,{...h,curve:r}),O=t(p,{...c,gain:0}),j=a(p,{...h,curve:k}),W=t(p,{...c,gain:0}),L=a(p,{...h,curve:w});return{connectGraph(){g.connect(M),g.connect(E.inputs===void 0?E:E.inputs[0]),M.connect(A,0),M.connect(D,0),M.connect(O,1),M.connect(W,1),E.connect(y),y.connect(I.inputs===void 0?I:I.inputs[0]),y.connect(P.inputs===void 0?P:P.inputs[0]),y.connect(j.inputs===void 0?j:j.inputs[0]),y.connect(L.inputs===void 0?L:L.inputs[0]),I.connect(A.gain),P.connect(D.gain),j.connect(O.gain),L.connect(W.gain),A.connect(b,0,0),O.connect(b,0,0),D.connect(b,0,1),W.connect(b,0,1)},disconnectGraph(){g.disconnect(M),g.disconnect(E.inputs===void 0?E:E.inputs[0]),M.disconnect(A,0),M.disconnect(D,0),M.disconnect(O,1),M.disconnect(W,1),E.disconnect(y),y.disconnect(I.inputs===void 0?I:I.inputs[0]),y.disconnect(P.inputs===void 0?P:P.inputs[0]),y.disconnect(j.inputs===void 0?j:j.inputs[0]),y.disconnect(L.inputs===void 0?L:L.inputs[0]),I.disconnect(A.gain),P.disconnect(D.gain),j.disconnect(O.gain),L.disconnect(W.gain),A.disconnect(b,0,0),O.disconnect(b,0,0),D.disconnect(b,0,1),W.disconnect(b,0,1)}}},m=(p,g,y,b,x)=>{if(g===1)return d(p,y,b,x);if(g===2)return u(p,y,b,x);throw i()};return(p,{channelCount:g,channelCountMode:y,pan:b,...x})=>{if(y==="max")throw i();const S=n(p,{...x,channelCount:1,channelCountMode:y,numberOfInputs:2}),k=t(p,{...x,channelCount:g,channelCountMode:y,gain:1}),w=t(p,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:b});let{connectGraph:C,disconnectGraph:M}=m(p,g,k,w,S);Object.defineProperty(w.gain,"defaultValue",{get:()=>0}),Object.defineProperty(w.gain,"maxValue",{get:()=>1}),Object.defineProperty(w.gain,"minValue",{get:()=>-1});const A={get bufferSize(){},get channelCount(){return k.channelCount},set channelCount(E){k.channelCount!==E&&(I&&M(),{connectGraph:C,disconnectGraph:M}=m(p,E,k,w,S),I&&C()),k.channelCount=E},get channelCountMode(){return k.channelCountMode},set channelCountMode(E){if(E==="clamped-max"||E==="max")throw i();k.channelCountMode=E},get channelInterpretation(){return k.channelInterpretation},set channelInterpretation(E){k.channelInterpretation=E},get context(){return k.context},get inputs(){return[k]},get numberOfInputs(){return k.numberOfInputs},get numberOfOutputs(){return k.numberOfOutputs},get pan(){return w.gain},addEventListener(...E){return k.addEventListener(E[0],E[1],E[2])},dispatchEvent(...E){return k.dispatchEvent(E[0])},removeEventListener(...E){return k.removeEventListener(E[0],E[1],E[2])}};let I=!1;const D=()=>{C(),I=!0},P=()=>{M(),I=!1};return o(Hi(A,S),D,P)}},_0=(n,e,t,a,i,o,s)=>(r,l)=>{const c=r.createWaveShaper();if(o!==null&&o.name==="webkitAudioContext"&&r.createGain().gain.automationRate===void 0)return t(r,l);nt(c,l);const h=l.curve===null||l.curve instanceof Float32Array?l.curve:new Float32Array(l.curve);if(h!==null&&h.length<2)throw e();je(c,{curve:h},"curve"),je(c,l,"oversample");let d=null,u=!1;return s(c,"curve",g=>()=>g.call(c),g=>y=>(g.call(c,y),u&&(a(y)&&d===null?d=n(r,c):!a(y)&&d!==null&&(d(),d=null)),y)),i(c,()=>{u=!0,a(c.curve)&&(d=n(r,c))},()=>{u=!1,d!==null&&(d(),d=null)})},k0=(n,e,t,a,i)=>(o,{curve:s,oversample:r,...l})=>{const c=o.createWaveShaper(),h=o.createWaveShaper();nt(c,l),nt(h,l);const d=t(o,{...l,gain:1}),u=t(o,{...l,gain:-1}),m=t(o,{...l,gain:1}),p=t(o,{...l,gain:-1});let g=null,y=!1,b=null;const x={get bufferSize(){},get channelCount(){return c.channelCount},set channelCount(w){d.channelCount=w,u.channelCount=w,c.channelCount=w,m.channelCount=w,h.channelCount=w,p.channelCount=w},get channelCountMode(){return c.channelCountMode},set channelCountMode(w){d.channelCountMode=w,u.channelCountMode=w,c.channelCountMode=w,m.channelCountMode=w,h.channelCountMode=w,p.channelCountMode=w},get channelInterpretation(){return c.channelInterpretation},set channelInterpretation(w){d.channelInterpretation=w,u.channelInterpretation=w,c.channelInterpretation=w,m.channelInterpretation=w,h.channelInterpretation=w,p.channelInterpretation=w},get context(){return c.context},get curve(){return b},set curve(w){if(w!==null&&w.length<2)throw e();if(w===null)c.curve=w,h.curve=w;else{const C=w.length,M=new Float32Array(C+2-C%2),A=new Float32Array(C+2-C%2);M[0]=w[0],A[0]=-w[C-1];const I=Math.ceil((C+1)/2),D=(C+1)/2-1;for(let P=1;P<I;P+=1){const E=P/I*D,O=Math.floor(E),j=Math.ceil(E);M[P]=O===j?w[O]:(1-(E-O))*w[O]+(1-(j-E))*w[j],A[P]=O===j?-w[C-1-O]:-((1-(E-O))*w[C-1-O])-(1-(j-E))*w[C-1-j]}M[I]=C%2===1?w[I-1]:(w[I-2]+w[I-1])/2,c.curve=M,h.curve=A}b=w,y&&(a(b)&&g===null?g=n(o,d):g!==null&&(g(),g=null))},get inputs(){return[d]},get numberOfInputs(){return c.numberOfInputs},get numberOfOutputs(){return c.numberOfOutputs},get oversample(){return c.oversample},set oversample(w){c.oversample=w,h.oversample=w},addEventListener(...w){return d.addEventListener(w[0],w[1],w[2])},dispatchEvent(...w){return d.dispatchEvent(w[0])},removeEventListener(...w){return d.removeEventListener(w[0],w[1],w[2])}};s!==null&&(x.curve=s instanceof Float32Array?s:new Float32Array(s)),r!==x.oversample&&(x.oversample=r);const S=()=>{d.connect(c).connect(m),d.connect(u).connect(h).connect(p).connect(m),y=!0,a(b)&&(g=n(o,d))},k=()=>{d.disconnect(c),c.disconnect(m),d.disconnect(u),u.disconnect(h),h.disconnect(p),p.disconnect(m),y=!1,g!==null&&(g(),g=null)};return i(Hi(x,m),S,k)},Et=()=>new DOMException("","NotSupportedError"),T0={numberOfChannels:1},x0=(n,e,t,a,i)=>class extends n{constructor(s,r,l){let c;if(typeof s=="number"&&r!==void 0&&l!==void 0)c={length:r,numberOfChannels:s,sampleRate:l};else if(typeof s=="object")c=s;else throw new Error("The given parameters are not valid.");const{length:h,numberOfChannels:d,sampleRate:u}={...T0,...c},m=a(d,h,u);e(Fo,()=>Fo(m))||m.addEventListener("statechange",(()=>{let p=0;const g=y=>{this._state==="running"&&(p>0?(m.removeEventListener("statechange",g),y.stopImmediatePropagation(),this._waitForThePromiseToSettle(y)):p+=1)};return g})()),super(m,d),this._length=h,this._nativeOfflineAudioContext=m,this._state=null}get length(){return this._nativeOfflineAudioContext.length===void 0?this._length:this._nativeOfflineAudioContext.length}get state(){return this._state===null?this._nativeOfflineAudioContext.state:this._state}startRendering(){return this._state==="running"?Promise.reject(t()):(this._state="running",i(this.destination,this._nativeOfflineAudioContext).finally(()=>{this._state=null,ip(this)}))}_waitForThePromiseToSettle(s){this._state===null?this._nativeOfflineAudioContext.dispatchEvent(s):setTimeout(()=>this._waitForThePromiseToSettle(s))}},S0={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",detune:0,frequency:440,periodicWave:void 0,type:"sine"},A0=(n,e,t,a,i,o,s)=>class extends n{constructor(l,c){const h=i(l),d={...S0,...c},u=t(h,d),m=o(h),p=m?a():null,g=l.sampleRate/2;super(l,!1,u,p),this._detune=e(this,m,u.detune,153600,-153600),this._frequency=e(this,m,u.frequency,g,-g),this._nativeOscillatorNode=u,this._onended=null,this._oscillatorNodeRenderer=p,this._oscillatorNodeRenderer!==null&&d.periodicWave!==void 0&&(this._oscillatorNodeRenderer.periodicWave=d.periodicWave)}get detune(){return this._detune}get frequency(){return this._frequency}get onended(){return this._onended}set onended(l){const c=typeof l=="function"?s(this,l):null;this._nativeOscillatorNode.onended=c;const h=this._nativeOscillatorNode.onended;this._onended=h!==null&&h===c?l:h}get type(){return this._nativeOscillatorNode.type}set type(l){this._nativeOscillatorNode.type=l,this._oscillatorNodeRenderer!==null&&(this._oscillatorNodeRenderer.periodicWave=null)}setPeriodicWave(l){this._nativeOscillatorNode.setPeriodicWave(l),this._oscillatorNodeRenderer!==null&&(this._oscillatorNodeRenderer.periodicWave=l)}start(l=0){if(this._nativeOscillatorNode.start(l),this._oscillatorNodeRenderer!==null&&(this._oscillatorNodeRenderer.start=l),this.context.state!=="closed"){qi(this);const c=()=>{this._nativeOscillatorNode.removeEventListener("ended",c),Un(this)&&ss(this)};this._nativeOscillatorNode.addEventListener("ended",c)}}stop(l=0){this._nativeOscillatorNode.stop(l),this._oscillatorNodeRenderer!==null&&(this._oscillatorNodeRenderer.stop=l)}},C0=(n,e,t,a,i)=>()=>{const o=new WeakMap;let s=null,r=null,l=null;const c=async(h,d)=>{let u=t(h);const m=kt(u,d);if(!m){const p={channelCount:u.channelCount,channelCountMode:u.channelCountMode,channelInterpretation:u.channelInterpretation,detune:u.detune.value,frequency:u.frequency.value,periodicWave:s===null?void 0:s,type:u.type};u=e(d,p),r!==null&&u.start(r),l!==null&&u.stop(l)}return o.set(d,u),m?(await n(d,h.detune,u.detune),await n(d,h.frequency,u.frequency)):(await a(d,h.detune,u.detune),await a(d,h.frequency,u.frequency)),await i(h,d,u),u};return{set periodicWave(h){s=h},set start(h){r=h},set stop(h){l=h},render(h,d){const u=o.get(d);return u!==void 0?Promise.resolve(u):c(h,d)}}},M0={channelCount:2,channelCountMode:"clamped-max",channelInterpretation:"speakers",coneInnerAngle:360,coneOuterAngle:360,coneOuterGain:0,distanceModel:"inverse",maxDistance:1e4,orientationX:1,orientationY:0,orientationZ:0,panningModel:"equalpower",positionX:0,positionY:0,positionZ:0,refDistance:1,rolloffFactor:1},I0=(n,e,t,a,i,o,s)=>class extends n{constructor(l,c){const h=i(l),d={...M0,...c},u=t(h,d),m=o(h),p=m?a():null;super(l,!1,u,p),this._nativePannerNode=u,this._orientationX=e(this,m,u.orientationX,Ct,Nt),this._orientationY=e(this,m,u.orientationY,Ct,Nt),this._orientationZ=e(this,m,u.orientationZ,Ct,Nt),this._positionX=e(this,m,u.positionX,Ct,Nt),this._positionY=e(this,m,u.positionY,Ct,Nt),this._positionZ=e(this,m,u.positionZ,Ct,Nt),s(this,1)}get coneInnerAngle(){return this._nativePannerNode.coneInnerAngle}set coneInnerAngle(l){this._nativePannerNode.coneInnerAngle=l}get coneOuterAngle(){return this._nativePannerNode.coneOuterAngle}set coneOuterAngle(l){this._nativePannerNode.coneOuterAngle=l}get coneOuterGain(){return this._nativePannerNode.coneOuterGain}set coneOuterGain(l){this._nativePannerNode.coneOuterGain=l}get distanceModel(){return this._nativePannerNode.distanceModel}set distanceModel(l){this._nativePannerNode.distanceModel=l}get maxDistance(){return this._nativePannerNode.maxDistance}set maxDistance(l){this._nativePannerNode.maxDistance=l}get orientationX(){return this._orientationX}get orientationY(){return this._orientationY}get orientationZ(){return this._orientationZ}get panningModel(){return this._nativePannerNode.panningModel}set panningModel(l){this._nativePannerNode.panningModel=l}get positionX(){return this._positionX}get positionY(){return this._positionY}get positionZ(){return this._positionZ}get refDistance(){return this._nativePannerNode.refDistance}set refDistance(l){this._nativePannerNode.refDistance=l}get rolloffFactor(){return this._nativePannerNode.rolloffFactor}set rolloffFactor(l){this._nativePannerNode.rolloffFactor=l}},E0=(n,e,t,a,i,o,s,r,l,c)=>()=>{const h=new WeakMap;let d=null;const u=async(m,p)=>{let g=null,y=o(m);const b={channelCount:y.channelCount,channelCountMode:y.channelCountMode,channelInterpretation:y.channelInterpretation},x={...b,coneInnerAngle:y.coneInnerAngle,coneOuterAngle:y.coneOuterAngle,coneOuterGain:y.coneOuterGain,distanceModel:y.distanceModel,maxDistance:y.maxDistance,panningModel:y.panningModel,refDistance:y.refDistance,rolloffFactor:y.rolloffFactor},S=kt(y,p);if("bufferSize"in y)g=a(p,{...b,gain:1});else if(!S){const k={...x,orientationX:y.orientationX.value,orientationY:y.orientationY.value,orientationZ:y.orientationZ.value,positionX:y.positionX.value,positionY:y.positionY.value,positionZ:y.positionZ.value};y=i(p,k)}if(h.set(p,g===null?y:g),g!==null){if(d===null){if(s===null)throw new Error("Missing the native OfflineAudioContext constructor.");const P=new s(6,m.context.length,p.sampleRate),E=e(P,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"speakers",numberOfInputs:6});E.connect(P.destination),d=(async()=>{const O=await Promise.all([m.orientationX,m.orientationY,m.orientationZ,m.positionX,m.positionY,m.positionZ].map(async(j,W)=>{const L=t(P,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",offset:W===0?1:0});return await r(P,j,L.offset),L}));for(let j=0;j<6;j+=1)O[j].connect(E,0,j),O[j].start(0);return c(P)})()}const k=await d,w=a(p,{...b,gain:1});await l(m,p,w);const C=[];for(let P=0;P<k.numberOfChannels;P+=1)C.push(k.getChannelData(P));let M=[C[0][0],C[1][0],C[2][0]],A=[C[3][0],C[4][0],C[5][0]],I=a(p,{...b,gain:1}),D=i(p,{...x,orientationX:M[0],orientationY:M[1],orientationZ:M[2],positionX:A[0],positionY:A[1],positionZ:A[2]});w.connect(I).connect(D.inputs[0]),D.connect(g);for(let P=128;P<k.length;P+=128){const E=[C[0][P],C[1][P],C[2][P]],O=[C[3][P],C[4][P],C[5][P]];if(E.some((j,W)=>j!==M[W])||O.some((j,W)=>j!==A[W])){M=E,A=O;const j=P/p.sampleRate;I.gain.setValueAtTime(0,j),I=a(p,{...b,gain:0}),D=i(p,{...x,orientationX:M[0],orientationY:M[1],orientationZ:M[2],positionX:A[0],positionY:A[1],positionZ:A[2]}),I.gain.setValueAtTime(1,j),w.connect(I).connect(D.inputs[0]),D.connect(g)}}return g}return S?(await n(p,m.orientationX,y.orientationX),await n(p,m.orientationY,y.orientationY),await n(p,m.orientationZ,y.orientationZ),await n(p,m.positionX,y.positionX),await n(p,m.positionY,y.positionY),await n(p,m.positionZ,y.positionZ)):(await r(p,m.orientationX,y.orientationX),await r(p,m.orientationY,y.orientationY),await r(p,m.orientationZ,y.orientationZ),await r(p,m.positionX,y.positionX),await r(p,m.positionY,y.positionY),await r(p,m.positionZ,y.positionZ)),Vi(y)?await l(m,p,y.inputs[0]):await l(m,p,y),y};return{render(m,p){const g=h.get(p);return g!==void 0?Promise.resolve(g):u(m,p)}}},D0={disableNormalization:!1},P0=(n,e,t,a)=>class pp{constructor(o,s){const r=e(o),l=a({...D0,...s}),c=n(r,l);return t.add(c),c}static[Symbol.hasInstance](o){return o!==null&&typeof o=="object"&&Object.getPrototypeOf(o)===pp.prototype||t.has(o)}},N0=(n,e)=>(t,a,i)=>(n(a).replay(i),e(a,t,i)),B0=(n,e,t)=>async(a,i,o)=>{const s=n(a);await Promise.all(s.activeInputs.map((r,l)=>Array.from(r).map(async([c,h])=>{const u=await e(c).render(c,i),m=a.context.destination;!t(c)&&(a!==m||!t(a))&&u.connect(o,h,l)})).reduce((r,l)=>[...r,...l],[]))},j0=(n,e,t)=>async(a,i,o)=>{const s=e(a);await Promise.all(Array.from(s.activeInputs).map(async([r,l])=>{const h=await n(r).render(r,i);t(r)||h.connect(o,l)}))},z0=(n,e,t,a)=>i=>n(Fo,()=>Fo(i))?Promise.resolve(n(a,a)).then(o=>{if(!o){const s=t(i,512,0,1);i.oncomplete=()=>{s.onaudioprocess=null,s.disconnect()},s.onaudioprocess=()=>i.currentTime,s.connect(i.destination)}return i.startRendering()}):new Promise(o=>{const s=e(i,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:0});i.oncomplete=r=>{s.disconnect(),o(r.renderedBuffer)},s.connect(i.destination),i.startRendering()}),R0=n=>(e,t)=>{n.set(e,t)},O0=n=>(e,t)=>n.set(e,t),q0=(n,e,t,a,i,o,s,r)=>(l,c)=>t(l).render(l,c).then(()=>Promise.all(Array.from(a(c)).map(h=>t(h).render(h,c)))).then(()=>i(c)).then(h=>(typeof h.copyFromChannel!="function"?(s(h),th(h)):e(o,()=>o(h))||r(h),n.add(h),h)),F0={channelCount:2,channelCountMode:"explicit",channelInterpretation:"speakers",pan:0},L0=(n,e,t,a,i,o)=>class extends n{constructor(r,l){const c=i(r),h={...F0,...l},d=t(c,h),u=o(c),m=u?a():null;super(r,!1,d,m),this._pan=e(this,u,d.pan)}get pan(){return this._pan}},G0=(n,e,t,a,i)=>()=>{const o=new WeakMap,s=async(r,l)=>{let c=t(r);const h=kt(c,l);if(!h){const d={channelCount:c.channelCount,channelCountMode:c.channelCountMode,channelInterpretation:c.channelInterpretation,pan:c.pan.value};c=e(l,d)}return o.set(l,c),h?await n(l,r.pan,c.pan):await a(l,r.pan,c.pan),Vi(c)?await i(r,l,c.inputs[0]):await i(r,l,c),c};return{render(r,l){const c=o.get(l);return c!==void 0?Promise.resolve(c):s(r,l)}}},$0=n=>()=>{if(n===null)return!1;try{new n({length:1,sampleRate:44100})}catch{return!1}return!0},V0=(n,e)=>async()=>{if(n===null)return!0;if(e===null)return!1;const t=new Blob(['class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor("a",A)'],{type:"application/javascript; charset=utf-8"}),a=new e(1,128,44100),i=URL.createObjectURL(t);let o=!1,s=!1;try{await a.audioWorklet.addModule(i);const r=new n(a,"a",{numberOfOutputs:0}),l=a.createOscillator();r.port.onmessage=()=>o=!0,r.onprocessorerror=()=>s=!0,l.connect(r),l.start(0),await a.startRendering(),await new Promise(c=>setTimeout(c))}catch{}finally{URL.revokeObjectURL(i)}return o&&!s},H0=(n,e)=>()=>{if(e===null)return Promise.resolve(!1);const t=new e(1,1,44100),a=n(t,{channelCount:1,channelCountMode:"explicit",channelInterpretation:"discrete",gain:0});return new Promise(i=>{t.oncomplete=()=>{a.disconnect(),i(t.currentTime!==0)},t.startRendering()})},W0=()=>new DOMException("","UnknownError"),U0={channelCount:2,channelCountMode:"max",channelInterpretation:"speakers",curve:null,oversample:"none"},K0=(n,e,t,a,i,o,s)=>class extends n{constructor(l,c){const h=i(l),d={...U0,...c},u=t(h,d),p=o(h)?a():null;super(l,!0,u,p),this._isCurveNullified=!1,this._nativeWaveShaperNode=u,s(this,1)}get curve(){return this._isCurveNullified?null:this._nativeWaveShaperNode.curve}set curve(l){if(l===null)this._isCurveNullified=!0,this._nativeWaveShaperNode.curve=new Float32Array([0,0]);else{if(l.length<2)throw e();this._isCurveNullified=!1,this._nativeWaveShaperNode.curve=l}}get oversample(){return this._nativeWaveShaperNode.oversample}set oversample(l){this._nativeWaveShaperNode.oversample=l}},J0=(n,e,t)=>()=>{const a=new WeakMap,i=async(o,s)=>{let r=e(o);if(!kt(r,s)){const c={channelCount:r.channelCount,channelCountMode:r.channelCountMode,channelInterpretation:r.channelInterpretation,curve:r.curve,oversample:r.oversample};r=n(s,c)}return a.set(s,r),Vi(r)?await t(o,s,r.inputs[0]):await t(o,s,r),r};return{render(o,s){const r=a.get(s);return r!==void 0?Promise.resolve(r):i(o,s)}}},Z0=()=>typeof window>"u"?null:window,Y0=(n,e)=>t=>{t.copyFromChannel=(a,i,o=0)=>{const s=n(o),r=n(i);if(r>=t.numberOfChannels)throw e();const l=t.length,c=t.getChannelData(r),h=a.length;for(let d=s<0?-s:0;d+s<l&&d<h;d+=1)a[d]=c[d+s]},t.copyToChannel=(a,i,o=0)=>{const s=n(o),r=n(i);if(r>=t.numberOfChannels)throw e();const l=t.length,c=t.getChannelData(r),h=a.length;for(let d=s<0?-s:0;d+s<l&&d<h;d+=1)c[d+s]=a[d]}},X0=n=>e=>{e.copyFromChannel=(t=>(a,i,o=0)=>{const s=n(o),r=n(i);if(s<e.length)return t.call(e,a,r,s)})(e.copyFromChannel),e.copyToChannel=(t=>(a,i,o=0)=>{const s=n(o),r=n(i);if(s<e.length)return t.call(e,a,r,s)})(e.copyToChannel)},Q0=n=>(e,t)=>{const a=t.createBuffer(1,1,44100);e.buffer===null&&(e.buffer=a),n(e,"buffer",i=>()=>{const o=i.call(e);return o===a?null:o},i=>o=>i.call(e,o===null?a:o))},e1=(n,e)=>(t,a)=>{a.channelCount=1,a.channelCountMode="explicit",Object.defineProperty(a,"channelCount",{get:()=>1,set:()=>{throw n()}}),Object.defineProperty(a,"channelCountMode",{get:()=>"explicit",set:()=>{throw n()}});const i=t.createBufferSource();e(a,()=>{const r=a.numberOfInputs;for(let l=0;l<r;l+=1)i.connect(a,0,l)},()=>i.disconnect(a))},fp=(n,e,t)=>n.copyFromChannel===void 0?n.getChannelData(t)[0]:(n.copyFromChannel(e,t),e[0]),gp=n=>{if(n===null)return!1;const e=n.length;return e%2!==0?n[Math.floor(e/2)]!==0:n[e/2-1]+n[e/2]!==0},ds=(n,e,t,a)=>{let i=n;for(;!i.hasOwnProperty(e);)i=Object.getPrototypeOf(i);const{get:o,set:s}=Object.getOwnPropertyDescriptor(i,e);Object.defineProperty(n,e,{get:t(o),set:a(s)})},t1=n=>({...n,outputChannelCount:n.outputChannelCount!==void 0?n.outputChannelCount:n.numberOfInputs===1&&n.numberOfOutputs===1?[n.channelCount]:Array.from({length:n.numberOfOutputs},()=>1)}),n1=n=>({...n,channelCount:n.numberOfOutputs}),a1=n=>{const{imag:e,real:t}=n;return e===void 0?t===void 0?{...n,imag:[0,0],real:[0,0]}:{...n,imag:Array.from(t,()=>0),real:t}:t===void 0?{...n,imag:e,real:Array.from(e,()=>0)}:{...n,imag:e,real:t}},yp=(n,e,t)=>{try{n.setValueAtTime(e,t)}catch(a){if(a.code!==9)throw a;yp(n,e,t+1e-7)}},i1=n=>{const e=n.createBufferSource();e.start();try{e.start()}catch{return!0}return!1},o1=n=>{const e=n.createBufferSource(),t=n.createBuffer(1,1,44100);e.buffer=t;try{e.start(0,1)}catch{return!1}return!0},s1=n=>{const e=n.createBufferSource();e.start();try{e.stop()}catch{return!1}return!0},sh=n=>{const e=n.createOscillator();try{e.start(-1)}catch(t){return t instanceof RangeError}return!1},bp=n=>{const e=n.createBuffer(1,1,44100),t=n.createBufferSource();t.buffer=e,t.start(),t.stop();try{return t.stop(),!0}catch{return!1}},rh=n=>{const e=n.createOscillator();try{e.stop(-1)}catch(t){return t instanceof RangeError}return!1},r1=n=>{const{port1:e,port2:t}=new MessageChannel;try{e.postMessage(n)}finally{e.close(),t.close()}},l1=n=>{n.start=(e=>(t=0,a=0,i)=>{const o=n.buffer,s=o===null?a:Math.min(o.duration,a);o!==null&&s>o.duration-.5/n.context.sampleRate?e.call(n,t,0,0):e.call(n,t,s,i)})(n.start)},vp=(n,e)=>{const t=e.createGain();n.connect(t);const a=(i=>()=>{i.call(n,t),n.removeEventListener("ended",a)})(n.disconnect);n.addEventListener("ended",a),Hi(n,t),n.stop=(i=>{let o=!1;return(s=0)=>{if(o)try{i.call(n,s)}catch{t.gain.setValueAtTime(0,s)}else i.call(n,s),o=!0}})(n.stop)},Wi=(n,e)=>t=>{const a={value:n};return Object.defineProperties(t,{currentTarget:a,target:a}),typeof e=="function"?e.call(n,t):e.handleEvent.call(n,t)},c1=Ib(ai),h1=jb(ai),d1=Uv($r),wp=new WeakMap,u1=dw(wp),vn=Tv(new Map,new WeakMap),Dn=Z0(),_p=Lw(vn,Rn),lh=hw(It),ft=B0(It,lh,Ja),m1=Fb(_p,Be,ft),Pe=pw(Gr),Xn=p0(Dn),Ie=Dw(Xn),kp=new WeakMap,Tp=aw(Wi),us=Hw(Dn),ch=Cw(us),hh=Mw(Dn),xp=Iw(Dn),Lo=Uw(Dn),Ke=dv(Eb(Ym),Bb(c1,h1,lr,d1,cr,It,u1,os,Be,ai,Un,Ja,Ks),vn,kw(gc,cr,It,Be,qo,Un),Rn,Vr,Et,$v(lr,gc,It,Be,qo,Pe,Un,Ie),Zv(kp,It,fn),Tp,Pe,ch,hh,xp,Ie,Lo),p1=qb(Ke,m1,Rn,_p,Pe,Ie),dh=new WeakSet,eu=Gw(Dn),Sp=zv(new Uint32Array(1)),uh=Y0(Sp,Rn),mh=X0(Sp),Ap=Gb(dh,vn,Et,eu,Xn,$0(eu),uh,mh),Hr=zb(zt),Cp=j0(lh,rs,Ja),On=Ev(Cp),Ui=Vw(Hr,vn,i1,o1,s1,sh,bp,rh,l1,Q0(ds),vp),qn=N0(uw(rs),Cp),f1=Hb(On,Ui,Be,qn,ft),wn=uv(Db(Xm),kp,eh,mv,Tb,xb,Sb,Ab,Cb,mc,Jm,us,yp),g1=Vb(Ke,f1,wn,lt,Ui,Pe,Ie,Wi),y1=ev(Ke,tv,Rn,lt,Ww(zt,ds),Pe,Ie,ft),b1=kv(On,up,Be,qn,ft),ii=O0(wp),v1=_v(Ke,wn,b1,Vr,up,Pe,Ie,ii),xa=qw(ai,hh),w1=e1(lt,xa),Sa=e0(us,w1),_1=Av(Sa,Be,ft),k1=Sv(Ke,_1,Sa,Pe,Ie),T1=Iv(cs,Be,ft),x1=Mv(Ke,T1,cs,Pe,Ie,n1),S1=a0(Hr,Ui,zt,xa),Ki=n0(Hr,vn,S1,sh,rh),A1=jv(On,Ki,Be,qn,ft),C1=Bv(Ke,wn,A1,Ki,Pe,Ie,Wi),Mp=i0(Et,ds),M1=qv(Mp,Be,ft),I1=Ov(Ke,M1,Mp,Pe,Ie,ii),E1=Wv(On,mp,Be,qn,ft),D1=Hv(Ke,wn,E1,mp,Pe,Ie,ii),Ip=o0(Et),P1=ew(On,Ip,Be,qn,ft),N1=Qv(Ke,wn,P1,Ip,Et,Pe,Ie,ii),B1=lw(On,zt,Be,qn,ft),j1=rw(Ke,wn,B1,zt,Pe,Ie),z1=c0(Vr,lt,hs,Et),Wr=z0(vn,zt,hs,H0(zt,Xn)),R1=_w(Ui,Be,Xn,ft,Wr),O1=s0(z1),q1=vw(Ke,O1,R1,Pe,Ie,ii),F1=nv(wn,Sa,Ki,hs,Et,fp,Ie,ds),Ep=new WeakMap,L1=Ow(y1,F1,Tp,Ie,Ep,Wi),Dp=f0(Hr,vn,sh,bp,rh,vp),G1=C0(On,Dp,Be,qn,ft),$1=A0(Ke,wn,Dp,G1,Pe,Ie,Wi),Pp=Pv(Ui),V1=k0(Pp,lt,zt,gp,xa),Ur=_0(Pp,lt,V1,gp,xa,us,ds),H1=y0(lr,lt,Sa,zt,hs,Ur,Et,cr,fp,xa),Np=g0(H1),W1=E0(On,Sa,Ki,zt,Np,Be,Xn,qn,ft,Wr),U1=I0(Ke,wn,Np,W1,Pe,Ie,ii),K1=b0(Rn),J1=P0(K1,Pe,new WeakSet,a1),Z1=w0(Sa,cs,zt,Ur,Et,xa),Bp=v0(Z1,Et),Y1=G0(On,Bp,Be,qn,ft),X1=L0(Ke,wn,Bp,Y1,Pe,Ie),Q1=J0(Ur,Be,ft),e_=K0(Ke,lt,Ur,Q1,Pe,Ie,ii),jp=Pw(Dn),ph=iw(Dn),zp=new WeakMap,t_=fw(zp,Xn),n_=jp?Nb(vn,Et,nw(Dn),ph,ow(Mb),Pe,t_,Ie,Lo,new WeakMap,new WeakMap,V0(Lo,Xn),Dn):void 0,a_=Ew(ch,Ie),i_=Gv(dh,vn,Lv,tw,new WeakSet,Pe,a_,sr,Fo,uh,mh),Rp=vv(n_,p1,Ap,g1,v1,k1,x1,C1,I1,i_,D1,N1,j1,q1,L1,$1,U1,J1,X1,e_),o_=Nw(Ke,h0,Pe,Ie),s_=jw(Ke,d0,Pe,Ie),r_=zw(Ke,u0,Pe,Ie),l_=m0(lt,Ie),c_=Rw(Ke,l_,Pe),h_=Qb(Rp,lt,Et,W0,o_,s_,r_,c_,us),fh=gw(Ep),d_=Rb(fh),Op=Dv(Rn),u_=Kv(fh),qp=Yv(Rn),Fp=new WeakMap,m_=cw(Fp,fn),p_=Qw(Op,Rn,lt,Sa,cs,Ki,zt,hs,Et,qp,ph,m_,xa),f_=Jw(lt,p_,zt,Et,xa),g_=bv(On,Op,Ui,Sa,cs,Ki,zt,u_,qp,ph,Be,Lo,Xn,qn,ft,Wr),y_=mw(zp),b_=R0(Fp),tu=jp?fv(d_,Ke,wn,g_,f_,It,y_,Pe,Ie,Lo,t1,b_,r1,Wi):void 0,v_=Fv(Et,Xn),w_=q0(dh,vn,lh,fh,Wr,sr,uh,mh),__=x0(Rp,vn,lt,v_,w_),k_=Tw(Gr,ch),T_=xw(Qc,hh),x_=Sw(eh,xp),S_=Aw(Gr,Ie);function Ft(n){return n===void 0}function me(n){return n!==void 0}function A_(n){return typeof n=="function"}function Xt(n){return typeof n=="number"}function ma(n){return Object.prototype.toString.call(n)==="[object Object]"&&n.constructor===Object}function Lp(n){return typeof n=="boolean"}function wt(n){return Array.isArray(n)}function Pn(n){return typeof n=="string"}function Bs(n){return Pn(n)&&/^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(n)}function ne(n,e){if(!n)throw new Error(e)}function Qt(n,e,t=1/0){if(!(e<=n&&n<=t))throw new RangeError(`Value must be within [${e}, ${t}], got: ${n}`)}function Gp(n){!n.isOffline&&n.state!=="running"&&ms('The AudioContext is "suspended". Invoke Tone.start() from a user action to start the audio.')}let $p=!1,nu=!1;function au(n){$p=n}function C_(n){Ft(n)&&$p&&!nu&&(nu=!0,ms("Events scheduled inside of scheduled callbacks should use the passed in scheduling time. See https://github.com/Tonejs/Tone.js/wiki/Accurate-Timing"))}let Vp=console;function M_(...n){Vp.log(...n)}function ms(...n){Vp.warn(...n)}function I_(n){return new h_(n)}function E_(n,e,t){return new __(n,e,t)}const Mt=typeof self=="object"?self:null,D_=Mt&&(Mt.hasOwnProperty("AudioContext")||Mt.hasOwnProperty("webkitAudioContext"));function P_(n,e,t){return ne(me(tu),"AudioWorkletNode only works in a secure context (https or localhost)"),new(n instanceof(Mt==null?void 0:Mt.BaseAudioContext)?Mt==null?void 0:Mt.AudioWorkletNode:tu)(n,e,t)}function _n(n,e,t,a){var i=arguments.length,o=i<3?e:a===null?a=Object.getOwnPropertyDescriptor(e,t):a,s;if(typeof Reflect=="object"&&typeof Reflect.decorate=="function")o=Reflect.decorate(n,e,t,a);else for(var r=n.length-1;r>=0;r--)(s=n[r])&&(o=(i<3?s(o):i>3?s(e,t,o):s(e,t))||o);return i>3&&o&&Object.defineProperty(e,t,o),o}function Ne(n,e,t,a){function i(o){return o instanceof t?o:new t(function(s){s(o)})}return new(t||(t=Promise))(function(o,s){function r(h){try{c(a.next(h))}catch(d){s(d)}}function l(h){try{c(a.throw(h))}catch(d){s(d)}}function c(h){h.done?o(h.value):i(h.value).then(r,l)}c((a=a.apply(n,e||[])).next())})}class N_{constructor(e,t,a,i){this._callback=e,this._type=t,this._minimumUpdateInterval=Math.max(128/(i||44100),.001),this.updateInterval=a,this._createClock()}_createWorker(){const e=new Blob([`
			// the initial timeout time
			let timeoutTime =  ${(this._updateInterval*1e3).toFixed(1)};
			// onmessage callback
			self.onmessage = function(msg){
				timeoutTime = parseInt(msg.data);
			};
			// the tick function which posts a message
			// and schedules a new tick
			function tick(){
				setTimeout(tick, timeoutTime);
				self.postMessage('tick');
			}
			// call tick initially
			tick();
			`],{type:"text/javascript"}),t=URL.createObjectURL(e),a=new Worker(t);a.onmessage=this._callback.bind(this),this._worker=a}_createTimeout(){this._timeout=setTimeout(()=>{this._createTimeout(),this._callback()},this._updateInterval*1e3)}_createClock(){if(this._type==="worker")try{this._createWorker()}catch{this._type="timeout",this._createClock()}else this._type==="timeout"&&this._createTimeout()}_disposeClock(){this._timeout&&clearTimeout(this._timeout),this._worker&&(this._worker.terminate(),this._worker.onmessage=null)}get updateInterval(){return this._updateInterval}set updateInterval(e){var t;this._updateInterval=Math.max(e,this._minimumUpdateInterval),this._type==="worker"&&((t=this._worker)===null||t===void 0||t.postMessage(this._updateInterval*1e3))}get type(){return this._type}set type(e){this._disposeClock(),this._type=e,this._createClock()}dispose(){this._disposeClock()}}function Za(n){return x_(n)}function pa(n){return T_(n)}function Js(n){return S_(n)}function Si(n){return k_(n)}function B_(n){return n instanceof Ap}function j_(n,e){return n==="value"||Za(e)||pa(e)||B_(e)}function fa(n,...e){if(!e.length)return n;const t=e.shift();if(ma(n)&&ma(t))for(const a in t)j_(a,t[a])?n[a]=t[a]:ma(t[a])?(n[a]||Object.assign(n,{[a]:{}}),fa(n[a],t[a])):Object.assign(n,{[a]:t[a]});return fa(n,...e)}function z_(n,e){return n.length===e.length&&n.every((t,a)=>e[a]===t)}function q(n,e,t=[],a){const i={},o=Array.from(e);if(ma(o[0])&&a&&!Reflect.has(o[0],a)&&(Object.keys(o[0]).some(r=>Reflect.has(n,r))||(fa(i,{[a]:o[0]}),t.splice(t.indexOf(a),1),o.shift())),o.length===1&&ma(o[0]))fa(i,o[0]);else for(let s=0;s<t.length;s++)me(o[s])&&(i[t[s]]=o[s]);return fa(n,i)}function R_(n){return n.constructor.getDefaults()}function Cn(n,e){return Ft(n)?e:n}function Bt(n,e){return e.forEach(t=>{Reflect.has(n,t)&&delete n[t]}),n}/**
 * Tone.js
 * @author Yotam Mann
 * @license http://opensource.org/licenses/MIT MIT License
 * @copyright 2014-2024 Yotam Mann
 */class Qn{constructor(){this.debug=!1,this._wasDisposed=!1}static getDefaults(){return{}}log(...e){(this.debug||Mt&&this.toString()===Mt.TONE_DEBUG_CLASS)&&M_(this,...e)}dispose(){return this._wasDisposed=!0,this}get disposed(){return this._wasDisposed}toString(){return this.name}}Qn.version=Km;const gh=1e-6;function Fi(n,e){return n>e+gh}function _c(n,e){return Fi(n,e)||sn(n,e)}function mr(n,e){return n+gh<e}function sn(n,e){return Math.abs(n-e)<gh}function oi(n,e,t){return Math.max(Math.min(n,t),e)}class Yt extends Qn{constructor(){super(),this.name="Timeline",this._timeline=[];const e=q(Yt.getDefaults(),arguments,["memory"]);this.memory=e.memory,this.increasing=e.increasing}static getDefaults(){return{memory:1/0,increasing:!1}}get length(){return this._timeline.length}add(e){if(ne(Reflect.has(e,"time"),"Timeline: events must have a time attribute"),e.time=e.time.valueOf(),this.increasing&&this.length){const t=this._timeline[this.length-1];ne(_c(e.time,t.time),"The time must be greater than or equal to the last scheduled time"),this._timeline.push(e)}else{const t=this._search(e.time);this._timeline.splice(t+1,0,e)}if(this.length>this.memory){const t=this.length-this.memory;this._timeline.splice(0,t)}return this}remove(e){const t=this._timeline.indexOf(e);return t!==-1&&this._timeline.splice(t,1),this}get(e,t="time"){const a=this._search(e,t);return a!==-1?this._timeline[a]:null}peek(){return this._timeline[0]}shift(){return this._timeline.shift()}getAfter(e,t="time"){const a=this._search(e,t);return a+1<this._timeline.length?this._timeline[a+1]:null}getBefore(e){const t=this._timeline.length;if(t>0&&this._timeline[t-1].time<e)return this._timeline[t-1];const a=this._search(e);return a-1>=0?this._timeline[a-1]:null}cancel(e){if(this._timeline.length>1){let t=this._search(e);if(t>=0)if(sn(this._timeline[t].time,e)){for(let a=t;a>=0&&sn(this._timeline[a].time,e);a--)t=a;this._timeline=this._timeline.slice(0,t)}else this._timeline=this._timeline.slice(0,t+1);else this._timeline=[]}else this._timeline.length===1&&_c(this._timeline[0].time,e)&&(this._timeline=[]);return this}cancelBefore(e){const t=this._search(e);return t>=0&&(this._timeline=this._timeline.slice(t+1)),this}previousEvent(e){const t=this._timeline.indexOf(e);return t>0?this._timeline[t-1]:null}_search(e,t="time"){if(this._timeline.length===0)return-1;let a=0;const i=this._timeline.length;let o=i;if(i>0&&this._timeline[i-1][t]<=e)return i-1;for(;a<o;){let s=Math.floor(a+(o-a)/2);const r=this._timeline[s],l=this._timeline[s+1];if(sn(r[t],e)){for(let c=s;c<this._timeline.length;c++){const h=this._timeline[c];if(sn(h[t],e))s=c;else break}return s}else{if(mr(r[t],e)&&Fi(l[t],e))return s;Fi(r[t],e)?o=s:a=s+1}}return-1}_iterate(e,t=0,a=this._timeline.length-1){this._timeline.slice(t,a+1).forEach(e)}forEach(e){return this._iterate(e),this}forEachBefore(e,t){const a=this._search(e);return a!==-1&&this._iterate(t,0,a),this}forEachAfter(e,t){const a=this._search(e);return this._iterate(t,a+1),this}forEachBetween(e,t,a){let i=this._search(e),o=this._search(t);return i!==-1&&o!==-1?(this._timeline[i].time!==e&&(i+=1),this._timeline[o].time===t&&(o-=1),this._iterate(a,i,o)):i===-1&&this._iterate(a,0,o),this}forEachFrom(e,t){let a=this._search(e);for(;a>=0&&this._timeline[a].time>=e;)a--;return this._iterate(t,a+1),this}forEachAtTime(e,t){const a=this._search(e);if(a!==-1&&sn(this._timeline[a].time,e)){let i=a;for(let o=a;o>=0&&sn(this._timeline[o].time,e);o--)i=o;this._iterate(o=>{t(o)},i,a)}return this}dispose(){return super.dispose(),this._timeline=[],this}}const Hp=[];function Kr(n){Hp.push(n)}function O_(n){Hp.forEach(e=>e(n))}const Wp=[];function Jr(n){Wp.push(n)}function q_(n){Wp.forEach(e=>e(n))}class ps extends Qn{constructor(){super(...arguments),this.name="Emitter"}on(e,t){return e.split(/\W+/).forEach(i=>{Ft(this._events)&&(this._events={}),this._events.hasOwnProperty(i)||(this._events[i]=[]),this._events[i].push(t)}),this}once(e,t){const a=(...i)=>{t(...i),this.off(e,a)};return this.on(e,a),this}off(e,t){return e.split(/\W+/).forEach(i=>{if(Ft(this._events)&&(this._events={}),this._events.hasOwnProperty(i))if(Ft(t))this._events[i]=[];else{const o=this._events[i];for(let s=o.length-1;s>=0;s--)o[s]===t&&o.splice(s,1)}}),this}emit(e,...t){if(this._events&&this._events.hasOwnProperty(e)){const a=this._events[e].slice(0);for(let i=0,o=a.length;i<o;i++)a[i].apply(this,t)}return this}static mixin(e){["on","once","off","emit"].forEach(t=>{const a=Object.getOwnPropertyDescriptor(ps.prototype,t);Object.defineProperty(e.prototype,t,a)})}dispose(){return super.dispose(),this._events=void 0,this}}class Up extends ps{constructor(){super(...arguments),this.isOffline=!1}toJSON(){return{}}}class fs extends Up{constructor(){var e,t;super(),this.name="Context",this._constants=new Map,this._timeouts=new Yt,this._timeoutIds=0,this._initialized=!1,this._closeStarted=!1,this.isOffline=!1,this._workletPromise=null;const a=q(fs.getDefaults(),arguments,["context"]);a.context?(this._context=a.context,this._latencyHint=((e=arguments[0])===null||e===void 0?void 0:e.latencyHint)||""):(this._context=I_({latencyHint:a.latencyHint}),this._latencyHint=a.latencyHint),this._ticker=new N_(this.emit.bind(this,"tick"),a.clockSource,a.updateInterval,this._context.sampleRate),this.on("tick",this._timeoutLoop.bind(this)),this._context.onstatechange=()=>{this.emit("statechange",this.state)},this[!((t=arguments[0])===null||t===void 0)&&t.hasOwnProperty("updateInterval")?"_lookAhead":"lookAhead"]=a.lookAhead}static getDefaults(){return{clockSource:"worker",latencyHint:"interactive",lookAhead:.1,updateInterval:.05}}initialize(){return this._initialized||(O_(this),this._initialized=!0),this}createAnalyser(){return this._context.createAnalyser()}createOscillator(){return this._context.createOscillator()}createBufferSource(){return this._context.createBufferSource()}createBiquadFilter(){return this._context.createBiquadFilter()}createBuffer(e,t,a){return this._context.createBuffer(e,t,a)}createChannelMerger(e){return this._context.createChannelMerger(e)}createChannelSplitter(e){return this._context.createChannelSplitter(e)}createConstantSource(){return this._context.createConstantSource()}createConvolver(){return this._context.createConvolver()}createDelay(e){return this._context.createDelay(e)}createDynamicsCompressor(){return this._context.createDynamicsCompressor()}createGain(){return this._context.createGain()}createIIRFilter(e,t){return this._context.createIIRFilter(e,t)}createPanner(){return this._context.createPanner()}createPeriodicWave(e,t,a){return this._context.createPeriodicWave(e,t,a)}createStereoPanner(){return this._context.createStereoPanner()}createWaveShaper(){return this._context.createWaveShaper()}createMediaStreamSource(e){return ne(Si(this._context),"Not available if OfflineAudioContext"),this._context.createMediaStreamSource(e)}createMediaElementSource(e){return ne(Si(this._context),"Not available if OfflineAudioContext"),this._context.createMediaElementSource(e)}createMediaStreamDestination(){return ne(Si(this._context),"Not available if OfflineAudioContext"),this._context.createMediaStreamDestination()}decodeAudioData(e){return this._context.decodeAudioData(e)}get currentTime(){return this._context.currentTime}get state(){return this._context.state}get sampleRate(){return this._context.sampleRate}get listener(){return this.initialize(),this._listener}set listener(e){ne(!this._initialized,"The listener cannot be set after initialization."),this._listener=e}get transport(){return this.initialize(),this._transport}set transport(e){ne(!this._initialized,"The transport cannot be set after initialization."),this._transport=e}get draw(){return this.initialize(),this._draw}set draw(e){ne(!this._initialized,"Draw cannot be set after initialization."),this._draw=e}get destination(){return this.initialize(),this._destination}set destination(e){ne(!this._initialized,"The destination cannot be set after initialization."),this._destination=e}createAudioWorkletNode(e,t){return P_(this.rawContext,e,t)}addAudioWorkletModule(e){return Ne(this,void 0,void 0,function*(){ne(me(this.rawContext.audioWorklet),"AudioWorkletNode is only available in a secure context (https or localhost)"),this._workletPromise||(this._workletPromise=this.rawContext.audioWorklet.addModule(e)),yield this._workletPromise})}workletsAreReady(){return Ne(this,void 0,void 0,function*(){(yield this._workletPromise)?this._workletPromise:Promise.resolve()})}get updateInterval(){return this._ticker.updateInterval}set updateInterval(e){this._ticker.updateInterval=e}get clockSource(){return this._ticker.type}set clockSource(e){this._ticker.type=e}get lookAhead(){return this._lookAhead}set lookAhead(e){this._lookAhead=e,this.updateInterval=e?e/2:.01}get latencyHint(){return this._latencyHint}get rawContext(){return this._context}now(){return this._context.currentTime+this._lookAhead}immediate(){return this._context.currentTime}resume(){return Si(this._context)?this._context.resume():Promise.resolve()}close(){return Ne(this,void 0,void 0,function*(){Si(this._context)&&this.state!=="closed"&&!this._closeStarted&&(this._closeStarted=!0,yield this._context.close()),this._initialized&&q_(this)})}getConstant(e){if(this._constants.has(e))return this._constants.get(e);{const t=this._context.createBuffer(1,128,this._context.sampleRate),a=t.getChannelData(0);for(let o=0;o<a.length;o++)a[o]=e;const i=this._context.createBufferSource();return i.channelCount=1,i.channelCountMode="explicit",i.buffer=t,i.loop=!0,i.start(0),this._constants.set(e,i),i}}dispose(){return super.dispose(),this._ticker.dispose(),this._timeouts.dispose(),Object.keys(this._constants).map(e=>this._constants[e].disconnect()),this.close(),this}_timeoutLoop(){const e=this.now();let t=this._timeouts.peek();for(;this._timeouts.length&&t&&t.time<=e;)t.callback(),this._timeouts.shift(),t=this._timeouts.peek()}setTimeout(e,t){this._timeoutIds++;const a=this.now();return this._timeouts.add({callback:e,id:this._timeoutIds,time:a+t}),this._timeoutIds}clearTimeout(e){return this._timeouts.forEach(t=>{t.id===e&&this._timeouts.remove(t)}),this}clearInterval(e){return this.clearTimeout(e)}setInterval(e,t){const a=++this._timeoutIds,i=()=>{const o=this.now();this._timeouts.add({callback:()=>{e(),i()},id:a,time:o+t})};return i(),a}}class F_ extends Up{constructor(){super(...arguments),this.lookAhead=0,this.latencyHint=0,this.isOffline=!1}createAnalyser(){return{}}createOscillator(){return{}}createBufferSource(){return{}}createBiquadFilter(){return{}}createBuffer(e,t,a){return{}}createChannelMerger(e){return{}}createChannelSplitter(e){return{}}createConstantSource(){return{}}createConvolver(){return{}}createDelay(e){return{}}createDynamicsCompressor(){return{}}createGain(){return{}}createIIRFilter(e,t){return{}}createPanner(){return{}}createPeriodicWave(e,t,a){return{}}createStereoPanner(){return{}}createWaveShaper(){return{}}createMediaStreamSource(e){return{}}createMediaElementSource(e){return{}}createMediaStreamDestination(){return{}}decodeAudioData(e){return Promise.resolve({})}createAudioWorkletNode(e,t){return{}}get rawContext(){return{}}addAudioWorkletModule(e){return Ne(this,void 0,void 0,function*(){return Promise.resolve()})}resume(){return Promise.resolve()}setTimeout(e,t){return 0}clearTimeout(e){return this}setInterval(e,t){return 0}clearInterval(e){return this}getConstant(e){return{}}get currentTime(){return 0}get state(){return{}}get sampleRate(){return 0}get listener(){return{}}get transport(){return{}}get draw(){return{}}set draw(e){}get destination(){return{}}set destination(e){}now(){return 0}immediate(){return 0}}function fe(n,e){wt(e)?e.forEach(t=>fe(n,t)):Object.defineProperty(n,e,{enumerable:!0,writable:!1})}function yh(n,e){wt(e)?e.forEach(t=>yh(n,t)):Object.defineProperty(n,e,{writable:!0})}const _e=()=>{};class Ae extends Qn{constructor(){super(),this.name="ToneAudioBuffer",this.onload=_e;const e=q(Ae.getDefaults(),arguments,["url","onload","onerror"]);this.reverse=e.reverse,this.onload=e.onload,Pn(e.url)?this.load(e.url).catch(e.onerror):e.url&&this.set(e.url)}static getDefaults(){return{onerror:_e,onload:_e,reverse:!1}}get sampleRate(){return this._buffer?this._buffer.sampleRate:Ue().sampleRate}set(e){return e instanceof Ae?e.loaded?this._buffer=e.get():e.onload=()=>{this.set(e),this.onload(this)}:this._buffer=e,this._reversed&&this._reverse(),this}get(){return this._buffer}load(e){return Ne(this,void 0,void 0,function*(){const t=Ae.load(e).then(a=>{this.set(a),this.onload(this)});Ae.downloads.push(t);try{yield t}finally{const a=Ae.downloads.indexOf(t);Ae.downloads.splice(a,1)}return this})}dispose(){return super.dispose(),this._buffer=void 0,this}fromArray(e){const t=wt(e)&&e[0].length>0,a=t?e.length:1,i=t?e[0].length:e.length,o=Ue(),s=o.createBuffer(a,i,o.sampleRate),r=!t&&a===1?[e]:e;for(let l=0;l<a;l++)s.copyToChannel(r[l],l);return this._buffer=s,this}toMono(e){if(Xt(e))this.fromArray(this.toArray(e));else{let t=new Float32Array(this.length);const a=this.numberOfChannels;for(let i=0;i<a;i++){const o=this.toArray(i);for(let s=0;s<o.length;s++)t[s]+=o[s]}t=t.map(i=>i/a),this.fromArray(t)}return this}toArray(e){if(Xt(e))return this.getChannelData(e);if(this.numberOfChannels===1)return this.toArray(0);{const t=[];for(let a=0;a<this.numberOfChannels;a++)t[a]=this.getChannelData(a);return t}}getChannelData(e){return this._buffer?this._buffer.getChannelData(e):new Float32Array(0)}slice(e,t=this.duration){ne(this.loaded,"Buffer is not loaded");const a=Math.floor(e*this.sampleRate),i=Math.floor(t*this.sampleRate);ne(a<i,"The start time must be less than the end time");const o=i-a,s=Ue().createBuffer(this.numberOfChannels,o,this.sampleRate);for(let r=0;r<this.numberOfChannels;r++)s.copyToChannel(this.getChannelData(r).subarray(a,i),r);return new Ae(s)}_reverse(){if(this.loaded)for(let e=0;e<this.numberOfChannels;e++)this.getChannelData(e).reverse();return this}get loaded(){return this.length>0}get duration(){return this._buffer?this._buffer.duration:0}get length(){return this._buffer?this._buffer.length:0}get numberOfChannels(){return this._buffer?this._buffer.numberOfChannels:0}get reverse(){return this._reversed}set reverse(e){this._reversed!==e&&(this._reversed=e,this._reverse())}static fromArray(e){return new Ae().fromArray(e)}static fromUrl(e){return Ne(this,void 0,void 0,function*(){return yield new Ae().load(e)})}static load(e){return Ne(this,void 0,void 0,function*(){const t=e.match(/\[([^\]\[]+\|.+)\]$/);if(t){const l=t[1].split("|");let c=l[0];for(const h of l)if(Ae.supportsType(h)){c=h;break}e=e.replace(t[0],c)}const a=Ae.baseUrl===""||Ae.baseUrl.endsWith("/")?Ae.baseUrl:Ae.baseUrl+"/",i=document.createElement("a");i.href=a+e,i.pathname=(i.pathname+i.hash).split("/").map(encodeURIComponent).join("/");const o=yield fetch(i.href);if(!o.ok)throw new Error(`could not load url: ${e}`);const s=yield o.arrayBuffer();return yield Ue().decodeAudioData(s)})}static supportsType(e){const t=e.split("."),a=t[t.length-1];return document.createElement("audio").canPlayType("audio/"+a)!==""}static loaded(){return Ne(this,void 0,void 0,function*(){for(yield Promise.resolve();Ae.downloads.length;)yield Ae.downloads[0]})}}Ae.baseUrl="";Ae.downloads=[];class Zr extends fs{constructor(){super({clockSource:"offline",context:Js(arguments[0])?arguments[0]:E_(arguments[0],arguments[1]*arguments[2],arguments[2]),lookAhead:0,updateInterval:Js(arguments[0])?128/arguments[0].sampleRate:128/arguments[2]}),this.name="OfflineContext",this._currentTime=0,this.isOffline=!0,this._duration=Js(arguments[0])?arguments[0].length/arguments[0].sampleRate:arguments[1]}now(){return this._currentTime}get currentTime(){return this._currentTime}_renderClock(e){return Ne(this,void 0,void 0,function*(){let t=0;for(;this._duration-this._currentTime>=0;){this.emit("tick"),this._currentTime+=128/this.sampleRate,t++;const a=Math.floor(this.sampleRate/128);e&&t%a===0&&(yield new Promise(i=>setTimeout(i,1)))}})}render(){return Ne(this,arguments,void 0,function*(e=!0){yield this.workletsAreReady(),yield this._renderClock(e);const t=yield this._context.startRendering();return new Ae(t)})}close(){return Promise.resolve()}}const Kp=new F_;let Ra=Kp;function Ue(){return Ra===Kp&&D_&&L_(new fs),Ra}function L_(n,e=!1){e&&Ra.dispose(),Si(n)?Ra=new fs(n):Js(n)?Ra=new Zr(n):Ra=n}function Ji(){return Ra.resume()}if(Mt&&!Mt.TONE_SILENCE_LOGGING){const e=` * Tone.js v${Km} * `;console.log(`%c${e}`,"background: #000; color: #fff")}function Go(n){return Math.pow(10,n/20)}function ea(n){return 20*(Math.log(n)/Math.LN10)}function Jp(n){return Math.pow(2,n/12)}let Yr=440;function G_(){return Yr}function $_(n){Yr=n}function Oa(n){return Math.round(Zp(n))}function Zp(n){return 69+12*Math.log2(n/Yr)}function Yp(n){return Yr*Math.pow(2,(n-69)/12)}class bh extends Qn{constructor(e,t,a){super(),this.defaultUnits="s",this._val=t,this._units=a,this.context=e,this._expressions=this._getExpressions()}_getExpressions(){return{hz:{method:e=>this._frequencyToUnits(parseFloat(e)),regexp:/^(\d+(?:\.\d+)?)hz$/i},i:{method:e=>this._ticksToUnits(parseInt(e,10)),regexp:/^(\d+)i$/i},m:{method:e=>this._beatsToUnits(parseInt(e,10)*this._getTimeSignature()),regexp:/^(\d+)m$/i},n:{method:(e,t)=>{const a=parseInt(e,10),i=t==="."?1.5:1;return a===1?this._beatsToUnits(this._getTimeSignature())*i:this._beatsToUnits(4/a)*i},regexp:/^(\d+)n(\.?)$/i},number:{method:e=>this._expressions[this.defaultUnits].method.call(this,e),regexp:/^(\d+(?:\.\d+)?)$/},s:{method:e=>this._secondsToUnits(parseFloat(e)),regexp:/^(\d+(?:\.\d+)?)s$/},samples:{method:e=>parseInt(e,10)/this.context.sampleRate,regexp:/^(\d+)samples$/},t:{method:e=>{const t=parseInt(e,10);return this._beatsToUnits(8/(Math.floor(t)*3))},regexp:/^(\d+)t$/i},tr:{method:(e,t,a)=>{let i=0;return e&&e!=="0"&&(i+=this._beatsToUnits(this._getTimeSignature()*parseFloat(e))),t&&t!=="0"&&(i+=this._beatsToUnits(parseFloat(t))),a&&a!=="0"&&(i+=this._beatsToUnits(parseFloat(a)/4)),i},regexp:/^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?$/}}}valueOf(){if(this._val instanceof bh&&this.fromType(this._val),Ft(this._val))return this._noArg();if(Pn(this._val)&&Ft(this._units)){for(const e in this._expressions)if(this._expressions[e].regexp.test(this._val.trim())){this._units=e;break}}else if(ma(this._val)){let e=0;for(const t in this._val)if(me(this._val[t])){const a=this._val[t],i=new this.constructor(this.context,t).valueOf()*a;e+=i}return e}if(me(this._units)){const e=this._expressions[this._units],t=this._val.toString().trim().match(e.regexp);return t?e.method.apply(this,t.slice(1)):e.method.call(this,this._val)}else return Pn(this._val)?parseFloat(this._val):this._val}_frequencyToUnits(e){return 1/e}_beatsToUnits(e){return 60/this._getBpm()*e}_secondsToUnits(e){return e}_ticksToUnits(e){return e*this._beatsToUnits(1)/this._getPPQ()}_noArg(){return this._now()}_getBpm(){return this.context.transport.bpm.value}_getTimeSignature(){return this.context.transport.timeSignature}_getPPQ(){return this.context.transport.PPQ}fromType(e){switch(this._units=void 0,this.defaultUnits){case"s":this._val=e.toSeconds();break;case"i":this._val=e.toTicks();break;case"hz":this._val=e.toFrequency();break;case"midi":this._val=e.toMidi();break}return this}toFrequency(){return 1/this.toSeconds()}toSamples(){return this.toSeconds()*this.context.sampleRate}toMilliseconds(){return this.toSeconds()*1e3}}class Kt extends bh{constructor(){super(...arguments),this.name="TimeClass"}_getExpressions(){return Object.assign(super._getExpressions(),{now:{method:e=>this._now()+new this.constructor(this.context,e).valueOf(),regexp:/^\+(.+)/},quantize:{method:e=>{const t=new Kt(this.context,e).valueOf();return this._secondsToUnits(this.context.transport.nextSubdivision(t))},regexp:/^@(.+)/}})}quantize(e,t=1){const a=new this.constructor(this.context,e).valueOf(),i=this.valueOf(),r=Math.round(i/a)*a-i;return i+r*t}toNotation(){const e=this.toSeconds(),t=["1m"];for(let o=1;o<9;o++){const s=Math.pow(2,o);t.push(s+"n."),t.push(s+"n"),t.push(s+"t")}t.push("0");let a=t[0],i=new Kt(this.context,t[0]).toSeconds();return t.forEach(o=>{const s=new Kt(this.context,o).toSeconds();Math.abs(s-e)<Math.abs(i-e)&&(a=o,i=s)}),a}toBarsBeatsSixteenths(){const e=this._beatsToUnits(1);let t=this.valueOf()/e;t=parseFloat(t.toFixed(4));const a=Math.floor(t/this._getTimeSignature());let i=t%1*4;t=Math.floor(t)%this._getTimeSignature();const o=i.toString();return o.length>3&&(i=parseFloat(parseFloat(o).toFixed(3))),[a,t,i].join(":")}toTicks(){const e=this._beatsToUnits(1);return this.valueOf()/e*this._getPPQ()}toSeconds(){return this.valueOf()}toMidi(){return Oa(this.toFrequency())}_now(){return this.context.now()}}function V_(n,e){return new Kt(Ue(),n,e)}class jt extends Kt{constructor(){super(...arguments),this.name="Frequency",this.defaultUnits="hz"}static get A4(){return G_()}static set A4(e){$_(e)}_getExpressions(){return Object.assign({},super._getExpressions(),{midi:{regexp:/^(\d+(?:\.\d+)?midi)/,method(e){return this.defaultUnits==="midi"?e:jt.mtof(e)}},note:{regexp:/^([a-g]{1}(?:b|#|##|x|bb|###|#x|x#|bbb)?)(-?[0-9]+)/i,method(e,t){const i=H_[e.toLowerCase()]+(parseInt(t,10)+1)*12;return this.defaultUnits==="midi"?i:jt.mtof(i)}},tr:{regexp:/^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,method(e,t,a){let i=1;return e&&e!=="0"&&(i*=this._beatsToUnits(this._getTimeSignature()*parseFloat(e))),t&&t!=="0"&&(i*=this._beatsToUnits(parseFloat(t))),a&&a!=="0"&&(i*=this._beatsToUnits(parseFloat(a)/4)),i}}})}transpose(e){return new jt(this.context,this.valueOf()*Jp(e))}harmonize(e){return e.map(t=>this.transpose(t))}toMidi(){return Oa(this.valueOf())}toNote(){const e=this.toFrequency(),t=Math.log2(e/jt.A4);let a=Math.round(12*t)+57;const i=Math.floor(a/12);return i<0&&(a+=-12*i),W_[a%12]+i.toString()}toSeconds(){return 1/super.toSeconds()}toTicks(){const e=this._beatsToUnits(1),t=this.valueOf()/e;return Math.floor(t*this._getPPQ())}_noArg(){return 0}_frequencyToUnits(e){return e}_ticksToUnits(e){return 1/(e*60/(this._getBpm()*this._getPPQ()))}_beatsToUnits(e){return 1/super._beatsToUnits(e)}_secondsToUnits(e){return 1/e}static mtof(e){return Yp(e)}static ftom(e){return Oa(e)}}const H_={cbbb:-3,cbb:-2,cb:-1,c:0,"c#":1,cx:2,"c##":2,"c###":3,"cx#":3,"c#x":3,dbbb:-1,dbb:0,db:1,d:2,"d#":3,dx:4,"d##":4,"d###":5,"dx#":5,"d#x":5,ebbb:1,ebb:2,eb:3,e:4,"e#":5,ex:6,"e##":6,"e###":7,"ex#":7,"e#x":7,fbbb:2,fbb:3,fb:4,f:5,"f#":6,fx:7,"f##":7,"f###":8,"fx#":8,"f#x":8,gbbb:4,gbb:5,gb:6,g:7,"g#":8,gx:9,"g##":9,"g###":10,"gx#":10,"g#x":10,abbb:6,abb:7,ab:8,a:9,"a#":10,ax:11,"a##":11,"a###":12,"ax#":12,"a#x":12,bbbb:8,bbb:9,bb:10,b:11,"b#":12,bx:13,"b##":13,"b###":14,"bx#":14,"b#x":14},W_=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"];function pr(n,e){return new jt(Ue(),n,e)}class Ei extends Kt{constructor(){super(...arguments),this.name="TransportTime"}_now(){return this.context.transport.seconds}}class ct extends Qn{constructor(){super();const e=q(ct.getDefaults(),arguments,["context"]);this.defaultContext?this.context=this.defaultContext:this.context=e.context}static getDefaults(){return{context:Ue()}}now(){return this.context.currentTime+this.context.lookAhead}immediate(){return this.context.currentTime}get sampleTime(){return 1/this.context.sampleRate}get blockTime(){return 128/this.context.sampleRate}toSeconds(e){return C_(e),new Kt(this.context,e).toSeconds()}toFrequency(e){return new jt(this.context,e).toFrequency()}toTicks(e){return new Ei(this.context,e).toTicks()}_getPartialProperties(e){const t=this.get();return Object.keys(t).forEach(a=>{Ft(e[a])&&delete t[a]}),t}get(){const e=R_(this);return Object.keys(e).forEach(t=>{if(Reflect.has(this,t)){const a=this[t];me(a)&&me(a.value)&&me(a.setValueAtTime)?e[t]=a.value:a instanceof ct?e[t]=a._getPartialProperties(e[t]):wt(a)||Xt(a)||Pn(a)||Lp(a)?e[t]=a:delete e[t]}}),e}set(e){return Object.keys(e).forEach(t=>{Reflect.has(this,t)&&me(this[t])&&(this[t]&&me(this[t].value)&&me(this[t].setValueAtTime)?this[t].value!==e[t]&&(this[t].value=e[t]):this[t]instanceof ct?this[t].set(e[t]):this[t]=e[t])}),this}}class gs extends Yt{constructor(e="stopped"){super(),this.name="StateTimeline",this._initial=e,this.setStateAtTime(this._initial,0)}getValueAtTime(e){const t=this.get(e);return t!==null?t.state:this._initial}setStateAtTime(e,t,a){return Qt(t,0),this.add(Object.assign({},a,{state:e,time:t})),this}getLastState(e,t){const a=this._search(t);for(let i=a;i>=0;i--){const o=this._timeline[i];if(o.state===e)return o}}getNextState(e,t){const a=this._search(t);if(a!==-1)for(let i=a;i<this._timeline.length;i++){const o=this._timeline[i];if(o.state===e)return o}}}class pe extends ct{constructor(){const e=q(pe.getDefaults(),arguments,["param","units","convert"]);for(super(e),this.name="Param",this.overridden=!1,this._minOutput=1e-7,ne(me(e.param)&&(Za(e.param)||e.param instanceof pe),"param must be an AudioParam");!Za(e.param);)e.param=e.param._param;this._swappable=me(e.swappable)?e.swappable:!1,this._swappable?(this.input=this.context.createGain(),this._param=e.param,this.input.connect(this._param)):this._param=this.input=e.param,this._events=new Yt(1e3),this._initialValue=this._param.defaultValue,this.units=e.units,this.convert=e.convert,this._minValue=e.minValue,this._maxValue=e.maxValue,me(e.value)&&e.value!==this._toType(this._initialValue)&&this.setValueAtTime(e.value,0)}static getDefaults(){return Object.assign(ct.getDefaults(),{convert:!0,units:"number"})}get value(){const e=this.now();return this.getValueAtTime(e)}set value(e){this.cancelScheduledValues(this.now()),this.setValueAtTime(e,this.now())}get minValue(){return me(this._minValue)?this._minValue:this.units==="time"||this.units==="frequency"||this.units==="normalRange"||this.units==="positive"||this.units==="transportTime"||this.units==="ticks"||this.units==="bpm"||this.units==="hertz"||this.units==="samples"?0:this.units==="audioRange"?-1:this.units==="decibels"?-1/0:this._param.minValue}get maxValue(){return me(this._maxValue)?this._maxValue:this.units==="normalRange"||this.units==="audioRange"?1:this._param.maxValue}_is(e,t){return this.units===t}_assertRange(e){return me(this.maxValue)&&me(this.minValue)&&Qt(e,this._fromType(this.minValue),this._fromType(this.maxValue)),e}_fromType(e){return this.convert&&!this.overridden?this._is(e,"time")?this.toSeconds(e):this._is(e,"decibels")?Go(e):this._is(e,"frequency")?this.toFrequency(e):e:this.overridden?0:e}_toType(e){return this.convert&&this.units==="decibels"?ea(e):e}setValueAtTime(e,t){const a=this.toSeconds(t),i=this._fromType(e);return ne(isFinite(i)&&isFinite(a),`Invalid argument(s) to setValueAtTime: ${JSON.stringify(e)}, ${JSON.stringify(t)}`),this._assertRange(i),this.log(this.units,"setValueAtTime",e,a),this._events.add({time:a,type:"setValueAtTime",value:i}),this._param.setValueAtTime(i,a),this}getValueAtTime(e){const t=Math.max(this.toSeconds(e),0),a=this._events.getAfter(t),i=this._events.get(t);let o=this._initialValue;if(i===null)o=this._initialValue;else if(i.type==="setTargetAtTime"&&(a===null||a.type==="setValueAtTime")){const s=this._events.getBefore(i.time);let r;s===null?r=this._initialValue:r=s.value,i.type==="setTargetAtTime"&&(o=this._exponentialApproach(i.time,r,i.value,i.constant,t))}else if(a===null)o=i.value;else if(a.type==="linearRampToValueAtTime"||a.type==="exponentialRampToValueAtTime"){let s=i.value;if(i.type==="setTargetAtTime"){const r=this._events.getBefore(i.time);r===null?s=this._initialValue:s=r.value}a.type==="linearRampToValueAtTime"?o=this._linearInterpolate(i.time,s,a.time,a.value,t):o=this._exponentialInterpolate(i.time,s,a.time,a.value,t)}else o=i.value;return this._toType(o)}setRampPoint(e){e=this.toSeconds(e);let t=this.getValueAtTime(e);return this.cancelAndHoldAtTime(e),this._fromType(t)===0&&(t=this._toType(this._minOutput)),this.setValueAtTime(t,e),this}linearRampToValueAtTime(e,t){const a=this._fromType(e),i=this.toSeconds(t);return ne(isFinite(a)&&isFinite(i),`Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(e)}, ${JSON.stringify(t)}`),this._assertRange(a),this._events.add({time:i,type:"linearRampToValueAtTime",value:a}),this.log(this.units,"linearRampToValueAtTime",e,i),this._param.linearRampToValueAtTime(a,i),this}exponentialRampToValueAtTime(e,t){let a=this._fromType(e);a=sn(a,0)?this._minOutput:a,this._assertRange(a);const i=this.toSeconds(t);return ne(isFinite(a)&&isFinite(i),`Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(e)}, ${JSON.stringify(t)}`),this._events.add({time:i,type:"exponentialRampToValueAtTime",value:a}),this.log(this.units,"exponentialRampToValueAtTime",e,i),this._param.exponentialRampToValueAtTime(a,i),this}exponentialRampTo(e,t,a){return a=this.toSeconds(a),this.setRampPoint(a),this.exponentialRampToValueAtTime(e,a+this.toSeconds(t)),this}linearRampTo(e,t,a){return a=this.toSeconds(a),this.setRampPoint(a),this.linearRampToValueAtTime(e,a+this.toSeconds(t)),this}targetRampTo(e,t,a){return a=this.toSeconds(a),this.setRampPoint(a),this.exponentialApproachValueAtTime(e,a,t),this}exponentialApproachValueAtTime(e,t,a){t=this.toSeconds(t),a=this.toSeconds(a);const i=Math.log(a+1)/Math.log(200);return this.setTargetAtTime(e,t,i),this.cancelAndHoldAtTime(t+a*.9),this.linearRampToValueAtTime(e,t+a),this}setTargetAtTime(e,t,a){const i=this._fromType(e);ne(isFinite(a)&&a>0,"timeConstant must be a number greater than 0");const o=this.toSeconds(t);return this._assertRange(i),ne(isFinite(i)&&isFinite(o),`Invalid argument(s) to setTargetAtTime: ${JSON.stringify(e)}, ${JSON.stringify(t)}`),this._events.add({constant:a,time:o,type:"setTargetAtTime",value:i}),this.log(this.units,"setTargetAtTime",e,o,a),this._param.setTargetAtTime(i,o,a),this}setValueCurveAtTime(e,t,a,i=1){a=this.toSeconds(a),t=this.toSeconds(t);const o=this._fromType(e[0])*i;this.setValueAtTime(this._toType(o),t);const s=a/(e.length-1);for(let r=1;r<e.length;r++){const l=this._fromType(e[r])*i;this.linearRampToValueAtTime(this._toType(l),t+r*s)}return this}cancelScheduledValues(e){const t=this.toSeconds(e);return ne(isFinite(t),`Invalid argument to cancelScheduledValues: ${JSON.stringify(e)}`),this._events.cancel(t),this._param.cancelScheduledValues(t),this.log(this.units,"cancelScheduledValues",t),this}cancelAndHoldAtTime(e){const t=this.toSeconds(e),a=this._fromType(this.getValueAtTime(t));ne(isFinite(t),`Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(e)}`),this.log(this.units,"cancelAndHoldAtTime",t,"value="+a);const i=this._events.get(t),o=this._events.getAfter(t);return i&&sn(i.time,t)?o?(this._param.cancelScheduledValues(o.time),this._events.cancel(o.time)):(this._param.cancelAndHoldAtTime(t),this._events.cancel(t+this.sampleTime)):o&&(this._param.cancelScheduledValues(o.time),this._events.cancel(o.time),o.type==="linearRampToValueAtTime"?this.linearRampToValueAtTime(this._toType(a),t):o.type==="exponentialRampToValueAtTime"&&this.exponentialRampToValueAtTime(this._toType(a),t)),this._events.add({time:t,type:"setValueAtTime",value:a}),this._param.setValueAtTime(a,t),this}rampTo(e,t=.1,a){return this.units==="frequency"||this.units==="bpm"||this.units==="decibels"?this.exponentialRampTo(e,t,a):this.linearRampTo(e,t,a),this}apply(e){const t=this.context.currentTime;e.setValueAtTime(this.getValueAtTime(t),t);const a=this._events.get(t);if(a&&a.type==="setTargetAtTime"){const i=this._events.getAfter(a.time),o=i?i.time:t+2,s=(o-t)/10;for(let r=t;r<o;r+=s)e.linearRampToValueAtTime(this.getValueAtTime(r),r)}return this._events.forEachAfter(this.context.currentTime,i=>{i.type==="cancelScheduledValues"?e.cancelScheduledValues(i.time):i.type==="setTargetAtTime"?e.setTargetAtTime(i.value,i.time,i.constant):e[i.type](i.value,i.time)}),this}setParam(e){ne(this._swappable,"The Param must be assigned as 'swappable' in the constructor");const t=this.input;return t.disconnect(this._param),this.apply(e),this._param=e,t.connect(this._param),this}dispose(){return super.dispose(),this._events.dispose(),this}get defaultValue(){return this._toType(this._param.defaultValue)}_exponentialApproach(e,t,a,i,o){return a+(t-a)*Math.exp(-(o-e)/i)}_linearInterpolate(e,t,a,i,o){return t+(i-t)*((o-e)/(a-e))}_exponentialInterpolate(e,t,a,i,o){return t*Math.pow(i/t,(o-e)/(a-e))}}class $ extends ct{constructor(){super(...arguments),this._internalChannels=[]}get numberOfInputs(){return me(this.input)?Za(this.input)||this.input instanceof pe?1:this.input.numberOfInputs:0}get numberOfOutputs(){return me(this.output)?this.output.numberOfOutputs:0}_isAudioNode(e){return me(e)&&(e instanceof $||pa(e))}_getInternalNodes(){const e=this._internalChannels.slice(0);return this._isAudioNode(this.input)&&e.push(this.input),this._isAudioNode(this.output)&&this.input!==this.output&&e.push(this.output),e}_setChannelProperties(e){this._getInternalNodes().forEach(a=>{a.channelCount=e.channelCount,a.channelCountMode=e.channelCountMode,a.channelInterpretation=e.channelInterpretation})}_getChannelProperties(){const e=this._getInternalNodes();ne(e.length>0,"ToneAudioNode does not have any internal nodes");const t=e[0];return{channelCount:t.channelCount,channelCountMode:t.channelCountMode,channelInterpretation:t.channelInterpretation}}get channelCount(){return this._getChannelProperties().channelCount}set channelCount(e){const t=this._getChannelProperties();this._setChannelProperties(Object.assign(t,{channelCount:e}))}get channelCountMode(){return this._getChannelProperties().channelCountMode}set channelCountMode(e){const t=this._getChannelProperties();this._setChannelProperties(Object.assign(t,{channelCountMode:e}))}get channelInterpretation(){return this._getChannelProperties().channelInterpretation}set channelInterpretation(e){const t=this._getChannelProperties();this._setChannelProperties(Object.assign(t,{channelInterpretation:e}))}connect(e,t=0,a=0){return Lt(this,e,t,a),this}toDestination(){return this.connect(this.context.destination),this}toMaster(){return ms("toMaster() has been renamed toDestination()"),this.toDestination()}disconnect(e,t=0,a=0){return Xp(this,e,t,a),this}chain(...e){return Nn(this,...e),this}fan(...e){return e.forEach(t=>this.connect(t)),this}dispose(){return super.dispose(),me(this.input)&&(this.input instanceof $?this.input.dispose():pa(this.input)&&this.input.disconnect()),me(this.output)&&(this.output instanceof $?this.output.dispose():pa(this.output)&&this.output.disconnect()),this._internalChannels=[],this}}function Nn(...n){const e=n.shift();n.reduce((t,a)=>(t instanceof $?t.connect(a):pa(t)&&Lt(t,a),a),e)}function Lt(n,e,t=0,a=0){for(ne(me(n),"Cannot connect from undefined node"),ne(me(e),"Cannot connect to undefined node"),(e instanceof $||pa(e))&&ne(e.numberOfInputs>0,"Cannot connect to node with no inputs"),ne(n.numberOfOutputs>0,"Cannot connect from node with no outputs");e instanceof $||e instanceof pe;)me(e.input)&&(e=e.input);for(;n instanceof $;)me(n.output)&&(n=n.output);Za(e)?n.connect(e,t):n.connect(e,t,a)}function Xp(n,e,t=0,a=0){if(me(e))for(;e instanceof $;)e=e.input;for(;!pa(n);)me(n.output)&&(n=n.output);Za(e)?n.disconnect(e,t):pa(e)?n.disconnect(e,t,a):n.disconnect()}class re extends ${constructor(){const e=q(re.getDefaults(),arguments,["gain","units"]);super(e),this.name="Gain",this._gainNode=this.context.createGain(),this.input=this._gainNode,this.output=this._gainNode,this.gain=new pe({context:this.context,convert:e.convert,param:this._gainNode.gain,units:e.units,value:e.gain,minValue:e.minValue,maxValue:e.maxValue}),fe(this,"gain")}static getDefaults(){return Object.assign($.getDefaults(),{convert:!0,gain:1,units:"gain"})}dispose(){return super.dispose(),this._gainNode.disconnect(),this.gain.dispose(),this}}class Li extends ${constructor(e){super(e),this.onended=_e,this._startTime=-1,this._stopTime=-1,this._timeout=-1,this.output=new re({context:this.context,gain:0}),this._gainNode=this.output,this.getStateAtTime=function(t){const a=this.toSeconds(t);return this._startTime!==-1&&a>=this._startTime&&(this._stopTime===-1||a<=this._stopTime)?"started":"stopped"},this._fadeIn=e.fadeIn,this._fadeOut=e.fadeOut,this._curve=e.curve,this.onended=e.onended}static getDefaults(){return Object.assign($.getDefaults(),{curve:"linear",fadeIn:0,fadeOut:0,onended:_e})}_startGain(e,t=1){ne(this._startTime===-1,"Source cannot be started more than once");const a=this.toSeconds(this._fadeIn);return this._startTime=e+a,this._startTime=Math.max(this._startTime,this.context.currentTime),a>0?(this._gainNode.gain.setValueAtTime(0,e),this._curve==="linear"?this._gainNode.gain.linearRampToValueAtTime(t,e+a):this._gainNode.gain.exponentialApproachValueAtTime(t,e,a)):this._gainNode.gain.setValueAtTime(t,e),this}stop(e){return this.log("stop",e),this._stopGain(this.toSeconds(e)),this}_stopGain(e){ne(this._startTime!==-1,"'start' must be called before 'stop'"),this.cancelStop();const t=this.toSeconds(this._fadeOut);return this._stopTime=this.toSeconds(e)+t,this._stopTime=Math.max(this._stopTime,this.now()),t>0?this._curve==="linear"?this._gainNode.gain.linearRampTo(0,t,e):this._gainNode.gain.targetRampTo(0,t,e):(this._gainNode.gain.cancelAndHoldAtTime(e),this._gainNode.gain.setValueAtTime(0,e)),this.context.clearTimeout(this._timeout),this._timeout=this.context.setTimeout(()=>{const a=this._curve==="exponential"?t*2:0;this._stopSource(this.now()+a),this._onended()},this._stopTime-this.context.currentTime),this}_onended(){if(this.onended!==_e&&(this.onended(this),this.onended=_e,!this.context.isOffline)){const e=()=>this.dispose();typeof window.requestIdleCallback<"u"?window.requestIdleCallback(e):setTimeout(e,1e3)}}get state(){return this.getStateAtTime(this.now())}cancelStop(){return this.log("cancelStop"),ne(this._startTime!==-1,"Source is not started"),this._gainNode.gain.cancelScheduledValues(this._startTime+this.sampleTime),this.context.clearTimeout(this._timeout),this._stopTime=-1,this}dispose(){return super.dispose(),this._gainNode.dispose(),this.onended=_e,this}}class vh extends Li{constructor(){const e=q(vh.getDefaults(),arguments,["offset"]);super(e),this.name="ToneConstantSource",this._source=this.context.createConstantSource(),Lt(this._source,this._gainNode),this.offset=new pe({context:this.context,convert:e.convert,param:this._source.offset,units:e.units,value:e.offset,minValue:e.minValue,maxValue:e.maxValue})}static getDefaults(){return Object.assign(Li.getDefaults(),{convert:!0,offset:1,units:"number"})}start(e){const t=this.toSeconds(e);return this.log("start",t),this._startGain(t),this._source.start(t),this}_stopSource(e){this._source.stop(e)}dispose(){return super.dispose(),this.state==="started"&&this.stop(),this._source.disconnect(),this.offset.dispose(),this}}class be extends ${constructor(){const e=q(be.getDefaults(),arguments,["value","units"]);super(e),this.name="Signal",this.override=!0,this.output=this._constantSource=new vh({context:this.context,convert:e.convert,offset:e.value,units:e.units,minValue:e.minValue,maxValue:e.maxValue}),this._constantSource.start(0),this.input=this._param=this._constantSource.offset}static getDefaults(){return Object.assign($.getDefaults(),{convert:!0,units:"number",value:0})}connect(e,t=0,a=0){return Xr(this,e,t,a),this}dispose(){return super.dispose(),this._param.dispose(),this._constantSource.dispose(),this}setValueAtTime(e,t){return this._param.setValueAtTime(e,t),this}getValueAtTime(e){return this._param.getValueAtTime(e)}setRampPoint(e){return this._param.setRampPoint(e),this}linearRampToValueAtTime(e,t){return this._param.linearRampToValueAtTime(e,t),this}exponentialRampToValueAtTime(e,t){return this._param.exponentialRampToValueAtTime(e,t),this}exponentialRampTo(e,t,a){return this._param.exponentialRampTo(e,t,a),this}linearRampTo(e,t,a){return this._param.linearRampTo(e,t,a),this}targetRampTo(e,t,a){return this._param.targetRampTo(e,t,a),this}exponentialApproachValueAtTime(e,t,a){return this._param.exponentialApproachValueAtTime(e,t,a),this}setTargetAtTime(e,t,a){return this._param.setTargetAtTime(e,t,a),this}setValueCurveAtTime(e,t,a,i){return this._param.setValueCurveAtTime(e,t,a,i),this}cancelScheduledValues(e){return this._param.cancelScheduledValues(e),this}cancelAndHoldAtTime(e){return this._param.cancelAndHoldAtTime(e),this}rampTo(e,t,a){return this._param.rampTo(e,t,a),this}get value(){return this._param.value}set value(e){this._param.value=e}get convert(){return this._param.convert}set convert(e){this._param.convert=e}get units(){return this._param.units}get overridden(){return this._param.overridden}set overridden(e){this._param.overridden=e}get maxValue(){return this._param.maxValue}get minValue(){return this._param.minValue}apply(e){return this._param.apply(e),this}}function Xr(n,e,t,a){(e instanceof pe||Za(e)||e instanceof be&&e.override)&&(e.cancelScheduledValues(0),e.setValueAtTime(0,0),e instanceof be&&(e.overridden=!0)),Lt(n,e,t,a)}class wh extends pe{constructor(){const e=q(wh.getDefaults(),arguments,["value"]);super(e),this.name="TickParam",this._events=new Yt(1/0),this._multiplier=1,this._multiplier=e.multiplier,this._events.cancel(0),this._events.add({ticks:0,time:0,type:"setValueAtTime",value:this._fromType(e.value)}),this.setValueAtTime(e.value,0)}static getDefaults(){return Object.assign(pe.getDefaults(),{multiplier:1,units:"hertz",value:1})}setTargetAtTime(e,t,a){t=this.toSeconds(t),this.setRampPoint(t);const i=this._fromType(e),o=this._events.get(t),s=Math.round(Math.max(1/a,1));for(let r=0;r<=s;r++){const l=a*r+t,c=this._exponentialApproach(o.time,o.value,i,a,l);this.linearRampToValueAtTime(this._toType(c),l)}return this}setValueAtTime(e,t){const a=this.toSeconds(t);super.setValueAtTime(e,t);const i=this._events.get(a),o=this._events.previousEvent(i),s=this._getTicksUntilEvent(o,a);return i.ticks=Math.max(s,0),this}linearRampToValueAtTime(e,t){const a=this.toSeconds(t);super.linearRampToValueAtTime(e,t);const i=this._events.get(a),o=this._events.previousEvent(i),s=this._getTicksUntilEvent(o,a);return i.ticks=Math.max(s,0),this}exponentialRampToValueAtTime(e,t){t=this.toSeconds(t);const a=this._fromType(e),i=this._events.get(t),o=Math.round(Math.max((t-i.time)*10,1)),s=(t-i.time)/o;for(let r=0;r<=o;r++){const l=s*r+i.time,c=this._exponentialInterpolate(i.time,i.value,t,a,l);this.linearRampToValueAtTime(this._toType(c),l)}return this}_getTicksUntilEvent(e,t){if(e===null)e={ticks:0,time:0,type:"setValueAtTime",value:0};else if(Ft(e.ticks)){const s=this._events.previousEvent(e);e.ticks=this._getTicksUntilEvent(s,e.time)}const a=this._fromType(this.getValueAtTime(e.time));let i=this._fromType(this.getValueAtTime(t));const o=this._events.get(t);return o&&o.time===t&&o.type==="setValueAtTime"&&(i=this._fromType(this.getValueAtTime(t-this.sampleTime))),.5*(t-e.time)*(a+i)+e.ticks}getTicksAtTime(e){const t=this.toSeconds(e),a=this._events.get(t);return Math.max(this._getTicksUntilEvent(a,t),0)}getDurationOfTicks(e,t){const a=this.toSeconds(t),i=this.getTicksAtTime(t);return this.getTimeOfTick(i+e)-a}getTimeOfTick(e){const t=this._events.get(e,"ticks"),a=this._events.getAfter(e,"ticks");if(t&&t.ticks===e)return t.time;if(t&&a&&a.type==="linearRampToValueAtTime"&&t.value!==a.value){const i=this._fromType(this.getValueAtTime(t.time)),s=(this._fromType(this.getValueAtTime(a.time))-i)/(a.time-t.time),r=Math.sqrt(Math.pow(i,2)-2*s*(t.ticks-e)),l=(-i+r)/s,c=(-i-r)/s;return(l>0?l:c)+t.time}else return t?t.value===0?1/0:t.time+(e-t.ticks)/t.value:e/this._initialValue}ticksToTime(e,t){return this.getDurationOfTicks(e,t)}timeToTicks(e,t){const a=this.toSeconds(t),i=this.toSeconds(e),o=this.getTicksAtTime(a);return this.getTicksAtTime(a+i)-o}_fromType(e){return this.units==="bpm"&&this.multiplier?1/(60/e/this.multiplier):super._fromType(e)}_toType(e){return this.units==="bpm"&&this.multiplier?e/this.multiplier*60:super._toType(e)}get multiplier(){return this._multiplier}set multiplier(e){const t=this.value;this._multiplier=e,this.cancelScheduledValues(0),this.setValueAtTime(t,0)}}class _h extends be{constructor(){const e=q(_h.getDefaults(),arguments,["value"]);super(e),this.name="TickSignal",this.input=this._param=new wh({context:this.context,convert:e.convert,multiplier:e.multiplier,param:this._constantSource.offset,units:e.units,value:e.value})}static getDefaults(){return Object.assign(be.getDefaults(),{multiplier:1,units:"hertz",value:1})}ticksToTime(e,t){return this._param.ticksToTime(e,t)}timeToTicks(e,t){return this._param.timeToTicks(e,t)}getTimeOfTick(e){return this._param.getTimeOfTick(e)}getDurationOfTicks(e,t){return this._param.getDurationOfTicks(e,t)}getTicksAtTime(e){return this._param.getTicksAtTime(e)}get multiplier(){return this._param.multiplier}set multiplier(e){this._param.multiplier=e}dispose(){return super.dispose(),this._param.dispose(),this}}class kh extends ct{constructor(){const e=q(kh.getDefaults(),arguments,["frequency"]);super(e),this.name="TickSource",this._state=new gs,this._tickOffset=new Yt,this._ticksAtTime=new Yt,this._secondsAtTime=new Yt,this.frequency=new _h({context:this.context,units:e.units,value:e.frequency}),fe(this,"frequency"),this._state.setStateAtTime("stopped",0),this.setTicksAtTime(0,0)}static getDefaults(){return Object.assign({frequency:1,units:"hertz"},ct.getDefaults())}get state(){return this.getStateAtTime(this.now())}start(e,t){const a=this.toSeconds(e);return this._state.getValueAtTime(a)!=="started"&&(this._state.setStateAtTime("started",a),me(t)&&this.setTicksAtTime(t,a),this._ticksAtTime.cancel(a),this._secondsAtTime.cancel(a)),this}stop(e){const t=this.toSeconds(e);if(this._state.getValueAtTime(t)==="stopped"){const a=this._state.get(t);a&&a.time>0&&(this._tickOffset.cancel(a.time),this._state.cancel(a.time))}return this._state.cancel(t),this._state.setStateAtTime("stopped",t),this.setTicksAtTime(0,t),this._ticksAtTime.cancel(t),this._secondsAtTime.cancel(t),this}pause(e){const t=this.toSeconds(e);return this._state.getValueAtTime(t)==="started"&&(this._state.setStateAtTime("paused",t),this._ticksAtTime.cancel(t),this._secondsAtTime.cancel(t)),this}cancel(e){return e=this.toSeconds(e),this._state.cancel(e),this._tickOffset.cancel(e),this._ticksAtTime.cancel(e),this._secondsAtTime.cancel(e),this}getTicksAtTime(e){const t=this.toSeconds(e),a=this._state.getLastState("stopped",t),i=this._ticksAtTime.get(t),o={state:"paused",time:t};this._state.add(o);let s=i||a,r=i?i.ticks:0,l=null;return this._state.forEachBetween(s.time,t+this.sampleTime,c=>{let h=s.time;const d=this._tickOffset.get(c.time);d&&d.time>=s.time&&(r=d.ticks,h=d.time),s.state==="started"&&c.state!=="started"&&(r+=this.frequency.getTicksAtTime(c.time)-this.frequency.getTicksAtTime(h),c.time!==o.time&&(l={state:c.state,time:c.time,ticks:r})),s=c}),this._state.remove(o),l&&this._ticksAtTime.add(l),r}get ticks(){return this.getTicksAtTime(this.now())}set ticks(e){this.setTicksAtTime(e,this.now())}get seconds(){return this.getSecondsAtTime(this.now())}set seconds(e){const t=this.now(),a=this.frequency.timeToTicks(e,t);this.setTicksAtTime(a,t)}getSecondsAtTime(e){e=this.toSeconds(e);const t=this._state.getLastState("stopped",e),a={state:"paused",time:e};this._state.add(a);const i=this._secondsAtTime.get(e);let o=i||t,s=i?i.seconds:0,r=null;return this._state.forEachBetween(o.time,e+this.sampleTime,l=>{let c=o.time;const h=this._tickOffset.get(l.time);h&&h.time>=o.time&&(s=h.seconds,c=h.time),o.state==="started"&&l.state!=="started"&&(s+=l.time-c,l.time!==a.time&&(r={state:l.state,time:l.time,seconds:s})),o=l}),this._state.remove(a),r&&this._secondsAtTime.add(r),s}setTicksAtTime(e,t){return t=this.toSeconds(t),this._tickOffset.cancel(t),this._tickOffset.add({seconds:this.frequency.getDurationOfTicks(e,t),ticks:e,time:t}),this._ticksAtTime.cancel(t),this._secondsAtTime.cancel(t),this}getStateAtTime(e){return e=this.toSeconds(e),this._state.getValueAtTime(e)}getTimeOfTick(e,t=this.now()){const a=this._tickOffset.get(t),i=this._state.get(t),o=Math.max(a.time,i.time),s=this.frequency.getTicksAtTime(o)+e-a.ticks;return this.frequency.getTimeOfTick(s)}forEachTickBetween(e,t,a){let i=this._state.get(e);this._state.forEachBetween(e,t,s=>{i&&i.state==="started"&&s.state!=="started"&&this.forEachTickBetween(Math.max(i.time,e),s.time-this.sampleTime,a),i=s});let o=null;if(i&&i.state==="started"){const s=Math.max(i.time,e),r=this.frequency.getTicksAtTime(s),l=this.frequency.getTicksAtTime(i.time),c=r-l;let h=Math.ceil(c)-c;h=sn(h,1)?0:h;let d=this.frequency.getTimeOfTick(r+h);for(;d<t;){try{a(d,Math.round(this.getTicksAtTime(d)))}catch(u){o=u;break}d+=this.frequency.getDurationOfTicks(1,d)}}if(o)throw o;return this}dispose(){return super.dispose(),this._state.dispose(),this._tickOffset.dispose(),this._ticksAtTime.dispose(),this._secondsAtTime.dispose(),this.frequency.dispose(),this}}class Qr extends ct{constructor(){const e=q(Qr.getDefaults(),arguments,["callback","frequency"]);super(e),this.name="Clock",this.callback=_e,this._lastUpdate=0,this._state=new gs("stopped"),this._boundLoop=this._loop.bind(this),this.callback=e.callback,this._tickSource=new kh({context:this.context,frequency:e.frequency,units:e.units}),this._lastUpdate=0,this.frequency=this._tickSource.frequency,fe(this,"frequency"),this._state.setStateAtTime("stopped",0),this.context.on("tick",this._boundLoop)}static getDefaults(){return Object.assign(ct.getDefaults(),{callback:_e,frequency:1,units:"hertz"})}get state(){return this._state.getValueAtTime(this.now())}start(e,t){Gp(this.context);const a=this.toSeconds(e);return this.log("start",a),this._state.getValueAtTime(a)!=="started"&&(this._state.setStateAtTime("started",a),this._tickSource.start(a,t),a<this._lastUpdate&&this.emit("start",a,t)),this}stop(e){const t=this.toSeconds(e);return this.log("stop",t),this._state.cancel(t),this._state.setStateAtTime("stopped",t),this._tickSource.stop(t),t<this._lastUpdate&&this.emit("stop",t),this}pause(e){const t=this.toSeconds(e);return this._state.getValueAtTime(t)==="started"&&(this._state.setStateAtTime("paused",t),this._tickSource.pause(t),t<this._lastUpdate&&this.emit("pause",t)),this}get ticks(){return Math.ceil(this.getTicksAtTime(this.now()))}set ticks(e){this._tickSource.ticks=e}get seconds(){return this._tickSource.seconds}set seconds(e){this._tickSource.seconds=e}getSecondsAtTime(e){return this._tickSource.getSecondsAtTime(e)}setTicksAtTime(e,t){return this._tickSource.setTicksAtTime(e,t),this}getTimeOfTick(e,t=this.now()){return this._tickSource.getTimeOfTick(e,t)}getTicksAtTime(e){return this._tickSource.getTicksAtTime(e)}nextTickTime(e,t){const a=this.toSeconds(t),i=this.getTicksAtTime(a);return this._tickSource.getTimeOfTick(i+e,a)}_loop(){const e=this._lastUpdate,t=this.now();this._lastUpdate=t,this.log("loop",e,t),e!==t&&(this._state.forEachBetween(e,t,a=>{switch(a.state){case"started":const i=this._tickSource.getTicksAtTime(a.time);this.emit("start",a.time,i);break;case"stopped":a.time!==0&&this.emit("stop",a.time);break;case"paused":this.emit("pause",a.time);break}}),this._tickSource.forEachTickBetween(e,t,(a,i)=>{this.callback(a,i)}))}getStateAtTime(e){const t=this.toSeconds(e);return this._state.getValueAtTime(t)}dispose(){return super.dispose(),this.context.off("tick",this._boundLoop),this._tickSource.dispose(),this._state.dispose(),this}}ps.mixin(Qr);class Ao extends ${constructor(){const e=q(Ao.getDefaults(),arguments,["delayTime","maxDelay"]);super(e),this.name="Delay";const t=this.toSeconds(e.maxDelay);this._maxDelay=Math.max(t,this.toSeconds(e.delayTime)),this._delayNode=this.input=this.output=this.context.createDelay(t),this.delayTime=new pe({context:this.context,param:this._delayNode.delayTime,units:"time",value:e.delayTime,minValue:0,maxValue:this.maxDelay}),fe(this,"delayTime")}static getDefaults(){return Object.assign($.getDefaults(),{delayTime:0,maxDelay:1})}get maxDelay(){return this._maxDelay}dispose(){return super.dispose(),this._delayNode.disconnect(),this.delayTime.dispose(),this}}class Aa extends ${constructor(){const e=q(Aa.getDefaults(),arguments,["volume"]);super(e),this.name="Volume",this.input=this.output=new re({context:this.context,gain:e.volume,units:"decibels"}),this.volume=this.output.gain,fe(this,"volume"),this._unmutedVolume=e.volume,this.mute=e.mute}static getDefaults(){return Object.assign($.getDefaults(),{mute:!1,volume:0})}get mute(){return this.volume.value===-1/0}set mute(e){!this.mute&&e?(this._unmutedVolume=this.volume.value,this.volume.value=-1/0):this.mute&&!e&&(this.volume.value=this._unmutedVolume)}dispose(){return super.dispose(),this.input.dispose(),this.volume.dispose(),this}}class Th extends ${constructor(){const e=q(Th.getDefaults(),arguments);super(e),this.name="Destination",this.input=new Aa({context:this.context}),this.output=new re({context:this.context}),this.volume=this.input.volume,Nn(this.input,this.output,this.context.rawContext.destination),this.mute=e.mute,this._internalChannels=[this.input,this.context.rawContext.destination,this.output]}static getDefaults(){return Object.assign($.getDefaults(),{mute:!1,volume:0})}get mute(){return this.input.mute}set mute(e){this.input.mute=e}chain(...e){return this.input.disconnect(),e.unshift(this.input),e.push(this.output),Nn(...e),this}get maxChannelCount(){return this.context.rawContext.destination.maxChannelCount}dispose(){return super.dispose(),this.volume.dispose(),this}}Kr(n=>{n.destination=new Th({context:n})});Jr(n=>{n.destination.dispose()});class U_ extends ${constructor(){super(...arguments),this.name="Listener",this.positionX=new pe({context:this.context,param:this.context.rawContext.listener.positionX}),this.positionY=new pe({context:this.context,param:this.context.rawContext.listener.positionY}),this.positionZ=new pe({context:this.context,param:this.context.rawContext.listener.positionZ}),this.forwardX=new pe({context:this.context,param:this.context.rawContext.listener.forwardX}),this.forwardY=new pe({context:this.context,param:this.context.rawContext.listener.forwardY}),this.forwardZ=new pe({context:this.context,param:this.context.rawContext.listener.forwardZ}),this.upX=new pe({context:this.context,param:this.context.rawContext.listener.upX}),this.upY=new pe({context:this.context,param:this.context.rawContext.listener.upY}),this.upZ=new pe({context:this.context,param:this.context.rawContext.listener.upZ})}static getDefaults(){return Object.assign($.getDefaults(),{positionX:0,positionY:0,positionZ:0,forwardX:0,forwardY:0,forwardZ:-1,upX:0,upY:1,upZ:0})}dispose(){return super.dispose(),this.positionX.dispose(),this.positionY.dispose(),this.positionZ.dispose(),this.forwardX.dispose(),this.forwardY.dispose(),this.forwardZ.dispose(),this.upX.dispose(),this.upY.dispose(),this.upZ.dispose(),this}}Kr(n=>{n.listener=new U_({context:n})});Jr(n=>{n.listener.dispose()});class xh extends Qn{constructor(){super(),this.name="ToneAudioBuffers",this._buffers=new Map,this._loadingCount=0;const e=q(xh.getDefaults(),arguments,["urls","onload","baseUrl"],"urls");this.baseUrl=e.baseUrl,Object.keys(e.urls).forEach(t=>{this._loadingCount++;const a=e.urls[t];this.add(t,a,this._bufferLoaded.bind(this,e.onload),e.onerror)})}static getDefaults(){return{baseUrl:"",onerror:_e,onload:_e,urls:{}}}has(e){return this._buffers.has(e.toString())}get(e){return ne(this.has(e),`ToneAudioBuffers has no buffer named: ${e}`),this._buffers.get(e.toString())}_bufferLoaded(e){this._loadingCount--,this._loadingCount===0&&e&&e()}get loaded(){return Array.from(this._buffers).every(([e,t])=>t.loaded)}add(e,t,a=_e,i=_e){return Pn(t)?(this.baseUrl&&t.trim().substring(0,11).toLowerCase()==="data:audio/"&&(this.baseUrl=""),this._buffers.set(e.toString(),new Ae(this.baseUrl+t,a,i))):this._buffers.set(e.toString(),new Ae(t,a,i)),this}dispose(){return super.dispose(),this._buffers.forEach(e=>e.dispose()),this._buffers.clear(),this}}class $o extends jt{constructor(){super(...arguments),this.name="MidiClass",this.defaultUnits="midi"}_frequencyToUnits(e){return Oa(super._frequencyToUnits(e))}_ticksToUnits(e){return Oa(super._ticksToUnits(e))}_beatsToUnits(e){return Oa(super._beatsToUnits(e))}_secondsToUnits(e){return Oa(super._secondsToUnits(e))}toMidi(){return this.valueOf()}toFrequency(){return Yp(this.toMidi())}transpose(e){return new $o(this.context,this.toMidi()+e)}}function kc(n,e){return new $o(Ue(),n,e)}class $e extends Ei{constructor(){super(...arguments),this.name="Ticks",this.defaultUnits="i"}_now(){return this.context.transport.ticks}_beatsToUnits(e){return this._getPPQ()*e}_secondsToUnits(e){return Math.floor(e/(60/this._getBpm())*this._getPPQ())}_ticksToUnits(e){return e}toTicks(){return this.valueOf()}toSeconds(){return this.valueOf()/this._getPPQ()*(60/this._getBpm())}}class K_ extends ct{constructor(){super(...arguments),this.name="Draw",this.expiration=.25,this.anticipation=.008,this._events=new Yt,this._boundDrawLoop=this._drawLoop.bind(this),this._animationFrame=-1}schedule(e,t){return this._events.add({callback:e,time:this.toSeconds(t)}),this._events.length===1&&(this._animationFrame=requestAnimationFrame(this._boundDrawLoop)),this}cancel(e){return this._events.cancel(this.toSeconds(e)),this}_drawLoop(){const e=this.context.currentTime;for(;this._events.length&&this._events.peek().time-this.anticipation<=e;){const t=this._events.shift();t&&e-t.time<=this.expiration&&t.callback()}this._events.length>0&&(this._animationFrame=requestAnimationFrame(this._boundDrawLoop))}dispose(){return super.dispose(),this._events.dispose(),cancelAnimationFrame(this._animationFrame),this}}Kr(n=>{n.draw=new K_({context:n})});Jr(n=>{n.draw.dispose()});class J_ extends Qn{constructor(){super(...arguments),this.name="IntervalTimeline",this._root=null,this._length=0}add(e){ne(me(e.time),"Events must have a time property"),ne(me(e.duration),"Events must have a duration parameter"),e.time=e.time.valueOf();let t=new Z_(e.time,e.time+e.duration,e);for(this._root===null?this._root=t:this._root.insert(t),this._length++;t!==null;)t.updateHeight(),t.updateMax(),this._rebalance(t),t=t.parent;return this}remove(e){if(this._root!==null){const t=[];this._root.search(e.time,t);for(const a of t)if(a.event===e){this._removeNode(a),this._length--;break}}return this}get length(){return this._length}cancel(e){return this.forEachFrom(e,t=>this.remove(t)),this}_setRoot(e){this._root=e,this._root!==null&&(this._root.parent=null)}_replaceNodeInParent(e,t){e.parent!==null?(e.isLeftChild()?e.parent.left=t:e.parent.right=t,this._rebalance(e.parent)):this._setRoot(t)}_removeNode(e){if(e.left===null&&e.right===null)this._replaceNodeInParent(e,null);else if(e.right===null)this._replaceNodeInParent(e,e.left);else if(e.left===null)this._replaceNodeInParent(e,e.right);else{const t=e.getBalance();let a,i=null;if(t>0)if(e.left.right===null)a=e.left,a.right=e.right,i=a;else{for(a=e.left.right;a.right!==null;)a=a.right;a.parent&&(a.parent.right=a.left,i=a.parent,a.left=e.left,a.right=e.right)}else if(e.right.left===null)a=e.right,a.left=e.left,i=a;else{for(a=e.right.left;a.left!==null;)a=a.left;a.parent&&(a.parent.left=a.right,i=a.parent,a.left=e.left,a.right=e.right)}e.parent!==null?e.isLeftChild()?e.parent.left=a:e.parent.right=a:this._setRoot(a),i&&this._rebalance(i)}e.dispose()}_rotateLeft(e){const t=e.parent,a=e.isLeftChild(),i=e.right;i&&(e.right=i.left,i.left=e),t!==null?a?t.left=i:t.right=i:this._setRoot(i)}_rotateRight(e){const t=e.parent,a=e.isLeftChild(),i=e.left;i&&(e.left=i.right,i.right=e),t!==null?a?t.left=i:t.right=i:this._setRoot(i)}_rebalance(e){const t=e.getBalance();t>1&&e.left?e.left.getBalance()<0?this._rotateLeft(e.left):this._rotateRight(e):t<-1&&e.right&&(e.right.getBalance()>0?this._rotateRight(e.right):this._rotateLeft(e))}get(e){if(this._root!==null){const t=[];if(this._root.search(e,t),t.length>0){let a=t[0];for(let i=1;i<t.length;i++)t[i].low>a.low&&(a=t[i]);return a.event}}return null}forEach(e){if(this._root!==null){const t=[];this._root.traverse(a=>t.push(a)),t.forEach(a=>{a.event&&e(a.event)})}return this}forEachAtTime(e,t){if(this._root!==null){const a=[];this._root.search(e,a),a.forEach(i=>{i.event&&t(i.event)})}return this}forEachFrom(e,t){if(this._root!==null){const a=[];this._root.searchAfter(e,a),a.forEach(i=>{i.event&&t(i.event)})}return this}dispose(){return super.dispose(),this._root!==null&&this._root.traverse(e=>e.dispose()),this._root=null,this}}class Z_{constructor(e,t,a){this._left=null,this._right=null,this.parent=null,this.height=0,this.event=a,this.low=e,this.high=t,this.max=this.high}insert(e){e.low<=this.low?this.left===null?this.left=e:this.left.insert(e):this.right===null?this.right=e:this.right.insert(e)}search(e,t){e>this.max||(this.left!==null&&this.left.search(e,t),this.low<=e&&this.high>e&&t.push(this),!(this.low>e)&&this.right!==null&&this.right.search(e,t))}searchAfter(e,t){this.low>=e&&(t.push(this),this.left!==null&&this.left.searchAfter(e,t)),this.right!==null&&this.right.searchAfter(e,t)}traverse(e){e(this),this.left!==null&&this.left.traverse(e),this.right!==null&&this.right.traverse(e)}updateHeight(){this.left!==null&&this.right!==null?this.height=Math.max(this.left.height,this.right.height)+1:this.right!==null?this.height=this.right.height+1:this.left!==null?this.height=this.left.height+1:this.height=0}updateMax(){this.max=this.high,this.left!==null&&(this.max=Math.max(this.max,this.left.max)),this.right!==null&&(this.max=Math.max(this.max,this.right.max))}getBalance(){let e=0;return this.left!==null&&this.right!==null?e=this.left.height-this.right.height:this.left!==null?e=this.left.height+1:this.right!==null&&(e=-(this.right.height+1)),e}isLeftChild(){return this.parent!==null&&this.parent.left===this}get left(){return this._left}set left(e){this._left=e,e!==null&&(e.parent=this),this.updateHeight(),this.updateMax()}get right(){return this._right}set right(e){this._right=e,e!==null&&(e.parent=this),this.updateHeight(),this.updateMax()}dispose(){this.parent=null,this._left=null,this._right=null,this.event=null}}class Y_ extends Qn{constructor(e){super(),this.name="TimelineValue",this._timeline=new Yt({memory:10}),this._initialValue=e}set(e,t){return this._timeline.add({value:e,time:t}),this}get(e){const t=this._timeline.get(e);return t?t.value:this._initialValue}}class Gt extends ${constructor(){super(q(Gt.getDefaults(),arguments,["context"]))}connect(e,t=0,a=0){return Xr(this,e,t,a),this}}class Ca extends Gt{constructor(){const e=q(Ca.getDefaults(),arguments,["mapping","length"]);super(e),this.name="WaveShaper",this._shaper=this.context.createWaveShaper(),this.input=this._shaper,this.output=this._shaper,wt(e.mapping)||e.mapping instanceof Float32Array?this.curve=Float32Array.from(e.mapping):A_(e.mapping)&&this.setMap(e.mapping,e.length)}static getDefaults(){return Object.assign(be.getDefaults(),{length:1024})}setMap(e,t=1024){const a=new Float32Array(t);for(let i=0,o=t;i<o;i++){const s=i/(o-1)*2-1;a[i]=e(s,i)}return this.curve=a,this}get curve(){return this._shaper.curve}set curve(e){this._shaper.curve=e}get oversample(){return this._shaper.oversample}set oversample(e){const t=["none","2x","4x"].some(a=>a.includes(e));ne(t,"oversampling must be either 'none', '2x', or '4x'"),this._shaper.oversample=e}dispose(){return super.dispose(),this._shaper.disconnect(),this}}class el extends Gt{constructor(){const e=q(el.getDefaults(),arguments,["value"]);super(e),this.name="Pow",this._exponentScaler=this.input=this.output=new Ca({context:this.context,mapping:this._expFunc(e.value),length:8192}),this._exponent=e.value}static getDefaults(){return Object.assign(Gt.getDefaults(),{value:1})}_expFunc(e){return t=>Math.pow(Math.abs(t),e)}get value(){return this._exponent}set value(e){this._exponent=e,this._exponentScaler.setMap(this._expFunc(this._exponent))}dispose(){return super.dispose(),this._exponentScaler.dispose(),this}}class wa{constructor(e,t){this.id=wa._eventId++,this._remainderTime=0;const a=Object.assign(wa.getDefaults(),t);this.transport=e,this.callback=a.callback,this._once=a.once,this.time=Math.floor(a.time),this._remainderTime=a.time-this.time}static getDefaults(){return{callback:_e,once:!1,time:0}}get floatTime(){return this.time+this._remainderTime}invoke(e){if(this.callback){const t=this.transport.bpm.getDurationOfTicks(1,e);this.callback(e+this._remainderTime*t),this._once&&this.transport.clear(this.id)}}dispose(){return this.callback=void 0,this}}wa._eventId=0;class Sh extends wa{constructor(e,t){super(e,t),this._currentId=-1,this._nextId=-1,this._nextTick=this.time,this._boundRestart=this._restart.bind(this);const a=Object.assign(Sh.getDefaults(),t);this.duration=a.duration,this._interval=a.interval,this._nextTick=a.time,this.transport.on("start",this._boundRestart),this.transport.on("loopStart",this._boundRestart),this.transport.on("ticks",this._boundRestart),this.context=this.transport.context,this._restart()}static getDefaults(){return Object.assign({},wa.getDefaults(),{duration:1/0,interval:1,once:!1})}invoke(e){this._createEvents(e),super.invoke(e)}_createEvent(){return mr(this._nextTick,this.floatTime+this.duration)?this.transport.scheduleOnce(this.invoke.bind(this),new $e(this.context,this._nextTick).toSeconds()):-1}_createEvents(e){mr(this._nextTick+this._interval,this.floatTime+this.duration)&&(this._nextTick+=this._interval,this._currentId=this._nextId,this._nextId=this.transport.scheduleOnce(this.invoke.bind(this),new $e(this.context,this._nextTick).toSeconds()))}_restart(e){this.transport.clear(this._currentId),this.transport.clear(this._nextId),this._nextTick=this.floatTime;const t=this.transport.getTicksAtTime(e);Fi(t,this.time)&&(this._nextTick=this.floatTime+Math.ceil((t-this.floatTime)/this._interval)*this._interval),this._currentId=this._createEvent(),this._nextTick+=this._interval,this._nextId=this._createEvent()}dispose(){return super.dispose(),this.transport.clear(this._currentId),this.transport.clear(this._nextId),this.transport.off("start",this._boundRestart),this.transport.off("loopStart",this._boundRestart),this.transport.off("ticks",this._boundRestart),this}}class tl extends ct{constructor(){const e=q(tl.getDefaults(),arguments);super(e),this.name="Transport",this._loop=new Y_(!1),this._loopStart=0,this._loopEnd=0,this._scheduledEvents={},this._timeline=new Yt,this._repeatedEvents=new J_,this._syncedSignals=[],this._swingAmount=0,this._ppq=e.ppq,this._clock=new Qr({callback:this._processTick.bind(this),context:this.context,frequency:0,units:"bpm"}),this._bindClockEvents(),this.bpm=this._clock.frequency,this._clock.frequency.multiplier=e.ppq,this.bpm.setValueAtTime(e.bpm,0),fe(this,"bpm"),this._timeSignature=e.timeSignature,this._swingTicks=e.ppq/2}static getDefaults(){return Object.assign(ct.getDefaults(),{bpm:120,loopEnd:"4m",loopStart:0,ppq:192,swing:0,swingSubdivision:"8n",timeSignature:4})}_processTick(e,t){if(this._loop.get(e)&&t>=this._loopEnd&&(this.emit("loopEnd",e),this._clock.setTicksAtTime(this._loopStart,e),t=this._loopStart,this.emit("loopStart",e,this._clock.getSecondsAtTime(e)),this.emit("loop",e)),this._swingAmount>0&&t%this._ppq!==0&&t%(this._swingTicks*2)!==0){const a=t%(this._swingTicks*2)/(this._swingTicks*2),i=Math.sin(a*Math.PI)*this._swingAmount;e+=new $e(this.context,this._swingTicks*2/3).toSeconds()*i}au(!0),this._timeline.forEachAtTime(t,a=>a.invoke(e)),au(!1)}schedule(e,t){const a=new wa(this,{callback:e,time:new Ei(this.context,t).toTicks()});return this._addEvent(a,this._timeline)}scheduleRepeat(e,t,a,i=1/0){const o=new Sh(this,{callback:e,duration:new Kt(this.context,i).toTicks(),interval:new Kt(this.context,t).toTicks(),time:new Ei(this.context,a).toTicks()});return this._addEvent(o,this._repeatedEvents)}scheduleOnce(e,t){const a=new wa(this,{callback:e,once:!0,time:new Ei(this.context,t).toTicks()});return this._addEvent(a,this._timeline)}clear(e){if(this._scheduledEvents.hasOwnProperty(e)){const t=this._scheduledEvents[e.toString()];t.timeline.remove(t.event),t.event.dispose(),delete this._scheduledEvents[e.toString()]}return this}_addEvent(e,t){return this._scheduledEvents[e.id.toString()]={event:e,timeline:t},t.add(e),e.id}cancel(e=0){const t=this.toTicks(e);return this._timeline.forEachFrom(t,a=>this.clear(a.id)),this._repeatedEvents.forEachFrom(t,a=>this.clear(a.id)),this}_bindClockEvents(){this._clock.on("start",(e,t)=>{t=new $e(this.context,t).toSeconds(),this.emit("start",e,t)}),this._clock.on("stop",e=>{this.emit("stop",e)}),this._clock.on("pause",e=>{this.emit("pause",e)})}get state(){return this._clock.getStateAtTime(this.now())}start(e,t){this.context.resume();let a;return me(t)&&(a=this.toTicks(t)),this._clock.start(e,a),this}stop(e){return this._clock.stop(e),this}pause(e){return this._clock.pause(e),this}toggle(e){return e=this.toSeconds(e),this._clock.getStateAtTime(e)!=="started"?this.start(e):this.stop(e),this}get timeSignature(){return this._timeSignature}set timeSignature(e){wt(e)&&(e=e[0]/e[1]*4),this._timeSignature=e}get loopStart(){return new Kt(this.context,this._loopStart,"i").toSeconds()}set loopStart(e){this._loopStart=this.toTicks(e)}get loopEnd(){return new Kt(this.context,this._loopEnd,"i").toSeconds()}set loopEnd(e){this._loopEnd=this.toTicks(e)}get loop(){return this._loop.get(this.now())}set loop(e){this._loop.set(e,this.now())}setLoopPoints(e,t){return this.loopStart=e,this.loopEnd=t,this}get swing(){return this._swingAmount}set swing(e){this._swingAmount=e}get swingSubdivision(){return new $e(this.context,this._swingTicks).toNotation()}set swingSubdivision(e){this._swingTicks=this.toTicks(e)}get position(){const e=this.now(),t=this._clock.getTicksAtTime(e);return new $e(this.context,t).toBarsBeatsSixteenths()}set position(e){const t=this.toTicks(e);this.ticks=t}get seconds(){return this._clock.seconds}set seconds(e){const t=this.now(),a=this._clock.frequency.timeToTicks(e,t);this.ticks=a}get progress(){if(this.loop){const e=this.now();return(this._clock.getTicksAtTime(e)-this._loopStart)/(this._loopEnd-this._loopStart)}else return 0}get ticks(){return this._clock.ticks}set ticks(e){if(this._clock.ticks!==e){const t=this.now();if(this.state==="started"){const a=this._clock.getTicksAtTime(t),i=this._clock.frequency.getDurationOfTicks(Math.ceil(a)-a,t),o=t+i;this.emit("stop",o),this._clock.setTicksAtTime(e,o),this.emit("start",o,this._clock.getSecondsAtTime(o))}else this.emit("ticks",t),this._clock.setTicksAtTime(e,t)}}getTicksAtTime(e){return this._clock.getTicksAtTime(e)}getSecondsAtTime(e){return this._clock.getSecondsAtTime(e)}get PPQ(){return this._clock.frequency.multiplier}set PPQ(e){this._clock.frequency.multiplier=e}nextSubdivision(e){if(e=this.toTicks(e),this.state!=="started")return 0;{const t=this.now(),a=this.getTicksAtTime(t),i=e-a%e;return this._clock.nextTickTime(i,t)}}syncSignal(e,t){const a=this.now();let i=this.bpm,o=1/(60/i.getValueAtTime(a)/this.PPQ),s=[];if(e.units==="time"){const l=.015625/o,c=new re(l),h=new el(-1),d=new re(l);i.chain(c,h,d),i=d,o=1/o,s=[c,h,d]}t||(e.getValueAtTime(a)!==0?t=e.getValueAtTime(a)/o:t=0);const r=new re(t);return i.connect(r),r.connect(e._param),s.push(r),this._syncedSignals.push({initial:e.value,nodes:s,signal:e}),e.value=0,this}unsyncSignal(e){for(let t=this._syncedSignals.length-1;t>=0;t--){const a=this._syncedSignals[t];a.signal===e&&(a.nodes.forEach(i=>i.dispose()),a.signal.value=a.initial,this._syncedSignals.splice(t,1))}return this}dispose(){return super.dispose(),this._clock.dispose(),yh(this,"bpm"),this._timeline.dispose(),this._repeatedEvents.dispose(),this}}ps.mixin(tl);Kr(n=>{n.transport=new tl({context:n})});Jr(n=>{n.transport.dispose()});class at extends ${constructor(e){super(e),this.input=void 0,this._state=new gs("stopped"),this._synced=!1,this._scheduled=[],this._syncedStart=_e,this._syncedStop=_e,this._state.memory=100,this._state.increasing=!0,this._volume=this.output=new Aa({context:this.context,mute:e.mute,volume:e.volume}),this.volume=this._volume.volume,fe(this,"volume"),this.onstop=e.onstop}static getDefaults(){return Object.assign($.getDefaults(),{mute:!1,onstop:_e,volume:0})}get state(){return this._synced?this.context.transport.state==="started"?this._state.getValueAtTime(this.context.transport.seconds):"stopped":this._state.getValueAtTime(this.now())}get mute(){return this._volume.mute}set mute(e){this._volume.mute=e}_clampToCurrentTime(e){return this._synced?e:Math.max(e,this.context.currentTime)}start(e,t,a){let i=Ft(e)&&this._synced?this.context.transport.seconds:this.toSeconds(e);if(i=this._clampToCurrentTime(i),!this._synced&&this._state.getValueAtTime(i)==="started")ne(Fi(i,this._state.get(i).time),"Start time must be strictly greater than previous start time"),this._state.cancel(i),this._state.setStateAtTime("started",i),this.log("restart",i),this.restart(i,t,a);else if(this.log("start",i),this._state.setStateAtTime("started",i),this._synced){const o=this._state.get(i);o&&(o.offset=this.toSeconds(Cn(t,0)),o.duration=a?this.toSeconds(a):void 0);const s=this.context.transport.schedule(r=>{this._start(r,t,a)},i);this._scheduled.push(s),this.context.transport.state==="started"&&this.context.transport.getSecondsAtTime(this.immediate())>i&&this._syncedStart(this.now(),this.context.transport.seconds)}else Gp(this.context),this._start(i,t,a);return this}stop(e){let t=Ft(e)&&this._synced?this.context.transport.seconds:this.toSeconds(e);if(t=this._clampToCurrentTime(t),this._state.getValueAtTime(t)==="started"||me(this._state.getNextState("started",t))){if(this.log("stop",t),!this._synced)this._stop(t);else{const a=this.context.transport.schedule(this._stop.bind(this),t);this._scheduled.push(a)}this._state.cancel(t),this._state.setStateAtTime("stopped",t)}return this}restart(e,t,a){return e=this.toSeconds(e),this._state.getValueAtTime(e)==="started"&&(this._state.cancel(e),this._restart(e,t,a)),this}sync(){return this._synced||(this._synced=!0,this._syncedStart=(e,t)=>{if(Fi(t,0)){const a=this._state.get(t);if(a&&a.state==="started"&&a.time!==t){const i=t-this.toSeconds(a.time);let o;a.duration&&(o=this.toSeconds(a.duration)-i),this._start(e,this.toSeconds(a.offset)+i,o)}}},this._syncedStop=e=>{const t=this.context.transport.getSecondsAtTime(Math.max(e-this.sampleTime,0));this._state.getValueAtTime(t)==="started"&&this._stop(e)},this.context.transport.on("start",this._syncedStart),this.context.transport.on("loopStart",this._syncedStart),this.context.transport.on("stop",this._syncedStop),this.context.transport.on("pause",this._syncedStop),this.context.transport.on("loopEnd",this._syncedStop)),this}unsync(){return this._synced&&(this.context.transport.off("stop",this._syncedStop),this.context.transport.off("pause",this._syncedStop),this.context.transport.off("loopEnd",this._syncedStop),this.context.transport.off("start",this._syncedStart),this.context.transport.off("loopStart",this._syncedStart)),this._synced=!1,this._scheduled.forEach(e=>this.context.transport.clear(e)),this._scheduled=[],this._state.cancel(0),this._stop(0),this}dispose(){return super.dispose(),this.onstop=_e,this.unsync(),this._volume.dispose(),this._state.dispose(),this}}class ys extends Li{constructor(){const e=q(ys.getDefaults(),arguments,["url","onload"]);super(e),this.name="ToneBufferSource",this._source=this.context.createBufferSource(),this._internalChannels=[this._source],this._sourceStarted=!1,this._sourceStopped=!1,Lt(this._source,this._gainNode),this._source.onended=()=>this._stopSource(),this.playbackRate=new pe({context:this.context,param:this._source.playbackRate,units:"positive",value:e.playbackRate}),this.loop=e.loop,this.loopStart=e.loopStart,this.loopEnd=e.loopEnd,this._buffer=new Ae(e.url,e.onload,e.onerror),this._internalChannels.push(this._source)}static getDefaults(){return Object.assign(Li.getDefaults(),{url:new Ae,loop:!1,loopEnd:0,loopStart:0,onload:_e,onerror:_e,playbackRate:1})}get fadeIn(){return this._fadeIn}set fadeIn(e){this._fadeIn=e}get fadeOut(){return this._fadeOut}set fadeOut(e){this._fadeOut=e}get curve(){return this._curve}set curve(e){this._curve=e}start(e,t,a,i=1){ne(this.buffer.loaded,"buffer is either not set or not loaded");const o=this.toSeconds(e);this._startGain(o,i),this.loop?t=Cn(t,this.loopStart):t=Cn(t,0);let s=Math.max(this.toSeconds(t),0);if(this.loop){const r=this.toSeconds(this.loopEnd)||this.buffer.duration,l=this.toSeconds(this.loopStart),c=r-l;_c(s,r)&&(s=(s-l)%c+l),sn(s,this.buffer.duration)&&(s=0)}if(this._source.buffer=this.buffer.get(),this._source.loopEnd=this.toSeconds(this.loopEnd)||this.buffer.duration,mr(s,this.buffer.duration)&&(this._sourceStarted=!0,this._source.start(o,s)),me(a)){let r=this.toSeconds(a);r=Math.max(r,0),this.stop(o+r)}return this}_stopSource(e){!this._sourceStopped&&this._sourceStarted&&(this._sourceStopped=!0,this._source.stop(this.toSeconds(e)),this._onended())}get loopStart(){return this._source.loopStart}set loopStart(e){this._source.loopStart=this.toSeconds(e)}get loopEnd(){return this._source.loopEnd}set loopEnd(e){this._source.loopEnd=this.toSeconds(e)}get buffer(){return this._buffer}set buffer(e){this._buffer.set(e)}get loop(){return this._source.loop}set loop(e){this._source.loop=e,this._sourceStarted&&this.cancelStop()}dispose(){return super.dispose(),this._source.onended=null,this._source.disconnect(),this._buffer.dispose(),this.playbackRate.dispose(),this}}class Ya extends at{constructor(){const e=q(Ya.getDefaults(),arguments,["type"]);super(e),this.name="Noise",this._source=null,this._playbackRate=e.playbackRate,this.type=e.type,this._fadeIn=e.fadeIn,this._fadeOut=e.fadeOut}static getDefaults(){return Object.assign(at.getDefaults(),{fadeIn:0,fadeOut:0,playbackRate:1,type:"white"})}get type(){return this._type}set type(e){if(ne(e in iu,"Noise: invalid type: "+e),this._type!==e&&(this._type=e,this.state==="started")){const t=this.now();this._stop(t),this._start(t)}}get playbackRate(){return this._playbackRate}set playbackRate(e){this._playbackRate=e,this._source&&(this._source.playbackRate.value=e)}_start(e){const t=iu[this._type];this._source=new ys({url:t,context:this.context,fadeIn:this._fadeIn,fadeOut:this._fadeOut,loop:!0,onended:()=>this.onstop(this),playbackRate:this._playbackRate}).connect(this.output),this._source.start(this.toSeconds(e),Math.random()*(t.duration-.001))}_stop(e){this._source&&(this._source.stop(this.toSeconds(e)),this._source=null)}get fadeIn(){return this._fadeIn}set fadeIn(e){this._fadeIn=e,this._source&&(this._source.fadeIn=this._fadeIn)}get fadeOut(){return this._fadeOut}set fadeOut(e){this._fadeOut=e,this._source&&(this._source.fadeOut=this._fadeOut)}_restart(e){this._stop(e),this._start(e)}dispose(){return super.dispose(),this._source&&this._source.disconnect(),this}}const mi=44100*5,Gl=2,Ln={brown:null,pink:null,white:null},iu={get brown(){if(!Ln.brown){const n=[];for(let e=0;e<Gl;e++){const t=new Float32Array(mi);n[e]=t;let a=0;for(let i=0;i<mi;i++){const o=Math.random()*2-1;t[i]=(a+.02*o)/1.02,a=t[i],t[i]*=3.5}}Ln.brown=new Ae().fromArray(n)}return Ln.brown},get pink(){if(!Ln.pink){const n=[];for(let e=0;e<Gl;e++){const t=new Float32Array(mi);n[e]=t;let a,i,o,s,r,l,c;a=i=o=s=r=l=c=0;for(let h=0;h<mi;h++){const d=Math.random()*2-1;a=.99886*a+d*.0555179,i=.99332*i+d*.0750759,o=.969*o+d*.153852,s=.8665*s+d*.3104856,r=.55*r+d*.5329522,l=-.7616*l-d*.016898,t[h]=a+i+o+s+r+l+c+d*.5362,t[h]*=.11,c=d*.115926}}Ln.pink=new Ae().fromArray(n)}return Ln.pink},get white(){if(!Ln.white){const n=[];for(let e=0;e<Gl;e++){const t=new Float32Array(mi);n[e]=t;for(let a=0;a<mi;a++)t[a]=Math.random()*2-1}Ln.white=new Ae().fromArray(n)}return Ln.white}};class Di extends ${constructor(){const e=q(Di.getDefaults(),arguments,["volume"]);super(e),this.name="UserMedia",this._volume=this.output=new Aa({context:this.context,volume:e.volume}),this.volume=this._volume.volume,fe(this,"volume"),this.mute=e.mute}static getDefaults(){return Object.assign($.getDefaults(),{mute:!1,volume:0})}open(e){return Ne(this,void 0,void 0,function*(){ne(Di.supported,"UserMedia is not supported"),this.state==="started"&&this.close();const t=yield Di.enumerateDevices();Xt(e)?this._device=t[e]:(this._device=t.find(o=>o.label===e||o.deviceId===e),!this._device&&t.length>0&&(this._device=t[0]),ne(me(this._device),`No matching device ${e}`));const a={audio:{echoCancellation:!1,sampleRate:this.context.sampleRate,noiseSuppression:!1,mozNoiseSuppression:!1}};this._device&&(a.audio.deviceId=this._device.deviceId);const i=yield navigator.mediaDevices.getUserMedia(a);if(!this._stream){this._stream=i;const o=this.context.createMediaStreamSource(i);Lt(o,this.output),this._mediaStream=o}return this})}close(){return this._stream&&this._mediaStream&&(this._stream.getAudioTracks().forEach(e=>{e.stop()}),this._stream=void 0,this._mediaStream.disconnect(),this._mediaStream=void 0),this._device=void 0,this}static enumerateDevices(){return Ne(this,void 0,void 0,function*(){return(yield navigator.mediaDevices.enumerateDevices()).filter(t=>t.kind==="audioinput")})}get state(){return this._stream&&this._stream.active?"started":"stopped"}get deviceId(){if(this._device)return this._device.deviceId}get groupId(){if(this._device)return this._device.groupId}get label(){if(this._device)return this._device.label}get mute(){return this._volume.mute}set mute(e){this._volume.mute=e}dispose(){return super.dispose(),this.close(),this._volume.dispose(),this.volume.dispose(),this}static get supported(){return me(navigator.mediaDevices)&&me(navigator.mediaDevices.getUserMedia)}}function si(n,e){return Ne(this,void 0,void 0,function*(){const t=e/n.context.sampleRate,a=new Zr(1,t,n.context.sampleRate);return new n.constructor(Object.assign(n.get(),{frequency:2/t,detune:0,context:a})).toDestination().start(0),(yield a.render()).getChannelData(0)})}class Ah extends Li{constructor(){const e=q(Ah.getDefaults(),arguments,["frequency","type"]);super(e),this.name="ToneOscillatorNode",this._oscillator=this.context.createOscillator(),this._internalChannels=[this._oscillator],Lt(this._oscillator,this._gainNode),this.type=e.type,this.frequency=new pe({context:this.context,param:this._oscillator.frequency,units:"frequency",value:e.frequency}),this.detune=new pe({context:this.context,param:this._oscillator.detune,units:"cents",value:e.detune}),fe(this,["frequency","detune"])}static getDefaults(){return Object.assign(Li.getDefaults(),{detune:0,frequency:440,type:"sine"})}start(e){const t=this.toSeconds(e);return this.log("start",t),this._startGain(t),this._oscillator.start(t),this}_stopSource(e){this._oscillator.stop(e)}setPeriodicWave(e){return this._oscillator.setPeriodicWave(e),this}get type(){return this._oscillator.type}set type(e){this._oscillator.type=e}dispose(){return super.dispose(),this.state==="started"&&this.stop(),this._oscillator.disconnect(),this.frequency.dispose(),this.detune.dispose(),this}}class We extends at{constructor(){const e=q(We.getDefaults(),arguments,["frequency","type"]);super(e),this.name="Oscillator",this._oscillator=null,this.frequency=new be({context:this.context,units:"frequency",value:e.frequency}),fe(this,"frequency"),this.detune=new be({context:this.context,units:"cents",value:e.detune}),fe(this,"detune"),this._partials=e.partials,this._partialCount=e.partialCount,this._type=e.type,e.partialCount&&e.type!=="custom"&&(this._type=this.baseType+e.partialCount.toString()),this.phase=e.phase}static getDefaults(){return Object.assign(at.getDefaults(),{detune:0,frequency:440,partialCount:0,partials:[],phase:0,type:"sine"})}_start(e){const t=this.toSeconds(e),a=new Ah({context:this.context,onended:()=>this.onstop(this)});this._oscillator=a,this._wave?this._oscillator.setPeriodicWave(this._wave):this._oscillator.type=this._type,this._oscillator.connect(this.output),this.frequency.connect(this._oscillator.frequency),this.detune.connect(this._oscillator.detune),this._oscillator.start(t)}_stop(e){const t=this.toSeconds(e);this._oscillator&&this._oscillator.stop(t)}_restart(e){const t=this.toSeconds(e);return this.log("restart",t),this._oscillator&&this._oscillator.cancelStop(),this._state.cancel(t),this}syncFrequency(){return this.context.transport.syncSignal(this.frequency),this}unsyncFrequency(){return this.context.transport.unsyncSignal(this.frequency),this}_getCachedPeriodicWave(){if(this._type==="custom")return We._periodicWaveCache.find(t=>t.phase===this._phase&&z_(t.partials,this._partials));{const e=We._periodicWaveCache.find(t=>t.type===this._type&&t.phase===this._phase);return this._partialCount=e?e.partialCount:this._partialCount,e}}get type(){return this._type}set type(e){this._type=e;const t=["sine","square","sawtooth","triangle"].indexOf(e)!==-1;if(this._phase===0&&t)this._wave=void 0,this._partialCount=0,this._oscillator!==null&&(this._oscillator.type=e);else{const a=this._getCachedPeriodicWave();if(me(a)){const{partials:i,wave:o}=a;this._wave=o,this._partials=i,this._oscillator!==null&&this._oscillator.setPeriodicWave(this._wave)}else{const[i,o]=this._getRealImaginary(e,this._phase),s=this.context.createPeriodicWave(i,o);this._wave=s,this._oscillator!==null&&this._oscillator.setPeriodicWave(this._wave),We._periodicWaveCache.push({imag:o,partialCount:this._partialCount,partials:this._partials,phase:this._phase,real:i,type:this._type,wave:this._wave}),We._periodicWaveCache.length>100&&We._periodicWaveCache.shift()}}}get baseType(){return this._type.replace(this.partialCount.toString(),"")}set baseType(e){this.partialCount&&this._type!=="custom"&&e!=="custom"?this.type=e+this.partialCount:this.type=e}get partialCount(){return this._partialCount}set partialCount(e){Qt(e,0);let t=this._type;const a=/^(sine|triangle|square|sawtooth)(\d+)$/.exec(this._type);if(a&&(t=a[1]),this._type!=="custom")e===0?this.type=t:this.type=t+e.toString();else{const i=new Float32Array(e);this._partials.forEach((o,s)=>i[s]=o),this._partials=Array.from(i),this.type=this._type}}_getRealImaginary(e,t){let i=2048;const o=new Float32Array(i),s=new Float32Array(i);let r=1;if(e==="custom"){if(r=this._partials.length+1,this._partialCount=this._partials.length,i=r,this._partials.length===0)return[o,s]}else{const l=/^(sine|triangle|square|sawtooth)(\d+)$/.exec(e);l?(r=parseInt(l[2],10)+1,this._partialCount=parseInt(l[2],10),e=l[1],r=Math.max(r,2),i=r):this._partialCount=0,this._partials=[]}for(let l=1;l<i;++l){const c=2/(l*Math.PI);let h;switch(e){case"sine":h=l<=r?1:0,this._partials[l-1]=h;break;case"square":h=l&1?2*c:0,this._partials[l-1]=h;break;case"sawtooth":h=c*(l&1?1:-1),this._partials[l-1]=h;break;case"triangle":l&1?h=2*(c*c)*(l-1>>1&1?-1:1):h=0,this._partials[l-1]=h;break;case"custom":h=this._partials[l-1];break;default:throw new TypeError("Oscillator: invalid type: "+e)}h!==0?(o[l]=-h*Math.sin(t*l),s[l]=h*Math.cos(t*l)):(o[l]=0,s[l]=0)}return[o,s]}_inverseFFT(e,t,a){let i=0;const o=e.length;for(let s=0;s<o;s++)i+=e[s]*Math.cos(s*a)+t[s]*Math.sin(s*a);return i}getInitialValue(){const[e,t]=this._getRealImaginary(this._type,0);let a=0;const i=Math.PI*2,o=32;for(let s=0;s<o;s++)a=Math.max(this._inverseFFT(e,t,s/o*i),a);return oi(-this._inverseFFT(e,t,this._phase)/a,-1,1)}get partials(){return this._partials.slice(0,this.partialCount)}set partials(e){this._partials=e,this._partialCount=this._partials.length,e.length&&(this.type="custom")}get phase(){return this._phase*(180/Math.PI)}set phase(e){this._phase=e*Math.PI/180,this.type=this._type}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this._oscillator!==null&&this._oscillator.dispose(),this._wave=void 0,this.frequency.dispose(),this.detune.dispose(),this}}We._periodicWaveCache=[];class Qp extends Gt{constructor(){super(...arguments),this.name="AudioToGain",this._norm=new Ca({context:this.context,mapping:e=>(e+1)/2}),this.input=this._norm,this.output=this._norm}dispose(){return super.dispose(),this._norm.dispose(),this}}class tt extends be{constructor(){const e=q(tt.getDefaults(),arguments,["value"]);super(e),this.name="Multiply",this.override=!1,this._mult=this.input=this.output=new re({context:this.context,minValue:e.minValue,maxValue:e.maxValue}),this.factor=this._param=this._mult.gain,this.factor.setValueAtTime(e.value,0)}static getDefaults(){return Object.assign(be.getDefaults(),{value:0})}dispose(){return super.dispose(),this._mult.dispose(),this}}class nl extends at{constructor(){const e=q(nl.getDefaults(),arguments,["frequency","type","modulationType"]);super(e),this.name="AMOscillator",this._modulationScale=new Qp({context:this.context}),this._modulationNode=new re({context:this.context}),this._carrier=new We({context:this.context,detune:e.detune,frequency:e.frequency,onstop:()=>this.onstop(this),phase:e.phase,type:e.type}),this.frequency=this._carrier.frequency,this.detune=this._carrier.detune,this._modulator=new We({context:this.context,phase:e.phase,type:e.modulationType}),this.harmonicity=new tt({context:this.context,units:"positive",value:e.harmonicity}),this.frequency.chain(this.harmonicity,this._modulator.frequency),this._modulator.chain(this._modulationScale,this._modulationNode.gain),this._carrier.chain(this._modulationNode,this.output),fe(this,["frequency","detune","harmonicity"])}static getDefaults(){return Object.assign(We.getDefaults(),{harmonicity:1,modulationType:"square"})}_start(e){this._modulator.start(e),this._carrier.start(e)}_stop(e){this._modulator.stop(e),this._carrier.stop(e)}_restart(e){this._modulator.restart(e),this._carrier.restart(e)}get type(){return this._carrier.type}set type(e){this._carrier.type=e}get baseType(){return this._carrier.baseType}set baseType(e){this._carrier.baseType=e}get partialCount(){return this._carrier.partialCount}set partialCount(e){this._carrier.partialCount=e}get modulationType(){return this._modulator.type}set modulationType(e){this._modulator.type=e}get phase(){return this._carrier.phase}set phase(e){this._carrier.phase=e,this._modulator.phase=e}get partials(){return this._carrier.partials}set partials(e){this._carrier.partials=e}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this.frequency.dispose(),this.detune.dispose(),this.harmonicity.dispose(),this._carrier.dispose(),this._modulator.dispose(),this._modulationNode.dispose(),this._modulationScale.dispose(),this}}class al extends at{constructor(){const e=q(al.getDefaults(),arguments,["frequency","type","modulationType"]);super(e),this.name="FMOscillator",this._modulationNode=new re({context:this.context,gain:0}),this._carrier=new We({context:this.context,detune:e.detune,frequency:0,onstop:()=>this.onstop(this),phase:e.phase,type:e.type}),this.detune=this._carrier.detune,this.frequency=new be({context:this.context,units:"frequency",value:e.frequency}),this._modulator=new We({context:this.context,phase:e.phase,type:e.modulationType}),this.harmonicity=new tt({context:this.context,units:"positive",value:e.harmonicity}),this.modulationIndex=new tt({context:this.context,units:"positive",value:e.modulationIndex}),this.frequency.connect(this._carrier.frequency),this.frequency.chain(this.harmonicity,this._modulator.frequency),this.frequency.chain(this.modulationIndex,this._modulationNode),this._modulator.connect(this._modulationNode.gain),this._modulationNode.connect(this._carrier.frequency),this._carrier.connect(this.output),this.detune.connect(this._modulator.detune),fe(this,["modulationIndex","frequency","detune","harmonicity"])}static getDefaults(){return Object.assign(We.getDefaults(),{harmonicity:1,modulationIndex:2,modulationType:"square"})}_start(e){this._modulator.start(e),this._carrier.start(e)}_stop(e){this._modulator.stop(e),this._carrier.stop(e)}_restart(e){return this._modulator.restart(e),this._carrier.restart(e),this}get type(){return this._carrier.type}set type(e){this._carrier.type=e}get baseType(){return this._carrier.baseType}set baseType(e){this._carrier.baseType=e}get partialCount(){return this._carrier.partialCount}set partialCount(e){this._carrier.partialCount=e}get modulationType(){return this._modulator.type}set modulationType(e){this._modulator.type=e}get phase(){return this._carrier.phase}set phase(e){this._carrier.phase=e,this._modulator.phase=e}get partials(){return this._carrier.partials}set partials(e){this._carrier.partials=e}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this.frequency.dispose(),this.harmonicity.dispose(),this._carrier.dispose(),this._modulator.dispose(),this._modulationNode.dispose(),this.modulationIndex.dispose(),this}}class bs extends at{constructor(){const e=q(bs.getDefaults(),arguments,["frequency","width"]);super(e),this.name="PulseOscillator",this._widthGate=new re({context:this.context,gain:0}),this._thresh=new Ca({context:this.context,mapping:t=>t<=0?-1:1}),this.width=new be({context:this.context,units:"audioRange",value:e.width}),this._triangle=new We({context:this.context,detune:e.detune,frequency:e.frequency,onstop:()=>this.onstop(this),phase:e.phase,type:"triangle"}),this.frequency=this._triangle.frequency,this.detune=this._triangle.detune,this._triangle.chain(this._thresh,this.output),this.width.chain(this._widthGate,this._thresh),fe(this,["width","frequency","detune"])}static getDefaults(){return Object.assign(at.getDefaults(),{detune:0,frequency:440,phase:0,type:"pulse",width:.2})}_start(e){e=this.toSeconds(e),this._triangle.start(e),this._widthGate.gain.setValueAtTime(1,e)}_stop(e){e=this.toSeconds(e),this._triangle.stop(e),this._widthGate.gain.cancelScheduledValues(e),this._widthGate.gain.setValueAtTime(0,e)}_restart(e){this._triangle.restart(e),this._widthGate.gain.cancelScheduledValues(e),this._widthGate.gain.setValueAtTime(1,e)}get phase(){return this._triangle.phase}set phase(e){this._triangle.phase=e}get type(){return"pulse"}get baseType(){return"pulse"}get partials(){return[]}get partialCount(){return 0}set carrierType(e){this._triangle.type=e}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this._triangle.dispose(),this.width.dispose(),this._widthGate.dispose(),this._thresh.dispose(),this}}class il extends at{constructor(){const e=q(il.getDefaults(),arguments,["frequency","type","spread"]);super(e),this.name="FatOscillator",this._oscillators=[],this.frequency=new be({context:this.context,units:"frequency",value:e.frequency}),this.detune=new be({context:this.context,units:"cents",value:e.detune}),this._spread=e.spread,this._type=e.type,this._phase=e.phase,this._partials=e.partials,this._partialCount=e.partialCount,this.count=e.count,fe(this,["frequency","detune"])}static getDefaults(){return Object.assign(We.getDefaults(),{count:3,spread:20,type:"sawtooth"})}_start(e){e=this.toSeconds(e),this._forEach(t=>t.start(e))}_stop(e){e=this.toSeconds(e),this._forEach(t=>t.stop(e))}_restart(e){this._forEach(t=>t.restart(e))}_forEach(e){for(let t=0;t<this._oscillators.length;t++)e(this._oscillators[t],t)}get type(){return this._type}set type(e){this._type=e,this._forEach(t=>t.type=e)}get spread(){return this._spread}set spread(e){if(this._spread=e,this._oscillators.length>1){const t=-e/2,a=e/(this._oscillators.length-1);this._forEach((i,o)=>i.detune.value=t+a*o)}}get count(){return this._oscillators.length}set count(e){if(Qt(e,1),this._oscillators.length!==e){this._forEach(t=>t.dispose()),this._oscillators=[];for(let t=0;t<e;t++){const a=new We({context:this.context,volume:-6-e*1.1,type:this._type,phase:this._phase+t/e*360,partialCount:this._partialCount,onstop:t===0?()=>this.onstop(this):_e});this.type==="custom"&&(a.partials=this._partials),this.frequency.connect(a.frequency),this.detune.connect(a.detune),a.detune.overridden=!1,a.connect(this.output),this._oscillators[t]=a}this.spread=this._spread,this.state==="started"&&this._forEach(t=>t.start())}}get phase(){return this._phase}set phase(e){this._phase=e,this._forEach((t,a)=>t.phase=this._phase+a/this.count*360)}get baseType(){return this._oscillators[0].baseType}set baseType(e){this._forEach(t=>t.baseType=e),this._type=this._oscillators[0].type}get partials(){return this._oscillators[0].partials}set partials(e){this._partials=e,this._partialCount=this._partials.length,e.length&&(this._type="custom",this._forEach(t=>t.partials=e))}get partialCount(){return this._oscillators[0].partialCount}set partialCount(e){this._partialCount=e,this._forEach(t=>t.partialCount=e),this._type=this._oscillators[0].type}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this.frequency.dispose(),this.detune.dispose(),this._forEach(e=>e.dispose()),this}}class ol extends at{constructor(){const e=q(ol.getDefaults(),arguments,["frequency","modulationFrequency"]);super(e),this.name="PWMOscillator",this.sourceType="pwm",this._scale=new tt({context:this.context,value:2}),this._pulse=new bs({context:this.context,frequency:e.modulationFrequency}),this._pulse.carrierType="sine",this.modulationFrequency=this._pulse.frequency,this._modulator=new We({context:this.context,detune:e.detune,frequency:e.frequency,onstop:()=>this.onstop(this),phase:e.phase}),this.frequency=this._modulator.frequency,this.detune=this._modulator.detune,this._modulator.chain(this._scale,this._pulse.width),this._pulse.connect(this.output),fe(this,["modulationFrequency","frequency","detune"])}static getDefaults(){return Object.assign(at.getDefaults(),{detune:0,frequency:440,modulationFrequency:.4,phase:0,type:"pwm"})}_start(e){e=this.toSeconds(e),this._modulator.start(e),this._pulse.start(e)}_stop(e){e=this.toSeconds(e),this._modulator.stop(e),this._pulse.stop(e)}_restart(e){this._modulator.restart(e),this._pulse.restart(e)}get type(){return"pwm"}get baseType(){return"pwm"}get partials(){return[]}get partialCount(){return 0}get phase(){return this._modulator.phase}set phase(e){this._modulator.phase=e}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this._pulse.dispose(),this._scale.dispose(),this._modulator.dispose(),this}}const ou={am:nl,fat:il,fm:al,oscillator:We,pulse:bs,pwm:ol};class _a extends at{constructor(){const e=q(_a.getDefaults(),arguments,["frequency","type"]);super(e),this.name="OmniOscillator",this.frequency=new be({context:this.context,units:"frequency",value:e.frequency}),this.detune=new be({context:this.context,units:"cents",value:e.detune}),fe(this,["frequency","detune"]),this.set(e)}static getDefaults(){return Object.assign(We.getDefaults(),al.getDefaults(),nl.getDefaults(),il.getDefaults(),bs.getDefaults(),ol.getDefaults())}_start(e){this._oscillator.start(e)}_stop(e){this._oscillator.stop(e)}_restart(e){return this._oscillator.restart(e),this}get type(){let e="";return["am","fm","fat"].some(t=>this._sourceType===t)&&(e=this._sourceType),e+this._oscillator.type}set type(e){e.substr(0,2)==="fm"?(this._createNewOscillator("fm"),this._oscillator=this._oscillator,this._oscillator.type=e.substr(2)):e.substr(0,2)==="am"?(this._createNewOscillator("am"),this._oscillator=this._oscillator,this._oscillator.type=e.substr(2)):e.substr(0,3)==="fat"?(this._createNewOscillator("fat"),this._oscillator=this._oscillator,this._oscillator.type=e.substr(3)):e==="pwm"?(this._createNewOscillator("pwm"),this._oscillator=this._oscillator):e==="pulse"?this._createNewOscillator("pulse"):(this._createNewOscillator("oscillator"),this._oscillator=this._oscillator,this._oscillator.type=e)}get partials(){return this._oscillator.partials}set partials(e){!this._getOscType(this._oscillator,"pulse")&&!this._getOscType(this._oscillator,"pwm")&&(this._oscillator.partials=e)}get partialCount(){return this._oscillator.partialCount}set partialCount(e){!this._getOscType(this._oscillator,"pulse")&&!this._getOscType(this._oscillator,"pwm")&&(this._oscillator.partialCount=e)}set(e){return Reflect.has(e,"type")&&e.type&&(this.type=e.type),super.set(e),this}_createNewOscillator(e){if(e!==this._sourceType){this._sourceType=e;const t=ou[e],a=this.now();if(this._oscillator){const i=this._oscillator;i.stop(a),this.context.setTimeout(()=>i.dispose(),this.blockTime)}this._oscillator=new t({context:this.context}),this.frequency.connect(this._oscillator.frequency),this.detune.connect(this._oscillator.detune),this._oscillator.connect(this.output),this._oscillator.onstop=()=>this.onstop(this),this.state==="started"&&this._oscillator.start(a)}}get phase(){return this._oscillator.phase}set phase(e){this._oscillator.phase=e}get sourceType(){return this._sourceType}set sourceType(e){let t="sine";this._oscillator.type!=="pwm"&&this._oscillator.type!=="pulse"&&(t=this._oscillator.type),e==="fm"?this.type="fm"+t:e==="am"?this.type="am"+t:e==="fat"?this.type="fat"+t:e==="oscillator"?this.type=t:e==="pulse"?this.type="pulse":e==="pwm"&&(this.type="pwm")}_getOscType(e,t){return e instanceof ou[t]}get baseType(){return this._oscillator.baseType}set baseType(e){!this._getOscType(this._oscillator,"pulse")&&!this._getOscType(this._oscillator,"pwm")&&e!=="pulse"&&e!=="pwm"&&(this._oscillator.baseType=e)}get width(){if(this._getOscType(this._oscillator,"pulse"))return this._oscillator.width}get count(){if(this._getOscType(this._oscillator,"fat"))return this._oscillator.count}set count(e){this._getOscType(this._oscillator,"fat")&&Xt(e)&&(this._oscillator.count=e)}get spread(){if(this._getOscType(this._oscillator,"fat"))return this._oscillator.spread}set spread(e){this._getOscType(this._oscillator,"fat")&&Xt(e)&&(this._oscillator.spread=e)}get modulationType(){if(this._getOscType(this._oscillator,"fm")||this._getOscType(this._oscillator,"am"))return this._oscillator.modulationType}set modulationType(e){(this._getOscType(this._oscillator,"fm")||this._getOscType(this._oscillator,"am"))&&Pn(e)&&(this._oscillator.modulationType=e)}get modulationIndex(){if(this._getOscType(this._oscillator,"fm"))return this._oscillator.modulationIndex}get harmonicity(){if(this._getOscType(this._oscillator,"fm")||this._getOscType(this._oscillator,"am"))return this._oscillator.harmonicity}get modulationFrequency(){if(this._getOscType(this._oscillator,"pwm"))return this._oscillator.modulationFrequency}asArray(){return Ne(this,arguments,void 0,function*(e=1024){return si(this,e)})}dispose(){return super.dispose(),this.detune.dispose(),this.frequency.dispose(),this._oscillator.dispose(),this}}class vs extends be{constructor(){super(q(vs.getDefaults(),arguments,["value"])),this.override=!1,this.name="Add",this._sum=new re({context:this.context}),this.input=this._sum,this.output=this._sum,this.addend=this._param,Nn(this._constantSource,this._sum)}static getDefaults(){return Object.assign(be.getDefaults(),{value:0})}dispose(){return super.dispose(),this._sum.dispose(),this}}class sl extends Gt{constructor(){const e=q(sl.getDefaults(),arguments,["min","max"]);super(e),this.name="Scale",this._mult=this.input=new tt({context:this.context,value:e.max-e.min}),this._add=this.output=new vs({context:this.context,value:e.min}),this._min=e.min,this._max=e.max,this.input.connect(this.output)}static getDefaults(){return Object.assign(Gt.getDefaults(),{max:1,min:0})}get min(){return this._min}set min(e){this._min=e,this._setRange()}get max(){return this._max}set max(e){this._max=e,this._setRange()}_setRange(){this._add.value=this._min,this._mult.value=this._max-this._min}dispose(){return super.dispose(),this._add.dispose(),this._mult.dispose(),this}}class Ch extends Gt{constructor(){super(q(Ch.getDefaults(),arguments)),this.name="Zero",this._gain=new re({context:this.context}),this.output=this._gain,this.input=void 0,Lt(this.context.getConstant(0),this._gain)}dispose(){return super.dispose(),Xp(this.context.getConstant(0),this._gain),this}}class Mh extends ${constructor(){const e=q(Mh.getDefaults(),arguments,["frequency","min","max"]);super(e),this.name="LFO",this._stoppedValue=0,this._units="number",this.convert=!0,this._fromType=pe.prototype._fromType,this._toType=pe.prototype._toType,this._is=pe.prototype._is,this._clampValue=pe.prototype._clampValue,this._oscillator=new We(e),this.frequency=this._oscillator.frequency,this._amplitudeGain=new re({context:this.context,gain:e.amplitude,units:"normalRange"}),this.amplitude=this._amplitudeGain.gain,this._stoppedSignal=new be({context:this.context,units:"audioRange",value:0}),this._zeros=new Ch({context:this.context}),this._a2g=new Qp({context:this.context}),this._scaler=this.output=new sl({context:this.context,max:e.max,min:e.min}),this.units=e.units,this.min=e.min,this.max=e.max,this._oscillator.chain(this._amplitudeGain,this._a2g,this._scaler),this._zeros.connect(this._a2g),this._stoppedSignal.connect(this._a2g),fe(this,["amplitude","frequency"]),this.phase=e.phase}static getDefaults(){return Object.assign(We.getDefaults(),{amplitude:1,frequency:"4n",max:1,min:0,type:"sine",units:"number"})}start(e){return e=this.toSeconds(e),this._stoppedSignal.setValueAtTime(0,e),this._oscillator.start(e),this}stop(e){return e=this.toSeconds(e),this._stoppedSignal.setValueAtTime(this._stoppedValue,e),this._oscillator.stop(e),this}sync(){return this._oscillator.sync(),this._oscillator.syncFrequency(),this}unsync(){return this._oscillator.unsync(),this._oscillator.unsyncFrequency(),this}_setStoppedValue(){this._stoppedValue=this._oscillator.getInitialValue(),this._stoppedSignal.value=this._stoppedValue}get min(){return this._toType(this._scaler.min)}set min(e){e=this._fromType(e),this._scaler.min=e}get max(){return this._toType(this._scaler.max)}set max(e){e=this._fromType(e),this._scaler.max=e}get type(){return this._oscillator.type}set type(e){this._oscillator.type=e,this._setStoppedValue()}get partials(){return this._oscillator.partials}set partials(e){this._oscillator.partials=e,this._setStoppedValue()}get phase(){return this._oscillator.phase}set phase(e){this._oscillator.phase=e,this._setStoppedValue()}get units(){return this._units}set units(e){const t=this.min,a=this.max;this._units=e,this.min=t,this.max=a}get state(){return this._oscillator.state}connect(e,t,a){return(e instanceof pe||e instanceof be)&&(this.convert=e.convert,this.units=e.units),Xr(this,e,t,a),this}dispose(){return super.dispose(),this._oscillator.dispose(),this._stoppedSignal.dispose(),this._zeros.dispose(),this._scaler.dispose(),this._a2g.dispose(),this._amplitudeGain.dispose(),this.amplitude.dispose(),this}}function ef(n,e=1/0){const t=new WeakMap;return function(a,i){Reflect.defineProperty(a,i,{configurable:!0,enumerable:!0,get:function(){return t.get(this)},set:function(o){Qt(o,n,e),t.set(this,o)}})}}function ta(n,e=1/0){const t=new WeakMap;return function(a,i){Reflect.defineProperty(a,i,{configurable:!0,enumerable:!0,get:function(){return t.get(this)},set:function(o){Qt(this.toSeconds(o),n,e),t.set(this,o)}})}}class rl extends at{constructor(){const e=q(rl.getDefaults(),arguments,["url","onload"]);super(e),this.name="Player",this._activeSources=new Set,this._buffer=new Ae({onload:this._onload.bind(this,e.onload),onerror:e.onerror,reverse:e.reverse,url:e.url}),this.autostart=e.autostart,this._loop=e.loop,this._loopStart=e.loopStart,this._loopEnd=e.loopEnd,this._playbackRate=e.playbackRate,this.fadeIn=e.fadeIn,this.fadeOut=e.fadeOut}static getDefaults(){return Object.assign(at.getDefaults(),{autostart:!1,fadeIn:0,fadeOut:0,loop:!1,loopEnd:0,loopStart:0,onload:_e,onerror:_e,playbackRate:1,reverse:!1})}load(e){return Ne(this,void 0,void 0,function*(){return yield this._buffer.load(e),this._onload(),this})}_onload(e=_e){e(),this.autostart&&this.start()}_onSourceEnd(e){this.onstop(this),this._activeSources.delete(e),this._activeSources.size===0&&!this._synced&&this._state.getValueAtTime(this.now())==="started"&&(this._state.cancel(this.now()),this._state.setStateAtTime("stopped",this.now()))}start(e,t,a){return super.start(e,t,a),this}_start(e,t,a){this._loop?t=Cn(t,this._loopStart):t=Cn(t,0);const i=this.toSeconds(t),o=a;a=Cn(a,Math.max(this._buffer.duration-i,0));let s=this.toSeconds(a);s=s/this._playbackRate,e=this.toSeconds(e);const r=new ys({url:this._buffer,context:this.context,fadeIn:this.fadeIn,fadeOut:this.fadeOut,loop:this._loop,loopEnd:this._loopEnd,loopStart:this._loopStart,onended:this._onSourceEnd.bind(this),playbackRate:this._playbackRate}).connect(this.output);!this._loop&&!this._synced&&(this._state.cancel(e+s),this._state.setStateAtTime("stopped",e+s,{implicitEnd:!0})),this._activeSources.add(r),this._loop&&Ft(o)?r.start(e,i):r.start(e,i,s-this.toSeconds(this.fadeOut))}_stop(e){const t=this.toSeconds(e);this._activeSources.forEach(a=>a.stop(t))}restart(e,t,a){return super.restart(e,t,a),this}_restart(e,t,a){var i;(i=[...this._activeSources].pop())===null||i===void 0||i.stop(e),this._start(e,t,a)}seek(e,t){const a=this.toSeconds(t);if(this._state.getValueAtTime(a)==="started"){const i=this.toSeconds(e);this._stop(a),this._start(a,i)}return this}setLoopPoints(e,t){return this.loopStart=e,this.loopEnd=t,this}get loopStart(){return this._loopStart}set loopStart(e){this._loopStart=e,this.buffer.loaded&&Qt(this.toSeconds(e),0,this.buffer.duration),this._activeSources.forEach(t=>{t.loopStart=e})}get loopEnd(){return this._loopEnd}set loopEnd(e){this._loopEnd=e,this.buffer.loaded&&Qt(this.toSeconds(e),0,this.buffer.duration),this._activeSources.forEach(t=>{t.loopEnd=e})}get buffer(){return this._buffer}set buffer(e){this._buffer.set(e)}get loop(){return this._loop}set loop(e){if(this._loop!==e&&(this._loop=e,this._activeSources.forEach(t=>{t.loop=e}),e)){const t=this._state.getNextState("stopped",this.now());t&&this._state.cancel(t.time)}}get playbackRate(){return this._playbackRate}set playbackRate(e){this._playbackRate=e;const t=this.now(),a=this._state.getNextState("stopped",t);a&&a.implicitEnd&&(this._state.cancel(a.time),this._activeSources.forEach(i=>i.cancelStop())),this._activeSources.forEach(i=>{i.playbackRate.setValueAtTime(e,t)})}get reverse(){return this._buffer.reverse}set reverse(e){this._buffer.reverse=e}get loaded(){return this._buffer.loaded}dispose(){return super.dispose(),this._activeSources.forEach(e=>e.dispose()),this._activeSources.clear(),this._buffer.dispose(),this}}_n([ta(0)],rl.prototype,"fadeIn",void 0);_n([ta(0)],rl.prototype,"fadeOut",void 0);class X_ extends Gt{constructor(){super(...arguments),this.name="Abs",this._abs=new Ca({context:this.context,mapping:e=>Math.abs(e)<.001?0:Math.abs(e)}),this.input=this._abs,this.output=this._abs}dispose(){return super.dispose(),this._abs.dispose(),this}}class Q_ extends Gt{constructor(){super(...arguments),this.name="GainToAudio",this._norm=new Ca({context:this.context,mapping:e=>Math.abs(e)*2-1}),this.input=this._norm,this.output=this._norm}dispose(){return super.dispose(),this._norm.dispose(),this}}class ek extends Gt{constructor(){super(...arguments),this.name="Negate",this._multiply=new tt({context:this.context,value:-1}),this.input=this._multiply,this.output=this._multiply}dispose(){return super.dispose(),this._multiply.dispose(),this}}class Zi extends be{constructor(){super(q(Zi.getDefaults(),arguments,["value"])),this.override=!1,this.name="Subtract",this._sum=new re({context:this.context}),this.input=this._sum,this.output=this._sum,this._neg=new ek({context:this.context}),this.subtrahend=this._param,Nn(this._constantSource,this._neg,this._sum)}static getDefaults(){return Object.assign(be.getDefaults(),{value:0})}dispose(){return super.dispose(),this._neg.dispose(),this._sum.dispose(),this}}class Ih extends Gt{constructor(){super(q(Ih.getDefaults(),arguments)),this.name="GreaterThanZero",this._thresh=this.output=new Ca({context:this.context,length:127,mapping:e=>e<=0?0:1}),this._scale=this.input=new tt({context:this.context,value:1e4}),this._scale.connect(this._thresh)}dispose(){return super.dispose(),this._scale.dispose(),this._thresh.dispose(),this}}class Eh extends be{constructor(){const e=q(Eh.getDefaults(),arguments,["value"]);super(e),this.name="GreaterThan",this.override=!1,this._subtract=this.input=new Zi({context:this.context,value:e.value}),this._gtz=this.output=new Ih({context:this.context}),this.comparator=this._param=this._subtract.subtrahend,fe(this,"comparator"),this._subtract.connect(this._gtz)}static getDefaults(){return Object.assign(be.getDefaults(),{value:0})}dispose(){return super.dispose(),this._gtz.dispose(),this._subtract.dispose(),this.comparator.dispose(),this}}class Rt extends ${constructor(){const e=q(Rt.getDefaults(),arguments,["attack","decay","sustain","release"]);super(e),this.name="Envelope",this._sig=new be({context:this.context,value:0}),this.output=this._sig,this.input=void 0,this.attack=e.attack,this.decay=e.decay,this.sustain=e.sustain,this.release=e.release,this.attackCurve=e.attackCurve,this.releaseCurve=e.releaseCurve,this.decayCurve=e.decayCurve}static getDefaults(){return Object.assign($.getDefaults(),{attack:.01,attackCurve:"linear",decay:.1,decayCurve:"exponential",release:1,releaseCurve:"exponential",sustain:.5})}get value(){return this.getValueAtTime(this.now())}_getCurve(e,t){if(Pn(e))return e;{let a;for(a in js)if(js[a][t]===e)return a;return e}}_setCurve(e,t,a){if(Pn(a)&&Reflect.has(js,a)){const i=js[a];ma(i)?e!=="_decayCurve"&&(this[e]=i[t]):this[e]=i}else if(wt(a)&&e!=="_decayCurve")this[e]=a;else throw new Error("Envelope: invalid curve: "+a)}get attackCurve(){return this._getCurve(this._attackCurve,"In")}set attackCurve(e){this._setCurve("_attackCurve","In",e)}get releaseCurve(){return this._getCurve(this._releaseCurve,"Out")}set releaseCurve(e){this._setCurve("_releaseCurve","Out",e)}get decayCurve(){return this._getCurve(this._decayCurve,"Out")}set decayCurve(e){this._setCurve("_decayCurve","Out",e)}triggerAttack(e,t=1){this.log("triggerAttack",e,t),e=this.toSeconds(e);let i=this.toSeconds(this.attack);const o=this.toSeconds(this.decay),s=this.getValueAtTime(e);if(s>0){const r=1/i;i=(1-s)/r}if(i<this.sampleTime)this._sig.cancelScheduledValues(e),this._sig.setValueAtTime(t,e);else if(this._attackCurve==="linear")this._sig.linearRampTo(t,i,e);else if(this._attackCurve==="exponential")this._sig.targetRampTo(t,i,e);else{this._sig.cancelAndHoldAtTime(e);let r=this._attackCurve;for(let l=1;l<r.length;l++)if(r[l-1]<=s&&s<=r[l]){r=this._attackCurve.slice(l),r[0]=s;break}this._sig.setValueCurveAtTime(r,e,i,t)}if(o&&this.sustain<1){const r=t*this.sustain,l=e+i;this.log("decay",l),this._decayCurve==="linear"?this._sig.linearRampToValueAtTime(r,o+l):this._sig.exponentialApproachValueAtTime(r,l,o)}return this}triggerRelease(e){this.log("triggerRelease",e),e=this.toSeconds(e);const t=this.getValueAtTime(e);if(t>0){const a=this.toSeconds(this.release);a<this.sampleTime?this._sig.setValueAtTime(0,e):this._releaseCurve==="linear"?this._sig.linearRampTo(0,a,e):this._releaseCurve==="exponential"?this._sig.targetRampTo(0,a,e):(ne(wt(this._releaseCurve),"releaseCurve must be either 'linear', 'exponential' or an array"),this._sig.cancelAndHoldAtTime(e),this._sig.setValueCurveAtTime(this._releaseCurve,e,a,t))}return this}getValueAtTime(e){return this._sig.getValueAtTime(e)}triggerAttackRelease(e,t,a=1){return t=this.toSeconds(t),this.triggerAttack(t,a),this.triggerRelease(t+this.toSeconds(e)),this}cancel(e){return this._sig.cancelScheduledValues(this.toSeconds(e)),this}connect(e,t=0,a=0){return Xr(this,e,t,a),this}asArray(){return Ne(this,arguments,void 0,function*(e=1024){const t=e/this.context.sampleRate,a=new Zr(1,t,this.context.sampleRate),i=this.toSeconds(this.attack)+this.toSeconds(this.decay),o=i+this.toSeconds(this.release),s=o*.1,r=o+s,l=new this.constructor(Object.assign(this.get(),{attack:t*this.toSeconds(this.attack)/r,decay:t*this.toSeconds(this.decay)/r,release:t*this.toSeconds(this.release)/r,context:a}));return l._sig.toDestination(),l.triggerAttackRelease(t*(i+s)/r,0),(yield a.render()).getChannelData(0)})}dispose(){return super.dispose(),this._sig.dispose(),this}}_n([ta(0)],Rt.prototype,"attack",void 0);_n([ta(0)],Rt.prototype,"decay",void 0);_n([ef(0,1)],Rt.prototype,"sustain",void 0);_n([ta(0)],Rt.prototype,"release",void 0);const js=(()=>{let e,t;const a=[];for(e=0;e<128;e++)a[e]=Math.sin(e/127*(Math.PI/2));const i=[],o=6.4;for(e=0;e<127;e++){t=e/127;const u=Math.sin(t*(Math.PI*2)*o-Math.PI/2)+1;i[e]=u/10+t*.83}i[127]=1;const s=[],r=5;for(e=0;e<128;e++)s[e]=Math.ceil(e/127*r)/r;const l=[];for(e=0;e<128;e++)t=e/127,l[e]=.5*(1-Math.cos(Math.PI*t));const c=[];for(e=0;e<128;e++){t=e/127;const u=Math.pow(t,3)*4+.2,m=Math.cos(u*Math.PI*2*t);c[e]=Math.abs(m*(1-t))}function h(u){const m=new Array(u.length);for(let p=0;p<u.length;p++)m[p]=1-u[p];return m}function d(u){return u.slice(0).reverse()}return{bounce:{In:h(c),Out:c},cosine:{In:a,Out:d(a)},exponential:"exponential",linear:"linear",ripple:{In:i,Out:h(i)},sine:{In:l,Out:h(l)},step:{In:s,Out:h(s)}}})();let Bn=class tf extends ${constructor(){const e=q(tf.getDefaults(),arguments);super(e),this._scheduledEvents=[],this._synced=!1,this._original_triggerAttack=this.triggerAttack,this._original_triggerRelease=this.triggerRelease,this._syncedRelease=t=>this._original_triggerRelease(t),this._volume=this.output=new Aa({context:this.context,volume:e.volume}),this.volume=this._volume.volume,fe(this,"volume")}static getDefaults(){return Object.assign($.getDefaults(),{volume:0})}sync(){return this._syncState()&&(this._syncMethod("triggerAttack",1),this._syncMethod("triggerRelease",0),this.context.transport.on("stop",this._syncedRelease),this.context.transport.on("pause",this._syncedRelease),this.context.transport.on("loopEnd",this._syncedRelease)),this}_syncState(){let e=!1;return this._synced||(this._synced=!0,e=!0),e}_syncMethod(e,t){const a=this["_original_"+e]=this[e];this[e]=(...i)=>{const o=i[t],s=this.context.transport.schedule(r=>{i[t]=r,a.apply(this,i)},o);this._scheduledEvents.push(s)}}unsync(){return this._scheduledEvents.forEach(e=>this.context.transport.clear(e)),this._scheduledEvents=[],this._synced&&(this._synced=!1,this.triggerAttack=this._original_triggerAttack,this.triggerRelease=this._original_triggerRelease,this.context.transport.off("stop",this._syncedRelease),this.context.transport.off("pause",this._syncedRelease),this.context.transport.off("loopEnd",this._syncedRelease)),this}triggerAttackRelease(e,t,a,i){const o=this.toSeconds(a),s=this.toSeconds(t);return this.triggerAttack(e,o,i),this.triggerRelease(o+s),this}dispose(){return super.dispose(),this._volume.dispose(),this.unsync(),this._scheduledEvents=[],this}};class gn extends Bn{constructor(){const e=q(gn.getDefaults(),arguments);super(e),this.portamento=e.portamento,this.onsilence=e.onsilence}static getDefaults(){return Object.assign(Bn.getDefaults(),{detune:0,onsilence:_e,portamento:0})}triggerAttack(e,t,a=1){this.log("triggerAttack",e,t,a);const i=this.toSeconds(t);return this._triggerEnvelopeAttack(i,a),this.setNote(e,i),this}triggerRelease(e){this.log("triggerRelease",e);const t=this.toSeconds(e);return this._triggerEnvelopeRelease(t),this}setNote(e,t){const a=this.toSeconds(t),i=e instanceof jt?e.toFrequency():e;if(this.portamento>0&&this.getLevelAtTime(a)>.05){const o=this.toSeconds(this.portamento);this.frequency.exponentialRampTo(i,o,a)}else this.frequency.setValueAtTime(i,a);return this}}_n([ta(0)],gn.prototype,"portamento",void 0);class ws extends Rt{constructor(){super(q(ws.getDefaults(),arguments,["attack","decay","sustain","release"])),this.name="AmplitudeEnvelope",this._gainNode=new re({context:this.context,gain:0}),this.output=this._gainNode,this.input=this._gainNode,this._sig.connect(this._gainNode.gain),this.output=this._gainNode,this.input=this._gainNode}dispose(){return super.dispose(),this._gainNode.dispose(),this}}class Xa extends gn{constructor(){const e=q(Xa.getDefaults(),arguments);super(e),this.name="Synth",this.oscillator=new _a(Object.assign({context:this.context,detune:e.detune,onstop:()=>this.onsilence(this)},e.oscillator)),this.frequency=this.oscillator.frequency,this.detune=this.oscillator.detune,this.envelope=new ws(Object.assign({context:this.context},e.envelope)),this.oscillator.chain(this.envelope,this.output),fe(this,["oscillator","frequency","detune","envelope"])}static getDefaults(){return Object.assign(gn.getDefaults(),{envelope:Object.assign(Bt(Rt.getDefaults(),Object.keys($.getDefaults())),{attack:.005,decay:.1,release:1,sustain:.3}),oscillator:Object.assign(Bt(_a.getDefaults(),[...Object.keys(at.getDefaults()),"frequency","detune"]),{type:"triangle"})})}_triggerEnvelopeAttack(e,t){if(this.envelope.triggerAttack(e,t),this.oscillator.start(e),this.envelope.sustain===0){const a=this.toSeconds(this.envelope.attack),i=this.toSeconds(this.envelope.decay);this.oscillator.stop(e+a+i)}}_triggerEnvelopeRelease(e){this.envelope.triggerRelease(e),this.oscillator.stop(e+this.toSeconds(this.envelope.release))}getLevelAtTime(e){return e=this.toSeconds(e),this.envelope.getValueAtTime(e)}dispose(){return super.dispose(),this.oscillator.dispose(),this.envelope.dispose(),this}}class fr extends gn{constructor(){const e=q(fr.getDefaults(),arguments);super(e),this.name="ModulationSynth",this._carrier=new Xa({context:this.context,oscillator:e.oscillator,envelope:e.envelope,onsilence:()=>this.onsilence(this),volume:-10}),this._modulator=new Xa({context:this.context,oscillator:e.modulation,envelope:e.modulationEnvelope,volume:-10}),this.oscillator=this._carrier.oscillator,this.envelope=this._carrier.envelope,this.modulation=this._modulator.oscillator,this.modulationEnvelope=this._modulator.envelope,this.frequency=new be({context:this.context,units:"frequency"}),this.detune=new be({context:this.context,value:e.detune,units:"cents"}),this.harmonicity=new tt({context:this.context,value:e.harmonicity,minValue:0}),this._modulationNode=new re({context:this.context,gain:0}),fe(this,["frequency","harmonicity","oscillator","envelope","modulation","modulationEnvelope","detune"])}static getDefaults(){return Object.assign(gn.getDefaults(),{harmonicity:3,oscillator:Object.assign(Bt(_a.getDefaults(),[...Object.keys(at.getDefaults()),"frequency","detune"]),{type:"sine"}),envelope:Object.assign(Bt(Rt.getDefaults(),Object.keys($.getDefaults())),{attack:.01,decay:.01,sustain:1,release:.5}),modulation:Object.assign(Bt(_a.getDefaults(),[...Object.keys(at.getDefaults()),"frequency","detune"]),{type:"square"}),modulationEnvelope:Object.assign(Bt(Rt.getDefaults(),Object.keys($.getDefaults())),{attack:.5,decay:0,sustain:1,release:.5})})}_triggerEnvelopeAttack(e,t){this._carrier._triggerEnvelopeAttack(e,t),this._modulator._triggerEnvelopeAttack(e,t)}_triggerEnvelopeRelease(e){return this._carrier._triggerEnvelopeRelease(e),this._modulator._triggerEnvelopeRelease(e),this}getLevelAtTime(e){return e=this.toSeconds(e),this.envelope.getValueAtTime(e)}dispose(){return super.dispose(),this._carrier.dispose(),this._modulator.dispose(),this.frequency.dispose(),this.detune.dispose(),this.harmonicity.dispose(),this._modulationNode.dispose(),this}}class gr extends ${constructor(){const e=q(gr.getDefaults(),arguments,["frequency","type"]);super(e),this.name="BiquadFilter",this._filter=this.context.createBiquadFilter(),this.input=this.output=this._filter,this.Q=new pe({context:this.context,units:"number",value:e.Q,param:this._filter.Q}),this.frequency=new pe({context:this.context,units:"frequency",value:e.frequency,param:this._filter.frequency}),this.detune=new pe({context:this.context,units:"cents",value:e.detune,param:this._filter.detune}),this.gain=new pe({context:this.context,units:"decibels",convert:!1,value:e.gain,param:this._filter.gain}),this.type=e.type}static getDefaults(){return Object.assign($.getDefaults(),{Q:1,type:"lowpass",frequency:350,detune:0,gain:0})}get type(){return this._filter.type}set type(e){ne(["lowpass","highpass","bandpass","lowshelf","highshelf","notch","allpass","peaking"].indexOf(e)!==-1,`Invalid filter type: ${e}`),this._filter.type=e}getFrequencyResponse(e=128){const t=new Float32Array(e);for(let s=0;s<e;s++){const l=Math.pow(s/e,2)*19980+20;t[s]=l}const a=new Float32Array(e),i=new Float32Array(e),o=this.context.createBiquadFilter();return o.type=this.type,o.Q.value=this.Q.value,o.frequency.value=this.frequency.value,o.gain.value=this.gain.value,o.getFrequencyResponse(t,a,i),a}dispose(){return super.dispose(),this._filter.disconnect(),this.Q.dispose(),this.frequency.dispose(),this.gain.dispose(),this.detune.dispose(),this}}class Vo extends ${constructor(){const e=q(Vo.getDefaults(),arguments,["frequency","type","rolloff"]);super(e),this.name="Filter",this.input=new re({context:this.context}),this.output=new re({context:this.context}),this._filters=[],this._filters=[],this.Q=new be({context:this.context,units:"positive",value:e.Q}),this.frequency=new be({context:this.context,units:"frequency",value:e.frequency}),this.detune=new be({context:this.context,units:"cents",value:e.detune}),this.gain=new be({context:this.context,units:"decibels",convert:!1,value:e.gain}),this._type=e.type,this.rolloff=e.rolloff,fe(this,["detune","frequency","gain","Q"])}static getDefaults(){return Object.assign($.getDefaults(),{Q:1,detune:0,frequency:350,gain:0,rolloff:-12,type:"lowpass"})}get type(){return this._type}set type(e){ne(["lowpass","highpass","bandpass","lowshelf","highshelf","notch","allpass","peaking"].indexOf(e)!==-1,`Invalid filter type: ${e}`),this._type=e,this._filters.forEach(a=>a.type=e)}get rolloff(){return this._rolloff}set rolloff(e){const t=Xt(e)?e:parseInt(e,10),a=[-12,-24,-48,-96];let i=a.indexOf(t);ne(i!==-1,`rolloff can only be ${a.join(", ")}`),i+=1,this._rolloff=t,this.input.disconnect(),this._filters.forEach(o=>o.disconnect()),this._filters=new Array(i);for(let o=0;o<i;o++){const s=new gr({context:this.context});s.type=this._type,this.frequency.connect(s.frequency),this.detune.connect(s.detune),this.Q.connect(s.Q),this.gain.connect(s.gain),this._filters[o]=s}this._internalChannels=this._filters,Nn(this.input,...this._internalChannels,this.output)}getFrequencyResponse(e=128){const t=new gr({frequency:this.frequency.value,gain:this.gain.value,Q:this.Q.value,type:this._type,detune:this.detune.value}),a=new Float32Array(e).map(()=>1);return this._filters.forEach(()=>{t.getFrequencyResponse(e).forEach((o,s)=>a[s]*=o)}),t.dispose(),a}dispose(){return super.dispose(),this._filters.forEach(e=>{e.dispose()}),yh(this,["detune","frequency","gain","Q"]),this.frequency.dispose(),this.Q.dispose(),this.detune.dispose(),this.gain.dispose(),this}}class yr extends Rt{constructor(){const e=q(yr.getDefaults(),arguments,["attack","decay","sustain","release"]);super(e),this.name="FrequencyEnvelope",this._octaves=e.octaves,this._baseFrequency=this.toFrequency(e.baseFrequency),this._exponent=this.input=new el({context:this.context,value:e.exponent}),this._scale=this.output=new sl({context:this.context,min:this._baseFrequency,max:this._baseFrequency*Math.pow(2,this._octaves)}),this._sig.chain(this._exponent,this._scale)}static getDefaults(){return Object.assign(Rt.getDefaults(),{baseFrequency:200,exponent:1,octaves:4})}get baseFrequency(){return this._baseFrequency}set baseFrequency(e){const t=this.toFrequency(e);Qt(t,0),this._baseFrequency=t,this._scale.min=this._baseFrequency,this.octaves=this._octaves}get octaves(){return this._octaves}set octaves(e){this._octaves=e,this._scale.max=this._baseFrequency*Math.pow(2,e)}get exponent(){return this._exponent.value}set exponent(e){this._exponent.value=e}dispose(){return super.dispose(),this._exponent.dispose(),this._scale.dispose(),this}}class Dh extends gn{constructor(){const e=q(Dh.getDefaults(),arguments);super(e),this.name="MonoSynth",this.oscillator=new _a(Object.assign(e.oscillator,{context:this.context,detune:e.detune,onstop:()=>this.onsilence(this)})),this.frequency=this.oscillator.frequency,this.detune=this.oscillator.detune,this.filter=new Vo(Object.assign(e.filter,{context:this.context})),this.filterEnvelope=new yr(Object.assign(e.filterEnvelope,{context:this.context})),this.envelope=new ws(Object.assign(e.envelope,{context:this.context})),this.oscillator.chain(this.filter,this.envelope,this.output),this.filterEnvelope.connect(this.filter.frequency),fe(this,["oscillator","frequency","detune","filter","filterEnvelope","envelope"])}static getDefaults(){return Object.assign(gn.getDefaults(),{envelope:Object.assign(Bt(Rt.getDefaults(),Object.keys($.getDefaults())),{attack:.005,decay:.1,release:1,sustain:.9}),filter:Object.assign(Bt(Vo.getDefaults(),Object.keys($.getDefaults())),{Q:1,rolloff:-12,type:"lowpass"}),filterEnvelope:Object.assign(Bt(yr.getDefaults(),Object.keys($.getDefaults())),{attack:.6,baseFrequency:200,decay:.2,exponent:2,octaves:3,release:2,sustain:.5}),oscillator:Object.assign(Bt(_a.getDefaults(),Object.keys(at.getDefaults())),{type:"sawtooth"})})}_triggerEnvelopeAttack(e,t=1){if(this.envelope.triggerAttack(e,t),this.filterEnvelope.triggerAttack(e),this.oscillator.start(e),this.envelope.sustain===0){const a=this.toSeconds(this.envelope.attack),i=this.toSeconds(this.envelope.decay);this.oscillator.stop(e+a+i)}}_triggerEnvelopeRelease(e){this.envelope.triggerRelease(e),this.filterEnvelope.triggerRelease(e),this.oscillator.stop(e+this.toSeconds(this.envelope.release))}getLevelAtTime(e){return e=this.toSeconds(e),this.envelope.getValueAtTime(e)}dispose(){return super.dispose(),this.oscillator.dispose(),this.envelope.dispose(),this.filterEnvelope.dispose(),this.filter.dispose(),this}}class nf extends fr{constructor(){const e=q(nf.getDefaults(),arguments);super(e),this.name="FMSynth",this.modulationIndex=new tt({context:this.context,value:e.modulationIndex}),this.frequency.connect(this._carrier.frequency),this.frequency.chain(this.harmonicity,this._modulator.frequency),this.frequency.chain(this.modulationIndex,this._modulationNode),this.detune.fan(this._carrier.detune,this._modulator.detune),this._modulator.connect(this._modulationNode.gain),this._modulationNode.connect(this._carrier.frequency),this._carrier.connect(this.output)}static getDefaults(){return Object.assign(fr.getDefaults(),{modulationIndex:10})}dispose(){return super.dispose(),this.modulationIndex.dispose(),this}}class ll extends Xa{constructor(){const e=q(ll.getDefaults(),arguments);super(e),this.name="MembraneSynth",this.portamento=0,this.pitchDecay=e.pitchDecay,this.octaves=e.octaves,fe(this,["oscillator","envelope"])}static getDefaults(){return fa(gn.getDefaults(),Xa.getDefaults(),{envelope:{attack:.001,attackCurve:"exponential",decay:.4,release:1.4,sustain:.01},octaves:10,oscillator:{type:"sine"},pitchDecay:.05})}setNote(e,t){const a=this.toSeconds(t),i=this.toFrequency(e instanceof jt?e.toFrequency():e),o=i*this.octaves;return this.oscillator.frequency.setValueAtTime(o,a),this.oscillator.frequency.exponentialRampToValueAtTime(i,a+this.toSeconds(this.pitchDecay)),this}dispose(){return super.dispose(),this}}_n([ef(0)],ll.prototype,"octaves",void 0);_n([ta(0)],ll.prototype,"pitchDecay",void 0);class Ph extends Bn{constructor(){const e=q(Ph.getDefaults(),arguments);super(e),this.name="NoiseSynth",this.noise=new Ya(Object.assign({context:this.context},e.noise)),this.envelope=new ws(Object.assign({context:this.context},e.envelope)),this.noise.chain(this.envelope,this.output)}static getDefaults(){return Object.assign(Bn.getDefaults(),{envelope:Object.assign(Bt(Rt.getDefaults(),Object.keys($.getDefaults())),{decay:.1,sustain:0}),noise:Object.assign(Bt(Ya.getDefaults(),Object.keys(at.getDefaults())),{type:"white"})})}triggerAttack(e,t=1){return e=this.toSeconds(e),this.envelope.triggerAttack(e,t),this.noise.start(e),this.envelope.sustain===0&&this.noise.stop(e+this.toSeconds(this.envelope.attack)+this.toSeconds(this.envelope.decay)),this}triggerRelease(e){return e=this.toSeconds(e),this.envelope.triggerRelease(e),this.noise.stop(e+this.toSeconds(this.envelope.release)),this}sync(){return this._syncState()&&(this._syncMethod("triggerAttack",0),this._syncMethod("triggerRelease",0)),this}triggerAttackRelease(e,t,a=1){return t=this.toSeconds(t),e=this.toSeconds(e),this.triggerAttack(t,a),this.triggerRelease(t+e),this}dispose(){return super.dispose(),this.noise.dispose(),this.envelope.dispose(),this}}const Nh=new Set;function Bh(n){Nh.add(n)}function af(n,e){const t=`registerProcessor("${n}", ${e})`;Nh.add(t)}function tk(){return Array.from(Nh).join(`
`)}class Tc extends ${constructor(e){super(e),this.name="ToneAudioWorklet",this.workletOptions={},this.onprocessorerror=_e;const t=URL.createObjectURL(new Blob([tk()],{type:"text/javascript"})),a=this._audioWorkletName();this._dummyGain=this.context.createGain(),this._dummyParam=this._dummyGain.gain,this.context.addAudioWorkletModule(t).then(()=>{this.disposed||(this._worklet=this.context.createAudioWorkletNode(a,this.workletOptions),this._worklet.onprocessorerror=this.onprocessorerror.bind(this),this.onReady(this._worklet))})}dispose(){return super.dispose(),this._dummyGain.disconnect(),this._worklet&&(this._worklet.port.postMessage("dispose"),this._worklet.disconnect()),this}}const nk=`
	/**
	 * The base AudioWorkletProcessor for use in Tone.js. Works with the {@link ToneAudioWorklet}. 
	 */
	class ToneAudioWorkletProcessor extends AudioWorkletProcessor {

		constructor(options) {
			
			super(options);
			/**
			 * If the processor was disposed or not. Keep alive until it's disposed.
			 */
			this.disposed = false;
		   	/** 
			 * The number of samples in the processing block
			 */
			this.blockSize = 128;
			/**
			 * the sample rate
			 */
			this.sampleRate = sampleRate;

			this.port.onmessage = (event) => {
				// when it receives a dispose 
				if (event.data === "dispose") {
					this.disposed = true;
				}
			};
		}
	}
`;Bh(nk);const ak=`
	/**
	 * Abstract class for a single input/output processor. 
	 * has a 'generate' function which processes one sample at a time
	 */
	class SingleIOProcessor extends ToneAudioWorkletProcessor {

		constructor(options) {
			super(Object.assign(options, {
				numberOfInputs: 1,
				numberOfOutputs: 1
			}));
			/**
			 * Holds the name of the parameter and a single value of that
			 * parameter at the current sample
			 * @type { [name: string]: number }
			 */
			this.params = {}
		}

		/**
		 * Generate an output sample from the input sample and parameters
		 * @abstract
		 * @param input number
		 * @param channel number
		 * @param parameters { [name: string]: number }
		 * @returns number
		 */
		generate(){}

		/**
		 * Update the private params object with the 
		 * values of the parameters at the given index
		 * @param parameters { [name: string]: Float32Array },
		 * @param index number
		 */
		updateParams(parameters, index) {
			for (const paramName in parameters) {
				const param = parameters[paramName];
				if (param.length > 1) {
					this.params[paramName] = parameters[paramName][index];
				} else {
					this.params[paramName] = parameters[paramName][0];
				}
			}
		}

		/**
		 * Process a single frame of the audio
		 * @param inputs Float32Array[][]
		 * @param outputs Float32Array[][]
		 */
		process(inputs, outputs, parameters) {
			const input = inputs[0];
			const output = outputs[0];
			// get the parameter values
			const channelCount = Math.max(input && input.length || 0, output.length);
			for (let sample = 0; sample < this.blockSize; sample++) {
				this.updateParams(parameters, sample);
				for (let channel = 0; channel < channelCount; channel++) {
					const inputSample = input && input.length ? input[channel][sample] : 0;
					output[channel][sample] = this.generate(inputSample, channel, this.params);
				}
			}
			return !this.disposed;
		}
	};
`;Bh(ak);const ik=`
	/**
	 * A multichannel buffer for use within an AudioWorkletProcessor as a delay line
	 */
	class DelayLine {
		
		constructor(size, channels) {
			this.buffer = [];
			this.writeHead = []
			this.size = size;

			// create the empty channels
			for (let i = 0; i < channels; i++) {
				this.buffer[i] = new Float32Array(this.size);
				this.writeHead[i] = 0;
			}
		}

		/**
		 * Push a value onto the end
		 * @param channel number
		 * @param value number
		 */
		push(channel, value) {
			this.writeHead[channel] += 1;
			if (this.writeHead[channel] > this.size) {
				this.writeHead[channel] = 0;
			}
			this.buffer[channel][this.writeHead[channel]] = value;
		}

		/**
		 * Get the recorded value of the channel given the delay
		 * @param channel number
		 * @param delay number delay samples
		 */
		get(channel, delay) {
			let readHead = this.writeHead[channel] - Math.floor(delay);
			if (readHead < 0) {
				readHead += this.size;
			}
			return this.buffer[channel][readHead];
		}
	}
`;Bh(ik);const of="feedback-comb-filter",ok=`
	class FeedbackCombFilterWorklet extends SingleIOProcessor {

		constructor(options) {
			super(options);
			this.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);
		}

		static get parameterDescriptors() {
			return [{
				name: "delayTime",
				defaultValue: 0.1,
				minValue: 0,
				maxValue: 1,
				automationRate: "k-rate"
			}, {
				name: "feedback",
				defaultValue: 0.5,
				minValue: 0,
				maxValue: 0.9999,
				automationRate: "k-rate"
			}];
		}

		generate(input, channel, parameters) {
			const delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);
			this.delayLine.push(channel, input + delayedSample * parameters.feedback);
			return delayedSample;
		}
	}
`;af(of,ok);class jh extends Tc{constructor(){const e=q(jh.getDefaults(),arguments,["delayTime","resonance"]);super(e),this.name="FeedbackCombFilter",this.input=new re({context:this.context}),this.output=new re({context:this.context}),this.delayTime=new pe({context:this.context,value:e.delayTime,units:"time",minValue:0,maxValue:1,param:this._dummyParam,swappable:!0}),this.resonance=new pe({context:this.context,value:e.resonance,units:"normalRange",param:this._dummyParam,swappable:!0}),fe(this,["resonance","delayTime"])}_audioWorkletName(){return of}static getDefaults(){return Object.assign($.getDefaults(),{delayTime:.1,resonance:.5})}onReady(e){Nn(this.input,e,this.output);const t=e.parameters.get("delayTime");this.delayTime.setParam(t);const a=e.parameters.get("feedback");this.resonance.setParam(a)}dispose(){return super.dispose(),this.input.dispose(),this.output.dispose(),this.delayTime.dispose(),this.resonance.dispose(),this}}class cl extends ${constructor(){const e=q(cl.getDefaults(),arguments,["frequency","type"]);super(e),this.name="OnePoleFilter",this._frequency=e.frequency,this._type=e.type,this.input=new re({context:this.context}),this.output=new re({context:this.context}),this._createFilter()}static getDefaults(){return Object.assign($.getDefaults(),{frequency:880,type:"lowpass"})}_createFilter(){const e=this._filter,t=this.toFrequency(this._frequency),a=1/(2*Math.PI*t);if(this._type==="lowpass"){const i=1/(a*this.context.sampleRate),o=i-1;this._filter=this.context.createIIRFilter([i,0],[1,o])}else{const i=1/(a*this.context.sampleRate)-1;this._filter=this.context.createIIRFilter([1,-1],[1,i])}this.input.chain(this._filter,this.output),e&&this.context.setTimeout(()=>{this.disposed||(this.input.disconnect(e),e.disconnect())},this.blockTime)}get frequency(){return this._frequency}set frequency(e){this._frequency=e,this._createFilter()}get type(){return this._type}set type(e){this._type=e,this._createFilter()}getFrequencyResponse(e=128){const t=new Float32Array(e);for(let o=0;o<e;o++){const r=Math.pow(o/e,2)*19980+20;t[o]=r}const a=new Float32Array(e),i=new Float32Array(e);return this._filter.getFrequencyResponse(t,a,i),a}dispose(){return super.dispose(),this.input.dispose(),this.output.dispose(),this._filter.disconnect(),this}}class zh extends ${constructor(){const e=q(zh.getDefaults(),arguments,["delayTime","resonance","dampening"]);super(e),this.name="LowpassCombFilter",this._combFilter=this.output=new jh({context:this.context,delayTime:e.delayTime,resonance:e.resonance}),this.delayTime=this._combFilter.delayTime,this.resonance=this._combFilter.resonance,this._lowpass=this.input=new cl({context:this.context,frequency:e.dampening,type:"lowpass"}),this._lowpass.connect(this._combFilter)}static getDefaults(){return Object.assign($.getDefaults(),{dampening:3e3,delayTime:.1,resonance:.5})}get dampening(){return this._lowpass.frequency}set dampening(e){this._lowpass.frequency=e}dispose(){return super.dispose(),this._combFilter.dispose(),this._lowpass.dispose(),this}}class sf extends Bn{constructor(){const e=q(sf.getDefaults(),arguments);super(e),this.name="PluckSynth",this._noise=new Ya({context:this.context,type:"pink"}),this.attackNoise=e.attackNoise,this._lfcf=new zh({context:this.context,dampening:e.dampening,resonance:e.resonance}),this.resonance=e.resonance,this.release=e.release,this._noise.connect(this._lfcf),this._lfcf.connect(this.output)}static getDefaults(){return fa(Bn.getDefaults(),{attackNoise:1,dampening:4e3,resonance:.7,release:1})}get dampening(){return this._lfcf.dampening}set dampening(e){this._lfcf.dampening=e}triggerAttack(e,t){const a=this.toFrequency(e);t=this.toSeconds(t);const i=1/a;return this._lfcf.delayTime.setValueAtTime(i,t),this._noise.start(t),this._noise.stop(t+i*this.attackNoise),this._lfcf.resonance.cancelScheduledValues(t),this._lfcf.resonance.setValueAtTime(this.resonance,t),this}triggerRelease(e){return this._lfcf.resonance.linearRampTo(0,this.release,e),this}dispose(){return super.dispose(),this._noise.dispose(),this._lfcf.dispose(),this}}class hl extends Bn{constructor(){const e=q(hl.getDefaults(),arguments,["voice","options"]);super(e),this.name="PolySynth",this._availableVoices=[],this._activeVoices=[],this._voices=[],this._gcTimeout=-1,this._averageActiveVoices=0,this._syncedRelease=i=>this.releaseAll(i),ne(!Xt(e.voice),"DEPRECATED: The polyphony count is no longer the first argument.");const t=e.voice.getDefaults();this.options=Object.assign(t,e.options),this.voice=e.voice,this.maxPolyphony=e.maxPolyphony,this._dummyVoice=this._getNextAvailableVoice();const a=this._voices.indexOf(this._dummyVoice);this._voices.splice(a,1),this._gcTimeout=this.context.setInterval(this._collectGarbage.bind(this),1)}static getDefaults(){return Object.assign(Bn.getDefaults(),{maxPolyphony:32,options:{},voice:Xa})}get activeVoices(){return this._activeVoices.length}_makeVoiceAvailable(e){this._availableVoices.push(e);const t=this._activeVoices.findIndex(a=>a.voice===e);this._activeVoices.splice(t,1)}_getNextAvailableVoice(){if(this._availableVoices.length)return this._availableVoices.shift();if(this._voices.length<this.maxPolyphony){const e=new this.voice(Object.assign(this.options,{context:this.context,onsilence:this._makeVoiceAvailable.bind(this)}));return ne(e instanceof gn,"Voice must extend Monophonic class"),e.connect(this.output),this._voices.push(e),e}else ms("Max polyphony exceeded. Note dropped.")}_collectGarbage(){if(this._averageActiveVoices=Math.max(this._averageActiveVoices*.95,this.activeVoices),this._availableVoices.length&&this._voices.length>Math.ceil(this._averageActiveVoices+1)){const e=this._availableVoices.shift(),t=this._voices.indexOf(e);this._voices.splice(t,1),this.context.isOffline||e.dispose()}}_triggerAttack(e,t,a){e.forEach(i=>{const o=new $o(this.context,i).toMidi(),s=this._getNextAvailableVoice();s&&(s.triggerAttack(i,t,a),this._activeVoices.push({midi:o,voice:s,released:!1}),this.log("triggerAttack",i,t))})}_triggerRelease(e,t){e.forEach(a=>{const i=new $o(this.context,a).toMidi(),o=this._activeVoices.find(({midi:s,released:r})=>s===i&&!r);o&&(o.voice.triggerRelease(t),o.released=!0,this.log("triggerRelease",a,t))})}_scheduleEvent(e,t,a,i){ne(!this.disposed,"Synth was already disposed"),a<=this.now()?e==="attack"?this._triggerAttack(t,a,i):this._triggerRelease(t,a):this.context.setTimeout(()=>{this.disposed||this._scheduleEvent(e,t,a,i)},a-this.now())}triggerAttack(e,t,a){Array.isArray(e)||(e=[e]);const i=this.toSeconds(t);return this._scheduleEvent("attack",e,i,a),this}triggerRelease(e,t){Array.isArray(e)||(e=[e]);const a=this.toSeconds(t);return this._scheduleEvent("release",e,a),this}triggerAttackRelease(e,t,a,i){const o=this.toSeconds(a);if(this.triggerAttack(e,o,i),wt(t)){ne(wt(e),"If the duration is an array, the notes must also be an array"),e=e;for(let s=0;s<e.length;s++){const r=t[Math.min(s,t.length-1)],l=this.toSeconds(r);ne(l>0,"The duration must be greater than 0"),this.triggerRelease(e[s],o+l)}}else{const s=this.toSeconds(t);ne(s>0,"The duration must be greater than 0"),this.triggerRelease(e,o+s)}return this}sync(){return this._syncState()&&(this._syncMethod("triggerAttack",1),this._syncMethod("triggerRelease",1),this.context.transport.on("stop",this._syncedRelease),this.context.transport.on("pause",this._syncedRelease),this.context.transport.on("loopEnd",this._syncedRelease)),this}set(e){const t=Bt(e,["onsilence","context"]);return this.options=fa(this.options,t),this._voices.forEach(a=>a.set(t)),this._dummyVoice.set(t),this}get(){return this._dummyVoice.get()}releaseAll(e){const t=this.toSeconds(e);return this._activeVoices.forEach(({voice:a})=>{a.triggerRelease(t)}),this}dispose(){return super.dispose(),this._dummyVoice.dispose(),this._voices.forEach(e=>e.dispose()),this._activeVoices=[],this._availableVoices=[],this.context.clearInterval(this._gcTimeout),this}}class ri extends Bn{constructor(){const e=q(ri.getDefaults(),arguments,["urls","onload","baseUrl"],"urls");super(e),this.name="Sampler",this._activeSources=new Map;const t={};Object.keys(e.urls).forEach(a=>{const i=parseInt(a,10);if(ne(Bs(a)||Xt(i)&&isFinite(i),`url key is neither a note or midi pitch: ${a}`),Bs(a)){const o=new jt(this.context,a).toMidi();t[o]=e.urls[a]}else Xt(i)&&isFinite(i)&&(t[i]=e.urls[i])}),this._buffers=new xh({urls:t,onload:e.onload,baseUrl:e.baseUrl,onerror:e.onerror}),this.attack=e.attack,this.release=e.release,this.curve=e.curve,this._buffers.loaded&&Promise.resolve().then(e.onload)}static getDefaults(){return Object.assign(Bn.getDefaults(),{attack:0,baseUrl:"",curve:"exponential",onload:_e,onerror:_e,release:.1,urls:{}})}_findClosest(e){let a=0;for(;a<96;){if(this._buffers.has(e+a))return-a;if(this._buffers.has(e-a))return a;a++}throw new Error(`No available buffers for note: ${e}`)}triggerAttack(e,t,a=1){return this.log("triggerAttack",e,t,a),Array.isArray(e)||(e=[e]),e.forEach(i=>{const o=Zp(new jt(this.context,i).toFrequency()),s=Math.round(o),r=o-s,l=this._findClosest(s),c=s-l,h=this._buffers.get(c),d=Jp(l+r),u=new ys({url:h,context:this.context,curve:this.curve,fadeIn:this.attack,fadeOut:this.release,playbackRate:d}).connect(this.output);u.start(t,0,h.duration/d,a),wt(this._activeSources.get(s))||this._activeSources.set(s,[]),this._activeSources.get(s).push(u),u.onended=()=>{if(this._activeSources&&this._activeSources.has(s)){const m=this._activeSources.get(s),p=m.indexOf(u);p!==-1&&m.splice(p,1)}}}),this}triggerRelease(e,t){return this.log("triggerRelease",e,t),Array.isArray(e)||(e=[e]),e.forEach(a=>{const i=new jt(this.context,a).toMidi();if(this._activeSources.has(i)&&this._activeSources.get(i).length){const o=this._activeSources.get(i);t=this.toSeconds(t),o.forEach(s=>{s.stop(t)}),this._activeSources.set(i,[])}}),this}releaseAll(e){const t=this.toSeconds(e);return this._activeSources.forEach(a=>{for(;a.length;)a.shift().stop(t)}),this}sync(){return this._syncState()&&(this._syncMethod("triggerAttack",1),this._syncMethod("triggerRelease",1)),this}triggerAttackRelease(e,t,a,i=1){const o=this.toSeconds(a);return this.triggerAttack(e,o,i),wt(t)?(ne(wt(e),"notes must be an array when duration is array"),e.forEach((s,r)=>{const l=t[Math.min(r,t.length-1)];this.triggerRelease(s,o+this.toSeconds(l))})):this.triggerRelease(e,o+this.toSeconds(t)),this}add(e,t,a){if(ne(Bs(e)||isFinite(e),`note must be a pitch or midi: ${e}`),Bs(e)){const i=new jt(this.context,e).toMidi();this._buffers.add(i,t,a)}else this._buffers.add(e,t,a);return this}get loaded(){return this._buffers.loaded}dispose(){return super.dispose(),this._buffers.dispose(),this._activeSources.forEach(e=>{e.forEach(t=>t.dispose())}),this._activeSources.clear(),this}}_n([ta(0)],ri.prototype,"attack",void 0);_n([ta(0)],ri.prototype,"release",void 0);class Hn extends ct{constructor(){const e=q(Hn.getDefaults(),arguments,["callback","value"]);super(e),this.name="ToneEvent",this._state=new gs("stopped"),this._startOffset=0,this._loop=e.loop,this.callback=e.callback,this.value=e.value,this._loopStart=this.toTicks(e.loopStart),this._loopEnd=this.toTicks(e.loopEnd),this._playbackRate=e.playbackRate,this._probability=e.probability,this._humanize=e.humanize,this.mute=e.mute,this._playbackRate=e.playbackRate,this._state.increasing=!0,this._rescheduleEvents()}static getDefaults(){return Object.assign(ct.getDefaults(),{callback:_e,humanize:!1,loop:!1,loopEnd:"1m",loopStart:0,mute:!1,playbackRate:1,probability:1,value:null})}_rescheduleEvents(e=-1){this._state.forEachFrom(e,t=>{let a;if(t.state==="started"){t.id!==-1&&this.context.transport.clear(t.id);const i=t.time+Math.round(this.startOffset/this._playbackRate);if(this._loop===!0||Xt(this._loop)&&this._loop>1){a=1/0,Xt(this._loop)&&(a=this._loop*this._getLoopDuration());const o=this._state.getAfter(i);o!==null&&(a=Math.min(a,o.time-i)),a!==1/0&&(a=new $e(this.context,a));const s=new $e(this.context,this._getLoopDuration());t.id=this.context.transport.scheduleRepeat(this._tick.bind(this),s,new $e(this.context,i),a)}else t.id=this.context.transport.schedule(this._tick.bind(this),new $e(this.context,i))}})}get state(){return this._state.getValueAtTime(this.context.transport.ticks)}get startOffset(){return this._startOffset}set startOffset(e){this._startOffset=e}get probability(){return this._probability}set probability(e){this._probability=e}get humanize(){return this._humanize}set humanize(e){this._humanize=e}start(e){const t=this.toTicks(e);return this._state.getValueAtTime(t)==="stopped"&&(this._state.add({id:-1,state:"started",time:t}),this._rescheduleEvents(t)),this}stop(e){this.cancel(e);const t=this.toTicks(e);if(this._state.getValueAtTime(t)==="started"){this._state.setStateAtTime("stopped",t,{id:-1});const a=this._state.getBefore(t);let i=t;a!==null&&(i=a.time),this._rescheduleEvents(i)}return this}cancel(e){e=Cn(e,-1/0);const t=this.toTicks(e);return this._state.forEachFrom(t,a=>{this.context.transport.clear(a.id)}),this._state.cancel(t),this}_tick(e){const t=this.context.transport.getTicksAtTime(e);if(!this.mute&&this._state.getValueAtTime(t)==="started"){if(this.probability<1&&Math.random()>this.probability)return;if(this.humanize){let a=.02;Lp(this.humanize)||(a=this.toSeconds(this.humanize)),e+=(Math.random()*2-1)*a}this.callback(e,this.value)}}_getLoopDuration(){return(this._loopEnd-this._loopStart)/this._playbackRate}get loop(){return this._loop}set loop(e){this._loop=e,this._rescheduleEvents()}get playbackRate(){return this._playbackRate}set playbackRate(e){this._playbackRate=e,this._rescheduleEvents()}get loopEnd(){return new $e(this.context,this._loopEnd).toSeconds()}set loopEnd(e){this._loopEnd=this.toTicks(e),this._loop&&this._rescheduleEvents()}get loopStart(){return new $e(this.context,this._loopStart).toSeconds()}set loopStart(e){this._loopStart=this.toTicks(e),this._loop&&this._rescheduleEvents()}get progress(){if(this._loop){const e=this.context.transport.ticks,t=this._state.get(e);if(t!==null&&t.state==="started"){const a=this._getLoopDuration();return(e-t.time)%a/a}else return 0}else return 0}dispose(){return super.dispose(),this.cancel(),this._state.dispose(),this}}class Gi extends ct{constructor(){const e=q(Gi.getDefaults(),arguments,["callback","interval"]);super(e),this.name="Loop",this._event=new Hn({context:this.context,callback:this._tick.bind(this),loop:!0,loopEnd:e.interval,playbackRate:e.playbackRate,probability:e.probability,humanize:e.humanize}),this.callback=e.callback,this.iterations=e.iterations}static getDefaults(){return Object.assign(ct.getDefaults(),{interval:"4n",callback:_e,playbackRate:1,iterations:1/0,probability:1,mute:!1,humanize:!1})}start(e){return this._event.start(e),this}stop(e){return this._event.stop(e),this}cancel(e){return this._event.cancel(e),this}_tick(e){this.callback(e)}get state(){return this._event.state}get progress(){return this._event.progress}get interval(){return this._event.loopEnd}set interval(e){this._event.loopEnd=e}get playbackRate(){return this._event.playbackRate}set playbackRate(e){this._event.playbackRate=e}get humanize(){return this._event.humanize}set humanize(e){this._event.humanize=e}get probability(){return this._event.probability}set probability(e){this._event.probability=e}get mute(){return this._event.mute}set mute(e){this._event.mute=e}get iterations(){return this._event.loop===!0?1/0:this._event.loop}set iterations(e){e===1/0?this._event.loop=!0:this._event.loop=e}dispose(){return super.dispose(),this._event.dispose(),this}}class br extends Hn{constructor(){const e=q(br.getDefaults(),arguments,["callback","events"]);super(e),this.name="Part",this._state=new gs("stopped"),this._events=new Set,this._state.increasing=!0,e.events.forEach(t=>{wt(t)?this.add(t[0],t[1]):this.add(t)})}static getDefaults(){return Object.assign(Hn.getDefaults(),{events:[]})}start(e,t){const a=this.toTicks(e);if(this._state.getValueAtTime(a)!=="started"){t=Cn(t,this._loop?this._loopStart:0),this._loop?t=Cn(t,this._loopStart):t=Cn(t,0);const i=this.toTicks(t);this._state.add({id:-1,offset:i,state:"started",time:a}),this._forEach(o=>{this._startNote(o,a,i)})}return this}_startNote(e,t,a){t-=a,this._loop?e.startOffset>=this._loopStart&&e.startOffset<this._loopEnd?(e.startOffset<a&&(t+=this._getLoopDuration()),e.start(new $e(this.context,t))):e.startOffset<this._loopStart&&e.startOffset>=a&&(e.loop=!1,e.start(new $e(this.context,t))):e.startOffset>=a&&e.start(new $e(this.context,t))}get startOffset(){return this._startOffset}set startOffset(e){this._startOffset=e,this._forEach(t=>{t.startOffset+=this._startOffset})}stop(e){const t=this.toTicks(e);return this._state.cancel(t),this._state.setStateAtTime("stopped",t),this._forEach(a=>{a.stop(e)}),this}at(e,t){const a=new Ei(this.context,e).toTicks(),i=new $e(this.context,1).toSeconds(),o=this._events.values();let s=o.next();for(;!s.done;){const r=s.value;if(Math.abs(a-r.startOffset)<i)return me(t)&&(r.value=t),r;s=o.next()}return me(t)?(this.add(e,t),this.at(e)):null}add(e,t){e instanceof Object&&Reflect.has(e,"time")&&(t=e,e=t.time);const a=this.toTicks(e);let i;return t instanceof Hn?(i=t,i.callback=this._tick.bind(this)):i=new Hn({callback:this._tick.bind(this),context:this.context,value:t}),i.startOffset=a,i.set({humanize:this.humanize,loop:this.loop,loopEnd:this.loopEnd,loopStart:this.loopStart,playbackRate:this.playbackRate,probability:this.probability}),this._events.add(i),this._restartEvent(i),this}_restartEvent(e){this._state.forEach(t=>{t.state==="started"?this._startNote(e,t.time,t.offset):e.stop(new $e(this.context,t.time))})}remove(e,t){return ma(e)&&e.hasOwnProperty("time")&&(t=e,e=t.time),e=this.toTicks(e),this._events.forEach(a=>{a.startOffset===e&&(Ft(t)||me(t)&&a.value===t)&&(this._events.delete(a),a.dispose())}),this}clear(){return this._forEach(e=>e.dispose()),this._events.clear(),this}cancel(e){return this._forEach(t=>t.cancel(e)),this._state.cancel(this.toTicks(e)),this}_forEach(e){return this._events&&this._events.forEach(t=>{t instanceof br?t._forEach(e):e(t)}),this}_setAll(e,t){this._forEach(a=>{a[e]=t})}_tick(e,t){this.mute||this.callback(e,t)}_testLoopBoundries(e){this._loop&&(e.startOffset<this._loopStart||e.startOffset>=this._loopEnd)?e.cancel(0):e.state==="stopped"&&this._restartEvent(e)}get probability(){return this._probability}set probability(e){this._probability=e,this._setAll("probability",e)}get humanize(){return this._humanize}set humanize(e){this._humanize=e,this._setAll("humanize",e)}get loop(){return this._loop}set loop(e){this._loop=e,this._forEach(t=>{t.loopStart=this.loopStart,t.loopEnd=this.loopEnd,t.loop=e,this._testLoopBoundries(t)})}get loopEnd(){return new $e(this.context,this._loopEnd).toSeconds()}set loopEnd(e){this._loopEnd=this.toTicks(e),this._loop&&this._forEach(t=>{t.loopEnd=e,this._testLoopBoundries(t)})}get loopStart(){return new $e(this.context,this._loopStart).toSeconds()}set loopStart(e){this._loopStart=this.toTicks(e),this._loop&&this._forEach(t=>{t.loopStart=this.loopStart,this._testLoopBoundries(t)})}get playbackRate(){return this._playbackRate}set playbackRate(e){this._playbackRate=e,this._setAll("playbackRate",e)}get length(){return this._events.size}dispose(){return super.dispose(),this.clear(),this}}function*sk(n){let e=0;for(;e<n;)e=oi(e,0,n-1),yield e,e++}function*rk(n){let e=n-1;for(;e>=0;)e=oi(e,0,n-1),yield e,e--}function*ho(n,e){for(;;)yield*e(n)}function*su(n,e){let t=e?0:n-1;for(;;)t=oi(t,0,n-1),yield t,e?(t++,t>=n-1&&(e=!1)):(t--,t<=0&&(e=!0))}function*lk(n){let e=0,t=0;for(;e<n;)e=oi(e,0,n-1),yield e,t++,e+=t%2?2:-1}function*ck(n){let e=n-1,t=0;for(;e>=0;)e=oi(e,0,n-1),yield e,t++,e+=t%2?-2:1}function*hk(n){for(;;)yield Math.floor(Math.random()*n)}function*dk(n){const e=[];for(let t=0;t<n;t++)e.push(t);for(;e.length>0;){const t=e.splice(Math.floor(e.length*Math.random()),1);yield oi(t[0],0,n-1)}}function*uk(n){let e=Math.floor(Math.random()*n);for(;;)e===0?e++:e===n-1||Math.random()<.5?e--:e++,yield e}function*ru(n,e="up",t=0){switch(ne(n>=1,"The number of values must be at least one"),e){case"up":yield*ho(n,sk);case"down":yield*ho(n,rk);case"upDown":yield*su(n,!0);case"downUp":yield*su(n,!1);case"alternateUp":yield*ho(n,lk);case"alternateDown":yield*ho(n,ck);case"random":yield*hk(n);case"randomOnce":yield*ho(n,dk);case"randomWalk":yield*uk(n)}}class rf extends Gi{constructor(){const e=q(rf.getDefaults(),arguments,["callback","values","pattern"]);super(e),this.name="Pattern",this.callback=e.callback,this._values=e.values,this._pattern=ru(e.values.length,e.pattern),this._type=e.pattern}static getDefaults(){return Object.assign(Gi.getDefaults(),{pattern:"up",values:[],callback:_e})}_tick(e){const t=this._pattern.next();this._index=t.value,this._value=this._values[t.value],this.callback(e,this._value)}get values(){return this._values}set values(e){this._values=e,this.pattern=this._type}get value(){return this._value}get index(){return this._index}get pattern(){return this._type}set pattern(e){this._type=e,this._pattern=ru(this._values.length,this._type)}}class Ho extends Hn{constructor(){const e=q(Ho.getDefaults(),arguments,["callback","events","subdivision"]);super(e),this.name="Sequence",this._part=new br({callback:this._seqCallback.bind(this),context:this.context}),this._events=[],this._eventsArray=[],this._subdivision=this.toTicks(e.subdivision),this.events=e.events,this.loop=e.loop,this.loopStart=e.loopStart,this.loopEnd=e.loopEnd,this.playbackRate=e.playbackRate,this.probability=e.probability,this.humanize=e.humanize,this.mute=e.mute,this.playbackRate=e.playbackRate}static getDefaults(){return Object.assign(Bt(Hn.getDefaults(),["value"]),{events:[],loop:!0,loopEnd:0,loopStart:0,subdivision:"8n"})}_seqCallback(e,t){t!==null&&!this.mute&&this.callback(e,t)}get events(){return this._events}set events(e){this.clear(),this._eventsArray=e,this._events=this._createSequence(this._eventsArray),this._eventsUpdated()}start(e,t){return this._part.start(e,t&&this._indexTime(t)),this}stop(e){return this._part.stop(e),this}get subdivision(){return new $e(this.context,this._subdivision).toSeconds()}_createSequence(e){return new Proxy(e,{get:(t,a)=>t[a],set:(t,a,i)=>(Pn(a)&&isFinite(parseInt(a,10))&&wt(i)?t[a]=this._createSequence(i):t[a]=i,this._eventsUpdated(),!0)})}_eventsUpdated(){this._part.clear(),this._rescheduleSequence(this._eventsArray,this._subdivision,this.startOffset),this.loopEnd=this.loopEnd}_rescheduleSequence(e,t,a){e.forEach((i,o)=>{const s=o*t+a;if(wt(i))this._rescheduleSequence(i,t/i.length,s);else{const r=new $e(this.context,s,"i").toSeconds();this._part.add(r,i)}})}_indexTime(e){return new $e(this.context,e*this._subdivision+this.startOffset).toSeconds()}clear(){return this._part.clear(),this}dispose(){return super.dispose(),this._part.dispose(),this}get loop(){return this._part.loop}set loop(e){this._part.loop=e}get loopStart(){return this._loopStart}set loopStart(e){this._loopStart=e,this._part.loopStart=this._indexTime(e)}get loopEnd(){return this._loopEnd}set loopEnd(e){this._loopEnd=e,e===0?this._part.loopEnd=this._indexTime(this._eventsArray.length):this._part.loopEnd=this._indexTime(e)}get startOffset(){return this._part.startOffset}set startOffset(e){this._part.startOffset=e}get playbackRate(){return this._part.playbackRate}set playbackRate(e){this._part.playbackRate=e}get probability(){return this._part.probability}set probability(e){this._part.probability=e}get progress(){return this._part.progress}get humanize(){return this._part.humanize}set humanize(e){this._part.humanize=e}get length(){return this._part.length}}class dl extends ${constructor(){const e=q(dl.getDefaults(),arguments,["fade"]);super(e),this.name="CrossFade",this._panner=this.context.createStereoPanner(),this._split=this.context.createChannelSplitter(2),this._g2a=new Q_({context:this.context}),this.a=new re({context:this.context,gain:0}),this.b=new re({context:this.context,gain:0}),this.output=new re({context:this.context}),this._internalChannels=[this.a,this.b],this.fade=new be({context:this.context,units:"normalRange",value:e.fade}),fe(this,"fade"),this.context.getConstant(1).connect(this._panner),this._panner.connect(this._split),this._panner.channelCount=1,this._panner.channelCountMode="explicit",Lt(this._split,this.a.gain,0),Lt(this._split,this.b.gain,1),this.fade.chain(this._g2a,this._panner.pan),this.a.connect(this.output),this.b.connect(this.output)}static getDefaults(){return Object.assign($.getDefaults(),{fade:.5})}dispose(){return super.dispose(),this.a.dispose(),this.b.dispose(),this.output.dispose(),this.fade.dispose(),this._g2a.dispose(),this._panner.disconnect(),this._split.disconnect(),this}}class Qa extends ${constructor(e){super(e),this.name="Effect",this._dryWet=new dl({context:this.context}),this.wet=this._dryWet.fade,this.effectSend=new re({context:this.context}),this.effectReturn=new re({context:this.context}),this.input=new re({context:this.context}),this.output=this._dryWet,this.input.fan(this._dryWet.a,this.effectSend),this.effectReturn.connect(this._dryWet.b),this.wet.setValueAtTime(e.wet,0),this._internalChannels=[this.effectReturn,this.effectSend],fe(this,"wet")}static getDefaults(){return Object.assign($.getDefaults(),{wet:1})}connectEffect(e){return this._internalChannels.push(e),this.effectSend.chain(e,this.effectReturn),this}dispose(){return super.dispose(),this._dryWet.dispose(),this.effectSend.dispose(),this.effectReturn.dispose(),this.wet.dispose(),this}}class vr extends Qa{constructor(e){super(e),this.name="LFOEffect",this._lfo=new Mh({context:this.context,frequency:e.frequency,amplitude:e.depth}),this.depth=this._lfo.amplitude,this.frequency=this._lfo.frequency,this.type=e.type,fe(this,["frequency","depth"])}static getDefaults(){return Object.assign(Qa.getDefaults(),{frequency:1,type:"sine",depth:1})}start(e){return this._lfo.start(e),this}stop(e){return this._lfo.stop(e),this}sync(){return this._lfo.sync(),this}unsync(){return this._lfo.unsync(),this}get type(){return this._lfo.type}set type(e){this._lfo.type=e}dispose(){return super.dispose(),this._lfo.dispose(),this.frequency.dispose(),this.depth.dispose(),this}}class Rh extends vr{constructor(){const e=q(Rh.getDefaults(),arguments,["frequency","baseFrequency","octaves"]);super(e),this.name="AutoFilter",this.filter=new Vo(Object.assign(e.filter,{context:this.context})),this.connectEffect(this.filter),this._lfo.connect(this.filter.frequency),this.octaves=e.octaves,this.baseFrequency=e.baseFrequency}static getDefaults(){return Object.assign(vr.getDefaults(),{baseFrequency:200,octaves:2.6,filter:{type:"lowpass",rolloff:-12,Q:1}})}get baseFrequency(){return this._lfo.min}set baseFrequency(e){this._lfo.min=this.toFrequency(e),this.octaves=this._octaves}get octaves(){return this._octaves}set octaves(e){this._octaves=e,this._lfo.max=this._lfo.min*Math.pow(2,e)}dispose(){return super.dispose(),this.filter.dispose(),this}}class ul extends ${constructor(){const e=q(ul.getDefaults(),arguments,["pan"]);super(e),this.name="Panner",this._panner=this.context.createStereoPanner(),this.input=this._panner,this.output=this._panner,this.pan=new pe({context:this.context,param:this._panner.pan,value:e.pan,minValue:-1,maxValue:1}),this._panner.channelCount=e.channelCount,this._panner.channelCountMode="explicit",fe(this,"pan")}static getDefaults(){return Object.assign($.getDefaults(),{pan:0,channelCount:1})}dispose(){return super.dispose(),this._panner.disconnect(),this.pan.dispose(),this}}class ml extends vr{constructor(){const e=q(ml.getDefaults(),arguments,["frequency"]);super(e),this.name="AutoPanner",this._panner=new ul({context:this.context,channelCount:e.channelCount}),this.connectEffect(this._panner),this._lfo.connect(this._panner.pan),this._lfo.min=-1,this._lfo.max=1}static getDefaults(){return Object.assign(vr.getDefaults(),{channelCount:1})}dispose(){return super.dispose(),this._panner.dispose(),this}}class Oh extends ${constructor(){const e=q(Oh.getDefaults(),arguments,["smoothing"]);super(e),this.name="Follower",this._abs=this.input=new X_({context:this.context}),this._lowpass=this.output=new cl({context:this.context,frequency:1/this.toSeconds(e.smoothing),type:"lowpass"}),this._abs.connect(this._lowpass),this._smoothing=e.smoothing}static getDefaults(){return Object.assign($.getDefaults(),{smoothing:.05})}get smoothing(){return this._smoothing}set smoothing(e){this._smoothing=e,this._lowpass.frequency=1/this.toSeconds(this.smoothing)}dispose(){return super.dispose(),this._abs.dispose(),this._lowpass.dispose(),this}}const lf="bit-crusher",mk=`
	class BitCrusherWorklet extends SingleIOProcessor {

		static get parameterDescriptors() {
			return [{
				name: "bits",
				defaultValue: 12,
				minValue: 1,
				maxValue: 16,
				automationRate: 'k-rate'
			}];
		}

		generate(input, _channel, parameters) {
			const step = Math.pow(0.5, parameters.bits - 1);
			const val = step * Math.floor(input / step + 0.5);
			return val;
		}
	}
`;af(lf,mk);class qh extends Qa{constructor(){const e=q(qh.getDefaults(),arguments,["bits"]);super(e),this.name="BitCrusher",this._bitCrusherWorklet=new Fh({context:this.context,bits:e.bits}),this.connectEffect(this._bitCrusherWorklet),this.bits=this._bitCrusherWorklet.bits}static getDefaults(){return Object.assign(Qa.getDefaults(),{bits:4})}dispose(){return super.dispose(),this._bitCrusherWorklet.dispose(),this}}class Fh extends Tc{constructor(){const e=q(Fh.getDefaults(),arguments);super(e),this.name="BitCrusherWorklet",this.input=new re({context:this.context}),this.output=new re({context:this.context}),this.bits=new pe({context:this.context,value:e.bits,units:"positive",minValue:1,maxValue:16,param:this._dummyParam,swappable:!0})}static getDefaults(){return Object.assign(Tc.getDefaults(),{bits:12})}_audioWorkletName(){return lf}onReady(e){Nn(this.input,e,this.output);const t=e.parameters.get("bits");this.bits.setParam(t)}dispose(){return super.dispose(),this.input.dispose(),this.output.dispose(),this.bits.dispose(),this}}class Yi extends ${constructor(){const e=q(Yi.getDefaults(),arguments,["channels"]);super(e),this.name="Split",this._splitter=this.input=this.output=this.context.createChannelSplitter(e.channels),this._internalChannels=[this._splitter]}static getDefaults(){return Object.assign($.getDefaults(),{channels:2})}dispose(){return super.dispose(),this._splitter.disconnect(),this}}class Xi extends ${constructor(){const e=q(Xi.getDefaults(),arguments,["channels"]);super(e),this.name="Merge",this._merger=this.output=this.input=this.context.createChannelMerger(e.channels)}static getDefaults(){return Object.assign($.getDefaults(),{channels:2})}dispose(){return super.dispose(),this._merger.disconnect(),this}}class lu extends ${constructor(e){super(e),this.name="StereoEffect",this.input=new re({context:this.context}),this.input.channelCount=2,this.input.channelCountMode="explicit",this._dryWet=this.output=new dl({context:this.context,fade:e.wet}),this.wet=this._dryWet.fade,this._split=new Yi({context:this.context,channels:2}),this._merge=new Xi({context:this.context,channels:2}),this.input.connect(this._split),this.input.connect(this._dryWet.a),this._merge.connect(this._dryWet.b),fe(this,["wet"])}connectEffectLeft(...e){this._split.connect(e[0],0,0),Nn(...e),Lt(e[e.length-1],this._merge,0,0)}connectEffectRight(...e){this._split.connect(e[0],1,0),Nn(...e),Lt(e[e.length-1],this._merge,0,1)}static getDefaults(){return Object.assign($.getDefaults(),{wet:1})}dispose(){return super.dispose(),this._dryWet.dispose(),this._split.dispose(),this._merge.dispose(),this}}class pk extends lu{constructor(e){super(e),this.feedback=new be({context:this.context,value:e.feedback,units:"normalRange"}),this._feedbackL=new re({context:this.context}),this._feedbackR=new re({context:this.context}),this._feedbackSplit=new Yi({context:this.context,channels:2}),this._feedbackMerge=new Xi({context:this.context,channels:2}),this._merge.connect(this._feedbackSplit),this._feedbackMerge.connect(this._split),this._feedbackSplit.connect(this._feedbackL,0,0),this._feedbackL.connect(this._feedbackMerge,0,0),this._feedbackSplit.connect(this._feedbackR,1,0),this._feedbackR.connect(this._feedbackMerge,0,1),this.feedback.fan(this._feedbackL.gain,this._feedbackR.gain),fe(this,["feedback"])}static getDefaults(){return Object.assign(lu.getDefaults(),{feedback:.5})}dispose(){return super.dispose(),this.feedback.dispose(),this._feedbackL.dispose(),this._feedbackR.dispose(),this._feedbackSplit.dispose(),this._feedbackMerge.dispose(),this}}class cu extends pk{constructor(e){super(e),this._feedbackL.disconnect(),this._feedbackL.connect(this._feedbackMerge,0,1),this._feedbackR.disconnect(),this._feedbackR.connect(this._feedbackMerge,0,0),fe(this,["feedback"])}}class Lh extends cu{constructor(){const e=q(Lh.getDefaults(),arguments,["delayTime","feedback"]);super(e),this.name="PingPongDelay",this._leftDelay=new Ao({context:this.context,maxDelay:e.maxDelay}),this._rightDelay=new Ao({context:this.context,maxDelay:e.maxDelay}),this._rightPreDelay=new Ao({context:this.context,maxDelay:e.maxDelay}),this.delayTime=new be({context:this.context,units:"time",value:e.delayTime}),this.connectEffectLeft(this._leftDelay),this.connectEffectRight(this._rightPreDelay,this._rightDelay),this.delayTime.fan(this._leftDelay.delayTime,this._rightDelay.delayTime,this._rightPreDelay.delayTime),this._feedbackL.disconnect(),this._feedbackL.connect(this._rightDelay),fe(this,["delayTime"])}static getDefaults(){return Object.assign(cu.getDefaults(),{delayTime:.25,maxDelay:1})}dispose(){return super.dispose(),this._leftDelay.dispose(),this._rightDelay.dispose(),this._rightPreDelay.dispose(),this.delayTime.dispose(),this}}class pl extends Qa{constructor(){const e=q(pl.getDefaults(),arguments,["decay"]);super(e),this.name="Reverb",this._convolver=this.context.createConvolver(),this.ready=Promise.resolve(),this._decay=e.decay,this._preDelay=e.preDelay,this.generate(),this.connectEffect(this._convolver)}static getDefaults(){return Object.assign(Qa.getDefaults(),{decay:1.5,preDelay:.01})}get decay(){return this._decay}set decay(e){e=this.toSeconds(e),Qt(e,.001),this._decay=e,this.generate()}get preDelay(){return this._preDelay}set preDelay(e){e=this.toSeconds(e),Qt(e,0),this._preDelay=e,this.generate()}generate(){return Ne(this,void 0,void 0,function*(){const e=this.ready,t=new Zr(2,this._decay+this._preDelay,this.context.sampleRate),a=new Ya({context:t}),i=new Ya({context:t}),o=new Xi({context:t});a.connect(o,0,0),i.connect(o,0,1);const s=new re({context:t}).toDestination();o.connect(s),a.start(0),i.start(0),s.gain.setValueAtTime(0,0),s.gain.setValueAtTime(1,this._preDelay),s.gain.exponentialApproachValueAtTime(0,this._preDelay,this.decay);const r=t.render();return this.ready=r.then(_e),yield e,this._convolver.buffer=(yield r).get(),this})}dispose(){return super.dispose(),this._convolver.disconnect(),this}}class Gh extends ${constructor(){super(q(Gh.getDefaults(),arguments)),this.name="MidSideSplit",this._split=this.input=new Yi({channels:2,context:this.context}),this._midAdd=new vs({context:this.context}),this.mid=new tt({context:this.context,value:Math.SQRT1_2}),this._sideSubtract=new Zi({context:this.context}),this.side=new tt({context:this.context,value:Math.SQRT1_2}),this._split.connect(this._midAdd,0),this._split.connect(this._midAdd.addend,1),this._split.connect(this._sideSubtract,0),this._split.connect(this._sideSubtract.subtrahend,1),this._midAdd.connect(this.mid),this._sideSubtract.connect(this.side)}dispose(){return super.dispose(),this.mid.dispose(),this.side.dispose(),this._midAdd.dispose(),this._sideSubtract.dispose(),this._split.dispose(),this}}class $h extends ${constructor(){super(q($h.getDefaults(),arguments)),this.name="MidSideMerge",this.mid=new re({context:this.context}),this.side=new re({context:this.context}),this._left=new vs({context:this.context}),this._leftMult=new tt({context:this.context,value:Math.SQRT1_2}),this._right=new Zi({context:this.context}),this._rightMult=new tt({context:this.context,value:Math.SQRT1_2}),this._merge=this.output=new Xi({context:this.context}),this.mid.fan(this._left),this.side.connect(this._left.addend),this.mid.connect(this._right),this.side.connect(this._right.subtrahend),this._left.connect(this._leftMult),this._right.connect(this._rightMult),this._leftMult.connect(this._merge,0,0),this._rightMult.connect(this._merge,0,1)}dispose(){return super.dispose(),this.mid.dispose(),this.side.dispose(),this._leftMult.dispose(),this._rightMult.dispose(),this._left.dispose(),this._right.dispose(),this}}class hu extends Qa{constructor(e){super(e),this.name="MidSideEffect",this._midSideMerge=new $h({context:this.context}),this._midSideSplit=new Gh({context:this.context}),this._midSend=this._midSideSplit.mid,this._sideSend=this._midSideSplit.side,this._midReturn=this._midSideMerge.mid,this._sideReturn=this._midSideMerge.side,this.effectSend.connect(this._midSideSplit),this._midSideMerge.connect(this.effectReturn)}connectEffectMid(...e){this._midSend.chain(...e,this._midReturn)}connectEffectSide(...e){this._sideSend.chain(...e,this._sideReturn)}dispose(){return super.dispose(),this._midSideSplit.dispose(),this._midSideMerge.dispose(),this._midSend.dispose(),this._sideSend.dispose(),this._midReturn.dispose(),this._sideReturn.dispose(),this}}class Vh extends hu{constructor(){const e=q(Vh.getDefaults(),arguments,["width"]);super(e),this.name="StereoWidener",this.width=new be({context:this.context,value:e.width,units:"normalRange"}),fe(this,["width"]),this._twoTimesWidthMid=new tt({context:this.context,value:2}),this._twoTimesWidthSide=new tt({context:this.context,value:2}),this._midMult=new tt({context:this.context}),this._twoTimesWidthMid.connect(this._midMult.factor),this.connectEffectMid(this._midMult),this._oneMinusWidth=new Zi({context:this.context}),this._oneMinusWidth.connect(this._twoTimesWidthMid),Lt(this.context.getConstant(1),this._oneMinusWidth),this.width.connect(this._oneMinusWidth.subtrahend),this._sideMult=new tt({context:this.context}),this.width.connect(this._twoTimesWidthSide),this._twoTimesWidthSide.connect(this._sideMult.factor),this.connectEffectSide(this._sideMult)}static getDefaults(){return Object.assign(hu.getDefaults(),{width:.5})}dispose(){return super.dispose(),this.width.dispose(),this._midMult.dispose(),this._sideMult.dispose(),this._twoTimesWidthMid.dispose(),this._twoTimesWidthSide.dispose(),this._oneMinusWidth.dispose(),this}}class fl extends ${constructor(){const e=q(fl.getDefaults(),arguments,["type","size"]);super(e),this.name="Analyser",this._analysers=[],this._buffers=[],this.input=this.output=this._gain=new re({context:this.context}),this._split=new Yi({context:this.context,channels:e.channels}),this.input.connect(this._split),Qt(e.channels,1);for(let t=0;t<e.channels;t++)this._analysers[t]=this.context.createAnalyser(),this._split.connect(this._analysers[t],t,0);this.size=e.size,this.type=e.type,this.smoothing=e.smoothing}static getDefaults(){return Object.assign($.getDefaults(),{size:1024,smoothing:.8,type:"fft",channels:1})}getValue(){return this._analysers.forEach((e,t)=>{const a=this._buffers[t];this._type==="fft"?e.getFloatFrequencyData(a):this._type==="waveform"&&e.getFloatTimeDomainData(a)}),this.channels===1?this._buffers[0]:this._buffers}get size(){return this._analysers[0].frequencyBinCount}set size(e){this._analysers.forEach((t,a)=>{t.fftSize=e*2,this._buffers[a]=new Float32Array(e)})}get channels(){return this._analysers.length}get type(){return this._type}set type(e){ne(e==="waveform"||e==="fft",`Analyser: invalid type: ${e}`),this._type=e}get smoothing(){return this._analysers[0].smoothingTimeConstant}set smoothing(e){this._analysers.forEach(t=>t.smoothingTimeConstant=e)}dispose(){return super.dispose(),this._analysers.forEach(e=>e.disconnect()),this._split.dispose(),this._gain.dispose(),this}}class Wo extends ${constructor(){super(q(Wo.getDefaults(),arguments)),this.name="MeterBase",this.input=this.output=this._analyser=new fl({context:this.context,size:256,type:"waveform"})}dispose(){return super.dispose(),this._analyser.dispose(),this}}class _s extends Wo{constructor(){const e=q(_s.getDefaults(),arguments,["smoothing"]);super(e),this.name="Meter",this.input=this.output=this._analyser=new fl({context:this.context,size:256,type:"waveform",channels:e.channelCount}),this.smoothing=e.smoothing,this.normalRange=e.normalRange,this._rms=new Array(e.channelCount),this._rms.fill(0)}static getDefaults(){return Object.assign(Wo.getDefaults(),{smoothing:.8,normalRange:!1,channelCount:1})}getLevel(){return ms("'getLevel' has been changed to 'getValue'"),this.getValue()}getValue(){const e=this._analyser.getValue(),a=(this.channels===1?[e]:e).map((i,o)=>{const s=i.reduce((l,c)=>l+c*c,0),r=Math.sqrt(s/i.length);return this._rms[o]=Math.max(r,this._rms[o]*this.smoothing),this.normalRange?this._rms[o]:ea(this._rms[o])});return this.channels===1?a[0]:a}get channels(){return this._analyser.channels}dispose(){return super.dispose(),this._analyser.dispose(),this}}class Hh extends Wo{constructor(){const e=q(Hh.getDefaults(),arguments,["size"]);super(e),this.name="FFT",this.normalRange=e.normalRange,this._analyser.type="fft",this.size=e.size}static getDefaults(){return Object.assign($.getDefaults(),{normalRange:!1,size:1024,smoothing:.8})}getValue(){return this._analyser.getValue().map(t=>this.normalRange?Go(t):t)}get size(){return this._analyser.size}set size(e){this._analyser.size=e}get smoothing(){return this._analyser.smoothing}set smoothing(e){this._analyser.smoothing=e}getFrequencyOfIndex(e){return ne(0<=e&&e<this.size,`index must be greater than or equal to 0 and less than ${this.size}`),e*this.context.sampleRate/(this.size*2)}}class Ze extends ${constructor(){const e=q(Ze.getDefaults(),arguments,["solo"]);super(e),this.name="Solo",this.input=this.output=new re({context:this.context}),Ze._allSolos.has(this.context)||Ze._allSolos.set(this.context,new Set),Ze._allSolos.get(this.context).add(this),this.solo=e.solo}static getDefaults(){return Object.assign($.getDefaults(),{solo:!1})}get solo(){return this._isSoloed()}set solo(e){e?this._addSolo():this._removeSolo(),Ze._allSolos.get(this.context).forEach(t=>t._updateSolo())}get muted(){return this.input.gain.value===0}_addSolo(){Ze._soloed.has(this.context)||Ze._soloed.set(this.context,new Set),Ze._soloed.get(this.context).add(this)}_removeSolo(){Ze._soloed.has(this.context)&&Ze._soloed.get(this.context).delete(this)}_isSoloed(){return Ze._soloed.has(this.context)&&Ze._soloed.get(this.context).has(this)}_noSolos(){return!Ze._soloed.has(this.context)||Ze._soloed.has(this.context)&&Ze._soloed.get(this.context).size===0}_updateSolo(){this._isSoloed()?this.input.gain.value=1:this._noSolos()?this.input.gain.value=1:this.input.gain.value=0}dispose(){return super.dispose(),Ze._allSolos.get(this.context).delete(this),this._removeSolo(),this}}Ze._allSolos=new Map;Ze._soloed=new Map;class ks extends ${constructor(){const e=q(ks.getDefaults(),arguments,["pan","volume"]);super(e),this.name="PanVol",this._panner=this.input=new ul({context:this.context,pan:e.pan,channelCount:e.channelCount}),this.pan=this._panner.pan,this._volume=this.output=new Aa({context:this.context,volume:e.volume}),this.volume=this._volume.volume,this._panner.connect(this._volume),this.mute=e.mute,fe(this,["pan","volume"])}static getDefaults(){return Object.assign($.getDefaults(),{mute:!1,pan:0,volume:0,channelCount:1})}get mute(){return this._volume.mute}set mute(e){this._volume.mute=e}dispose(){return super.dispose(),this._panner.dispose(),this.pan.dispose(),this._volume.dispose(),this.volume.dispose(),this}}class Ci extends ${constructor(){const e=q(Ci.getDefaults(),arguments,["volume","pan"]);super(e),this.name="Channel",this._solo=this.input=new Ze({solo:e.solo,context:this.context}),this._panVol=this.output=new ks({context:this.context,pan:e.pan,volume:e.volume,mute:e.mute,channelCount:e.channelCount}),this.pan=this._panVol.pan,this.volume=this._panVol.volume,this._solo.connect(this._panVol),fe(this,["pan","volume"])}static getDefaults(){return Object.assign($.getDefaults(),{pan:0,volume:0,mute:!1,solo:!1,channelCount:1})}get solo(){return this._solo.solo}set solo(e){this._solo.solo=e}get muted(){return this._solo.muted||this.mute}get mute(){return this._panVol.mute}set mute(e){this._panVol.mute=e}_getBus(e){return Ci.buses.has(e)||Ci.buses.set(e,new re({context:this.context})),Ci.buses.get(e)}send(e,t=0){const a=this._getBus(e),i=new re({context:this.context,units:"decibels",gain:t});return this.connect(i),i.connect(a),i}receive(e){return this._getBus(e).connect(this),this}dispose(){return super.dispose(),this._panVol.dispose(),this.pan.dispose(),this.volume.dispose(),this._solo.dispose(),this}}Ci.buses=new Map;class Uo extends ${constructor(){const e=q(Uo.getDefaults(),arguments);super(e),this.name="Recorder",this.input=new re({context:this.context}),ne(Uo.supported,"Media Recorder API is not available"),this._stream=this.context.createMediaStreamDestination(),this.input.connect(this._stream),this._recorder=new MediaRecorder(this._stream.stream,{mimeType:e.mimeType})}static getDefaults(){return $.getDefaults()}get mimeType(){return this._recorder.mimeType}static get supported(){return Mt!==null&&Reflect.has(Mt,"MediaRecorder")}get state(){return this._recorder.state==="inactive"?"stopped":this._recorder.state==="paused"?"paused":"started"}start(){return Ne(this,void 0,void 0,function*(){ne(this.state!=="started","Recorder is already started");const e=new Promise(t=>{const a=()=>{this._recorder.removeEventListener("start",a,!1),t()};this._recorder.addEventListener("start",a,!1)});return this._recorder.start(),yield e})}stop(){return Ne(this,void 0,void 0,function*(){ne(this.state!=="stopped","Recorder is not started");const e=new Promise(t=>{const a=i=>{this._recorder.removeEventListener("dataavailable",a,!1),t(i.data)};this._recorder.addEventListener("dataavailable",a,!1)});return this._recorder.stop(),yield e})}pause(){return ne(this.state==="started","Recorder must be started"),this._recorder.pause(),this}dispose(){return super.dispose(),this.input.dispose(),this._stream.disconnect(),this}}class Ts extends ${constructor(){const e=q(Ts.getDefaults(),arguments,["threshold","ratio"]);super(e),this.name="Compressor",this._compressor=this.context.createDynamicsCompressor(),this.input=this._compressor,this.output=this._compressor,this.threshold=new pe({minValue:this._compressor.threshold.minValue,maxValue:this._compressor.threshold.maxValue,context:this.context,convert:!1,param:this._compressor.threshold,units:"decibels",value:e.threshold}),this.attack=new pe({minValue:this._compressor.attack.minValue,maxValue:this._compressor.attack.maxValue,context:this.context,param:this._compressor.attack,units:"time",value:e.attack}),this.release=new pe({minValue:this._compressor.release.minValue,maxValue:this._compressor.release.maxValue,context:this.context,param:this._compressor.release,units:"time",value:e.release}),this.knee=new pe({minValue:this._compressor.knee.minValue,maxValue:this._compressor.knee.maxValue,context:this.context,convert:!1,param:this._compressor.knee,units:"decibels",value:e.knee}),this.ratio=new pe({minValue:this._compressor.ratio.minValue,maxValue:this._compressor.ratio.maxValue,context:this.context,convert:!1,param:this._compressor.ratio,units:"positive",value:e.ratio}),fe(this,["knee","release","attack","ratio","threshold"])}static getDefaults(){return Object.assign($.getDefaults(),{attack:.003,knee:30,ratio:12,release:.25,threshold:-24})}get reduction(){return this._compressor.reduction}dispose(){return super.dispose(),this._compressor.disconnect(),this.attack.dispose(),this.release.dispose(),this.threshold.dispose(),this.ratio.dispose(),this.knee.dispose(),this}}class Wh extends ${constructor(){const e=q(Wh.getDefaults(),arguments,["threshold","smoothing"]);super(e),this.name="Gate",this._follower=new Oh({context:this.context,smoothing:e.smoothing}),this._gt=new Eh({context:this.context,value:Go(e.threshold)}),this.input=new re({context:this.context}),this._gate=this.output=new re({context:this.context}),this.input.connect(this._gate),this.input.chain(this._follower,this._gt,this._gate.gain)}static getDefaults(){return Object.assign($.getDefaults(),{smoothing:.1,threshold:-40})}get threshold(){return ea(this._gt.value)}set threshold(e){this._gt.value=Go(e)}get smoothing(){return this._follower.smoothing}set smoothing(e){this._follower.smoothing=e}dispose(){return super.dispose(),this.input.dispose(),this._follower.dispose(),this._gt.dispose(),this._gate.dispose(),this}}class gl extends ${constructor(){const e=q(gl.getDefaults(),arguments,["threshold"]);super(e),this.name="Limiter",this._compressor=this.input=this.output=new Ts({context:this.context,ratio:20,attack:.003,release:.01,threshold:e.threshold}),this.threshold=this._compressor.threshold,fe(this,"threshold")}static getDefaults(){return Object.assign($.getDefaults(),{threshold:-12})}get reduction(){return this._compressor.reduction}dispose(){return super.dispose(),this._compressor.dispose(),this.threshold.dispose(),this}}function iR(){return Ue().now()}Ue().transport;function pi(){return Ue().transport}Ue().destination;Ue().destination;function fk(){return Ue().destination}Ue().listener;Ue().draw;function Uh(){return Ue().draw}const oR=Ue();function yt(n,e,t){if(typeof n=="function"||Jy(n))return H(()=>Fl(sa(n),sa(e),sa(t)));const a=ee(n);return H({get(){return a.value=Fl(a.value,sa(e),sa(t))},set(i){a.value=Fl(i,sa(e),sa(t))}})}function sR(n){return H(()=>Math.round(sa(n)))}class cn{constructor(e=!1){this.eventMap={},this.eventsSuspended=e==!0}addListener(e,t,a={}){if(typeof e=="string"&&e.length<1||e instanceof String&&e.length<1||typeof e!="string"&&!(e instanceof String)&&e!==cn.ANY_EVENT)throw new TypeError("The 'event' parameter must be a string or EventEmitter.ANY_EVENT.");if(typeof t!="function")throw new TypeError("The callback must be a function.");const i=new du(e,this,t,a);return this.eventMap[e]||(this.eventMap[e]=[]),a.prepend?this.eventMap[e].unshift(i):this.eventMap[e].push(i),i}addOneTimeListener(e,t,a={}){a.remaining=1,this.addListener(e,t,a)}static get ANY_EVENT(){return Symbol.for("Any event")}hasListener(e,t){return e===void 0?this.eventMap[cn.ANY_EVENT]&&this.eventMap[cn.ANY_EVENT].length>0?!0:Object.entries(this.eventMap).some(([,a])=>a.length>0):this.eventMap[e]&&this.eventMap[e].length>0?t instanceof du?this.eventMap[e].filter(i=>i===t).length>0:typeof t=="function"?this.eventMap[e].filter(i=>i.callback===t).length>0:t==null:!1}get eventNames(){return Object.keys(this.eventMap)}getListeners(e){return this.eventMap[e]||[]}suspendEvent(e){this.getListeners(e).forEach(t=>{t.suspended=!0})}unsuspendEvent(e){this.getListeners(e).forEach(t=>{t.suspended=!1})}getListenerCount(e){return this.getListeners(e).length}emit(e,...t){if(typeof e!="string"&&!(e instanceof String))throw new TypeError("The 'event' parameter must be a string.");if(this.eventsSuspended)return;let a=[],i=this.eventMap[cn.ANY_EVENT]||[];return this.eventMap[e]&&(i=i.concat(this.eventMap[e])),i.forEach(o=>{if(o.suspended)return;let s=[...t];Array.isArray(o.arguments)&&(s=s.concat(o.arguments)),o.remaining>0&&(a.push(o.callback.apply(o.context,s)),o.count++),--o.remaining<1&&o.remove()}),a}removeListener(e,t,a={}){if(e===void 0){this.eventMap={};return}else if(!this.eventMap[e])return;let i=this.eventMap[e].filter(o=>t&&o.callback!==t||a.remaining&&a.remaining!==o.remaining||a.context&&a.context!==o.context);i.length?this.eventMap[e]=i:delete this.eventMap[e]}async waitFor(e,t={}){return t.duration=parseInt(t.duration),(isNaN(t.duration)||t.duration<=0)&&(t.duration=1/0),new Promise((a,i)=>{let o,s=this.addListener(e,()=>{clearTimeout(o),a()},{remaining:1});t.duration!==1/0&&(o=setTimeout(()=>{s.remove(),i("The duration expired before the event was emitted.")},t.duration))})}get eventCount(){return Object.keys(this.eventMap).length}}class du{constructor(e,t,a,i={}){if(typeof e!="string"&&!(e instanceof String)&&e!==cn.ANY_EVENT)throw new TypeError("The 'event' parameter must be a string or EventEmitter.ANY_EVENT.");if(!t)throw new ReferenceError("The 'target' parameter is mandatory.");if(typeof a!="function")throw new TypeError("The 'callback' must be a function.");i.arguments!==void 0&&!Array.isArray(i.arguments)&&(i.arguments=[i.arguments]),i=Object.assign({context:t,remaining:1/0,arguments:void 0,duration:1/0},i),i.duration!==1/0&&setTimeout(()=>this.remove(),i.duration),this.arguments=i.arguments,this.callback=a,this.context=i.context,this.count=0,this.event=e,this.remaining=parseInt(i.remaining)>=1?parseInt(i.remaining):1/0,this.suspended=!1,this.target=t}remove(){this.target.removeListener(this.event,this.callback,{context:this.context,remaining:this.remaining})}}/**
 * The `Enumerations` class contains enumerations and arrays of elements used throughout the
 * library. All its properties are static and should be referenced using the class name. For
 * example: `Enumerations.CHANNEL_MESSAGES`.
 *
 * @license Apache-2.0
 * @since 3.0.0
 */class N{static get MIDI_CHANNEL_MESSAGES(){return this.validation&&console.warn("The MIDI_CHANNEL_MESSAGES enum has been deprecated. Use the Enumerations.CHANNEL_MESSAGES enum instead."),N.CHANNEL_MESSAGES}static get CHANNEL_MESSAGES(){return{noteoff:8,noteon:9,keyaftertouch:10,controlchange:11,programchange:12,channelaftertouch:13,pitchbend:14}}static get CHANNEL_NUMBERS(){return[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}static get MIDI_CHANNEL_NUMBERS(){return this.validation&&console.warn("The MIDI_CHANNEL_NUMBERS array has been deprecated. Use the Enumerations.CHANNEL_NUMBERS array instead."),[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}static get CHANNEL_MODE_MESSAGES(){return{allsoundoff:120,resetallcontrollers:121,localcontrol:122,allnotesoff:123,omnimodeoff:124,omnimodeon:125,monomodeon:126,polymodeon:127}}static get MIDI_CHANNEL_MODE_MESSAGES(){return this.validation&&console.warn("The MIDI_CHANNEL_MODE_MESSAGES enum has been deprecated. Use the Enumerations.CHANNEL_MODE_MESSAGES enum instead."),N.CHANNEL_MODE_MESSAGES}static get MIDI_CONTROL_CHANGE_MESSAGES(){return this.validation&&console.warn("The MIDI_CONTROL_CHANGE_MESSAGES enum has been deprecated. Use the Enumerations.CONTROL_CHANGE_MESSAGES array instead."),{bankselectcoarse:0,modulationwheelcoarse:1,breathcontrollercoarse:2,controller3:3,footcontrollercoarse:4,portamentotimecoarse:5,dataentrycoarse:6,volumecoarse:7,balancecoarse:8,controller9:9,pancoarse:10,expressioncoarse:11,effectcontrol1coarse:12,effectcontrol2coarse:13,controller14:14,controller15:15,generalpurposeslider1:16,generalpurposeslider2:17,generalpurposeslider3:18,generalpurposeslider4:19,controller20:20,controller21:21,controller22:22,controller23:23,controller24:24,controller25:25,controller26:26,controller27:27,controller28:28,controller29:29,controller30:30,controller31:31,bankselectfine:32,modulationwheelfine:33,breathcontrollerfine:34,controller35:35,footcontrollerfine:36,portamentotimefine:37,dataentryfine:38,volumefine:39,balancefine:40,controller41:41,panfine:42,expressionfine:43,effectcontrol1fine:44,effectcontrol2fine:45,controller46:46,controller47:47,controller48:48,controller49:49,controller50:50,controller51:51,controller52:52,controller53:53,controller54:54,controller55:55,controller56:56,controller57:57,controller58:58,controller59:59,controller60:60,controller61:61,controller62:62,controller63:63,holdpedal:64,portamento:65,sustenutopedal:66,softpedal:67,legatopedal:68,hold2pedal:69,soundvariation:70,resonance:71,soundreleasetime:72,soundattacktime:73,brightness:74,soundcontrol6:75,soundcontrol7:76,soundcontrol8:77,soundcontrol9:78,soundcontrol10:79,generalpurposebutton1:80,generalpurposebutton2:81,generalpurposebutton3:82,generalpurposebutton4:83,controller84:84,controller85:85,controller86:86,controller87:87,controller88:88,controller89:89,controller90:90,reverblevel:91,tremololevel:92,choruslevel:93,celestelevel:94,phaserlevel:95,databuttonincrement:96,databuttondecrement:97,nonregisteredparametercoarse:98,nonregisteredparameterfine:99,registeredparametercoarse:100,registeredparameterfine:101,controller102:102,controller103:103,controller104:104,controller105:105,controller106:106,controller107:107,controller108:108,controller109:109,controller110:110,controller111:111,controller112:112,controller113:113,controller114:114,controller115:115,controller116:116,controller117:117,controller118:118,controller119:119,allsoundoff:120,resetallcontrollers:121,localcontrol:122,allnotesoff:123,omnimodeoff:124,omnimodeon:125,monomodeon:126,polymodeon:127}}static get CONTROL_CHANGE_MESSAGES(){return[{number:0,name:"bankselectcoarse",description:"Bank Select (Coarse)",position:"msb"},{number:1,name:"modulationwheelcoarse",description:"Modulation Wheel (Coarse)",position:"msb"},{number:2,name:"breathcontrollercoarse",description:"Breath Controller (Coarse)",position:"msb"},{number:3,name:"controller3",description:"Undefined",position:"msb"},{number:4,name:"footcontrollercoarse",description:"Foot Controller (Coarse)",position:"msb"},{number:5,name:"portamentotimecoarse",description:"Portamento Time (Coarse)",position:"msb"},{number:6,name:"dataentrycoarse",description:"Data Entry (Coarse)",position:"msb"},{number:7,name:"volumecoarse",description:"Channel Volume (Coarse)",position:"msb"},{number:8,name:"balancecoarse",description:"Balance (Coarse)",position:"msb"},{number:9,name:"controller9",description:"Controller 9 (Coarse)",position:"msb"},{number:10,name:"pancoarse",description:"Pan (Coarse)",position:"msb"},{number:11,name:"expressioncoarse",description:"Expression Controller (Coarse)",position:"msb"},{number:12,name:"effectcontrol1coarse",description:"Effect Control 1 (Coarse)",position:"msb"},{number:13,name:"effectcontrol2coarse",description:"Effect Control 2 (Coarse)",position:"msb"},{number:14,name:"controller14",description:"Undefined",position:"msb"},{number:15,name:"controller15",description:"Undefined",position:"msb"},{number:16,name:"generalpurposecontroller1",description:"General Purpose Controller 1 (Coarse)",position:"msb"},{number:17,name:"generalpurposecontroller2",description:"General Purpose Controller 2 (Coarse)",position:"msb"},{number:18,name:"generalpurposecontroller3",description:"General Purpose Controller 3 (Coarse)",position:"msb"},{number:19,name:"generalpurposecontroller4",description:"General Purpose Controller 4 (Coarse)",position:"msb"},{number:20,name:"controller20",description:"Undefined",position:"msb"},{number:21,name:"controller21",description:"Undefined",position:"msb"},{number:22,name:"controller22",description:"Undefined",position:"msb"},{number:23,name:"controller23",description:"Undefined",position:"msb"},{number:24,name:"controller24",description:"Undefined",position:"msb"},{number:25,name:"controller25",description:"Undefined",position:"msb"},{number:26,name:"controller26",description:"Undefined",position:"msb"},{number:27,name:"controller27",description:"Undefined",position:"msb"},{number:28,name:"controller28",description:"Undefined",position:"msb"},{number:29,name:"controller29",description:"Undefined",position:"msb"},{number:30,name:"controller30",description:"Undefined",position:"msb"},{number:31,name:"controller31",description:"Undefined",position:"msb"},{number:32,name:"bankselectfine",description:"Bank Select (Fine)",position:"lsb"},{number:33,name:"modulationwheelfine",description:"Modulation Wheel (Fine)",position:"lsb"},{number:34,name:"breathcontrollerfine",description:"Breath Controller (Fine)",position:"lsb"},{number:35,name:"controller35",description:"Undefined",position:"lsb"},{number:36,name:"footcontrollerfine",description:"Foot Controller (Fine)",position:"lsb"},{number:37,name:"portamentotimefine",description:"Portamento Time (Fine)",position:"lsb"},{number:38,name:"dataentryfine",description:"Data Entry (Fine)",position:"lsb"},{number:39,name:"channelvolumefine",description:"Channel Volume (Fine)",position:"lsb"},{number:40,name:"balancefine",description:"Balance (Fine)",position:"lsb"},{number:41,name:"controller41",description:"Undefined",position:"lsb"},{number:42,name:"panfine",description:"Pan (Fine)",position:"lsb"},{number:43,name:"expressionfine",description:"Expression Controller (Fine)",position:"lsb"},{number:44,name:"effectcontrol1fine",description:"Effect control 1 (Fine)",position:"lsb"},{number:45,name:"effectcontrol2fine",description:"Effect control 2 (Fine)",position:"lsb"},{number:46,name:"controller46",description:"Undefined",position:"lsb"},{number:47,name:"controller47",description:"Undefined",position:"lsb"},{number:48,name:"controller48",description:"General Purpose Controller 1 (Fine)",position:"lsb"},{number:49,name:"controller49",description:"General Purpose Controller 2 (Fine)",position:"lsb"},{number:50,name:"controller50",description:"General Purpose Controller 3 (Fine)",position:"lsb"},{number:51,name:"controller51",description:"General Purpose Controller 4 (Fine)",position:"lsb"},{number:52,name:"controller52",description:"Undefined",position:"lsb"},{number:53,name:"controller53",description:"Undefined",position:"lsb"},{number:54,name:"controller54",description:"Undefined",position:"lsb"},{number:55,name:"controller55",description:"Undefined",position:"lsb"},{number:56,name:"controller56",description:"Undefined",position:"lsb"},{number:57,name:"controller57",description:"Undefined",position:"lsb"},{number:58,name:"controller58",description:"Undefined",position:"lsb"},{number:59,name:"controller59",description:"Undefined",position:"lsb"},{number:60,name:"controller60",description:"Undefined",position:"lsb"},{number:61,name:"controller61",description:"Undefined",position:"lsb"},{number:62,name:"controller62",description:"Undefined",position:"lsb"},{number:63,name:"controller63",description:"Undefined",position:"lsb"},{number:64,name:"damperpedal",description:"Damper Pedal On/Off"},{number:65,name:"portamento",description:"Portamento On/Off"},{number:66,name:"sostenuto",description:"Sostenuto On/Off"},{number:67,name:"softpedal",description:"Soft Pedal On/Off"},{number:68,name:"legatopedal",description:"Legato Pedal On/Off"},{number:69,name:"hold2",description:"Hold 2 On/Off"},{number:70,name:"soundvariation",description:"Sound Variation",position:"lsb"},{number:71,name:"resonance",description:"Resonance",position:"lsb"},{number:72,name:"releasetime",description:"Release Time",position:"lsb"},{number:73,name:"attacktime",description:"Attack Time",position:"lsb"},{number:74,name:"brightness",description:"Brightness",position:"lsb"},{number:75,name:"decaytime",description:"Decay Time",position:"lsb"},{number:76,name:"vibratorate",description:"Vibrato Rate",position:"lsb"},{number:77,name:"vibratodepth",description:"Vibrato Depth",position:"lsb"},{number:78,name:"vibratodelay",description:"Vibrato Delay",position:"lsb"},{number:79,name:"controller79",description:"Undefined",position:"lsb"},{number:80,name:"generalpurposecontroller5",description:"General Purpose Controller 5",position:"lsb"},{number:81,name:"generalpurposecontroller6",description:"General Purpose Controller 6",position:"lsb"},{number:82,name:"generalpurposecontroller7",description:"General Purpose Controller 7",position:"lsb"},{number:83,name:"generalpurposecontroller8",description:"General Purpose Controller 8",position:"lsb"},{number:84,name:"portamentocontrol",description:"Portamento Control",position:"lsb"},{number:85,name:"controller85",description:"Undefined"},{number:86,name:"controller86",description:"Undefined"},{number:87,name:"controller87",description:"Undefined"},{number:88,name:"highresolutionvelocityprefix",description:"High Resolution Velocity Prefix",position:"lsb"},{number:89,name:"controller89",description:"Undefined"},{number:90,name:"controller90",description:"Undefined"},{number:91,name:"effect1depth",description:"Effects 1 Depth (Reverb Send Level)"},{number:92,name:"effect2depth",description:"Effects 2 Depth"},{number:93,name:"effect3depth",description:"Effects 3 Depth (Chorus Send Level)"},{number:94,name:"effect4depth",description:"Effects 4 Depth"},{number:95,name:"effect5depth",description:"Effects 5 Depth"},{number:96,name:"dataincrement",description:"Data Increment"},{number:97,name:"datadecrement",description:"Data Decrement"},{number:98,name:"nonregisteredparameterfine",description:"Non-Registered Parameter Number (Fine)",position:"lsb"},{number:99,name:"nonregisteredparametercoarse",description:"Non-Registered Parameter Number (Coarse)",position:"msb"},{number:100,name:"registeredparameterfine",description:"Registered Parameter Number (Fine)",position:"lsb"},{number:101,name:"registeredparametercoarse",description:"Registered Parameter Number (Coarse)",position:"msb"},{number:102,name:"controller102",description:"Undefined"},{number:103,name:"controller103",description:"Undefined"},{number:104,name:"controller104",description:"Undefined"},{number:105,name:"controller105",description:"Undefined"},{number:106,name:"controller106",description:"Undefined"},{number:107,name:"controller107",description:"Undefined"},{number:108,name:"controller108",description:"Undefined"},{number:109,name:"controller109",description:"Undefined"},{number:110,name:"controller110",description:"Undefined"},{number:111,name:"controller111",description:"Undefined"},{number:112,name:"controller112",description:"Undefined"},{number:113,name:"controller113",description:"Undefined"},{number:114,name:"controller114",description:"Undefined"},{number:115,name:"controller115",description:"Undefined"},{number:116,name:"controller116",description:"Undefined"},{number:117,name:"controller117",description:"Undefined"},{number:118,name:"controller118",description:"Undefined"},{number:119,name:"controller119",description:"Undefined"},{number:120,name:"allsoundoff",description:"All Sound Off"},{number:121,name:"resetallcontrollers",description:"Reset All Controllers"},{number:122,name:"localcontrol",description:"Local Control On/Off"},{number:123,name:"allnotesoff",description:"All Notes Off"},{number:124,name:"omnimodeoff",description:"Omni Mode Off"},{number:125,name:"omnimodeon",description:"Omni Mode On"},{number:126,name:"monomodeon",description:"Mono Mode On"},{number:127,name:"polymodeon",description:"Poly Mode On"}]}static get REGISTERED_PARAMETERS(){return{pitchbendrange:[0,0],channelfinetuning:[0,1],channelcoarsetuning:[0,2],tuningprogram:[0,3],tuningbank:[0,4],modulationrange:[0,5],azimuthangle:[61,0],elevationangle:[61,1],gain:[61,2],distanceratio:[61,3],maximumdistance:[61,4],maximumdistancegain:[61,5],referencedistanceratio:[61,6],panspreadangle:[61,7],rollangle:[61,8]}}static get MIDI_REGISTERED_PARAMETERS(){return this.validation&&console.warn("The MIDI_REGISTERED_PARAMETERS enum has been deprecated. Use the Enumerations.REGISTERED_PARAMETERS enum instead."),N.MIDI_REGISTERED_PARAMETERS}static get SYSTEM_MESSAGES(){return{sysex:240,timecode:241,songposition:242,songselect:243,tunerequest:246,tuningrequest:246,sysexend:247,clock:248,start:250,continue:251,stop:252,activesensing:254,reset:255,midimessage:0,unknownsystemmessage:-1}}static get MIDI_SYSTEM_MESSAGES(){return this.validation&&console.warn("The MIDI_SYSTEM_MESSAGES enum has been deprecated. Use the Enumerations.SYSTEM_MESSAGES enum instead."),N.SYSTEM_MESSAGES}static get CHANNEL_EVENTS(){return["noteoff","controlchange","noteon","keyaftertouch","programchange","channelaftertouch","pitchbend","allnotesoff","allsoundoff","localcontrol","monomode","omnimode","resetallcontrollers","nrpn","nrpn-dataentrycoarse","nrpn-dataentryfine","nrpn-dataincrement","nrpn-datadecrement","rpn","rpn-dataentrycoarse","rpn-dataentryfine","rpn-dataincrement","rpn-datadecrement","nrpn-databuttonincrement","nrpn-databuttondecrement","rpn-databuttonincrement","rpn-databuttondecrement"]}}/**
 * The `Note` class represents a single musical note such as `"D3"`, `"G#4"`, `"F-1"`, `"Gb7"`, etc.
 *
 * `Note` objects can be played back on a single channel by calling
 * [`OutputChannel.playNote()`]{@link OutputChannel#playNote} or, on multiple channels of the same
 * output, by calling [`Output.playNote()`]{@link Output#playNote}.
 *
 * The note has [`attack`](#attack) and [`release`](#release) velocities set at `0.5` by default.
 * These can be changed by passing in the appropriate option. It is also possible to set a
 * system-wide default for attack and release velocities by using the
 * [`WebMidi.defaults`](WebMidi#defaults) property.
 *
 * If you prefer to work with raw MIDI values (`0` to `127`), you can use [`rawAttack`](#rawAttack) and
 * [`rawRelease`](#rawRelease) to both get and set the values.
 *
 * The note may have a [`duration`](#duration). If it does, playback will be automatically stopped
 * when the duration has elapsed by sending a `"noteoff"` event. By default, the duration is set to
 * `Infinity`. In this case, it will never stop playing unless explicitly stopped by calling a
 * method such as [`OutputChannel.stopNote()`]{@link OutputChannel#stopNote},
 * [`Output.stopNote()`]{@link Output#stopNote} or similar.
 *
 * @license Apache-2.0
 * @since 3.0.0
 */let qa=class{constructor(e,t={}){this.duration=R.defaults.note.duration,this.attack=R.defaults.note.attack,this.release=R.defaults.note.release,t.duration!=null&&(this.duration=t.duration),t.attack!=null&&(this.attack=t.attack),t.rawAttack!=null&&(this.attack=G.from7bitToFloat(t.rawAttack)),t.release!=null&&(this.release=t.release),t.rawRelease!=null&&(this.release=G.from7bitToFloat(t.rawRelease)),Number.isInteger(e)?this.identifier=G.toNoteIdentifier(e):this.identifier=e}get identifier(){return this._name+(this._accidental||"")+this._octave}set identifier(e){const t=G.getNoteDetails(e);if(R.validation&&!e)throw new Error("Invalid note identifier");this._name=t.name,this._accidental=t.accidental,this._octave=t.octave}get name(){return this._name}set name(e){if(R.validation&&(e=e.toUpperCase(),!["C","D","E","F","G","A","B"].includes(e)))throw new Error("Invalid name value");this._name=e}get accidental(){return this._accidental}set accidental(e){if(R.validation&&(e=e.toLowerCase(),!["#","##","b","bb"].includes(e)))throw new Error("Invalid accidental value");this._accidental=e}get octave(){return this._octave}set octave(e){if(R.validation&&(e=parseInt(e),isNaN(e)))throw new Error("Invalid octave value");this._octave=e}get duration(){return this._duration}set duration(e){if(R.validation&&(e=parseFloat(e),isNaN(e)||e===null||e<0))throw new RangeError("Invalid duration value.");this._duration=e}get attack(){return this._attack}set attack(e){if(R.validation&&(e=parseFloat(e),isNaN(e)||!(e>=0&&e<=1)))throw new RangeError("Invalid attack value.");this._attack=e}get release(){return this._release}set release(e){if(R.validation&&(e=parseFloat(e),isNaN(e)||!(e>=0&&e<=1)))throw new RangeError("Invalid release value.");this._release=e}get rawAttack(){return G.fromFloatTo7Bit(this._attack)}set rawAttack(e){this._attack=G.from7bitToFloat(e)}get rawRelease(){return G.fromFloatTo7Bit(this._release)}set rawRelease(e){this._release=G.from7bitToFloat(e)}get number(){return G.toNoteNumber(this.identifier)}getOffsetNumber(e=0,t=0){return R.validation&&(e=parseInt(e)||0,t=parseInt(t)||0),Math.min(Math.max(this.number+e*12+t,0),127)}};/**
 * The `Utilities` class contains general-purpose utility methods. All methods are static and
 * should be called using the class name. For example: `Utilities.getNoteDetails("C4")`.
 *
 * @license Apache-2.0
 * @since 3.0.0
 */class G{static toNoteNumber(e,t=0){if(t=t==null?0:parseInt(t),isNaN(t))throw new RangeError("Invalid 'octaveOffset' value");typeof e!="string"&&(e="");const a=this.getNoteDetails(e);if(!a)throw new TypeError("Invalid note identifier");const i={C:0,D:2,E:4,F:5,G:7,A:9,B:11};let o=(a.octave+1+t)*12;if(o+=i[a.name],a.accidental&&(a.accidental.startsWith("b")?o-=a.accidental.length:o+=a.accidental.length),o<0||o>127)throw new RangeError("Invalid octaveOffset value");return o}static getNoteDetails(e){Number.isInteger(e)&&(e=this.toNoteIdentifier(e));const t=e.match(/^([CDEFGAB])(#{0,2}|b{0,2})(-?\d+)$/i);if(!t)throw new TypeError("Invalid note identifier");const a=t[1].toUpperCase(),i=parseInt(t[3]);let o=t[2].toLowerCase();return o=o===""?void 0:o,{accidental:o,identifier:a+(o||"")+i,name:a,octave:i}}static sanitizeChannels(e){let t;if(R.validation){if(e==="all")t=["all"];else if(e==="none")return[]}return Array.isArray(e)?t=e:t=[e],t.indexOf("all")>-1&&(t=N.MIDI_CHANNEL_NUMBERS),t.map(function(a){return parseInt(a)}).filter(function(a){return a>=1&&a<=16})}static toTimestamp(e){let t=!1;const a=parseFloat(e);return isNaN(a)?!1:(typeof e=="string"&&e.substring(0,1)==="+"?a>=0&&(t=R.time+a):a>=0&&(t=a),t)}static guessNoteNumber(e,t){t=parseInt(t)||0;let a=!1;if(Number.isInteger(e)&&e>=0&&e<=127)a=parseInt(e);else if(parseInt(e)>=0&&parseInt(e)<=127)a=parseInt(e);else if(typeof e=="string"||e instanceof String)try{a=this.toNoteNumber(e.trim(),t)}catch{return!1}return a}static toNoteIdentifier(e,t){if(e=parseInt(e),isNaN(e)||e<0||e>127)throw new RangeError("Invalid note number");if(t=t==null?0:parseInt(t),isNaN(t))throw new RangeError("Invalid octaveOffset value");const a=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"],i=Math.floor(e/12-1)+t;return a[e%12]+i.toString()}static buildNote(e,t={}){if(t.octaveOffset=parseInt(t.octaveOffset)||0,e instanceof qa)return e;let a=this.guessNoteNumber(e,t.octaveOffset);if(a===!1)throw new TypeError(`The input could not be parsed as a note (${e})`);return t.octaveOffset=void 0,new qa(a,t)}static buildNoteArray(e,t={}){let a=[];return Array.isArray(e)||(e=[e]),e.forEach(i=>{a.push(this.buildNote(i,t))}),a}static from7bitToFloat(e){return e===1/0&&(e=127),e=parseInt(e)||0,Math.min(Math.max(e/127,0),1)}static fromFloatTo7Bit(e){return e===1/0&&(e=1),e=parseFloat(e)||0,Math.min(Math.max(Math.round(e*127),0),127)}static fromMsbLsbToFloat(e,t=0){R.validation&&(e=Math.min(Math.max(parseInt(e)||0,0),127),t=Math.min(Math.max(parseInt(t)||0,0),127));const a=((e<<7)+t)/16383;return Math.min(Math.max(a,0),1)}static fromFloatToMsbLsb(e){R.validation&&(e=Math.min(Math.max(parseFloat(e)||0,0),1));const t=Math.round(e*16383);return{msb:t>>7,lsb:t&127}}static offsetNumber(e,t=0,a=0){if(R.validation){if(e=parseInt(e),isNaN(e))throw new Error("Invalid note number");t=parseInt(t)||0,a=parseInt(a)||0}return Math.min(Math.max(e+t*12+a,0),127)}static getPropertyByValue(e,t){return Object.keys(e).find(a=>e[a]===t)}static getCcNameByNumber(e){if(!(R.validation&&(e=parseInt(e),!(e>=0&&e<=127))))return N.CONTROL_CHANGE_MESSAGES[e].name}static getCcNumberByName(e){let t=N.CONTROL_CHANGE_MESSAGES.find(a=>a.name===e);return t?t.number:N.MIDI_CONTROL_CHANGE_MESSAGES[e]}static getChannelModeByNumber(e){if(!(e>=120&&e<=127))return!1;for(let t in N.CHANNEL_MODE_MESSAGES)if(N.CHANNEL_MODE_MESSAGES.hasOwnProperty(t)&&e===N.CHANNEL_MODE_MESSAGES[t])return t;return!1}static get isNode(){return typeof process<"u"&&process.versions!=null&&process.versions.node!=null}static get isBrowser(){return typeof window<"u"&&typeof window.document<"u"}}/**
 * The `OutputChannel` class represents a single output MIDI channel. `OutputChannel` objects are
 * provided by an [`Output`](Output) port which, itself, is made available by a device. The
 * `OutputChannel` object is derived from the host's MIDI subsystem and should not be instantiated
 * directly.
 *
 * All 16 `OutputChannel` objects can be found inside the parent output's
 * [`channels`]{@link Output#channels} property.
 *
 * @param {Output} output The [`Output`](Output) this channel belongs to.
 * @param {number} number The MIDI channel number (`1` - `16`).
 *
 * @extends EventEmitter
 * @license Apache-2.0
 * @since 3.0.0
 */class gk extends cn{constructor(e,t){super(),this._output=e,this._number=t,this._octaveOffset=0}destroy(){this._output=null,this._number=null,this._octaveOffset=0,this.removeListener()}send(e,t={time:0}){return this.output.send(e,t),this}sendKeyAftertouch(e,t,a={}){if(R.validation){if(a.useRawValue&&(a.rawValue=a.useRawValue),isNaN(parseFloat(t)))throw new RangeError("Invalid key aftertouch value.");if(a.rawValue){if(!(t>=0&&t<=127&&Number.isInteger(t)))throw new RangeError("Key aftertouch raw value must be an integer between 0 and 127.")}else if(!(t>=0&&t<=1))throw new RangeError("Key aftertouch value must be a float between 0 and 1.")}a.rawValue||(t=G.fromFloatTo7Bit(t));const i=R.octaveOffset+this.output.octaveOffset+this.octaveOffset;return Array.isArray(e)||(e=[e]),G.buildNoteArray(e).forEach(o=>{this.send([(N.CHANNEL_MESSAGES.keyaftertouch<<4)+(this.number-1),o.getOffsetNumber(i),t],{time:G.toTimestamp(a.time)})}),this}sendControlChange(e,t,a={}){if(typeof e=="string"&&(e=G.getCcNumberByName(e)),Array.isArray(t)||(t=[t]),R.validation){if(e===void 0)throw new TypeError("Control change must be identified with a valid name or an integer between 0 and 127.");if(!Number.isInteger(e)||!(e>=0&&e<=127))throw new TypeError("Control change number must be an integer between 0 and 127.");if(t=t.map(i=>{const o=Math.min(Math.max(parseInt(i),0),127);if(isNaN(o))throw new TypeError("Values must be integers between 0 and 127");return o}),t.length===2&&e>=32)throw new TypeError("To use a value array, the controller must be between 0 and 31")}return t.forEach((i,o)=>{this.send([(N.CHANNEL_MESSAGES.controlchange<<4)+(this.number-1),e+o*32,t[o]],{time:G.toTimestamp(a.time)})}),this}_selectNonRegisteredParameter(e,t={}){return this.sendControlChange(99,e[0],t),this.sendControlChange(98,e[1],t),this}_deselectRegisteredParameter(e={}){return this.sendControlChange(101,127,e),this.sendControlChange(100,127,e),this}_deselectNonRegisteredParameter(e={}){return this.sendControlChange(101,127,e),this.sendControlChange(100,127,e),this}_selectRegisteredParameter(e,t={}){return this.sendControlChange(101,e[0],t),this.sendControlChange(100,e[1],t),this}_setCurrentParameter(e,t={}){return e=[].concat(e),this.sendControlChange(6,e[0],t),e.length<2?this:(this.sendControlChange(38,e[1],t),this)}sendRpnDecrement(e,t={}){if(Array.isArray(e)||(e=N.REGISTERED_PARAMETERS[e]),R.validation){if(e===void 0)throw new TypeError("The specified registered parameter is invalid.");let a=!1;if(Object.getOwnPropertyNames(N.REGISTERED_PARAMETERS).forEach(i=>{N.REGISTERED_PARAMETERS[i][0]===e[0]&&N.REGISTERED_PARAMETERS[i][1]===e[1]&&(a=!0)}),!a)throw new TypeError("The specified registered parameter is invalid.")}return this._selectRegisteredParameter(e,t),this.sendControlChange(97,0,t),this._deselectRegisteredParameter(t),this}sendRpnIncrement(e,t={}){if(Array.isArray(e)||(e=N.REGISTERED_PARAMETERS[e]),R.validation){if(e===void 0)throw new TypeError("The specified registered parameter is invalid.");let a=!1;if(Object.getOwnPropertyNames(N.REGISTERED_PARAMETERS).forEach(i=>{N.REGISTERED_PARAMETERS[i][0]===e[0]&&N.REGISTERED_PARAMETERS[i][1]===e[1]&&(a=!0)}),!a)throw new TypeError("The specified registered parameter is invalid.")}return this._selectRegisteredParameter(e,t),this.sendControlChange(96,0,t),this._deselectRegisteredParameter(t),this}playNote(e,t={}){this.sendNoteOn(e,t);const a=Array.isArray(e)?e:[e];for(let i of a)if(parseInt(i.duration)>0){const o={time:(G.toTimestamp(t.time)||R.time)+parseInt(i.duration),release:i.release,rawRelease:i.rawRelease};this.sendNoteOff(i,o)}else if(parseInt(t.duration)>0){const o={time:(G.toTimestamp(t.time)||R.time)+parseInt(t.duration),release:t.release,rawRelease:t.rawRelease};this.sendNoteOff(i,o)}return this}sendNoteOff(e,t={}){if(R.validation){if(t.rawRelease!=null&&!(t.rawRelease>=0&&t.rawRelease<=127))throw new RangeError("The 'rawRelease' option must be an integer between 0 and 127");if(t.release!=null&&!(t.release>=0&&t.release<=1))throw new RangeError("The 'release' option must be an number between 0 and 1");t.rawVelocity&&(t.rawRelease=t.velocity,console.warn("The 'rawVelocity' option is deprecated. Use 'rawRelease' instead.")),t.velocity&&(t.release=t.velocity,console.warn("The 'velocity' option is deprecated. Use 'attack' instead."))}let a=64;t.rawRelease!=null?a=t.rawRelease:isNaN(t.release)||(a=Math.round(t.release*127));const i=R.octaveOffset+this.output.octaveOffset+this.octaveOffset;return G.buildNoteArray(e,{rawRelease:parseInt(a)}).forEach(o=>{this.send([(N.CHANNEL_MESSAGES.noteoff<<4)+(this.number-1),o.getOffsetNumber(i),o.rawRelease],{time:G.toTimestamp(t.time)})}),this}stopNote(e,t={}){return this.sendNoteOff(e,t)}sendNoteOn(e,t={}){if(R.validation){if(t.rawAttack!=null&&!(t.rawAttack>=0&&t.rawAttack<=127))throw new RangeError("The 'rawAttack' option must be an integer between 0 and 127");if(t.attack!=null&&!(t.attack>=0&&t.attack<=1))throw new RangeError("The 'attack' option must be an number between 0 and 1");t.rawVelocity&&(t.rawAttack=t.velocity,t.rawRelease=t.release,console.warn("The 'rawVelocity' option is deprecated. Use 'rawAttack' or 'rawRelease'.")),t.velocity&&(t.attack=t.velocity,console.warn("The 'velocity' option is deprecated. Use 'attack' instead."))}let a=64;t.rawAttack!=null?a=t.rawAttack:isNaN(t.attack)||(a=Math.round(t.attack*127));const i=R.octaveOffset+this.output.octaveOffset+this.octaveOffset;return G.buildNoteArray(e,{rawAttack:a}).forEach(o=>{this.send([(N.CHANNEL_MESSAGES.noteon<<4)+(this.number-1),o.getOffsetNumber(i),o.rawAttack],{time:G.toTimestamp(t.time)})}),this}sendChannelMode(e,t=0,a={}){if(typeof e=="string"&&(e=N.CHANNEL_MODE_MESSAGES[e]),R.validation){if(e===void 0)throw new TypeError("Invalid channel mode message name or number.");if(isNaN(e)||!(e>=120&&e<=127))throw new TypeError("Invalid channel mode message number.");if(isNaN(parseInt(t))||t<0||t>127)throw new RangeError("Value must be an integer between 0 and 127.")}return this.send([(N.CHANNEL_MESSAGES.controlchange<<4)+(this.number-1),e,t],{time:G.toTimestamp(a.time)}),this}sendOmniMode(e,t={}){return e===void 0||e?this.sendChannelMode("omnimodeon",0,t):this.sendChannelMode("omnimodeoff",0,t),this}sendChannelAftertouch(e,t={}){if(R.validation){if(isNaN(parseFloat(e)))throw new RangeError("Invalid channel aftertouch value.");if(t.rawValue){if(!(e>=0&&e<=127&&Number.isInteger(e)))throw new RangeError("Channel aftertouch raw value must be an integer between 0 and 127.")}else if(!(e>=0&&e<=1))throw new RangeError("Channel aftertouch value must be a float between 0 and 1.")}return t.rawValue||(e=G.fromFloatTo7Bit(e)),this.send([(N.CHANNEL_MESSAGES.channelaftertouch<<4)+(this.number-1),Math.round(e)],{time:G.toTimestamp(t.time)}),this}sendMasterTuning(e,t={}){if(e=parseFloat(e)||0,R.validation&&!(e>-65&&e<64))throw new RangeError("The value must be a decimal number larger than -65 and smaller than 64.");let a=Math.floor(e)+64,i=e-Math.floor(e);i=Math.round((i+1)/2*16383);let o=i>>7&127,s=i&127;return this.sendRpnValue("channelcoarsetuning",a,t),this.sendRpnValue("channelfinetuning",[o,s],t),this}sendModulationRange(e,t,a={}){if(R.validation){if(!Number.isInteger(e)||!(e>=0&&e<=127))throw new RangeError("The semitones value must be an integer between 0 and 127.");if(t!=null&&(!Number.isInteger(t)||!(t>=0&&t<=127)))throw new RangeError("If specified, the cents value must be an integer between 0 and 127.")}return t>=0&&t<=127||(t=0),this.sendRpnValue("modulationrange",[e,t],a),this}sendNrpnValue(e,t,a={}){if(t=[].concat(t),R.validation){if(!Array.isArray(e)||!Number.isInteger(e[0])||!Number.isInteger(e[1]))throw new TypeError("The specified NRPN is invalid.");if(!(e[0]>=0&&e[0]<=127))throw new RangeError("The first byte of the NRPN must be between 0 and 127.");if(!(e[1]>=0&&e[1]<=127))throw new RangeError("The second byte of the NRPN must be between 0 and 127.");t.forEach(i=>{if(!(i>=0&&i<=127))throw new RangeError("The data bytes of the NRPN must be between 0 and 127.")})}return this._selectNonRegisteredParameter(e,a),this._setCurrentParameter(t,a),this._deselectNonRegisteredParameter(a),this}sendPitchBend(e,t={}){if(R.validation)if(t.rawValue&&Array.isArray(e)){if(!(e[0]>=0&&e[0]<=127))throw new RangeError("The pitch bend MSB must be an integer between 0 and 127.");if(!(e[1]>=0&&e[1]<=127))throw new RangeError("The pitch bend LSB must be an integer between 0 and 127.")}else if(t.rawValue&&!Array.isArray(e)){if(!(e>=0&&e<=127))throw new RangeError("The pitch bend MSB must be an integer between 0 and 127.")}else{if(isNaN(e)||e===null)throw new RangeError("Invalid pitch bend value.");if(!(e>=-1&&e<=1))throw new RangeError("The pitch bend value must be a float between -1 and 1.")}let a=0,i=0;if(t.rawValue&&Array.isArray(e))a=e[0],i=e[1];else if(t.rawValue&&!Array.isArray(e))a=e;else{const o=G.fromFloatToMsbLsb((e+1)/2);a=o.msb,i=o.lsb}return this.send([(N.CHANNEL_MESSAGES.pitchbend<<4)+(this.number-1),i,a],{time:G.toTimestamp(t.time)}),this}sendPitchBendRange(e,t,a={}){if(R.validation){if(!Number.isInteger(e)||!(e>=0&&e<=127))throw new RangeError("The semitones value must be an integer between 0 and 127.");if(!Number.isInteger(t)||!(t>=0&&t<=127))throw new RangeError("The cents value must be an integer between 0 and 127.")}return this.sendRpnValue("pitchbendrange",[e,t],a),this}sendProgramChange(e,t={}){if(e=parseInt(e)||0,R.validation&&!(e>=0&&e<=127))throw new RangeError("The program number must be between 0 and 127.");return this.send([(N.CHANNEL_MESSAGES.programchange<<4)+(this.number-1),e],{time:G.toTimestamp(t.time)}),this}sendRpnValue(e,t,a={}){if(Array.isArray(e)||(e=N.REGISTERED_PARAMETERS[e]),R.validation){if(!Number.isInteger(e[0])||!Number.isInteger(e[1]))throw new TypeError("The specified NRPN is invalid.");if(!(e[0]>=0&&e[0]<=127))throw new RangeError("The first byte of the RPN must be between 0 and 127.");if(!(e[1]>=0&&e[1]<=127))throw new RangeError("The second byte of the RPN must be between 0 and 127.");[].concat(t).forEach(i=>{if(!(i>=0&&i<=127))throw new RangeError("The data bytes of the RPN must be between 0 and 127.")})}return this._selectRegisteredParameter(e,a),this._setCurrentParameter(t,a),this._deselectRegisteredParameter(a),this}sendTuningBank(e,t={}){if(R.validation&&(!Number.isInteger(e)||!(e>=0&&e<=127)))throw new RangeError("The tuning bank number must be between 0 and 127.");return this.sendRpnValue("tuningbank",e,t),this}sendTuningProgram(e,t={}){if(R.validation&&(!Number.isInteger(e)||!(e>=0&&e<=127)))throw new RangeError("The tuning program number must be between 0 and 127.");return this.sendRpnValue("tuningprogram",e,t),this}sendLocalControl(e,t={}){return e?this.sendChannelMode("localcontrol",127,t):this.sendChannelMode("localcontrol",0,t)}sendAllNotesOff(e={}){return this.sendChannelMode("allnotesoff",0,e)}sendAllSoundOff(e={}){return this.sendChannelMode("allsoundoff",0,e)}sendResetAllControllers(e={}){return this.sendChannelMode("resetallcontrollers",0,e)}sendPolyphonicMode(e,t={}){return e==="mono"?this.sendChannelMode("monomodeon",0,t):this.sendChannelMode("polymodeon",0,t)}get octaveOffset(){return this._octaveOffset}set octaveOffset(e){if(this.validation&&(e=parseInt(e),isNaN(e)))throw new TypeError("The 'octaveOffset' property must be an integer.");this._octaveOffset=e}get output(){return this._output}get number(){return this._number}}/**
 * The `Output` class represents a single MIDI output port (not to be confused with a MIDI channel).
 * A port is made available by a MIDI device. A MIDI device can advertise several input and output
 * ports. Each port has 16 MIDI channels which can be accessed via the [`channels`](#channels)
 * property.
 *
 * The `Output` object is automatically instantiated by the library according to the host's MIDI
 * subsystem and should not be directly instantiated.
 *
 * You can access all available `Output` objects by referring to the
 * [`WebMidi.outputs`](WebMidi#outputs) array or by using methods such as
 * [`WebMidi.getOutputByName()`](WebMidi#getOutputByName) or
 * [`WebMidi.getOutputById()`](WebMidi#getOutputById).
 *
 * @fires Output#opened
 * @fires Output#disconnected
 * @fires Output#closed
 *
 * @extends EventEmitter
 * @license Apache-2.0
 */class xc extends cn{constructor(e){super(),this._midiOutput=e,this._octaveOffset=0,this.channels=[];for(let t=1;t<=16;t++)this.channels[t]=new gk(this,t);this._midiOutput.onstatechange=this._onStateChange.bind(this)}async destroy(){this.removeListener(),this.channels.forEach(e=>e.destroy()),this.channels=[],this._midiOutput&&(this._midiOutput.onstatechange=null),await this.close(),this._midiOutput=null}_onStateChange(e){let t={timestamp:R.time};e.port.connection==="open"?(t.type="opened",t.target=this,t.port=t.target,this.emit("opened",t)):e.port.connection==="closed"&&e.port.state==="connected"?(t.type="closed",t.target=this,t.port=t.target,this.emit("closed",t)):e.port.connection==="closed"&&e.port.state==="disconnected"?(t.type="disconnected",t.port={connection:e.port.connection,id:e.port.id,manufacturer:e.port.manufacturer,name:e.port.name,state:e.port.state,type:e.port.type},this.emit("disconnected",t)):e.port.connection==="pending"&&e.port.state==="disconnected"||console.warn("This statechange event was not caught:",e.port.connection,e.port.state)}async open(){try{return await this._midiOutput.open(),Promise.resolve(this)}catch(e){return Promise.reject(e)}}async close(){this._midiOutput?await this._midiOutput.close():await Promise.resolve()}send(e,t={time:0},a=0){if(e instanceof cf&&(e=G.isNode?e.data:e.rawData),e instanceof Uint8Array&&G.isNode&&(e=Array.from(e)),R.validation){if(!Array.isArray(e)&&!(e instanceof Uint8Array)&&(e=[e],Array.isArray(t)&&(e=e.concat(t)),t=isNaN(a)?{time:0}:{time:a}),!(parseInt(e[0])>=128&&parseInt(e[0])<=255))throw new RangeError("The first byte (status) must be an integer between 128 and 255.");e.slice(1).forEach(i=>{if(i=parseInt(i),!(i>=0&&i<=255))throw new RangeError("Data bytes must be integers between 0 and 255.")}),t||(t={time:0})}return this._midiOutput.send(e,G.toTimestamp(t.time)),this}sendSysex(e,t=[],a={}){if(e=[].concat(e),t instanceof Uint8Array){const i=new Uint8Array(1+e.length+t.length+1);i[0]=N.SYSTEM_MESSAGES.sysex,i.set(Uint8Array.from(e),1),i.set(t,1+e.length),i[i.length-1]=N.SYSTEM_MESSAGES.sysexend,this.send(i,{time:a.time})}else{const i=e.concat(t,N.SYSTEM_MESSAGES.sysexend);this.send([N.SYSTEM_MESSAGES.sysex].concat(i),{time:a.time})}return this}clear(){return this._midiOutput.clear?this._midiOutput.clear():R.validation&&console.warn("The 'clear()' method has not yet been implemented in your environment."),this}sendTimecodeQuarterFrame(e,t={}){if(R.validation&&(e=parseInt(e),isNaN(e)||!(e>=0&&e<=127)))throw new RangeError("The value must be an integer between 0 and 127.");return this.send([N.SYSTEM_MESSAGES.timecode,e],{time:t.time}),this}sendSongPosition(e=0,t={}){e=Math.floor(e)||0;var a=e>>7&127,i=e&127;return this.send([N.SYSTEM_MESSAGES.songposition,a,i],{time:t.time}),this}sendSongSelect(e=0,t={}){if(R.validation&&(e=parseInt(e),isNaN(e)||!(e>=0&&e<=127)))throw new RangeError("The program value must be between 0 and 127");return this.send([N.SYSTEM_MESSAGES.songselect,e],{time:t.time}),this}sendTuneRequest(e={}){return this.send([N.SYSTEM_MESSAGES.tunerequest],{time:e.time}),this}sendClock(e={}){return this.send([N.SYSTEM_MESSAGES.clock],{time:e.time}),this}sendStart(e={}){return this.send([N.SYSTEM_MESSAGES.start],{time:e.time}),this}sendContinue(e={}){return this.send([N.SYSTEM_MESSAGES.continue],{time:e.time}),this}sendStop(e={}){return this.send([N.SYSTEM_MESSAGES.stop],{time:e.time}),this}sendActiveSensing(e={}){return this.send([N.SYSTEM_MESSAGES.activesensing],{time:e.time}),this}sendReset(e={}){return this.send([N.SYSTEM_MESSAGES.reset],{time:e.time}),this}sendTuningRequest(e={}){return R.validation&&console.warn("The sendTuningRequest() method has been deprecated. Use sendTuningRequest() instead."),this.sendTuneRequest(e)}sendKeyAftertouch(e,t,a={}){return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].sendKeyAftertouch(e,t,a)}),this}sendControlChange(e,t,a={},i={}){if(R.validation&&(Array.isArray(a)||Number.isInteger(a)||a==="all")){const o=a;a=i,a.channels=o,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)}return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(o=>{this.channels[o].sendControlChange(e,t,a)}),this}sendPitchBendRange(e=0,t=0,a={}){return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].sendPitchBendRange(e,t,a)}),this}setPitchBendRange(e=0,t=0,a="all",i={}){return R.validation&&(console.warn("The setPitchBendRange() method is deprecated. Use sendPitchBendRange() instead."),i.channels=a,i.channels==="all"&&(i.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendPitchBendRange(e,t,i)}sendRpnValue(e,t,a={}){return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].sendRpnValue(e,t,a)}),this}setRegisteredParameter(e,t=[],a="all",i={}){return R.validation&&(console.warn("The setRegisteredParameter() method is deprecated. Use sendRpnValue() instead."),i.channels=a,i.channels==="all"&&(i.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendRpnValue(e,t,i)}sendChannelAftertouch(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendChannelAftertouch(e,t)}),this}sendPitchBend(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendPitchBend(e,t)}),this}sendProgramChange(e=0,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendProgramChange(e,t)}),this}sendModulationRange(e,t,a={}){return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].sendModulationRange(e,t,a)}),this}setModulationRange(e=0,t=0,a="all",i={}){return R.validation&&(console.warn("The setModulationRange() method is deprecated. Use sendModulationRange() instead."),i.channels=a,i.channels==="all"&&(i.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendModulationRange(e,t,i)}sendMasterTuning(e,t={}){return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(a=>{this.channels[a].sendMasterTuning(e,t)}),this}setMasterTuning(e,t={},a={}){return R.validation&&(console.warn("The setMasterTuning() method is deprecated. Use sendMasterTuning() instead."),a.channels=t,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendMasterTuning(e,a)}sendTuningProgram(e,t={}){return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(a=>{this.channels[a].sendTuningProgram(e,t)}),this}setTuningProgram(e,t="all",a={}){return R.validation&&(console.warn("The setTuningProgram() method is deprecated. Use sendTuningProgram() instead."),a.channels=t,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendTuningProgram(e,a)}sendTuningBank(e=0,t={}){return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(a=>{this.channels[a].sendTuningBank(e,t)}),this}setTuningBank(e,t="all",a={}){return R.validation&&(console.warn("The setTuningBank() method is deprecated. Use sendTuningBank() instead."),a.channels=t,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendTuningBank(e,a)}sendChannelMode(e,t=0,a={},i={}){if(R.validation&&(Array.isArray(a)||Number.isInteger(a)||a==="all")){const o=a;a=i,a.channels=o,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)}return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(o=>{this.channels[o].sendChannelMode(e,t,a)}),this}sendAllSoundOff(e={}){return e.channels==null&&(e.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(e.channels).forEach(t=>{this.channels[t].sendAllSoundOff(e)}),this}sendAllNotesOff(e={}){return e.channels==null&&(e.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(e.channels).forEach(t=>{this.channels[t].sendAllNotesOff(e)}),this}sendResetAllControllers(e={},t={}){if(R.validation&&(Array.isArray(e)||Number.isInteger(e)||e==="all")){const a=e;e=t,e.channels=a,e.channels==="all"&&(e.channels=N.MIDI_CHANNEL_NUMBERS)}return e.channels==null&&(e.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(e.channels).forEach(a=>{this.channels[a].sendResetAllControllers(e)}),this}sendPolyphonicMode(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendPolyphonicMode(e,t)}),this}sendLocalControl(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendLocalControl(e,t)}),this}sendOmniMode(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendOmniMode(e,t)}),this}sendNrpnValue(e,t,a={}){return a.channels==null&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].sendNrpnValue(e,t,a)}),this}setNonRegisteredParameter(e,t=[],a="all",i={}){return R.validation&&(console.warn("The setNonRegisteredParameter() method is deprecated. Use sendNrpnValue() instead."),i.channels=a,i.channels==="all"&&(i.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendNrpnValue(e,t,i)}sendRpnIncrement(e,t={}){return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(a=>{this.channels[a].sendRpnIncrement(e,t)}),this}incrementRegisteredParameter(e,t="all",a={}){return R.validation&&(console.warn("The incrementRegisteredParameter() method is deprecated. Use sendRpnIncrement() instead."),a.channels=t,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendRpnIncrement(e,a)}sendRpnDecrement(e,t={}){return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(a=>{this.channels[a].sendRpnDecrement(e,t)}),this}decrementRegisteredParameter(e,t="all",a={}){return R.validation&&(console.warn("The decrementRegisteredParameter() method is deprecated. Use sendRpnDecrement() instead."),a.channels=t,a.channels==="all"&&(a.channels=N.MIDI_CHANNEL_NUMBERS)),this.sendRpnDecrement(e,a)}sendNoteOff(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendNoteOff(e,t)}),this}stopNote(e,t){return this.sendNoteOff(e,t)}playNote(e,t={},a={}){if(R.validation&&(t.rawVelocity&&console.warn("The 'rawVelocity' option is deprecated. Use 'rawAttack' instead."),t.velocity&&console.warn("The 'velocity' option is deprecated. Use 'velocity' instead."),Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].playNote(e,t)}),this}sendNoteOn(e,t={},a={}){if(R.validation&&(Array.isArray(t)||Number.isInteger(t)||t==="all")){const i=t;t=a,t.channels=i,t.channels==="all"&&(t.channels=N.MIDI_CHANNEL_NUMBERS)}return t.channels==null&&(t.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(t.channels).forEach(i=>{this.channels[i].sendNoteOn(e,t)}),this}get name(){return this._midiOutput.name}get id(){return this._midiOutput.id}get connection(){return this._midiOutput.connection}get manufacturer(){return this._midiOutput.manufacturer}get state(){return this._midiOutput.state}get type(){return this._midiOutput.type}get octaveOffset(){return this._octaveOffset}set octaveOffset(e){if(this.validation&&(e=parseInt(e),isNaN(e)))throw new TypeError("The 'octaveOffset' property must be an integer.");this._octaveOffset=e}}/**
 * The `Forwarder` class allows the forwarding of MIDI messages to predetermined outputs. When you
 * call its [`forward()`](#forward) method, it will send the specified [`Message`](Message) object
 * to all the outputs listed in its [`destinations`](#destinations) property.
 *
 * If specific channels or message types have been defined in the [`channels`](#channels) or
 * [`types`](#types) properties, only messages matching the channels/types will be forwarded.
 *
 * While it can be manually instantiated, you are more likely to come across a `Forwarder` object as
 * the return value of the [`Input.addForwarder()`](Input#addForwarder) method.
 *
 * @license Apache-2.0
 * @since 3.0.0
 */class uu{constructor(e=[],t={}){this.destinations=[],this.types=[...Object.keys(N.SYSTEM_MESSAGES),...Object.keys(N.CHANNEL_MESSAGES)],this.channels=N.MIDI_CHANNEL_NUMBERS,this.suspended=!1,Array.isArray(e)||(e=[e]),t.types&&!Array.isArray(t.types)&&(t.types=[t.types]),t.channels&&!Array.isArray(t.channels)&&(t.channels=[t.channels]),R.validation&&(e.forEach(a=>{if(!(a instanceof xc))throw new TypeError("Destinations must be of type 'Output'.")}),t.types!==void 0&&t.types.forEach(a=>{if(!N.SYSTEM_MESSAGES.hasOwnProperty(a)&&!N.CHANNEL_MESSAGES.hasOwnProperty(a))throw new TypeError("Type must be a valid message type.")}),t.channels!==void 0&&t.channels.forEach(a=>{if(!N.MIDI_CHANNEL_NUMBERS.includes(a))throw new TypeError("MIDI channel must be between 1 and 16.")})),this.destinations=e,t.types&&(this.types=t.types),t.channels&&(this.channels=t.channels)}forward(e){this.suspended||this.types.includes(e.type)&&(e.channel&&!this.channels.includes(e.channel)||this.destinations.forEach(t=>{R.validation&&!(t instanceof xc)||t.send(e)}))}}/**
 * The `InputChannel` class represents a single MIDI input channel (1-16) from a single input
 * device. This object is derived from the host's MIDI subsystem and should not be instantiated
 * directly.
 *
 * All 16 `InputChannel` objects can be found inside the input's [`channels`](Input#channels)
 * property.
 *
 * @fires InputChannel#midimessage
 * @fires InputChannel#unknownmessage
 *
 * @fires InputChannel#noteoff
 * @fires InputChannel#noteon
 * @fires InputChannel#keyaftertouch
 * @fires InputChannel#programchange
 * @fires InputChannel#channelaftertouch
 * @fires InputChannel#pitchbend
 *
 * @fires InputChannel#allnotesoff
 * @fires InputChannel#allsoundoff
 * @fires InputChannel#localcontrol
 * @fires InputChannel#monomode
 * @fires InputChannel#omnimode
 * @fires InputChannel#resetallcontrollers
 *
 * @fires InputChannel#event:nrpn
 * @fires InputChannel#event:nrpn-dataentrycoarse
 * @fires InputChannel#event:nrpn-dataentryfine
 * @fires InputChannel#event:nrpn-dataincrement
 * @fires InputChannel#event:nrpn-datadecrement
 * @fires InputChannel#event:rpn
 * @fires InputChannel#event:rpn-dataentrycoarse
 * @fires InputChannel#event:rpn-dataentryfine
 * @fires InputChannel#event:rpn-dataincrement
 * @fires InputChannel#event:rpn-datadecrement
 *
 * @fires InputChannel#controlchange
 * @fires InputChannel#event:controlchange-controllerxxx
 * @fires InputChannel#event:controlchange-bankselectcoarse
 * @fires InputChannel#event:controlchange-modulationwheelcoarse
 * @fires InputChannel#event:controlchange-breathcontrollercoarse
 * @fires InputChannel#event:controlchange-footcontrollercoarse
 * @fires InputChannel#event:controlchange-portamentotimecoarse
 * @fires InputChannel#event:controlchange-dataentrycoarse
 * @fires InputChannel#event:controlchange-volumecoarse
 * @fires InputChannel#event:controlchange-balancecoarse
 * @fires InputChannel#event:controlchange-pancoarse
 * @fires InputChannel#event:controlchange-expressioncoarse
 * @fires InputChannel#event:controlchange-effectcontrol1coarse
 * @fires InputChannel#event:controlchange-effectcontrol2coarse
 * @fires InputChannel#event:controlchange-generalpurposecontroller1
 * @fires InputChannel#event:controlchange-generalpurposecontroller2
 * @fires InputChannel#event:controlchange-generalpurposecontroller3
 * @fires InputChannel#event:controlchange-generalpurposecontroller4
 * @fires InputChannel#event:controlchange-bankselectfine
 * @fires InputChannel#event:controlchange-modulationwheelfine
 * @fires InputChannel#event:controlchange-breathcontrollerfine
 * @fires InputChannel#event:controlchange-footcontrollerfine
 * @fires InputChannel#event:controlchange-portamentotimefine
 * @fires InputChannel#event:controlchange-dataentryfine
 * @fires InputChannel#event:controlchange-channelvolumefine
 * @fires InputChannel#event:controlchange-balancefine
 * @fires InputChannel#event:controlchange-panfine
 * @fires InputChannel#event:controlchange-expressionfine
 * @fires InputChannel#event:controlchange-effectcontrol1fine
 * @fires InputChannel#event:controlchange-effectcontrol2fine
 * @fires InputChannel#event:controlchange-damperpedal
 * @fires InputChannel#event:controlchange-portamento
 * @fires InputChannel#event:controlchange-sostenuto
 * @fires InputChannel#event:controlchange-softpedal
 * @fires InputChannel#event:controlchange-legatopedal
 * @fires InputChannel#event:controlchange-hold2
 * @fires InputChannel#event:controlchange-soundvariation
 * @fires InputChannel#event:controlchange-resonance
 * @fires InputChannel#event:controlchange-releasetime
 * @fires InputChannel#event:controlchange-attacktime
 * @fires InputChannel#event:controlchange-brightness
 * @fires InputChannel#event:controlchange-decaytime
 * @fires InputChannel#event:controlchange-vibratorate
 * @fires InputChannel#event:controlchange-vibratodepth
 * @fires InputChannel#event:controlchange-vibratodelay
 * @fires InputChannel#event:controlchange-generalpurposecontroller5
 * @fires InputChannel#event:controlchange-generalpurposecontroller6
 * @fires InputChannel#event:controlchange-generalpurposecontroller7
 * @fires InputChannel#event:controlchange-generalpurposecontroller8
 * @fires InputChannel#event:controlchange-portamentocontrol
 * @fires InputChannel#event:controlchange-highresolutionvelocityprefix
 * @fires InputChannel#event:controlchange-effect1depth
 * @fires InputChannel#event:controlchange-effect2depth
 * @fires InputChannel#event:controlchange-effect3depth
 * @fires InputChannel#event:controlchange-effect4depth
 * @fires InputChannel#event:controlchange-effect5depth
 * @fires InputChannel#event:controlchange-dataincrement
 * @fires InputChannel#event:controlchange-datadecrement
 * @fires InputChannel#event:controlchange-nonregisteredparameterfine
 * @fires InputChannel#event:controlchange-nonregisteredparametercoarse
 * @fires InputChannel#event:controlchange-registeredparameterfine
 * @fires InputChannel#event:controlchange-registeredparametercoarse
 * @fires InputChannel#event:controlchange-allsoundoff
 * @fires InputChannel#event:controlchange-resetallcontrollers
 * @fires InputChannel#event:controlchange-localcontrol
 * @fires InputChannel#event:controlchange-allnotesoff
 * @fires InputChannel#event:controlchange-omnimodeoff
 * @fires InputChannel#event:controlchange-omnimodeon
 * @fires InputChannel#event:controlchange-monomodeon
 * @fires InputChannel#event:controlchange-polymodeon
 * @fires InputChannel#event:
 *
 * @extends EventEmitter
 * @license Apache-2.0
 * @since 3.0.0
 */class yk extends cn{constructor(e,t){super(),this._input=e,this._number=t,this._octaveOffset=0,this._nrpnBuffer=[],this._rpnBuffer=[],this.parameterNumberEventsEnabled=!0,this.notesState=new Array(128).fill(!1)}destroy(){this._input=null,this._number=null,this._octaveOffset=0,this._nrpnBuffer=[],this.notesState=new Array(128).fill(!1),this.parameterNumberEventsEnabled=!1,this.removeListener()}_processMidiMessageEvent(e){const t=Object.assign({},e);t.port=this.input,t.target=this,t.type="midimessage",this.emit(t.type,t),this._parseEventForStandardMessages(t)}_parseEventForStandardMessages(e){const t=Object.assign({},e);t.type=t.message.type||"unknownmessage";const a=e.message.dataBytes[0],i=e.message.dataBytes[1];if(t.type==="noteoff"||t.type==="noteon"&&i===0)this.notesState[a]=!1,t.type="noteoff",t.note=new qa(G.offsetNumber(a,this.octaveOffset+this.input.octaveOffset+R.octaveOffset),{rawAttack:0,rawRelease:i}),t.value=G.from7bitToFloat(i),t.rawValue=i,t.velocity=t.note.release,t.rawVelocity=t.note.rawRelease;else if(t.type==="noteon")this.notesState[a]=!0,t.note=new qa(G.offsetNumber(a,this.octaveOffset+this.input.octaveOffset+R.octaveOffset),{rawAttack:i}),t.value=G.from7bitToFloat(i),t.rawValue=i,t.velocity=t.note.attack,t.rawVelocity=t.note.rawAttack;else if(t.type==="keyaftertouch")t.note=new qa(G.offsetNumber(a,this.octaveOffset+this.input.octaveOffset+R.octaveOffset)),t.value=G.from7bitToFloat(i),t.rawValue=i,t.identifier=t.note.identifier,t.key=t.note.number,t.rawKey=a;else if(t.type==="controlchange"){t.controller={number:a,name:N.CONTROL_CHANGE_MESSAGES[a].name,description:N.CONTROL_CHANGE_MESSAGES[a].description,position:N.CONTROL_CHANGE_MESSAGES[a].position},t.subtype=t.controller.name||"controller"+a,t.value=G.from7bitToFloat(i),t.rawValue=i;const o=Object.assign({},t);o.type=`${t.type}-controller${a}`,delete o.subtype,this.emit(o.type,o);const s=Object.assign({},t);s.type=`${t.type}-`+N.CONTROL_CHANGE_MESSAGES[a].name,delete s.subtype,s.type.indexOf("controller")!==0&&this.emit(s.type,s),t.message.dataBytes[0]>=120&&this._parseChannelModeMessage(t),this.parameterNumberEventsEnabled&&this._isRpnOrNrpnController(t.message.dataBytes[0])&&this._parseEventForParameterNumber(t)}else t.type==="programchange"?(t.value=a,t.rawValue=t.value):t.type==="channelaftertouch"?(t.value=G.from7bitToFloat(a),t.rawValue=a):t.type==="pitchbend"?(t.value=((i<<7)+a-8192)/8192,t.rawValue=(i<<7)+a):t.type="unknownmessage";this.emit(t.type,t)}_parseChannelModeMessage(e){const t=Object.assign({},e);t.type=t.controller.name,t.type==="localcontrol"&&(t.value=t.message.data[2]===127,t.rawValue=t.message.data[2]),t.type==="omnimodeon"?(t.type="omnimode",t.value=!0,t.rawValue=t.message.data[2]):t.type==="omnimodeoff"&&(t.type="omnimode",t.value=!1,t.rawValue=t.message.data[2]),t.type==="monomodeon"?(t.type="monomode",t.value=!0,t.rawValue=t.message.data[2]):t.type==="polymodeon"&&(t.type="monomode",t.value=!1,t.rawValue=t.message.data[2]),this.emit(t.type,t)}_parseEventForParameterNumber(e){const t=e.message.dataBytes[0],a=e.message.dataBytes[1];t===99||t===101?(this._nrpnBuffer=[],this._rpnBuffer=[],t===99?this._nrpnBuffer=[e.message]:a!==127&&(this._rpnBuffer=[e.message])):t===98||t===100?t===98?(this._rpnBuffer=[],this._nrpnBuffer.length===1?this._nrpnBuffer.push(e.message):this._nrpnBuffer=[]):(this._nrpnBuffer=[],this._rpnBuffer.length===1&&a!==127?this._rpnBuffer.push(e.message):this._rpnBuffer=[]):(t===6||t===38||t===96||t===97)&&(this._rpnBuffer.length===2?this._dispatchParameterNumberEvent("rpn",this._rpnBuffer[0].dataBytes[1],this._rpnBuffer[1].dataBytes[1],e):this._nrpnBuffer.length===2?this._dispatchParameterNumberEvent("nrpn",this._nrpnBuffer[0].dataBytes[1],this._nrpnBuffer[1].dataBytes[1],e):(this._nrpnBuffer=[],this._rpnBuffer=[]))}_isRpnOrNrpnController(e){return e===6||e===38||e===96||e===97||e===98||e===99||e===100||e===101}_dispatchParameterNumberEvent(e,t,a,i){e=e==="nrpn"?"nrpn":"rpn";const o={target:i.target,timestamp:i.timestamp,message:i.message,parameterMsb:t,parameterLsb:a,value:G.from7bitToFloat(i.message.dataBytes[1]),rawValue:i.message.dataBytes[1]};e==="rpn"?o.parameter=Object.keys(N.REGISTERED_PARAMETERS).find(l=>N.REGISTERED_PARAMETERS[l][0]===t&&N.REGISTERED_PARAMETERS[l][1]===a):o.parameter=(t<<7)+a;const s=N.CONTROL_CHANGE_MESSAGES[i.message.dataBytes[0]].name;o.type=`${e}-${s}`,this.emit(o.type,o);const r=Object.assign({},o);r.type==="nrpn-dataincrement"?r.type="nrpn-databuttonincrement":r.type==="nrpn-datadecrement"?r.type="nrpn-databuttondecrement":r.type==="rpn-dataincrement"?r.type="rpn-databuttonincrement":r.type==="rpn-datadecrement"&&(r.type="rpn-databuttondecrement"),this.emit(r.type,r),o.type=e,o.subtype=s,this.emit(o.type,o)}getChannelModeByNumber(e){return R.validation&&(console.warn("The 'getChannelModeByNumber()' method has been moved to the 'Utilities' class."),e=Math.floor(e)),G.getChannelModeByNumber(e)}getCcNameByNumber(e){if(R.validation&&(console.warn("The 'getCcNameByNumber()' method has been moved to the 'Utilities' class."),e=parseInt(e),!(e>=0&&e<=127)))throw new RangeError("Invalid control change number.");return G.getCcNameByNumber(e)}getNoteState(e){e instanceof qa&&(e=e.identifier);const t=G.guessNoteNumber(e,R.octaveOffset+this.input.octaveOffset+this.octaveOffset);return this.notesState[t]}get octaveOffset(){return this._octaveOffset}set octaveOffset(e){if(this.validation&&(e=parseInt(e),isNaN(e)))throw new TypeError("The 'octaveOffset' property must be an integer.");this._octaveOffset=e}get input(){return this._input}get number(){return this._number}get nrpnEventsEnabled(){return this.parameterNumberEventsEnabled}set nrpnEventsEnabled(e){this.validation&&(e=!!e),this.parameterNumberEventsEnabled=e}}/**
 * The `Message` class represents a single MIDI message. It has several properties that make it
 * easy to make sense of the binary data it contains.
 *
 * @license Apache-2.0
 * @since 3.0.0
 */class cf{constructor(e){this.rawData=e,this.data=Array.from(this.rawData),this.statusByte=this.rawData[0],this.rawDataBytes=this.rawData.slice(1),this.dataBytes=this.data.slice(1),this.isChannelMessage=!1,this.isSystemMessage=!1,this.command=void 0,this.channel=void 0,this.manufacturerId=void 0,this.type=void 0,this.statusByte<240?(this.isChannelMessage=!0,this.command=this.statusByte>>4,this.channel=(this.statusByte&15)+1):(this.isSystemMessage=!0,this.command=this.statusByte),this.isChannelMessage?this.type=G.getPropertyByValue(N.CHANNEL_MESSAGES,this.command):this.isSystemMessage&&(this.type=G.getPropertyByValue(N.SYSTEM_MESSAGES,this.command)),this.statusByte===N.SYSTEM_MESSAGES.sysex&&(this.dataBytes[0]===0?(this.manufacturerId=this.dataBytes.slice(0,3),this.dataBytes=this.dataBytes.slice(3,this.rawDataBytes.length-1),this.rawDataBytes=this.rawDataBytes.slice(3,this.rawDataBytes.length-1)):(this.manufacturerId=[this.dataBytes[0]],this.dataBytes=this.dataBytes.slice(1,this.dataBytes.length-1),this.rawDataBytes=this.rawDataBytes.slice(1,this.rawDataBytes.length-1)))}}/**
 * The `Input` class represents a single MIDI input port. This object is automatically instantiated
 * by the library according to the host's MIDI subsystem and does not need to be directly
 * instantiated. Instead, you can access all `Input` objects by referring to the
 * [`WebMidi.inputs`](WebMidi#inputs) array. You can also retrieve inputs by using methods such as
 * [`WebMidi.getInputByName()`](WebMidi#getInputByName) and
 * [`WebMidi.getInputById()`](WebMidi#getInputById).
 *
 * Note that a single MIDI device may expose several inputs and/or outputs.
 *
 * **Important**: the `Input` class does not directly fire channel-specific MIDI messages
 * (such as [`noteon`](InputChannel#event:noteon) or
 * [`controlchange`](InputChannel#event:controlchange), etc.). The [`InputChannel`](InputChannel)
 * object does that. However, you can still use the
 * [`Input.addListener()`](#addListener) method to listen to channel-specific events on multiple
 * [`InputChannel`](InputChannel) objects at once.
 *
 * @fires Input#opened
 * @fires Input#disconnected
 * @fires Input#closed
 * @fires Input#midimessage
 *
 * @fires Input#sysex
 * @fires Input#timecode
 * @fires Input#songposition
 * @fires Input#songselect
 * @fires Input#tunerequest
 * @fires Input#clock
 * @fires Input#start
 * @fires Input#continue
 * @fires Input#stop
 * @fires Input#activesensing
 * @fires Input#reset
 *
 * @fires Input#unknownmidimessage
 *
 * @extends EventEmitter
 * @license Apache-2.0
 */class bk extends cn{constructor(e){super(),this._midiInput=e,this._octaveOffset=0,this.channels=[];for(let t=1;t<=16;t++)this.channels[t]=new yk(this,t);this._forwarders=[],this._midiInput.onstatechange=this._onStateChange.bind(this),this._midiInput.onmidimessage=this._onMidiMessage.bind(this)}async destroy(){this.removeListener(),this.channels.forEach(e=>e.destroy()),this.channels=[],this._forwarders=[],this._midiInput&&(this._midiInput.onstatechange=null,this._midiInput.onmidimessage=null),await this.close(),this._midiInput=null}_onStateChange(e){let t={timestamp:R.time,target:this,port:this};e.port.connection==="open"?(t.type="opened",this.emit("opened",t)):e.port.connection==="closed"&&e.port.state==="connected"?(t.type="closed",this.emit("closed",t)):e.port.connection==="closed"&&e.port.state==="disconnected"?(t.type="disconnected",t.port={connection:e.port.connection,id:e.port.id,manufacturer:e.port.manufacturer,name:e.port.name,state:e.port.state,type:e.port.type},this.emit("disconnected",t)):e.port.connection==="pending"&&e.port.state==="disconnected"||console.warn("This statechange event was not caught: ",e.port.connection,e.port.state)}_onMidiMessage(e){const t=new cf(e.data),a={port:this,target:this,message:t,timestamp:e.timeStamp,type:"midimessage",data:t.data,rawData:t.data,statusByte:t.data[0],dataBytes:t.dataBytes};this.emit("midimessage",a),t.isSystemMessage?this._parseEvent(a):t.isChannelMessage&&this.channels[t.channel]._processMidiMessageEvent(a),this._forwarders.forEach(i=>i.forward(t))}_parseEvent(e){const t=Object.assign({},e);t.type=t.message.type||"unknownmidimessage",t.type==="songselect"&&(t.song=e.data[1]+1,t.value=e.data[1],t.rawValue=t.value),this.emit(t.type,t)}async open(){try{await this._midiInput.open()}catch(e){return Promise.reject(e)}return Promise.resolve(this)}async close(){if(!this._midiInput)return Promise.resolve(this);try{await this._midiInput.close()}catch(e){return Promise.reject(e)}return Promise.resolve(this)}getChannelModeByNumber(){R.validation&&console.warn("The 'getChannelModeByNumber()' method has been moved to the 'Utilities' class.")}addListener(e,t,a={}){if(R.validation&&typeof a=="function"){let i=t!=null?[].concat(t):void 0;t=a,a={channels:i}}if(N.CHANNEL_EVENTS.includes(e)){a.channels===void 0&&(a.channels=N.MIDI_CHANNEL_NUMBERS);let i=[];return G.sanitizeChannels(a.channels).forEach(o=>{i.push(this.channels[o].addListener(e,t,a))}),i}else return super.addListener(e,t,a)}addOneTimeListener(e,t,a={}){return a.remaining=1,this.addListener(e,t,a)}on(e,t,a,i){return this.addListener(e,t,a,i)}hasListener(e,t,a={}){if(R.validation&&typeof a=="function"){let i=[].concat(t);t=a,a={channels:i}}return N.CHANNEL_EVENTS.includes(e)?(a.channels===void 0&&(a.channels=N.MIDI_CHANNEL_NUMBERS),G.sanitizeChannels(a.channels).every(i=>this.channels[i].hasListener(e,t))):super.hasListener(e,t)}removeListener(e,t,a={}){if(R.validation&&typeof a=="function"){let i=[].concat(t);t=a,a={channels:i}}if(a.channels===void 0&&(a.channels=N.MIDI_CHANNEL_NUMBERS),e==null)return G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i]&&this.channels[i].removeListener()}),super.removeListener();N.CHANNEL_EVENTS.includes(e)?G.sanitizeChannels(a.channels).forEach(i=>{this.channels[i].removeListener(e,t,a)}):super.removeListener(e,t,a)}addForwarder(e,t={}){let a;return e instanceof uu?a=e:a=new uu(e,t),this._forwarders.push(a),a}removeForwarder(e){this._forwarders=this._forwarders.filter(t=>t!==e)}hasForwarder(e){return this._forwarders.includes(e)}get name(){return this._midiInput.name}get id(){return this._midiInput.id}get connection(){return this._midiInput.connection}get manufacturer(){return this._midiInput.manufacturer}get octaveOffset(){return this._octaveOffset}set octaveOffset(e){if(this.validation&&(e=parseInt(e),isNaN(e)))throw new TypeError("The 'octaveOffset' property must be an integer.");this._octaveOffset=e}get state(){return this._midiInput.state}get type(){return this._midiInput.type}get nrpnEventsEnabled(){return R.validation&&console.warn("The 'nrpnEventsEnabled' property has been moved to the 'InputChannel' class."),!1}}/**
 * The `WebMidi` object makes it easier to work with the low-level Web MIDI API. Basically, it
 * simplifies sending outgoing MIDI messages and reacting to incoming MIDI messages.
 *
 * When using the WebMidi.js library, you should know that the `WebMidi` class has already been
 * instantiated. You cannot instantiate it yourself. If you use the **IIFE** version, you should
 * simply use the global object called `WebMidi`. If you use the **CJS** (CommonJS) or **ESM** (ES6
 * module) version, you get an already-instantiated object when you import the module.
 *
 * @fires WebMidi#connected
 * @fires WebMidi#disabled
 * @fires WebMidi#disconnected
 * @fires WebMidi#enabled
 * @fires WebMidi#error
 * @fires WebMidi#midiaccessgranted
 * @fires WebMidi#portschanged
 *
 * @extends EventEmitter
 * @license Apache-2.0
 */class vk extends cn{constructor(){super(),this.defaults={note:{attack:G.from7bitToFloat(64),release:G.from7bitToFloat(64),duration:1/0}},this.interface=null,this.validation=!0,this._inputs=[],this._disconnectedInputs=[],this._outputs=[],this._disconnectedOutputs=[],this._stateChangeQueue=[],this._octaveOffset=0}async enable(e={},t=!1){if(G.isNode){try{window.navigator}catch{let r=await Object.getPrototypeOf(async function(){}).constructor(`
        let jzz = await import("jzz");
        return jzz.default;
        `)();global.navigator||(global.navigator={}),Object.assign(global.navigator,r)}try{}catch{global.performance=await Object.getPrototypeOf(async function(){}).constructor(`
        let perf_hooks = await import("perf_hooks");
        return perf_hooks.performance;
        `)()}}if(this.validation=e.validation!==!1,this.validation&&(typeof e=="function"&&(e={callback:e,sysex:t}),t&&(e.sysex=!0)),this.enabled)return typeof e.callback=="function"&&e.callback(),Promise.resolve();const a={timestamp:this.time,target:this,type:"error",error:void 0},i={timestamp:this.time,target:this,type:"midiaccessgranted"},o={timestamp:this.time,target:this,type:"enabled"};try{typeof e.requestMIDIAccessFunction=="function"?this.interface=await e.requestMIDIAccessFunction({sysex:e.sysex,software:e.software}):this.interface=await navigator.requestMIDIAccess({sysex:e.sysex,software:e.software})}catch(s){return a.error=s,this.emit("error",a),typeof e.callback=="function"&&e.callback(s),Promise.reject(s)}this.emit("midiaccessgranted",i),this.interface.onstatechange=this._onInterfaceStateChange.bind(this);try{await this._updateInputsAndOutputs()}catch(s){return a.error=s,this.emit("error",a),typeof e.callback=="function"&&e.callback(s),Promise.reject(s)}return this.emit("enabled",o),typeof e.callback=="function"&&e.callback(),Promise.resolve(this)}async disable(){return this.interface&&(this.interface.onstatechange=void 0),this._destroyInputsAndOutputs().then(()=>{navigator&&typeof navigator.close=="function"&&navigator.close(),this.interface=null;let e={timestamp:this.time,target:this,type:"disabled"};this.emit("disabled",e),this.removeListener()})}getInputById(e,t={disconnected:!1}){if(this.validation){if(!this.enabled)throw new Error("WebMidi is not enabled.");if(!e)return}if(t.disconnected){for(let a=0;a<this._disconnectedInputs.length;a++)if(this._disconnectedInputs[a].id===e.toString())return this._disconnectedInputs[a]}else for(let a=0;a<this.inputs.length;a++)if(this.inputs[a].id===e.toString())return this.inputs[a]}getInputByName(e,t={disconnected:!1}){if(this.validation){if(!this.enabled)throw new Error("WebMidi is not enabled.");if(!e)return;e=e.toString()}if(t.disconnected){for(let a=0;a<this._disconnectedInputs.length;a++)if(~this._disconnectedInputs[a].name.indexOf(e))return this._disconnectedInputs[a]}else for(let a=0;a<this.inputs.length;a++)if(~this.inputs[a].name.indexOf(e))return this.inputs[a]}getOutputByName(e,t={disconnected:!1}){if(this.validation){if(!this.enabled)throw new Error("WebMidi is not enabled.");if(!e)return;e=e.toString()}if(t.disconnected){for(let a=0;a<this._disconnectedOutputs.length;a++)if(~this._disconnectedOutputs[a].name.indexOf(e))return this._disconnectedOutputs[a]}else for(let a=0;a<this.outputs.length;a++)if(~this.outputs[a].name.indexOf(e))return this.outputs[a]}getOutputById(e,t={disconnected:!1}){if(this.validation){if(!this.enabled)throw new Error("WebMidi is not enabled.");if(!e)return}if(t.disconnected){for(let a=0;a<this._disconnectedOutputs.length;a++)if(this._disconnectedOutputs[a].id===e.toString())return this._disconnectedOutputs[a]}else for(let a=0;a<this.outputs.length;a++)if(this.outputs[a].id===e.toString())return this.outputs[a]}noteNameToNumber(e){return this.validation&&console.warn("The noteNameToNumber() method is deprecated. Use Utilities.toNoteNumber() instead."),G.toNoteNumber(e,this.octaveOffset)}getOctave(e){return this.validation&&(console.warn("The getOctave()is deprecated. Use Utilities.getNoteDetails() instead"),e=parseInt(e)),!isNaN(e)&&e>=0&&e<=127?G.getNoteDetails(G.offsetNumber(e,this.octaveOffset)).octave:!1}sanitizeChannels(e){return this.validation&&console.warn("The sanitizeChannels() method has been moved to the utilities class."),G.sanitizeChannels(e)}toMIDIChannels(e){return this.validation&&console.warn("The toMIDIChannels() method has been deprecated. Use Utilities.sanitizeChannels() instead."),G.sanitizeChannels(e)}guessNoteNumber(e){return this.validation&&console.warn("The guessNoteNumber() method has been deprecated. Use Utilities.guessNoteNumber() instead."),G.guessNoteNumber(e,this.octaveOffset)}getValidNoteArray(e,t={}){return this.validation&&console.warn("The getValidNoteArray() method has been moved to the Utilities.buildNoteArray()"),G.buildNoteArray(e,t)}convertToTimestamp(e){return this.validation&&console.warn("The convertToTimestamp() method has been moved to Utilities.toTimestamp()."),G.toTimestamp(e)}async _destroyInputsAndOutputs(){let e=[];return this.inputs.forEach(t=>e.push(t.destroy())),this.outputs.forEach(t=>e.push(t.destroy())),Promise.all(e).then(()=>{this._inputs=[],this._outputs=[]})}_onInterfaceStateChange(e){this._updateInputsAndOutputs();let t={timestamp:e.timeStamp,type:e.port.state,target:this};if(e.port.state==="connected"&&e.port.connection==="open"){e.port.type==="output"?t.port=this.getOutputById(e.port.id):e.port.type==="input"&&(t.port=this.getInputById(e.port.id)),this.emit(e.port.state,t);const a=Object.assign({},t);a.type="portschanged",this.emit(a.type,a)}else if(e.port.state==="disconnected"&&e.port.connection==="pending"){e.port.type==="input"?t.port=this.getInputById(e.port.id,{disconnected:!0}):e.port.type==="output"&&(t.port=this.getOutputById(e.port.id,{disconnected:!0})),this.emit(e.port.state,t);const a=Object.assign({},t);a.type="portschanged",this.emit(a.type,a)}}async _updateInputsAndOutputs(){return Promise.all([this._updateInputs(),this._updateOutputs()])}async _updateInputs(){if(!this.interface)return;for(let t=this._inputs.length-1;t>=0;t--){const a=this._inputs[t];Array.from(this.interface.inputs.values()).find(o=>o===a._midiInput)||(this._disconnectedInputs.push(a),this._inputs.splice(t,1))}let e=[];return this.interface.inputs.forEach(t=>{if(!this._inputs.find(a=>a._midiInput===t)){let a=this._disconnectedInputs.find(i=>i._midiInput===t);a||(a=new bk(t)),this._inputs.push(a),e.push(a.open())}}),Promise.all(e)}async _updateOutputs(){if(!this.interface)return;for(let t=this._outputs.length-1;t>=0;t--){const a=this._outputs[t];Array.from(this.interface.outputs.values()).find(o=>o===a._midiOutput)||(this._disconnectedOutputs.push(a),this._outputs.splice(t,1))}let e=[];return this.interface.outputs.forEach(t=>{if(!this._outputs.find(a=>a._midiOutput===t)){let a=this._disconnectedOutputs.find(i=>i._midiOutput===t);a||(a=new xc(t)),this._outputs.push(a),e.push(a.open())}}),Promise.all(e)}get enabled(){return this.interface!==null}get inputs(){return this._inputs}get isNode(){return this.validation&&console.warn("WebMidi.isNode has been deprecated. Use Utilities.isNode instead."),G.isNode}get isBrowser(){return this.validation&&console.warn("WebMidi.isBrowser has been deprecated. Use Utilities.isBrowser instead."),G.isBrowser}get octaveOffset(){return this._octaveOffset}set octaveOffset(e){if(this.validation&&(e=parseInt(e),isNaN(e)))throw new TypeError("The 'octaveOffset' property must be an integer.");this._octaveOffset=e}get outputs(){return this._outputs}get supported(){return typeof navigator<"u"&&!!navigator.requestMIDIAccess}get sysexEnabled(){return!!(this.interface&&this.interface.sysexEnabled)}get time(){return performance.now()}get version(){return"3.1.9"}get flavour(){return"esm"}get CHANNEL_EVENTS(){return this.validation&&console.warn("The CHANNEL_EVENTS enum has been moved to Enumerations.CHANNEL_EVENTS."),N.CHANNEL_EVENTS}get MIDI_SYSTEM_MESSAGES(){return this.validation&&console.warn("The MIDI_SYSTEM_MESSAGES enum has been moved to Enumerations.SYSTEM_MESSAGES."),N.SYSTEM_MESSAGES}get MIDI_CHANNEL_MODE_MESSAGES(){return this.validation&&console.warn("The MIDI_CHANNEL_MODE_MESSAGES enum has been moved to Enumerations.CHANNEL_MODE_MESSAGES."),N.CHANNEL_MODE_MESSAGES}get MIDI_CONTROL_CHANGE_MESSAGES(){return this.validation&&console.warn("The MIDI_CONTROL_CHANGE_MESSAGES enum has been replaced by the Enumerations.CONTROL_CHANGE_MESSAGES array."),N.MIDI_CONTROL_CHANGE_MESSAGES}get MIDI_REGISTERED_PARAMETER(){return this.validation&&console.warn("The MIDI_REGISTERED_PARAMETER enum has been moved to Enumerations.REGISTERED_PARAMETERS."),N.REGISTERED_PARAMETERS}get NOTES(){return this.validation&&console.warn("The NOTES enum has been deprecated."),["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"]}}const R=new vk;R.constructor=null;const fi={KeyQ:{note:"F",offset:1},Digit2:{note:"F#",offset:1},KeyW:{note:"G",offset:1},Digit3:{note:"G#",offset:1},KeyE:{note:"A",offset:1},Digit4:{note:"A#",offset:1},KeyR:{note:"B",offset:1},KeyT:{note:"C",offset:2},Digit6:{note:"C#",offset:2},KeyY:{note:"D",offset:2},Digit7:{note:"D#",offset:2},KeyU:{note:"E",offset:2},KeyI:{note:"F",offset:2},Digit9:{note:"F#",offset:2},KeyO:{note:"G",offset:2},Digit0:{note:"G#",offset:2},KeyP:{note:"A",offset:2},Minus:{note:"A#",offset:2},BracketLeft:{note:"B",offset:2},BracketRIght:{note:"C",offset:3},KeyZ:{note:"C",offset:0},KeyS:{note:"C#",offset:0},KeyX:{note:"D",offset:0},KeyD:{note:"D#",offset:0},KeyC:{note:"E",offset:0},KeyV:{note:"F",offset:0},KeyG:{note:"F#",offset:0},KeyB:{note:"G",offset:0},KeyH:{note:"G#",offset:0},KeyN:{note:"A",offset:0},KeyJ:{note:"A#",offset:0},KeyM:{note:"B",offset:0},Comma:{note:"C",offset:1},KeyL:{note:"C#",offset:1},Period:{note:"D",offset:1},Semicolon:{note:"D#",offset:1},Slash:{note:"E",offset:1}};function wk(){document.addEventListener("keydown",n=>{n.code=="Digit1"&&B.offset--,n.code=="Equal"&&B.offset++,!(n.repeat||!B.keyboard||!fi[n.code])&&(n.ctrlKey||n.altKey||n.metaKey||(n.code=="Slash"&&n.preventDefault(),_r(fi[n.code].note,fi[n.code].offset)))}),document.addEventListener("keyup",n=>{fi[n.code]&&_r(fi[n.code].note,fi[n.code].offset,!0)})}var Fa=typeof globalThis<"u"?globalThis:typeof window<"u"?window:typeof global<"u"?global:typeof self<"u"?self:{};function _k(n){return n&&n.__esModule&&Object.prototype.hasOwnProperty.call(n,"default")?n.default:n}function kk(n){if(n.__esModule)return n;var e=n.default;if(typeof e=="function"){var t=function a(){return this instanceof a?Reflect.construct(e,arguments,this.constructor):e.apply(this,arguments)};t.prototype=e.prototype}else t={};return Object.defineProperty(t,"__esModule",{value:!0}),Object.keys(n).forEach(function(a){var i=Object.getOwnPropertyDescriptor(n,a);Object.defineProperty(t,a,i.get?i:{enumerable:!0,get:function(){return n[a]}})}),t}var hf={exports:{}};(function(n,e){(function(t,a){n.exports=a()})(Fa,function(){const t=(r,l,c,h)=>{const d=(l*c+2*r)/c**3,u=-(2*l*c+3*r)/c**2,m=l,p=r;return d*h**3+u*h**2+m*h+p},a=(r,l,c,h)=>{const d=(l*c+2*r)/c**3,u=-(2*l*c+3*r)/c**2,m=l;return 3*d*h**2+2*u*h+m},i=function(r,l){Object.entries(typeof r=="number"?{value:r}:r).map(([h,d])=>l(d,h))};function o(r,l){this.start=new Date/1e3,this.time=l,this.from=r,this.current=r,this.to=r,this.speed=0}o.prototype.get=function(r){const l=r/1e3-this.start;if(l<0)throw new Error("Cannot read in the past");return l>=this.time?this.to:this.to-t(this.to-this.from,this.speed,this.time,l)},o.prototype.getSpeed=function(r){const l=r/1e3-this.start;return l>=this.time?0:a(this.to-this.from,this.speed,this.time,l)},o.prototype.set=function(r,l){const c=new Date,h=this.get(c);return this.speed=this.getSpeed(c),this.start=c/1e3,this.from=h,this.to=r,l&&(this.time=l),h};function s(r,l=300){return typeof r=="number"&&(r={value:r}),i(r,(c,h)=>{const d=new o(c,l/1e3);Object.defineProperty(r,"_"+h,{value:d}),Object.defineProperty(r,"$"+h,{get:()=>d.to}),Object.defineProperty(r,h,{get:()=>d.get(new Date),set:u=>d.set(u),enumerable:!0})}),Object.defineProperty(r,"get",{get:()=>function(c="value",h=new Date){return this["_"+c].get(h)}}),Object.defineProperty(r,"set",{get:()=>function(c,h=0){i(c,(d,u)=>{this["_"+u].set(d,h/1e3)})}}),r}return s})})(hf);var Tk=hf.exports;const xk=_k(Tk);function Kh(n){return n!==null&&typeof n=="object"&&"name"in n&&typeof n.name=="string"}function Jh(n){return n!==null&&typeof n=="object"&&"step"in n&&typeof n.step=="number"&&"alt"in n&&typeof n.alt=="number"&&!isNaN(n.step)&&!isNaN(n.alt)}var df=[0,2,4,-1,1,3,5],uf=df.map(n=>Math.floor(n*7/12));function mf(n){const{step:e,alt:t,oct:a,dir:i=1}=n,o=df[e]+7*t;if(a===void 0)return[i*o];const s=a-uf[e]-4*t;return[i*o,i*s]}var Sk=[3,0,4,1,5,2,6];function pf(n){const[e,t,a]=n,i=Sk[Ak(e)],o=Math.floor((e+1)/7);if(t===void 0)return{step:i,alt:o,dir:a};const s=t+4*o+uf[i];return{step:i,alt:o,oct:s,dir:a}}function Ak(n){const e=(n+1)%7;return e<0?7+e:e}var mu=(n,e)=>Array(Math.abs(e)+1).join(n),Sc=Object.freeze({empty:!0,name:"",num:NaN,q:"",type:"",step:NaN,alt:NaN,dir:NaN,simple:NaN,semitones:NaN,chroma:NaN,coord:[],oct:NaN}),Ck="([-+]?\\d+)(d{1,4}|m|M|P|A{1,4})",Mk="(AA|A|P|M|m|d|dd)([-+]?\\d+)",Ik=new RegExp("^"+Ck+"|"+Mk+"$");function Ek(n){const e=Ik.exec(`${n}`);return e===null?["",""]:e[1]?[e[1],e[2]]:[e[4],e[3]]}var pu={};function ht(n){return typeof n=="string"?pu[n]||(pu[n]=Dk(n)):Jh(n)?ht(Nk(n)):Kh(n)?ht(n.name):Sc}var fu=[0,2,4,5,7,9,11],ff="PMMPPMM";function Dk(n){const e=Ek(n);if(e[0]==="")return Sc;const t=+e[0],a=e[1],i=(Math.abs(t)-1)%7,o=ff[i];if(o==="M"&&a==="P")return Sc;const s=o==="M"?"majorable":"perfectable",r=""+t+a,l=t<0?-1:1,c=t===8||t===-8?t:l*(i+1),h=Pk(s,a),d=Math.floor((Math.abs(t)-1)/7),u=l*(fu[i]+h+12*d),m=(l*(fu[i]+h)%12+12)%12,p=mf({step:i,alt:h,oct:d,dir:l});return{empty:!1,name:r,num:t,q:a,step:i,alt:h,dir:l,type:s,simple:c,semitones:u,chroma:m,coord:p,oct:d}}function Zh(n,e){const[t,a=0]=n,i=t*7+a*12<0,o=e||i?[-t,-a,-1]:[t,a,1];return ht(pf(o))}function Pk(n,e){return e==="M"&&n==="majorable"||e==="P"&&n==="perfectable"?0:e==="m"&&n==="majorable"?-1:/^A+$/.test(e)?e.length:/^d+$/.test(e)?-1*(n==="perfectable"?e.length:e.length+1):0}function Nk(n){const{step:e,alt:t,oct:a=0,dir:i}=n;if(!i)return"";const o=e+1+7*a,s=o===0?e+1:o,r=i<0?"-":"",l=ff[e]==="M"?"majorable":"perfectable";return r+s+Bk(l,t)}function Bk(n,e){return e===0?n==="majorable"?"M":"P":e===-1&&n==="majorable"?"m":e>0?mu("A",e):mu("d",n==="perfectable"?e:e+1)}var gu=(n,e)=>Array(Math.abs(e)+1).join(n),gf=Object.freeze({empty:!0,name:"",letter:"",acc:"",pc:"",step:NaN,alt:NaN,chroma:NaN,height:NaN,coord:[],midi:null,freq:null}),yu=new Map,jk=n=>"CDEFGAB".charAt(n),yf=n=>n<0?gu("b",-n):gu("#",n),bf=n=>n[0]==="b"?-n.length:n.length;function Se(n){const e=JSON.stringify(n),t=yu.get(e);if(t)return t;const a=typeof n=="string"?qk(n):Jh(n)?Se(Fk(n)):Kh(n)?Se(n.name):gf;return yu.set(e,a),a}var zk=/^([a-gA-G]?)(#{1,}|b{1,}|x{1,}|)(-?\d*)\s*(.*)$/;function Yh(n){const e=zk.exec(n);return e?[e[1].toUpperCase(),e[2].replace(/x/g,"##"),e[3],e[4]]:["","","",""]}function Rk(n){return Se(pf(n))}var Ok=(n,e)=>(n%e+e)%e,$l=[0,2,4,5,7,9,11];function qk(n){const e=Yh(n);if(e[0]===""||e[3]!=="")return gf;const t=e[0],a=e[1],i=e[2],o=(t.charCodeAt(0)+3)%7,s=bf(a),r=i.length?+i:void 0,l=mf({step:o,alt:s,oct:r}),c=t+a+i,h=t+a,d=($l[o]+s+120)%12,u=r===void 0?Ok($l[o]+s,12)-12*99:$l[o]+s+12*(r+1),m=u>=0&&u<=127?u:null,p=r===void 0?null:Math.pow(2,(u-69)/12)*440;return{empty:!1,acc:a,alt:s,chroma:d,coord:l,freq:p,height:u,letter:t,midi:m,name:c,oct:r,pc:h,step:o}}function Fk(n){const{step:e,alt:t,oct:a}=n,i=jk(e);if(!i)return"";const o=i+yf(t);return a||a===0?o+a:o}function en(n,e){const t=Se(n),a=Array.isArray(e)?e:ht(e).coord;if(t.empty||!a||a.length<2)return"";const i=t.coord,o=i.length===1?[i[0]+a[0]]:[i[0]+a[0],i[1]+a[1]];return Rk(o).name}function yl(n,e){const t=n.length;return a=>{if(!e)return"";const i=a<0?(t- -a%t)%t:a%t,o=Math.floor(a/t),s=en(e,[0,o]);return en(s,n[i])}}function wr(n,e){const t=Se(n),a=Se(e);if(t.empty||a.empty)return"";const i=t.coord,o=a.coord,s=o[0]-i[0],r=i.length===2&&o.length===2?o[1]-i[1]:-Math.floor(s*7/12),l=a.height===t.height&&a.midi!==null&&t.midi!==null&&t.step>a.step;return Zh([s,r],l).name}function li(n,e,t){return function(...a){return console.warn(`${n} is deprecated. Use ${e}.`),t.apply(this,a)}}var Lk=li("isNamed","isNamedPitch",Kh);function Gk(n,e){const t=[];for(;e--;t[e]=e+n);return t}function $k(n,e){const t=[];for(;e--;t[e]=n-e);return t}function Xh(n,e){return n<e?Gk(n,e-n+1):$k(n,n-e+1)}function xs(n,e){const t=e.length,a=(n%t+t)%t;return e.slice(a,t).concat(e.slice(0,a))}function vf(n){return n.filter(e=>e===0||e)}var ei={empty:!0,name:"",setNum:0,chroma:"000000000000",normalized:"000000000000",intervals:[]},Qh=n=>Number(n).toString(2).padStart(12,"0"),bu=n=>parseInt(n,2),Vk=/^[01]{12}$/;function ed(n){return Vk.test(n)}var Hk=n=>typeof n=="number"&&n>=0&&n<=4095,Wk=n=>n&&ed(n.chroma),vu={[ei.chroma]:ei};function _t(n){const e=ed(n)?n:Hk(n)?Qh(n):Array.isArray(n)?oT(n):Wk(n)?n.chroma:ei.chroma;return vu[e]=vu[e]||iT(e)}var Uk=li("Pcset.pcset","Pcset.get",_t),wf=n=>_t(n).chroma,Kk=n=>_t(n).intervals,Jk=n=>_t(n).setNum,Zk=["1P","2m","2M","3m","3M","4P","5d","5P","6m","6M","7m","7M"];function Yk(n){const e=[];for(let t=0;t<12;t++)n.charAt(t)==="1"&&e.push(Zk[t]);return e}function Xk(n){return _t(n).intervals.map(e=>en("C",e))}function Qk(){return Xh(2048,4095).map(Qh)}function td(n,e=!0){const a=_t(n).chroma.split("");return vf(a.map((i,o)=>{const s=xs(o,a);return e&&s[0]==="0"?null:s.join("")}))}function eT(n,e){return _t(n).setNum===_t(e).setNum}function bl(n){const e=_t(n).setNum;return t=>{const a=_t(t).setNum;return e&&e!==a&&(a&e)===a}}function vl(n){const e=_t(n).setNum;return t=>{const a=_t(t).setNum;return e&&e!==a&&(a|e)===a}}function _f(n){const e=_t(n);return t=>{const a=Se(t);return e&&!a.empty&&e.chroma.charAt(a.chroma)==="1"}}function tT(n){const e=_f(n);return t=>t.filter(e)}var nT={get:_t,chroma:wf,num:Jk,intervals:Kk,chromas:Qk,isSupersetOf:vl,isSubsetOf:bl,isNoteIncludedIn:_f,isEqual:eT,filter:tT,modes:td,notes:Xk,pcset:Uk};function aT(n){const e=n.split("");return e.map((t,a)=>xs(a,e).join(""))}function iT(n){const e=bu(n),t=aT(n).map(bu).filter(o=>o>=2048).sort()[0],a=Qh(t),i=Yk(n);return{empty:!1,name:"",setNum:e,chroma:n,normalized:a,intervals:i}}function oT(n){if(n.length===0)return ei.chroma;let e;const t=[0,0,0,0,0,0,0,0,0,0,0,0];for(let a=0;a<n.length;a++)e=Se(n[a]),e.empty&&(e=ht(n[a])),e.empty||(t[e.chroma]=1);return t.join("")}var sT=[["1P 3M 5P","major","M ^  maj"],["1P 3M 5P 7M","major seventh","maj7 Δ ma7 M7 Maj7 ^7"],["1P 3M 5P 7M 9M","major ninth","maj9 Δ9 ^9"],["1P 3M 5P 7M 9M 13M","major thirteenth","maj13 Maj13 ^13"],["1P 3M 5P 6M","sixth","6 add6 add13 M6"],["1P 3M 5P 6M 9M","sixth added ninth","6add9 6/9 69 M69"],["1P 3M 6m 7M","major seventh flat sixth","M7b6 ^7b6"],["1P 3M 5P 7M 11A","major seventh sharp eleventh","maj#4 Δ#4 Δ#11 M7#11 ^7#11 maj7#11"],["1P 3m 5P","minor","m min -"],["1P 3m 5P 7m","minor seventh","m7 min7 mi7 -7"],["1P 3m 5P 7M","minor/major seventh","m/ma7 m/maj7 mM7 mMaj7 m/M7 -Δ7 mΔ -^7 -maj7"],["1P 3m 5P 6M","minor sixth","m6 -6"],["1P 3m 5P 7m 9M","minor ninth","m9 -9"],["1P 3m 5P 7M 9M","minor/major ninth","mM9 mMaj9 -^9"],["1P 3m 5P 7m 9M 11P","minor eleventh","m11 -11"],["1P 3m 5P 7m 9M 13M","minor thirteenth","m13 -13"],["1P 3m 5d","diminished","dim ° o"],["1P 3m 5d 7d","diminished seventh","dim7 °7 o7"],["1P 3m 5d 7m","half-diminished","m7b5 ø -7b5 h7 h"],["1P 3M 5P 7m","dominant seventh","7 dom"],["1P 3M 5P 7m 9M","dominant ninth","9"],["1P 3M 5P 7m 9M 13M","dominant thirteenth","13"],["1P 3M 5P 7m 11A","lydian dominant seventh","7#11 7#4"],["1P 3M 5P 7m 9m","dominant flat ninth","7b9"],["1P 3M 5P 7m 9A","dominant sharp ninth","7#9"],["1P 3M 7m 9m","altered","alt7"],["1P 4P 5P","suspended fourth","sus4 sus"],["1P 2M 5P","suspended second","sus2"],["1P 4P 5P 7m","suspended fourth seventh","7sus4 7sus"],["1P 5P 7m 9M 11P","eleventh","11"],["1P 4P 5P 7m 9m","suspended fourth flat ninth","b9sus phryg 7b9sus 7b9sus4"],["1P 5P","fifth","5"],["1P 3M 5A","augmented","aug + +5 ^#5"],["1P 3m 5A","minor augmented","m#5 -#5 m+"],["1P 3M 5A 7M","augmented seventh","maj7#5 maj7+5 +maj7 ^7#5"],["1P 3M 5P 7M 9M 11A","major sharp eleventh (lydian)","maj9#11 Δ9#11 ^9#11"],["1P 2M 4P 5P","","sus24 sus4add9"],["1P 3M 5A 7M 9M","","maj9#5 Maj9#5"],["1P 3M 5A 7m","","7#5 +7 7+ 7aug aug7"],["1P 3M 5A 7m 9A","","7#5#9 7#9#5 7alt"],["1P 3M 5A 7m 9M","","9#5 9+"],["1P 3M 5A 7m 9M 11A","","9#5#11"],["1P 3M 5A 7m 9m","","7#5b9 7b9#5"],["1P 3M 5A 7m 9m 11A","","7#5b9#11"],["1P 3M 5A 9A","","+add#9"],["1P 3M 5A 9M","","M#5add9 +add9"],["1P 3M 5P 6M 11A","","M6#11 M6b5 6#11 6b5"],["1P 3M 5P 6M 7M 9M","","M7add13"],["1P 3M 5P 6M 9M 11A","","69#11"],["1P 3m 5P 6M 9M","","m69 -69"],["1P 3M 5P 6m 7m","","7b6"],["1P 3M 5P 7M 9A 11A","","maj7#9#11"],["1P 3M 5P 7M 9M 11A 13M","","M13#11 maj13#11 M13+4 M13#4"],["1P 3M 5P 7M 9m","","M7b9"],["1P 3M 5P 7m 11A 13m","","7#11b13 7b5b13"],["1P 3M 5P 7m 13M","","7add6 67 7add13"],["1P 3M 5P 7m 9A 11A","","7#9#11 7b5#9 7#9b5"],["1P 3M 5P 7m 9A 11A 13M","","13#9#11"],["1P 3M 5P 7m 9A 11A 13m","","7#9#11b13"],["1P 3M 5P 7m 9A 13M","","13#9"],["1P 3M 5P 7m 9A 13m","","7#9b13"],["1P 3M 5P 7m 9M 11A","","9#11 9+4 9#4"],["1P 3M 5P 7m 9M 11A 13M","","13#11 13+4 13#4"],["1P 3M 5P 7m 9M 11A 13m","","9#11b13 9b5b13"],["1P 3M 5P 7m 9m 11A","","7b9#11 7b5b9 7b9b5"],["1P 3M 5P 7m 9m 11A 13M","","13b9#11"],["1P 3M 5P 7m 9m 11A 13m","","7b9b13#11 7b9#11b13 7b5b9b13"],["1P 3M 5P 7m 9m 13M","","13b9"],["1P 3M 5P 7m 9m 13m","","7b9b13"],["1P 3M 5P 7m 9m 9A","","7b9#9"],["1P 3M 5P 9M","","Madd9 2 add9 add2"],["1P 3M 5P 9m","","Maddb9"],["1P 3M 5d","","Mb5"],["1P 3M 5d 6M 7m 9M","","13b5"],["1P 3M 5d 7M","","M7b5"],["1P 3M 5d 7M 9M","","M9b5"],["1P 3M 5d 7m","","7b5"],["1P 3M 5d 7m 9M","","9b5"],["1P 3M 7m","","7no5"],["1P 3M 7m 13m","","7b13"],["1P 3M 7m 9M","","9no5"],["1P 3M 7m 9M 13M","","13no5"],["1P 3M 7m 9M 13m","","9b13"],["1P 3m 4P 5P","","madd4"],["1P 3m 5P 6m 7M","","mMaj7b6"],["1P 3m 5P 6m 7M 9M","","mMaj9b6"],["1P 3m 5P 7m 11P","","m7add11 m7add4"],["1P 3m 5P 9M","","madd9"],["1P 3m 5d 6M 7M","","o7M7"],["1P 3m 5d 7M","","oM7"],["1P 3m 6m 7M","","mb6M7"],["1P 3m 6m 7m","","m7#5"],["1P 3m 6m 7m 9M","","m9#5"],["1P 3m 5A 7m 9M 11P","","m11A"],["1P 3m 6m 9m","","mb6b9"],["1P 2M 3m 5d 7m","","m9b5"],["1P 4P 5A 7M","","M7#5sus4"],["1P 4P 5A 7M 9M","","M9#5sus4"],["1P 4P 5A 7m","","7#5sus4"],["1P 4P 5P 7M","","M7sus4"],["1P 4P 5P 7M 9M","","M9sus4"],["1P 4P 5P 7m 9M","","9sus4 9sus"],["1P 4P 5P 7m 9M 13M","","13sus4 13sus"],["1P 4P 5P 7m 9m 13m","","7sus4b9b13 7b9b13sus4"],["1P 4P 7m 10m","","4 quartal"],["1P 5P 7m 9m 11P","","11b9"]],rT=sT,lT={...ei,name:"",quality:"Unknown",intervals:[],aliases:[]},Qi=[],$a={};function nd(n){return $a[n]||lT}var cT=li("ChordType.chordType","ChordType.get",nd);function hT(){return Qi.map(n=>n.name).filter(n=>n)}function dT(){return Qi.map(n=>n.aliases[0]).filter(n=>n)}function uT(){return Object.keys($a)}function eo(){return Qi.slice()}var mT=li("ChordType.entries","ChordType.all",eo);function pT(){Qi=[],$a={}}function kf(n,e,t){const a=gT(n),i={..._t(n),name:t||"",quality:a,intervals:n,aliases:e};Qi.push(i),i.name&&($a[i.name]=i),$a[i.setNum]=i,$a[i.chroma]=i,i.aliases.forEach(o=>fT(i,o))}function fT(n,e){$a[e]=n}function gT(n){const e=t=>n.indexOf(t)!==-1;return e("5A")?"Augmented":e("3M")?"Major":e("5d")?"Diminished":e("3m")?"Minor":"Unknown"}rT.forEach(([n,e,t])=>kf(n.split(" "),t.split(" "),e));Qi.sort((n,e)=>n.setNum-e.setNum);var wu={names:hT,symbols:dT,get:nd,all:eo,add:kf,removeAll:pT,keys:uT,entries:mT,chordType:cT},yT=n=>{const e=n.reduce((t,a)=>{const i=Se(a).chroma;return i!==void 0&&(t[i]=t[i]||Se(a).name),t},{});return t=>e[t]};function bT(n,e={}){const t=n.map(i=>Se(i).pc).filter(i=>i);return Se.length===0?[]:ST(t,1,e).filter(i=>i.weight).sort((i,o)=>o.weight-i.weight).map(i=>i.name)}var wl={anyThirds:384,perfectFifth:16,nonPerfectFifths:40,anySeventh:3},_l=n=>e=>!!(e&n),vT=_l(wl.anyThirds),wT=_l(wl.perfectFifth),_T=_l(wl.anySeventh),kT=_l(wl.nonPerfectFifths);function TT(n){const e=parseInt(n.chroma,2);return vT(e)&&wT(e)&&_T(e)}function xT(n){const e=parseInt(n,2);return kT(e)?n:(e|16).toString(2)}function ST(n,e,t){const a=n[0],i=Se(a).chroma,o=yT(n),s=td(n,!1),r=[];return s.forEach((l,c)=>{const h=t.assumePerfectFifth&&xT(l);eo().filter(u=>t.assumePerfectFifth&&TT(u)?u.chroma===h:u.chroma===l).forEach(u=>{const m=u.aliases[0],p=o(c);c!==i?r.push({weight:.5*e,name:`${p}${m}/${a}`}):r.push({weight:1*e,name:`${p}${m}`})})}),r}function AT(){return"1P 2M 3M 4P 5P 6m 7m".split(" ")}var Tf=ht,CT=n=>ht(n).name,MT=n=>ht(n).semitones,IT=n=>ht(n).q,ET=n=>ht(n).num;function DT(n){const e=ht(n);return e.empty?"":e.simple+e.q}function PT(n){const e=ht(n);if(e.empty)return"";const t=(7-e.step)%7,a=e.type==="perfectable"?-e.alt:-(e.alt+1);return ht({step:t,alt:a,oct:e.oct,dir:e.dir}).name}var NT=[1,2,2,3,3,4,5,5,6,6,7,7],BT="P m M m M P d P m M m M".split(" ");function jT(n){const e=n<0?-1:1,t=Math.abs(n),a=t%12,i=Math.floor(t/12);return e*(NT[a]+7*i)+BT[a]}var zT=wr,xf=Af((n,e)=>[n[0]+e[0],n[1]+e[1]]),RT=n=>e=>xf(n,e),Sf=Af((n,e)=>[n[0]-e[0],n[1]-e[1]]);function OT(n,e){const t=Tf(n);if(t.empty)return"";const[a,i,o]=t.coord;return Zh([a+e,i,o]).name}var lR={names:AT,get:Tf,name:CT,num:ET,semitones:MT,quality:IT,fromSemitones:jT,distance:zT,invert:PT,simplify:DT,add:xf,addTo:RT,subtract:Sf,transposeFifths:OT};function Af(n){return(e,t)=>{const a=ht(e).coord,i=ht(t).coord;if(a&&i){const o=n(a,i);return Zh(o).name}}}var qT=[["1P 2M 3M 5P 6M","major pentatonic","pentatonic"],["1P 2M 3M 4P 5P 6M 7M","major","ionian"],["1P 2M 3m 4P 5P 6m 7m","minor","aeolian"],["1P 2M 3m 3M 5P 6M","major blues"],["1P 3m 4P 5d 5P 7m","minor blues","blues"],["1P 2M 3m 4P 5P 6M 7M","melodic minor"],["1P 2M 3m 4P 5P 6m 7M","harmonic minor"],["1P 2M 3M 4P 5P 6M 7m 7M","bebop"],["1P 2M 3m 4P 5d 6m 6M 7M","diminished","whole-half diminished"],["1P 2M 3m 4P 5P 6M 7m","dorian"],["1P 2M 3M 4A 5P 6M 7M","lydian"],["1P 2M 3M 4P 5P 6M 7m","mixolydian","dominant"],["1P 2m 3m 4P 5P 6m 7m","phrygian"],["1P 2m 3m 4P 5d 6m 7m","locrian"],["1P 3M 4P 5P 7M","ionian pentatonic"],["1P 3M 4P 5P 7m","mixolydian pentatonic","indian"],["1P 2M 4P 5P 6M","ritusen"],["1P 2M 4P 5P 7m","egyptian"],["1P 3M 4P 5d 7m","neopolitan major pentatonic"],["1P 3m 4P 5P 6m","vietnamese 1"],["1P 2m 3m 5P 6m","pelog"],["1P 2m 4P 5P 6m","kumoijoshi"],["1P 2M 3m 5P 6m","hirajoshi"],["1P 2m 4P 5d 7m","iwato"],["1P 2m 4P 5P 7m","in-sen"],["1P 3M 4A 5P 7M","lydian pentatonic","chinese"],["1P 3m 4P 6m 7m","malkos raga"],["1P 3m 4P 5d 7m","locrian pentatonic","minor seven flat five pentatonic"],["1P 3m 4P 5P 7m","minor pentatonic","vietnamese 2"],["1P 3m 4P 5P 6M","minor six pentatonic"],["1P 2M 3m 5P 6M","flat three pentatonic","kumoi"],["1P 2M 3M 5P 6m","flat six pentatonic"],["1P 2m 3M 5P 6M","scriabin"],["1P 3M 5d 6m 7m","whole tone pentatonic"],["1P 3M 4A 5A 7M","lydian #5P pentatonic"],["1P 3M 4A 5P 7m","lydian dominant pentatonic"],["1P 3m 4P 5P 7M","minor #7M pentatonic"],["1P 3m 4d 5d 7m","super locrian pentatonic"],["1P 2M 3m 4P 5P 7M","minor hexatonic"],["1P 2A 3M 5P 5A 7M","augmented"],["1P 2M 4P 5P 6M 7m","piongio"],["1P 2m 3M 4A 6M 7m","prometheus neopolitan"],["1P 2M 3M 4A 6M 7m","prometheus"],["1P 2m 3M 5d 6m 7m","mystery #1"],["1P 2m 3M 4P 5A 6M","six tone symmetric"],["1P 2M 3M 4A 5A 6A","whole tone","messiaen's mode #1"],["1P 2m 4P 4A 5P 7M","messiaen's mode #5"],["1P 2M 3M 4P 5d 6m 7m","locrian major","arabian"],["1P 2m 3M 4A 5P 6m 7M","double harmonic lydian"],["1P 2m 2A 3M 4A 6m 7m","altered","super locrian","diminished whole tone","pomeroy"],["1P 2M 3m 4P 5d 6m 7m","locrian #2","half-diminished","aeolian b5"],["1P 2M 3M 4P 5P 6m 7m","mixolydian b6","melodic minor fifth mode","hindu"],["1P 2M 3M 4A 5P 6M 7m","lydian dominant","lydian b7","overtone"],["1P 2M 3M 4A 5A 6M 7M","lydian augmented"],["1P 2m 3m 4P 5P 6M 7m","dorian b2","phrygian #6","melodic minor second mode"],["1P 2m 3m 4d 5d 6m 7d","ultralocrian","superlocrian bb7","superlocrian diminished"],["1P 2m 3m 4P 5d 6M 7m","locrian 6","locrian natural 6","locrian sharp 6"],["1P 2A 3M 4P 5P 5A 7M","augmented heptatonic"],["1P 2M 3m 4A 5P 6M 7m","dorian #4","ukrainian dorian","romanian minor","altered dorian"],["1P 2M 3m 4A 5P 6M 7M","lydian diminished"],["1P 2M 3M 4A 5A 7m 7M","leading whole tone"],["1P 2M 3M 4A 5P 6m 7m","lydian minor"],["1P 2m 3M 4P 5P 6m 7m","phrygian dominant","spanish","phrygian major"],["1P 2m 3m 4P 5P 6m 7M","balinese"],["1P 2m 3m 4P 5P 6M 7M","neopolitan major"],["1P 2M 3M 4P 5P 6m 7M","harmonic major"],["1P 2m 3M 4P 5P 6m 7M","double harmonic major","gypsy"],["1P 2M 3m 4A 5P 6m 7M","hungarian minor"],["1P 2A 3M 4A 5P 6M 7m","hungarian major"],["1P 2m 3M 4P 5d 6M 7m","oriental"],["1P 2m 3m 3M 4A 5P 7m","flamenco"],["1P 2m 3m 4A 5P 6m 7M","todi raga"],["1P 2m 3M 4P 5d 6m 7M","persian"],["1P 2m 3M 5d 6m 7m 7M","enigmatic"],["1P 2M 3M 4P 5A 6M 7M","major augmented","major #5","ionian augmented","ionian #5"],["1P 2A 3M 4A 5P 6M 7M","lydian #9"],["1P 2m 2M 4P 4A 5P 6m 7M","messiaen's mode #4"],["1P 2m 3M 4P 4A 5P 6m 7M","purvi raga"],["1P 2m 3m 3M 4P 5P 6m 7m","spanish heptatonic"],["1P 2M 3m 3M 4P 5P 6M 7m","bebop minor"],["1P 2M 3M 4P 5P 5A 6M 7M","bebop major"],["1P 2m 3m 4P 5d 5P 6m 7m","bebop locrian"],["1P 2M 3m 4P 5P 6m 7m 7M","minor bebop"],["1P 2M 3M 4P 5d 5P 6M 7M","ichikosucho"],["1P 2M 3m 4P 5P 6m 6M 7M","minor six diminished"],["1P 2m 3m 3M 4A 5P 6M 7m","half-whole diminished","dominant diminished","messiaen's mode #2"],["1P 3m 3M 4P 5P 6M 7m 7M","kafi raga"],["1P 2M 3M 4P 4A 5A 6A 7M","messiaen's mode #6"],["1P 2M 3m 3M 4P 5d 5P 6M 7m","composite blues"],["1P 2M 3m 3M 4A 5P 6m 7m 7M","messiaen's mode #3"],["1P 2m 2M 3m 4P 4A 5P 6m 6M 7M","messiaen's mode #7"],["1P 2m 2M 3m 3M 4P 5d 5P 6m 6M 7m 7M","chromatic"]],FT=qT,LT={...ei,intervals:[],aliases:[]},kl=[],Va={};function Cf(){return kl.map(n=>n.name)}function Tl(n){return Va[n]||LT}var GT=li("ScaleDictionary.scaleType","ScaleType.get",Tl);function to(){return kl.slice()}var $T=li("ScaleDictionary.entries","ScaleType.all",to);function VT(){return Object.keys(Va)}function HT(){kl=[],Va={}}function Mf(n,e,t=[]){const a={..._t(n),name:e,intervals:n,aliases:t};return kl.push(a),Va[a.name]=a,Va[a.setNum]=a,Va[a.chroma]=a,a.aliases.forEach(i=>WT(a,i)),a}function WT(n,e){Va[e]=n}FT.forEach(([n,e,...t])=>Mf(n.split(" "),e,t));var Ko={names:Cf,get:Tl,all:to,add:Mf,removeAll:HT,keys:VT,entries:$T,scaleType:GT},If={empty:!0,name:"",symbol:"",root:"",bass:"",rootDegree:0,type:"",tonic:null,setNum:NaN,quality:"Unknown",chroma:"",normalized:"",aliases:[],notes:[],intervals:[]};function xl(n){const[e,t,a,i]=Yh(n);return e===""?Vl("",n):e==="A"&&i==="ug"?Vl("","aug"):Vl(e+t,a+i)}function Vl(n,e){const t=e.split("/");if(t.length===1)return[n,t[0],""];const[a,i,o,s]=Yh(t[1]);return a!==""&&o===""&&s===""?[n,t[0],a+i]:[n,e,""]}function Ma(n){if(Array.isArray(n))return Zs(n[1]||"",n[0],n[2]);if(n==="")return If;{const[e,t,a]=xl(n),i=Zs(t,e,a);return i.empty?Zs(n):i}}function Zs(n,e,t){const a=nd(n),i=Se(e||""),o=Se(t||"");if(a.empty||e&&i.empty||t&&o.empty)return If;const s=wr(i.pc,o.pc),r=a.intervals.indexOf(s),l=r>=0,c=l?o:Se(""),h=r===-1?NaN:r+1,d=o.pc&&o.pc!==i.pc,u=Array.from(a.intervals);if(l)for(let y=1;y<h;y++){const b=u[0][0],x=u[0][1],S=parseInt(b,10)+7;u.push(`${S}${x}`),u.shift()}else if(d){const y=Sf(wr(i.pc,o.pc),"8P");y&&u.unshift(y)}const m=i.empty?[]:u.map(y=>en(i.pc,y));n=a.aliases.indexOf(n)!==-1?n:a.aliases[0];const p=`${i.empty?"":i.pc}${n}${l&&h>1?"/"+c.pc:d?"/"+o.pc:""}`,g=`${e?i.pc+" ":""}${a.name}${l&&h>1?" over "+c.pc:d?" over "+o.pc:""}`;return{...a,name:g,symbol:p,tonic:i.pc,type:a.name,root:c.pc,bass:d?o.pc:"",intervals:u,rootDegree:h,notes:m}}var UT=Ma;function KT(n,e){const[t,a,i]=xl(n);if(!t)return n;const o=en(i,e),s=o?"/"+o:"";return en(t,e)+a+s}function JT(n){const e=Ma(n),t=vl(e.chroma);return to().filter(a=>t(a.chroma)).map(a=>a.name)}function ZT(n){const e=Ma(n),t=vl(e.chroma);return eo().filter(a=>t(a.chroma)).map(a=>e.tonic+a.aliases[0])}function YT(n){const e=Ma(n),t=bl(e.chroma);return eo().filter(a=>t(a.chroma)).map(a=>e.tonic+a.aliases[0])}function XT(n,e){const t=Ma(n),a=e||t.tonic;return!a||t.empty?[]:t.intervals.map(i=>en(a,i))}function QT(n,e){const t=Ma(n),a=e||t.tonic,i=yl(t.intervals,a);return o=>o?i(o>0?o-1:o):""}function ex(n,e){const t=Ma(n),a=e||t.tonic;return yl(t.intervals,a)}var tx={getChord:Zs,get:Ma,detect:bT,chordScales:JT,extended:ZT,reduced:YT,tokenize:xl,transpose:KT,degrees:QT,steps:ex,notes:XT,chord:UT};function Ef(n){return+n>=0&&+n<=127}function Df(n){if(Ef(n))return+n;const e=Se(n);return e.empty?null:e.midi}function nx(n,e=440){return Math.pow(2,(n-69)/12)*e}var ax=Math.log(2),ix=Math.log(440);function ad(n){const e=12*(Math.log(n)-ix)/ax+69;return Math.round(e*100)/100}var ox="C C# D D# E F F# G G# A A# B".split(" "),sx="C Db D Eb E F Gb G Ab A Bb B".split(" ");function Ia(n,e={}){if(isNaN(n)||n===-1/0||n===1/0)return"";n=Math.round(n);const a=(e.sharps===!0?ox:sx)[n%12];if(e.pitchClass)return a;const i=Math.floor(n/12)-1;return a+i}function id(n){return n%12}function rx(n){return n.split("").reduce((e,t,a)=>(a<12&&t==="1"&&e.push(a),e),[])}function lx(n){return n.map(id).sort((e,t)=>e-t).filter((e,t,a)=>t===0||e!==a[t-1])}function od(n){return Array.isArray(n)?lx(n):rx(n)}function cx(n){const e=od(n);return t=>{const a=id(t);for(let i=0;i<12;i++){if(e.includes(a+i))return t+i;if(e.includes(a-i))return t-i}}}function Pf(n,e){const t=od(n),a=t.length;return i=>{const o=i<0?(a- -i%a)%a:i%a,s=Math.floor(i/a);return t[o]+s*12+e}}function hx(n,e){const t=Pf(n,e);return a=>{if(a!==0)return t(a>0?a-1:a)}}var dx={chroma:id,freqToMidi:ad,isMidi:Ef,midiToFreq:nx,midiToNoteName:Ia,pcsetNearest:cx,pcset:od,pcsetDegrees:hx,pcsetSteps:Pf,toMidi:Df},ux=["C","D","E","F","G","A","B"],Nf=n=>n.name,Bf=n=>n.map(Se).filter(e=>!e.empty);function mx(n){return n===void 0?ux.slice():Array.isArray(n)?Bf(n).map(Nf):[]}var yn=Se,px=n=>yn(n).name,fx=n=>yn(n).pc,gx=n=>yn(n).acc,yx=n=>yn(n).oct,bx=n=>yn(n).midi,vx=n=>yn(n).freq,wx=n=>yn(n).chroma;function jf(n){return Ia(n)}function _x(n){return Ia(ad(n))}function kx(n){return Ia(ad(n),{sharps:!0})}function Tx(n){return Ia(n,{sharps:!0})}var Ss=en,xx=en,zf=n=>e=>Ss(e,n),Sx=zf,Rf=n=>e=>Ss(n,e),Ax=Rf;function Of(n,e){return Ss(n,[e,0])}var Cx=Of;function Mx(n,e){return Ss(n,[0,e])}var sd=(n,e)=>n.height-e.height,Ix=(n,e)=>e.height-n.height;function qf(n,e){return e=e||sd,Bf(n).sort(e).map(Nf)}function Ff(n){return qf(n,sd).filter((e,t,a)=>t===0||e!==a[t-1])}var Ex=n=>{const e=yn(n);return e.empty?"":Ia(e.midi||e.chroma,{sharps:e.alt>0,pitchClass:e.midi===null})};function Lf(n,e){const t=yn(n);if(t.empty)return"";const a=yn(e||Ia(t.midi||t.chroma,{sharps:t.alt<0,pitchClass:!0}));if(a.empty||a.chroma!==t.chroma)return"";if(t.oct===void 0)return a.pc;const i=t.chroma-t.alt,o=a.chroma-a.alt,s=i>11||o<0?-1:i<0||o>11?1:0,r=t.oct+s;return a.pc+r}var Ac={names:mx,get:yn,name:px,pitchClass:fx,accidentals:gx,octave:yx,midi:bx,ascending:sd,descending:Ix,sortedNames:qf,sortedUniqNames:Ff,fromMidi:jf,fromMidiSharps:Tx,freq:vx,fromFreq:_x,fromFreqSharps:kx,chroma:wx,transpose:Ss,tr:xx,transposeBy:zf,trBy:Sx,transposeFrom:Rf,trFrom:Ax,transposeFifths:Of,transposeOctaves:Mx,trFifths:Cx,simplify:Ex,enharmonic:Lf},Gf={empty:!0,name:"",chordType:""},_u={};function Jo(n){return typeof n=="string"?_u[n]||(_u[n]=jx(n)):typeof n=="number"?Jo(rd[n]||""):Jh(n)?Dx(n):Lk(n)?Jo(n.name):Gf}function Dx(n){return Jo(yf(n.alt)+rd[n.step])}var Px=/^(#{1,}|b{1,}|x{1,}|)(IV|I{1,3}|VI{0,2}|iv|i{1,3}|vi{0,2})([^IViv]*)$/;function Nx(n){return Px.exec(n)||["","","",""]}var Bx="I II III IV V VI VII",rd=Bx.split(" ");function jx(n){const[e,t,a,i]=Nx(n);if(!a)return Gf;const o=a.toUpperCase(),s=rd.indexOf(o),r=bf(t),l=1;return{empty:!1,name:e,roman:a,interval:ht({step:s,alt:r,dir:l}).name,acc:t,chordType:i,alt:r,step:s,major:a===o,oct:0,dir:l}}var ld=[[0,2773,0,"ionian","","Maj7","major"],[1,2902,2,"dorian","m","m7"],[2,3418,4,"phrygian","m","m7"],[3,2741,-1,"lydian","","Maj7"],[4,2774,1,"mixolydian","","7"],[5,2906,3,"aeolian","m","m7","minor"],[6,3434,5,"locrian","dim","m7b5"]],ku={...ei,name:"",alt:0,modeNum:NaN,triad:"",seventh:"",aliases:[]},zx=ld.map(Rx),Cc={};zx.forEach(n=>{Cc[n.name]=n,n.aliases.forEach(e=>{Cc[e]=n})});function $f(n){return typeof n=="string"?Cc[n.toLowerCase()]||ku:n&&n.name?$f(n.name):ku}function Rx(n){const[e,t,a,i,o,s,r]=n,l=r?[r]:[],c=Number(t).toString(2);return{empty:!1,intervals:Tl(i).intervals,modeNum:e,chroma:c,normalized:c,name:i,setNum:t,alt:a,triad:o,seventh:s,aliases:l}}function Vf(n){return(e,t)=>{const a=$f(e);if(a.empty)return[];const i=xs(a.modeNum,n),o=a.intervals.map(s=>en(t,s));return i.map((s,r)=>o[r]+s)}}Vf(ld.map(n=>n[4]));Vf(ld.map(n=>n[5]));function Ox(n,e){return e.map(Jo).map(a=>en(n,ht(a))+a.chordType)}function qx(n,e){return e.map(t=>{const[a,i]=xl(t),o=wr(n,a);return Jo(ht(o)).name+i})}var cR={fromRomanNumerals:Ox,toRomanNumerals:qx};function Hf(n){const e=vf(n.map(t=>typeof t=="number"?t:Df(t)));return!n.length||e.length!==n.length?[]:e.reduce((t,a)=>{const i=t[t.length-1];return t.concat(Xh(i,a).slice(1))},[e[0]])}function Fx(n,e){return Hf(n).map(t=>Ia(t,e))}var hR={numeric:Hf,chromatic:Fx},Lx={empty:!0,name:"",type:"",tonic:null,setNum:NaN,chroma:"",normalized:"",aliases:[],notes:[],intervals:[]};function Wf(n){if(typeof n!="string")return["",""];const e=n.indexOf(" "),t=Se(n.substring(0,e));if(t.empty){const i=Se(n);return i.empty?["",n]:[i.name,""]}const a=n.substring(t.name.length+1).toLowerCase();return[t.name,a.length?a:""]}var Gx=Cf;function jn(n){const e=Array.isArray(n)?n:Wf(n),t=Se(e[0]).name,a=Tl(e[1]);if(a.empty)return Lx;const i=a.name,o=t?a.intervals.map(r=>en(t,r)):[],s=t?t+" "+i:i;return{...a,name:s,type:i,tonic:t,notes:o}}var $x=li("Scale.scale","Scale.get",jn);function Vx(n,e={}){const t=wf(n),a=Se(e.tonic??n[0]??""),i=a.chroma;if(i===void 0)return[];const o=t.split("");o[i]="1";const s=xs(i,o).join(""),r=to().find(c=>c.chroma===s),l=[];return r&&l.push(a.name+" "+r.name),e.match==="exact"||Uf(s).forEach(c=>{l.push(a.name+" "+c)}),l}function Hx(n){const e=jn(n),t=bl(e.chroma);return eo().filter(a=>t(a.chroma)).map(a=>a.aliases[0])}function Uf(n){const e=ed(n)?n:jn(n).chroma,t=vl(e);return to().filter(a=>t(a.chroma)).map(a=>a.name)}function Wx(n){const e=bl(jn(n).chroma);return to().filter(t=>e(t.chroma)).map(t=>t.name)}function Kf(n){const e=n.map(i=>Se(i).pc).filter(i=>i),t=e[0],a=Ff(e);return xs(a.indexOf(t),a)}function Ux(n){const e=jn(n);if(e.empty)return[];const t=e.tonic?e.notes:e.intervals;return td(e.chroma).map((a,i)=>{const o=jn(a).name;return o?[t[i],o]:["",""]}).filter(a=>a[0])}function Kx(n){const e=Array.isArray(n)?Kf(n):jn(n).notes,t=e.map(a=>Se(a).chroma);return a=>{const i=Se(typeof a=="number"?jf(a):a),o=i.height;if(o===void 0)return;const s=o%12,r=t.indexOf(s);if(r!==-1)return Lf(i.name,e[r])}}function Jx(n){const e=Kx(n);return(t,a)=>{const i=Se(t).height,o=Se(a).height;return i===void 0||o===void 0?[]:Xh(i,o).map(e).filter(s=>s)}}function Zx(n){const{intervals:e,tonic:t}=jn(n),a=yl(e,t);return i=>i?a(i>0?i-1:i):""}function Yx(n){const{intervals:e,tonic:t}=jn(n);return yl(e,t)}var Tu={degrees:Zx,detect:Vx,extended:Uf,get:jn,modeNames:Ux,names:Gx,rangeOf:Jx,reduced:Wx,scaleChords:Hx,scaleNotes:Kf,steps:Yx,tokenize:Wf,scale:$x};const B=De({enabled:!1,initiated:!1,playing:!1,stopped:!1,out:!0,inputs:{},outputs:{},forwards:{},channels:{},channel:ue("global-midi-channel",1),note:{pitch:0,channel:1,velocity:0},offset:yt(0,-3,3),keyboard:!0,cc:{},ccLearn:{},message:null,log:[],clock:0,filter:ue("global-midi-filter",{}),available:H(()=>Object.entries(B.outputs).length>0),activeNotes:H(()=>{let n={};for(let e in B.channels)for(let t in B.channels[e].activeNotes)n[t]=B.channels[e].activeNotes[t];return n}),guessChords:H(()=>{const n=Object.keys(B.activeNotes).map(e=>dx.midiToNoteName(Number(e),{sharps:!0}));return n.length>2?tx.detect(n):[]}),activeChroma:H(()=>{let n=new Array(12).fill(0);for(let e in B.activeNotes){const t=(Number(e)-9)%12;n[t]=B.activeNotes[e]}return n.join("")}),activeChromaMidi:H(()=>{let n=new Array(12).fill(0);for(let e in B.activeNotes){const t=(Number(e)-9)%12;n[t]=e}return n}),stopAll:tg,attack:Xf,release:hd,once:Qf,setCC:eg});function Jf({number:n,channel:e}){const t=ee(0);return de(()=>B.cc,a=>{e&&a.channel!=e||n==a.number&&(t.value=a.value)}),t}function _r(n="A",e=0,t=!1,a=1,i){let o=n+(4+e+B.offset);const s=new qa(o,{attack:t?0:a,release:t?0:a,duration:i}),r={type:t?"noteoff":"noteon",note:s,port:{id:"PC Keyboard"},timestamp:B.time,target:{number:0},channel:0,message:{}};Mc(r)}function cd(){return B.initiated||(bn(()=>{wk(),Xx()}),dn(()=>{if(!B.out)return;let n=Object.values(R.outputs);B.playing?n.forEach(e=>{e.sendContinue()}):n.forEach(e=>{e.sendStop()})}),B.stopped=!1,B.initiated=!0),{midi:B,midiAttack:Xf,midiRelease:hd,midiOnce:Qf,setCC:eg,midiPlay:As,midiStop:Sl,playKey:_r,stopAll:tg}}function Xx(){R.enable(),R.supported&&(R.addListener("enabled",()=>{B.enabled=!0,xu()}),R.addListener("connected",n=>{xu()}),R.addListener("disconnected",n=>{delete B[n.port.type+"s"][n.port.id]}),B.initiated=!0)}function xu(){B.inputs=zo({}),B.enabled=!0,R.inputs.forEach(n=>{B.inputs[n.id]={name:n.name,manufacturer:n.manufacturer,forwarder:n.addForwarder(),clock:0,event:null,note:null,cc:null},n.removeListener(),n.addListener("start",()=>{B.playing=!0,B.stopped=!1}),n.addListener("stop",()=>{B.playing=!1,B.stopped=Date.now()});const e=[],t=xk({value:15});n.addListener("clock",a=>{const i=a.timestamp-B.inputs[n.id].clock;e.push(i),e.length>50&&e.shift(),t.value=e.reduce((o,s)=>o+s,0)/e.length,B.inputs[n.id].diff=t.value,B.inputs[n.id].bpm=1e3/t.value/24*60,B.inputs[n.id].clock=a.timestamp}),n.addListener("midimessage",a=>{var i;((i=a==null?void 0:a.message)===null||i===void 0?void 0:i.type)!="clock"&&(B.inputs[n.id].event=a,B.message=a.message,B.log.unshift(a),B.log.length>100&&B.log.pop())}),n.addListener("noteon",a=>{B.inputs[n.id].note=Mc(a)}),n.addListener("noteoff",a=>{B.inputs[n.id].note=Mc(a)}),n.addListener("controlchange",a=>{const i=Qx(a);i&&(B.inputs[n.id].cc=i,B.cc=i)}),n.addListener("clock",a=>{B.clock=a.timestamp})}),B.outputs=zo({}),R.outputs.forEach(n=>{B.outputs[n.id]={name:n.name,manufacturer:n.manufacturer}})}function Mc(n){const e={...n.note,port:n.port.id,type:n.type,timestamp:n.timestamp,channel:n.target.number,velocity:0,number:n.note.number,pitch:(n.note.number+3)%12,octA:Math.floor((n.note.number+3)/12)-1};if(!B.filter[e.channel])return Zf(e.channel),B.channels[e.channel].notes[e.number]=e,n.type=="noteoff"?(e.velocity=0,delete B.channels[e.channel].activeNotes[e.number]):(e.velocity=120*(n.note.attack||1),B.channels[e.channel].activeNotes[e.number]=n.note.attack),B.note=e,e}function Qx(n){if(B.filter[n.message.channel])return;let e={channel:n.message.channel,timestamp:n.timestamp,number:n.controller.number,value:Number(n.value),raw:n.rawValue,port:n.port.id};return Zf(e.channel),B.channels[e.channel].cc[e.number]=e,e}function Zf(n){B.channels[n]||(B.channels[n]=De({num:n,activeNotes:{},notes:{},cc:{}}))}function Yf(n,e,t){var a,i,o;!((o=(i=(a=B.channels)===null||a===void 0?void 0:a[n])===null||i===void 0?void 0:i.notes)===null||o===void 0)&&o[e]&&(B.channels[n].notes[e].velocity=t)}function Xf(n,e){if(!B.out)return;let t=(n==null?void 0:n.channel)||B.channel;Yf(t,n==null?void 0:n.number,100),R.outputs.forEach(a=>{a.playNote(n.number,{channels:t,...e})})}function As(n,e){B.out&&R.outputs.forEach(t=>{t.playNote(n,{channels:B.channel,...e})})}function Sl(n,e){B.out&&(n?R.outputs.forEach(t=>{t.stopNote(n,{channels:B.channel,...e})}):(R.outputs.forEach(t=>{t.sendAllNotesOff(),t.sendAllSoundOff({time:"+1"})}),B.stopped=!0))}function hd(n){if(B.out)if(n){let e=(n==null?void 0:n.channel)||B.channel;Yf(e,n==null?void 0:n.number,0),R.outputs.forEach(t=>{t.stopNote(n.number,{channels:e})})}else R.outputs.forEach(e=>{e.sendAllNotesOff(),e.sendAllSoundOff({time:"+1"})})}function Qf(n,e){!B.out||B.filter[B.channel]||(As(n,e),setTimeout(()=>{Sl(n,e)},300))}function eg(n,e){B.out&&R.outputs.forEach(t=>{t.sendControlChange(Number(n.number),e,n.channel)})}function tg(){B.out&&(B.channels={},B.playing=!1,R.outputs.forEach(n=>{n.sendAllNotesOff(),n.sendAllSoundOff(),n.sendReset(),n.sendSongPosition(0)}),B.stopped=!0)}function dR(n,e){console.log(n,e);var t,a;const i=R.outputs.find(r=>r.id==e),o=B.inputs[n].forwarder.destinations,s=o.indexOf(i);s==-1?(o.push(i),B.forwards[n]=B.forwards[n]||{},B.forwards[n][e]=!0):(o.splice(s,1),(a=(t=B.forwards)===null||t===void 0?void 0:t[n])===null||a===void 0||delete a[e])}function uR(n,e=!1){return n?Object.values(n).sort((a,i)=>{let o=a.number>i.number?-1:1;return e&&(o*=-1),o}):[]}const Wt=ue("cast-camera","default"),Kn=ue("cast-mic","default");ee();const Ys=ee(""),ha=ee(!0),Ha=ue("slidev-record-mimetype","video/webm"),dd={"video/webm":"webm","video/webm;codecs=h264":"mp4","video/x-matroska;codecs=avc1":"mkv"};function Zo(n,e){const t=new Date,a=s=>`${s}`.padStart(2,"0"),i=`${a(t.getMonth()+1)}${a(t.getDate())}-${a(t.getHours())}${a(t.getMinutes())}`,o=e?dd[e]:"webm";return`${[i,n,Ys.value].filter(s=>!!s).join("-")}.${o}`}function e2(){return MediaRecorder&&typeof(MediaRecorder==null?void 0:MediaRecorder.isTypeSupported)=="function"?Object.keys(dd).filter(n=>MediaRecorder.isTypeSupported(n)):[]}const Su=De({screen:H(()=>Zo("screen",Ha.value)),camera:H(()=>Zo("camera",Ha.value))}),{devices:mR,videoInputs:Ic,audioInputs:Ec,ensurePermissions:Dc}=Zy({onUpdated:function(){var n,e;Wt.value!=="none"&&(Ic.value.find(t=>t.deviceId===Wt.value)||(Wt.value=((n=Ic.value[0])==null?void 0:n.deviceId)||"default")),Kn.value!=="none"&&(Ec.value.find(t=>t.deviceId===Kn.value)||(Kn.value=((e=Ec.value[0])==null?void 0:e.deviceId)||"default"))}});function Au(n,e){const t=document.createElement("a");t.setAttribute("href",e),t.setAttribute("download",n),document.body.appendChild(t),t.click(),document.body.removeChild(t)}function t2(){const n=ee(!1),e=ee(),t=Lm();de(n,b=>b?e.value=Date.now():e.value=null);const a=H(()=>e.value?t.value-e.value:0),i=ee(!1),o=Ti(),s=Ti(),r=Ti(),l=Ti(),c=Ti(),h={type:"video",bitsPerSecond:4*256*8*1024,timeSlice:24*60*60*1e3};async function d(){Wt.value!=="none"&&(i.value?(i.value=!1,n.value||g(r)):(await u(),r.value&&(i.value=!!r.value)))}async function u(){if(await Dc(),await rn(),!r.value){if(Wt.value==="none"&&Kn.value==="none")return;r.value=await navigator.mediaDevices.getUserMedia({video:Wt.value==="none"||ha.value!==!0?!1:{deviceId:Wt.value},audio:Kn.value==="none"?!1:{deviceId:Kn.value}})}}de(Wt,async b=>{if(b==="none")g(r);else{if(n.value)return;r.value&&(g(r),await u())}});async function m(b){var S;await Dc();const{default:x}=await Ua(async()=>{const{default:k}=await import("./RecordRTC.BjbTD4yn.js").then(w=>w.R);return{default:k}},[]);await u(),l.value=await navigator.mediaDevices.getDisplayMedia({video:{frameRate:30,width:3840,height:2160}}),l.value.addEventListener("inactive",p),c.value=new MediaStream,l.value.getVideoTracks().forEach(k=>c.value.addTrack(k)),Object.assign(h,b),r.value&&(c.value.addTrack((S=Qe.stream.stream.getAudioTracks())==null?void 0:S[0]),o.value=new x(r.value,h),o.value.startRecording()),s.value=new x(c.value,h),s.value.startRecording(),n.value=!0}async function p(){var b,x;n.value=!1,(b=o.value)==null||b.stopRecording(()=>{if(ha.value){const S=o.value.getBlob(),k=URL.createObjectURL(S);Au(Zo("camera",Ha.value),k),window.URL.revokeObjectURL(k)}o.value=void 0,i.value||g(r)}),(x=s.value)==null||x.stopRecording(()=>{const S=s.value.getBlob(),k=URL.createObjectURL(S);Au(Zo("screen",Ha.value),k),window.URL.revokeObjectURL(k),g(l),g(c),s.value=void 0})}function g(b){const x=b.value;x&&(x.getTracks().forEach(S=>{S.stop(),x.removeTrack(S)}),b.value=void 0)}function y(){n.value?p():m()}return Gm("beforeunload",b=>{n.value&&(confirm("Recording is not saved yet, do you want to leave?")||(b.preventDefault(),b.returnValue=""))}),{recording:n,recordingTime:a,showAvatar:i,toggleRecording:y,startRecording:m,stopRecording:p,toggleAvatar:d,recorderCamera:o,recorderSlides:s,streamCamera:r,streamCapture:l,streamSlides:c}}const ng=t2();let Pi;const kr=ee(!1),ag=Yy(kr),n2=Lm(),a2=H(()=>n2.value-ag.value),i2={start(){Pi||Al(),Pi.start(),kr.value=!0},async stop(){kr.value=!1;const n=await Pi.stop(),e=URL.createObjectURL(n),t=document.createElement("a");t.download=Zo("rec"),t.href=e,t.click()}};function Al(){return Pi||(Pi=new Uo),{recorder:Pi,record:i2,recording:kr,toggled:ag,duration:a2}}const gi=De({initiated:!1,mute:ue("mute",!1),volume:yt(ue("main-vol",1),0,2),meter:0}),Qe=De({}),ig=zo({});function ud(){if(!gi.initiated){Ji(),Qe.context=xi(new AudioContext),Qe.destination=fk();const{recorder:n}=Al();Qe.stream=xi(Ue().createMediaStreamDestination()),Qe.meter=xi(new _s().toDestination()),Qe.meter.normalRange=!0,Qe.meter.connect(Qe.stream),Qe.meter.connect(n),qr(()=>{gi.meter=Qe.meter.getValue()}),Qe.limiter=xi(new gl(-18).connect(Qe.meter)),Qe.reverb=xi(new pl({decay:1,wet:.5}).connect(Qe.meter)),Qe.limiter.connect(Qe.reverb),dn(()=>{Qe.destination.mute=gi.mute}),dn(()=>{Qe.destination.volume.targetRampTo(ea(gi.volume),.1)}),gi.initiated=!0}return{audio:gi,master:Qe,channels:ig}}function ci(n=(Math.random()*1e3).toFixed(0),e){const{master:t}=ud(),a=new Aa().connect(t.limiter),{recorder:i}=Al();a.connect(i);const o=new gl(e).connect(a);return ig[n]={channel:o,volume:a}}function o2(){if(window.AudioContext=window.AudioContext||(window==null?void 0:window.webkitAudioContext),!window.AudioContext)return alert("AudioContext not supported");navigator.mediaDevices===void 0&&(navigator.mediaDevices={}),navigator.mediaDevices.getUserMedia===void 0&&(navigator.mediaDevices.getUserMedia=function(n){const e=navigator.webkitGetUserMedia||navigator.mozGetUserMedia;return e||alert("getUserMedia is not implemented in this browser"),new Promise(function(t,a){e.call(navigator,n,t,a)})})}const s2=["+0","@8n","@16n","@32n"],oe={state:De({midi:ue("synth-midi",!0),initiated:!1,mute:!1,quantize:Yc(s2,{initialValue:"+0"}),volume:yt(1,0,2)}),delayParams:De({feedback:.3,wet:.3}),params:De({maxPolyphony:50,oscillator:{type:ue("synth-osc","sawtooth8")},volume:-20,envelope:{attack:.01,decay:.1,sustain:.6,release:1},filterEnvelope:{attack:.001,decay:.7,sustain:.5,release:1,baseFrequency:60,octaves:5}}),poly:null,widener:null,delay:null,reverb:null,pan:null,compressor:null};function r2(){return oe.state.initiated||($m("Escape",()=>{Hl()}),de(()=>oe.state.volume,n=>oe.poly&&oe.poly.volume.rampTo(ea(n))),de(oe.params,n=>{oe.poly&&oe.poly.set(n)},{deep:!0,immediate:!0}),de(oe.delayParams,n=>{var e;(e=oe.delay)==null||e.set(n)}),de(()=>B.note,n=>{var e;(e=oe==null?void 0:oe.state)!=null&&e.midi&&(n.velocity>0?Tr(kc(n.number).toFrequency(),n.velocity/127):xr(kc(n.number).toFrequency()))}),de(()=>B.playing,n=>{n||Hl()})),{init:Cs,synth:oe,once:l2,attack:Tr,release:xr,releaseAll:Hl}}function Cs(){if(Ji(),oe!=null&&oe.poly)return;const{channel:n}=ci("synth");oe.widener=new Vh(.7).connect(n),oe.reverb=new pl(3).connect(oe.widener),oe.delay=new Lh({delayTime:"16n",feedback:.3,wet:.3,maxDelay:"1m"}).connect(oe.widener),oe.pan=new ml({frequency:"4n",depth:.4}).connect(oe.reverb).connect(oe.delay).connect(oe.widener),oe.compressor=new Ts().connect(oe.pan),oe.poly=new hl(Dh,oe.params).connect(oe.compressor),oe.pan.start()}function l2(n,e="16n",t){if(!oe.poly||oe.state.mute)return Cs();oe.poly.triggerAttackRelease(n||"A4",e,t)}function Tr(n,e){if(!oe.poly||oe.state.mute)return Cs();oe.poly.triggerAttack(n,oe.state.quantize.state,e)}function xr(n){if(!oe.poly||oe.state.mute)return Cs();oe.poly.triggerRelease(n,oe.state.quantize.state)}function Hl(){if(!oe.poly||oe.state.mute)return Cs();oe.poly.releaseAll()}function c2(n=0,e=3,t=440,a="equal"){let i=0;const o=[0,112,204,316,386,498,590,702,814,884,1017,1088];if(a=="equal"&&(i=Number(t*Math.pow(2,e-3+n/12))),a=="just"){let s=Number(Math.pow(Math.pow(2,.0008333333333333334),o[n]));i=Number(t*Math.pow(2,e-4)*s)}return i}function Yo(n=0,e=0,t=1,a=1){return e===void 0&&(e=Math.floor(n/12)+4),`hsla(${n%12*30},${t*100}%,${Math.abs(e+2)*8}%,${a})`}function h2(n){return Yo(og(n),3)}function og(n,e=440){return 12*(Math.log(Number(n)/e)/Math.log(2))}function d2(n,e,t){return n.split("")[(24+t-e)%12]=="1"}function u2(n=0,e=12,t=35,a=100){let i=(n-e/4)/(e/2)*Math.PI,o=t*Math.cos(i)+a/2,s=t*Math.sin(i)+a/2;return{x:o,y:s}}function Zn(n,e=1){return[...n.slice(e,n.length),...n.slice(0,e)]}const pR=["1P","2m","2M","3m","3M","4P","TT","5P","6m","6M","7m","7M"],sg=["A","A#","B","C","C#","D","D#","E","F","F#","G","G#"],m2=["G##","A#","A##","B#","C#","C##","D#","D##","E#","F#","F##","G#"],rg=["Bbb","Bb","Cb","Dbb","Db","Ebb","Eb","Fb","Gbb","Gb","Abb","Ab"],md=[];sg.forEach((n,e)=>{md[n]=e});m2.forEach((n,e)=>{md[n]=e});rg.forEach((n,e)=>{md[n]=e});const ua=sg,lg=[...ua].map((n,e)=>({name:n,pitch:e})),qe=De({tonic:yt(ue("global-tonic",0),0,11),note:H(()=>lg[qe.tonic]),chroma:ue("global-chroma","101011010101"),set:H(()=>Ko.get(qe.chroma)),full:H(()=>{let n=qe.note.name+"4 "+qe.set.name;return Tu.get(n)}),pcs:H(()=>Tu.scaleNotes(qe.full.notes)),isIn:H(()=>nT.isNoteIncludedIn(qe.pcs))});function cg(n="100010010000",e=qe.tonic){let t=Zn(n.split(""),-e),i=Zn(lg,-e).map(o=>pr(o.pitch+e+57,"midi").toNote()).filter((o,s)=>{if(t[s]=="1")return!0});return Ac.sortedNames(i)}function p2(n,e){let t=cg(n,e);t.forEach(a=>{As(a)}),Tr(t)}function zs(n,e){let t=cg(n,e);t.forEach(a=>{Sl(a)}),xr(t)}function fR(n){As(n),Tr(n)}function gR(n){Sl(n),xr(n)}var f2={grad:.9,turn:360,rad:360/(2*Math.PI)},Gn=function(n){return typeof n=="string"?n.length>0:typeof n=="number"},st=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=Math.pow(10,e)),Math.round(t*n)/t+0},Jt=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},hg=function(n){return(n=isFinite(n)?n%360:0)>0?n:n+360},Cu=function(n){return{r:Jt(n.r,0,255),g:Jt(n.g,0,255),b:Jt(n.b,0,255),a:Jt(n.a)}},Wl=function(n){return{r:st(n.r),g:st(n.g),b:st(n.b),a:st(n.a,3)}},g2=/^#([0-9a-f]{3,8})$/i,Rs=function(n){var e=n.toString(16);return e.length<2?"0"+e:e},dg=function(n){var e=n.r,t=n.g,a=n.b,i=n.a,o=Math.max(e,t,a),s=o-Math.min(e,t,a),r=s?o===e?(t-a)/s:o===t?2+(a-e)/s:4+(e-t)/s:0;return{h:60*(r<0?r+6:r),s:o?s/o*100:0,v:o/255*100,a:i}},ug=function(n){var e=n.h,t=n.s,a=n.v,i=n.a;e=e/360*6,t/=100,a/=100;var o=Math.floor(e),s=a*(1-t),r=a*(1-(e-o)*t),l=a*(1-(1-e+o)*t),c=o%6;return{r:255*[a,r,s,s,l,a][c],g:255*[l,a,a,r,s,s][c],b:255*[s,s,l,a,a,r][c],a:i}},Mu=function(n){return{h:hg(n.h),s:Jt(n.s,0,100),l:Jt(n.l,0,100),a:Jt(n.a)}},Iu=function(n){return{h:st(n.h),s:st(n.s),l:st(n.l),a:st(n.a,3)}},Eu=function(n){return ug((t=(e=n).s,{h:e.h,s:(t*=((a=e.l)<50?a:100-a)/100)>0?2*t/(a+t)*100:0,v:a+t,a:e.a}));var e,t,a},Co=function(n){return{h:(e=dg(n)).h,s:(i=(200-(t=e.s))*(a=e.v)/100)>0&&i<200?t*a/100/(i<=100?i:200-i)*100:0,l:i/2,a:e.a};var e,t,a,i},y2=/^hsla?\(\s*([+-]?\d*\.?\d+)(deg|rad|grad|turn)?\s*,\s*([+-]?\d*\.?\d+)%\s*,\s*([+-]?\d*\.?\d+)%\s*(?:,\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,b2=/^hsla?\(\s*([+-]?\d*\.?\d+)(deg|rad|grad|turn)?\s+([+-]?\d*\.?\d+)%\s+([+-]?\d*\.?\d+)%\s*(?:\/\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,v2=/^rgba?\(\s*([+-]?\d*\.?\d+)(%)?\s*,\s*([+-]?\d*\.?\d+)(%)?\s*,\s*([+-]?\d*\.?\d+)(%)?\s*(?:,\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,w2=/^rgba?\(\s*([+-]?\d*\.?\d+)(%)?\s+([+-]?\d*\.?\d+)(%)?\s+([+-]?\d*\.?\d+)(%)?\s*(?:\/\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,Pc={string:[[function(n){var e=g2.exec(n);return e?(n=e[1]).length<=4?{r:parseInt(n[0]+n[0],16),g:parseInt(n[1]+n[1],16),b:parseInt(n[2]+n[2],16),a:n.length===4?st(parseInt(n[3]+n[3],16)/255,2):1}:n.length===6||n.length===8?{r:parseInt(n.substr(0,2),16),g:parseInt(n.substr(2,2),16),b:parseInt(n.substr(4,2),16),a:n.length===8?st(parseInt(n.substr(6,2),16)/255,2):1}:null:null},"hex"],[function(n){var e=v2.exec(n)||w2.exec(n);return e?e[2]!==e[4]||e[4]!==e[6]?null:Cu({r:Number(e[1])/(e[2]?100/255:1),g:Number(e[3])/(e[4]?100/255:1),b:Number(e[5])/(e[6]?100/255:1),a:e[7]===void 0?1:Number(e[7])/(e[8]?100:1)}):null},"rgb"],[function(n){var e=y2.exec(n)||b2.exec(n);if(!e)return null;var t,a,i=Mu({h:(t=e[1],a=e[2],a===void 0&&(a="deg"),Number(t)*(f2[a]||1)),s:Number(e[3]),l:Number(e[4]),a:e[5]===void 0?1:Number(e[5])/(e[6]?100:1)});return Eu(i)},"hsl"]],object:[[function(n){var e=n.r,t=n.g,a=n.b,i=n.a,o=i===void 0?1:i;return Gn(e)&&Gn(t)&&Gn(a)?Cu({r:Number(e),g:Number(t),b:Number(a),a:Number(o)}):null},"rgb"],[function(n){var e=n.h,t=n.s,a=n.l,i=n.a,o=i===void 0?1:i;if(!Gn(e)||!Gn(t)||!Gn(a))return null;var s=Mu({h:Number(e),s:Number(t),l:Number(a),a:Number(o)});return Eu(s)},"hsl"],[function(n){var e=n.h,t=n.s,a=n.v,i=n.a,o=i===void 0?1:i;if(!Gn(e)||!Gn(t)||!Gn(a))return null;var s=function(r){return{h:hg(r.h),s:Jt(r.s,0,100),v:Jt(r.v,0,100),a:Jt(r.a)}}({h:Number(e),s:Number(t),v:Number(a),a:Number(o)});return ug(s)},"hsv"]]},Du=function(n,e){for(var t=0;t<e.length;t++){var a=e[t][0](n);if(a)return[a,e[t][1]]}return[null,void 0]},_2=function(n){return typeof n=="string"?Du(n.trim(),Pc.string):typeof n=="object"&&n!==null?Du(n,Pc.object):[null,void 0]},Ul=function(n,e){var t=Co(n);return{h:t.h,s:Jt(t.s+100*e,0,100),l:t.l,a:t.a}},Kl=function(n){return(299*n.r+587*n.g+114*n.b)/1e3/255},Pu=function(n,e){var t=Co(n);return{h:t.h,s:t.s,l:Jt(t.l+100*e,0,100),a:t.a}},Nc=function(){function n(e){this.parsed=_2(e)[0],this.rgba=this.parsed||{r:0,g:0,b:0,a:1}}return n.prototype.isValid=function(){return this.parsed!==null},n.prototype.brightness=function(){return st(Kl(this.rgba),2)},n.prototype.isDark=function(){return Kl(this.rgba)<.5},n.prototype.isLight=function(){return Kl(this.rgba)>=.5},n.prototype.toHex=function(){return e=Wl(this.rgba),t=e.r,a=e.g,i=e.b,s=(o=e.a)<1?Rs(st(255*o)):"","#"+Rs(t)+Rs(a)+Rs(i)+s;var e,t,a,i,o,s},n.prototype.toRgb=function(){return Wl(this.rgba)},n.prototype.toRgbString=function(){return e=Wl(this.rgba),t=e.r,a=e.g,i=e.b,(o=e.a)<1?"rgba("+t+", "+a+", "+i+", "+o+")":"rgb("+t+", "+a+", "+i+")";var e,t,a,i,o},n.prototype.toHsl=function(){return Iu(Co(this.rgba))},n.prototype.toHslString=function(){return e=Iu(Co(this.rgba)),t=e.h,a=e.s,i=e.l,(o=e.a)<1?"hsla("+t+", "+a+"%, "+i+"%, "+o+")":"hsl("+t+", "+a+"%, "+i+"%)";var e,t,a,i,o},n.prototype.toHsv=function(){return e=dg(this.rgba),{h:st(e.h),s:st(e.s),v:st(e.v),a:st(e.a,3)};var e},n.prototype.invert=function(){return Re({r:255-(e=this.rgba).r,g:255-e.g,b:255-e.b,a:e.a});var e},n.prototype.saturate=function(e){return e===void 0&&(e=.1),Re(Ul(this.rgba,e))},n.prototype.desaturate=function(e){return e===void 0&&(e=.1),Re(Ul(this.rgba,-e))},n.prototype.grayscale=function(){return Re(Ul(this.rgba,-1))},n.prototype.lighten=function(e){return e===void 0&&(e=.1),Re(Pu(this.rgba,e))},n.prototype.darken=function(e){return e===void 0&&(e=.1),Re(Pu(this.rgba,-e))},n.prototype.rotate=function(e){return e===void 0&&(e=15),this.hue(this.hue()+e)},n.prototype.alpha=function(e){return typeof e=="number"?Re({r:(t=this.rgba).r,g:t.g,b:t.b,a:e}):st(this.rgba.a,3);var t},n.prototype.hue=function(e){var t=Co(this.rgba);return typeof e=="number"?Re({h:e,s:t.s,l:t.l,a:t.a}):st(t.h)},n.prototype.isEqual=function(e){return this.toHex()===Re(e).toHex()},n}(),Re=function(n){return n instanceof Nc?n:new Nc(n)},Nu=[],k2=function(n){n.forEach(function(e){Nu.indexOf(e)<0&&(e(Nc,Pc),Nu.push(e))})},T2={grad:.9,turn:360,rad:360/(2*Math.PI)},Jl=function(n){return typeof n=="string"?n.length>0:typeof n=="number"},Mi=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=Math.pow(10,e)),Math.round(t*n)/t+0},Wn=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},Zl=function(n){var e=n/255;return e<.04045?e/12.92:Math.pow((e+.055)/1.055,2.4)},Yl=function(n){return 255*(n>.0031308?1.055*Math.pow(n,1/2.4)-.055:12.92*n)},pd=96.422,fd=100,gd=82.521,x2=function(n){var e,t,a={x:.9555766*(e=n).x+-.0230393*e.y+.0631636*e.z,y:-.0282895*e.x+1.0099416*e.y+.0210077*e.z,z:.0122982*e.x+-.020483*e.y+1.3299098*e.z};return t={r:Yl(.032404542*a.x-.015371385*a.y-.004985314*a.z),g:Yl(-.00969266*a.x+.018760108*a.y+41556e-8*a.z),b:Yl(556434e-9*a.x-.002040259*a.y+.010572252*a.z),a:n.a},{r:Wn(t.r,0,255),g:Wn(t.g,0,255),b:Wn(t.b,0,255),a:Wn(t.a)}},S2=function(n){var e=Zl(n.r),t=Zl(n.g),a=Zl(n.b);return function(i){return{x:Wn(i.x,0,pd),y:Wn(i.y,0,fd),z:Wn(i.z,0,gd),a:Wn(i.a)}}(function(i){return{x:1.0478112*i.x+.0228866*i.y+-.050127*i.z,y:.0295424*i.x+.9904844*i.y+-.0170491*i.z,z:-.0092345*i.x+.0150436*i.y+.7521316*i.z,a:i.a}}({x:100*(.4124564*e+.3575761*t+.1804375*a),y:100*(.2126729*e+.7151522*t+.072175*a),z:100*(.0193339*e+.119192*t+.9503041*a),a:n.a}))},Mo=216/24389,Ni=24389/27,mg=function(n){return{l:Wn(n.l,0,100),c:n.c,h:(e=n.h,(e=isFinite(e)?e%360:0)>0?e:e+360),a:n.a};var e},Bu=function(n){return{l:Mi(n.l,2),c:Mi(n.c,2),h:Mi(n.h,2),a:Mi(n.a,3)}},A2=function(n){var e=n.l,t=n.c,a=n.h,i=n.a,o=i===void 0?1:i;if(!Jl(e)||!Jl(t)||!Jl(a))return null;var s=mg({l:Number(e),c:Number(t),h:Number(a),a:Number(o)});return pg(s)},ju=function(n){var e=function(o){var s=S2(o),r=s.x/pd,l=s.y/fd,c=s.z/gd;return r=r>Mo?Math.cbrt(r):(Ni*r+16)/116,{l:116*(l=l>Mo?Math.cbrt(l):(Ni*l+16)/116)-16,a:500*(r-l),b:200*(l-(c=c>Mo?Math.cbrt(c):(Ni*c+16)/116)),alpha:s.a}}(n),t=Mi(e.a,3),a=Mi(e.b,3),i=Math.atan2(a,t)/Math.PI*180;return{l:e.l,c:Math.sqrt(t*t+a*a),h:i<0?i+360:i,a:e.alpha}},pg=function(n){return e={l:n.l,a:n.c*Math.cos(n.h*Math.PI/180),b:n.c*Math.sin(n.h*Math.PI/180),alpha:n.a},a=e.a/500+(t=(e.l+16)/116),i=t-e.b/200,x2({x:(Math.pow(a,3)>Mo?Math.pow(a,3):(116*a-16)/Ni)*pd,y:(e.l>8?Math.pow((e.l+16)/116,3):e.l/Ni)*fd,z:(Math.pow(i,3)>Mo?Math.pow(i,3):(116*i-16)/Ni)*gd,a:e.alpha});var e,t,a,i},C2=/^lch\(\s*([+-]?\d*\.?\d+)%\s+([+-]?\d*\.?\d+)\s+([+-]?\d*\.?\d+)(deg|rad|grad|turn)?\s*(?:\/\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,M2=function(n){var e=C2.exec(n);if(!e)return null;var t,a,i=mg({l:Number(e[1]),c:Number(e[2]),h:(t=e[3],a=e[4],a===void 0&&(a="deg"),Number(t)*(T2[a]||1)),a:e[5]===void 0?1:Number(e[5])/(e[6]?100:1)});return pg(i)};function I2(n,e){n.prototype.toLch=function(){return Bu(ju(this.rgba))},n.prototype.toLchString=function(){return t=Bu(ju(this.rgba)),a=t.l,i=t.c,o=t.h,(s=t.a)<1?"lch("+a+"% "+i+" "+o+" / "+s+")":"lch("+a+"% "+i+" "+o+")";var t,a,i,o,s},e.string.push([M2,"lch"]),e.object.push([A2,"lch"])}var Sn=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},Xl=function(n){var e=n/255;return e<.04045?e/12.92:Math.pow((e+.055)/1.055,2.4)},Ql=function(n){return 255*(n>.0031308?1.055*Math.pow(n,1/2.4)-.055:12.92*n)},yd=96.422,bd=100,vd=82.521,E2=function(n){var e,t,a={x:.9555766*(e=n).x+-.0230393*e.y+.0631636*e.z,y:-.0282895*e.x+1.0099416*e.y+.0210077*e.z,z:.0122982*e.x+-.020483*e.y+1.3299098*e.z};return t={r:Ql(.032404542*a.x-.015371385*a.y-.004985314*a.z),g:Ql(-.00969266*a.x+.018760108*a.y+41556e-8*a.z),b:Ql(556434e-9*a.x-.002040259*a.y+.010572252*a.z),a:n.a},{r:Sn(t.r,0,255),g:Sn(t.g,0,255),b:Sn(t.b,0,255),a:Sn(t.a)}},D2=function(n){var e=Xl(n.r),t=Xl(n.g),a=Xl(n.b);return function(i){return{x:Sn(i.x,0,yd),y:Sn(i.y,0,bd),z:Sn(i.z,0,vd),a:Sn(i.a)}}(function(i){return{x:1.0478112*i.x+.0228866*i.y+-.050127*i.z,y:.0295424*i.x+.9904844*i.y+-.0170491*i.z,z:-.0092345*i.x+.0150436*i.y+.7521316*i.z,a:i.a}}({x:100*(.4124564*e+.3575761*t+.1804375*a),y:100*(.2126729*e+.7151522*t+.072175*a),z:100*(.0193339*e+.119192*t+.9503041*a),a:n.a}))},Io=216/24389,Bi=24389/27,zu=function(n){var e=D2(n),t=e.x/yd,a=e.y/bd,i=e.z/vd;return t=t>Io?Math.cbrt(t):(Bi*t+16)/116,{l:116*(a=a>Io?Math.cbrt(a):(Bi*a+16)/116)-16,a:500*(t-a),b:200*(a-(i=i>Io?Math.cbrt(i):(Bi*i+16)/116)),alpha:e.a}},P2=function(n,e,t){var a,i=zu(n),o=zu(e);return function(s){var r=(s.l+16)/116,l=s.a/500+r,c=r-s.b/200;return E2({x:(Math.pow(l,3)>Io?Math.pow(l,3):(116*l-16)/Bi)*yd,y:(s.l>8?Math.pow((s.l+16)/116,3):s.l/Bi)*bd,z:(Math.pow(c,3)>Io?Math.pow(c,3):(116*c-16)/Bi)*vd,a:s.alpha})}({l:Sn((a={l:i.l*(1-t)+o.l*t,a:i.a*(1-t)+o.a*t,b:i.b*(1-t)+o.b*t,alpha:i.alpha*(1-t)+o.alpha*t}).l,0,400),a:a.a,b:a.b,alpha:Sn(a.alpha)})};function N2(n){function e(t,a,i){i===void 0&&(i=5);for(var o=[],s=1/(i-1),r=0;r<=i-1;r++)o.push(t.mix(a,s*r));return o}n.prototype.mix=function(t,a){a===void 0&&(a=.5);var i=t instanceof n?t:new n(t),o=P2(this.toRgb(),i.toRgb(),a);return new n(o)},n.prototype.tints=function(t){return e(this,"#fff",t)},n.prototype.shades=function(t){return e(this,"#000",t)},n.prototype.tones=function(t){return e(this,"#808080",t)}}function B2(n,e){var t={white:"#ffffff",bisque:"#ffe4c4",blue:"#0000ff",cadetblue:"#5f9ea0",chartreuse:"#7fff00",chocolate:"#d2691e",coral:"#ff7f50",antiquewhite:"#faebd7",aqua:"#00ffff",azure:"#f0ffff",whitesmoke:"#f5f5f5",papayawhip:"#ffefd5",plum:"#dda0dd",blanchedalmond:"#ffebcd",black:"#000000",gold:"#ffd700",goldenrod:"#daa520",gainsboro:"#dcdcdc",cornsilk:"#fff8dc",cornflowerblue:"#6495ed",burlywood:"#deb887",aquamarine:"#7fffd4",beige:"#f5f5dc",crimson:"#dc143c",cyan:"#00ffff",darkblue:"#00008b",darkcyan:"#008b8b",darkgoldenrod:"#b8860b",darkkhaki:"#bdb76b",darkgray:"#a9a9a9",darkgreen:"#006400",darkgrey:"#a9a9a9",peachpuff:"#ffdab9",darkmagenta:"#8b008b",darkred:"#8b0000",darkorchid:"#9932cc",darkorange:"#ff8c00",darkslateblue:"#483d8b",gray:"#808080",darkslategray:"#2f4f4f",darkslategrey:"#2f4f4f",deeppink:"#ff1493",deepskyblue:"#00bfff",wheat:"#f5deb3",firebrick:"#b22222",floralwhite:"#fffaf0",ghostwhite:"#f8f8ff",darkviolet:"#9400d3",magenta:"#ff00ff",green:"#008000",dodgerblue:"#1e90ff",grey:"#808080",honeydew:"#f0fff0",hotpink:"#ff69b4",blueviolet:"#8a2be2",forestgreen:"#228b22",lawngreen:"#7cfc00",indianred:"#cd5c5c",indigo:"#4b0082",fuchsia:"#ff00ff",brown:"#a52a2a",maroon:"#800000",mediumblue:"#0000cd",lightcoral:"#f08080",darkturquoise:"#00ced1",lightcyan:"#e0ffff",ivory:"#fffff0",lightyellow:"#ffffe0",lightsalmon:"#ffa07a",lightseagreen:"#20b2aa",linen:"#faf0e6",mediumaquamarine:"#66cdaa",lemonchiffon:"#fffacd",lime:"#00ff00",khaki:"#f0e68c",mediumseagreen:"#3cb371",limegreen:"#32cd32",mediumspringgreen:"#00fa9a",lightskyblue:"#87cefa",lightblue:"#add8e6",midnightblue:"#191970",lightpink:"#ffb6c1",mistyrose:"#ffe4e1",moccasin:"#ffe4b5",mintcream:"#f5fffa",lightslategray:"#778899",lightslategrey:"#778899",navajowhite:"#ffdead",navy:"#000080",mediumvioletred:"#c71585",powderblue:"#b0e0e6",palegoldenrod:"#eee8aa",oldlace:"#fdf5e6",paleturquoise:"#afeeee",mediumturquoise:"#48d1cc",mediumorchid:"#ba55d3",rebeccapurple:"#663399",lightsteelblue:"#b0c4de",mediumslateblue:"#7b68ee",thistle:"#d8bfd8",tan:"#d2b48c",orchid:"#da70d6",mediumpurple:"#9370db",purple:"#800080",pink:"#ffc0cb",skyblue:"#87ceeb",springgreen:"#00ff7f",palegreen:"#98fb98",red:"#ff0000",yellow:"#ffff00",slateblue:"#6a5acd",lavenderblush:"#fff0f5",peru:"#cd853f",palevioletred:"#db7093",violet:"#ee82ee",teal:"#008080",slategray:"#708090",slategrey:"#708090",aliceblue:"#f0f8ff",darkseagreen:"#8fbc8f",darkolivegreen:"#556b2f",greenyellow:"#adff2f",seagreen:"#2e8b57",seashell:"#fff5ee",tomato:"#ff6347",silver:"#c0c0c0",sienna:"#a0522d",lavender:"#e6e6fa",lightgreen:"#90ee90",orange:"#ffa500",orangered:"#ff4500",steelblue:"#4682b4",royalblue:"#4169e1",turquoise:"#40e0d0",yellowgreen:"#9acd32",salmon:"#fa8072",saddlebrown:"#8b4513",sandybrown:"#f4a460",rosybrown:"#bc8f8f",darksalmon:"#e9967a",lightgoldenrodyellow:"#fafad2",snow:"#fffafa",lightgrey:"#d3d3d3",lightgray:"#d3d3d3",dimgray:"#696969",dimgrey:"#696969",olivedrab:"#6b8e23",olive:"#808000"},a={};for(var i in t)a[t[i]]=i;var o={};n.prototype.toName=function(s){if(!(this.rgba.a||this.rgba.r||this.rgba.g||this.rgba.b))return"transparent";var r,l,c=a[this.toHex()];if(c)return c;if(s!=null&&s.closest){var h=this.toRgb(),d=1/0,u="black";if(!o.length)for(var m in t)o[m]=new n(t[m]).toRgb();for(var p in t){var g=(r=h,l=o[p],Math.pow(r.r-l.r,2)+Math.pow(r.g-l.g,2)+Math.pow(r.b-l.b,2));g<d&&(d=g,u=p)}return u}},e.string.push([function(s){var r=s.toLowerCase(),l=r==="transparent"?"#0000":t[r];return l?new n(l).toRgb():null},"name"])}var ec=function(n){return typeof n=="string"?n.length>0:typeof n=="number"},uo=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=Math.pow(10,e)),Math.round(t*n)/t+0},hn=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},tc=function(n){var e=n/255;return e<.04045?e/12.92:Math.pow((e+.055)/1.055,2.4)},nc=function(n){return 255*(n>.0031308?1.055*Math.pow(n,1/2.4)-.055:12.92*n)},wd=96.422,_d=100,kd=82.521,j2=function(n){var e,t,a={x:.9555766*(e=n).x+-.0230393*e.y+.0631636*e.z,y:-.0282895*e.x+1.0099416*e.y+.0210077*e.z,z:.0122982*e.x+-.020483*e.y+1.3299098*e.z};return t={r:nc(.032404542*a.x-.015371385*a.y-.004985314*a.z),g:nc(-.00969266*a.x+.018760108*a.y+41556e-8*a.z),b:nc(556434e-9*a.x-.002040259*a.y+.010572252*a.z),a:n.a},{r:hn(t.r,0,255),g:hn(t.g,0,255),b:hn(t.b,0,255),a:hn(t.a)}},z2=function(n){var e=tc(n.r),t=tc(n.g),a=tc(n.b);return function(i){return{x:hn(i.x,0,wd),y:hn(i.y,0,_d),z:hn(i.z,0,kd),a:hn(i.a)}}(function(i){return{x:1.0478112*i.x+.0228866*i.y+-.050127*i.z,y:.0295424*i.x+.9904844*i.y+-.0170491*i.z,z:-.0092345*i.x+.0150436*i.y+.7521316*i.z,a:i.a}}({x:100*(.4124564*e+.3575761*t+.1804375*a),y:100*(.2126729*e+.7151522*t+.072175*a),z:100*(.0193339*e+.119192*t+.9503041*a),a:n.a}))},Eo=216/24389,ji=24389/27,R2=function(n){var e=n.l,t=n.a,a=n.b,i=n.alpha,o=i===void 0?1:i;if(!ec(e)||!ec(t)||!ec(a))return null;var s=function(r){return{l:hn(r.l,0,400),a:r.a,b:r.b,alpha:hn(r.alpha)}}({l:Number(e),a:Number(t),b:Number(a),alpha:Number(o)});return O2(s)},O2=function(n){var e=(n.l+16)/116,t=n.a/500+e,a=e-n.b/200;return j2({x:(Math.pow(t,3)>Eo?Math.pow(t,3):(116*t-16)/ji)*wd,y:(n.l>8?Math.pow((n.l+16)/116,3):n.l/ji)*_d,z:(Math.pow(a,3)>Eo?Math.pow(a,3):(116*a-16)/ji)*kd,a:n.alpha})};function q2(n,e){n.prototype.toLab=function(){return a=z2(this.rgba),o=a.y/_d,s=a.z/kd,i=(i=a.x/wd)>Eo?Math.cbrt(i):(ji*i+16)/116,t={l:116*(o=o>Eo?Math.cbrt(o):(ji*o+16)/116)-16,a:500*(i-o),b:200*(o-(s=s>Eo?Math.cbrt(s):(ji*s+16)/116)),alpha:a.a},{l:uo(t.l,2),a:uo(t.a,2),b:uo(t.b,2),alpha:uo(t.alpha,3)};var t,a,i,o,s},n.prototype.delta=function(t){t===void 0&&(t="#FFF");var a=t instanceof n?t:new n(t),i=function(o,s){var r=o.l,l=o.a,c=o.b,h=s.l,d=s.a,u=s.b,m=180/Math.PI,p=Math.PI/180,g=Math.pow(Math.pow(l,2)+Math.pow(c,2),.5),y=Math.pow(Math.pow(d,2)+Math.pow(u,2),.5),b=(r+h)/2,x=Math.pow((g+y)/2,7),S=.5*(1-Math.pow(x/(x+Math.pow(25,7)),.5)),k=l*(1+S),w=d*(1+S),C=Math.pow(Math.pow(k,2)+Math.pow(c,2),.5),M=Math.pow(Math.pow(w,2)+Math.pow(u,2),.5),A=(C+M)/2,I=k===0&&c===0?0:Math.atan2(c,k)*m,D=w===0&&u===0?0:Math.atan2(u,w)*m;I<0&&(I+=360),D<0&&(D+=360);var P=D-I,E=Math.abs(D-I);E>180&&D<=I?P+=360:E>180&&D>I&&(P-=360);var O=I+D;E<=180?O/=2:O=(I+D<360?O+360:O-360)/2;var j=1-.17*Math.cos(p*(O-30))+.24*Math.cos(2*p*O)+.32*Math.cos(p*(3*O+6))-.2*Math.cos(p*(4*O-63)),W=h-r,L=M-C,z=2*Math.sin(p*P/2)*Math.pow(C*M,.5),Y=1+.015*Math.pow(b-50,2)/Math.pow(20+Math.pow(b-50,2),.5),V=1+.045*A,J=1+.015*A*j,ie=30*Math.exp(-1*Math.pow((O-275)/25,2)),ge=-2*Math.pow(x/(x+Math.pow(25,7)),.5)*Math.sin(2*p*ie);return Math.pow(Math.pow(W/1/Y,2)+Math.pow(L/1/V,2)+Math.pow(z/1/J,2)+ge*L*z/(1*V*1*J),.5)}(this.toLab(),a.toLab())/100;return hn(uo(i,3))},e.object.push([R2,"lab"])}var Os=function(n){return typeof n=="string"?n.length>0:typeof n=="number"},Ut=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=Math.pow(10,e)),Math.round(t*n)/t+0},mo=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},fg=function(n){return{c:mo(n.c,0,100),m:mo(n.m,0,100),y:mo(n.y,0,100),k:mo(n.k,0,100),a:mo(n.a)}},Ru=function(n){return{c:Ut(n.c,2),m:Ut(n.m,2),y:Ut(n.y,2),k:Ut(n.k,2),a:Ut(n.a,3)}};function gg(n){return{r:Ut(255*(1-n.c/100)*(1-n.k/100)),g:Ut(255*(1-n.m/100)*(1-n.k/100)),b:Ut(255*(1-n.y/100)*(1-n.k/100)),a:n.a}}function Ou(n){var e=1-Math.max(n.r/255,n.g/255,n.b/255),t=(1-n.r/255-e)/(1-e),a=(1-n.g/255-e)/(1-e),i=(1-n.b/255-e)/(1-e);return{c:isNaN(t)?0:Ut(100*t),m:isNaN(a)?0:Ut(100*a),y:isNaN(i)?0:Ut(100*i),k:Ut(100*e),a:n.a}}function F2(n){var e=n.c,t=n.m,a=n.y,i=n.k,o=n.a,s=o===void 0?1:o;return Os(e)&&Os(t)&&Os(a)&&Os(i)?gg(fg({c:Number(e),m:Number(t),y:Number(a),k:Number(i),a:Number(s)})):null}var L2=/^device-cmyk\(\s*([+-]?\d*\.?\d+)(%)?\s+([+-]?\d*\.?\d+)(%)?\s+([+-]?\d*\.?\d+)(%)?\s+([+-]?\d*\.?\d+)(%)?\s*(?:\/\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,G2=function(n){var e=L2.exec(n);return e?gg(fg({c:Number(e[1])*(e[2]?1:100),m:Number(e[3])*(e[4]?1:100),y:Number(e[5])*(e[6]?1:100),k:Number(e[7])*(e[8]?1:100),a:e[9]===void 0?1:Number(e[9])/(e[10]?100:1)})):null};function $2(n,e){n.prototype.toCmyk=function(){return Ru(Ou(this.rgba))},n.prototype.toCmykString=function(){return t=Ru(Ou(this.rgba)),a=t.c,i=t.m,o=t.y,s=t.k,(r=t.a)<1?"device-cmyk("+a+"% "+i+"% "+o+"% "+s+"% / "+r+")":"device-cmyk("+a+"% "+i+"% "+o+"% "+s+"%)";var t,a,i,o,s,r},e.object.push([F2,"cmyk"]),e.string.push([G2,"cmyk"])}var V2={grad:.9,turn:360,rad:360/(2*Math.PI)},ac=function(n){return typeof n=="string"?n.length>0:typeof n=="number"},qs=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=Math.pow(10,e)),Math.round(t*n)/t+0},ic=function(n,e,t){return e===void 0&&(e=0),t===void 0&&(t=1),n>t?t:n>e?n:e},yg=function(n){return{h:(e=n.h,(e=isFinite(e)?e%360:0)>0?e:e+360),w:ic(n.w,0,100),b:ic(n.b,0,100),a:ic(n.a)};var e},qu=function(n){return{h:qs(n.h),w:qs(n.w),b:qs(n.b),a:qs(n.a,3)}},Fu=function(n){return{h:function(e){var t=e.r,a=e.g,i=e.b,o=e.a,s=Math.max(t,a,i),r=s-Math.min(t,a,i),l=r?s===t?(a-i)/r:s===a?2+(i-t)/r:4+(t-a)/r:0;return{h:60*(l<0?l+6:l),s:s?r/s*100:0,v:s/255*100,a:o}}(n).h,w:Math.min(n.r,n.g,n.b)/255*100,b:100-Math.max(n.r,n.g,n.b)/255*100,a:n.a}},bg=function(n){return function(e){var t=e.h,a=e.s,i=e.v,o=e.a;t=t/360*6,a/=100,i/=100;var s=Math.floor(t),r=i*(1-a),l=i*(1-(t-s)*a),c=i*(1-(1-t+s)*a),h=s%6;return{r:255*[i,l,r,r,c,i][h],g:255*[c,i,i,l,r,r][h],b:255*[r,r,c,i,i,l][h],a:o}}({h:n.h,s:n.b===100?0:100-n.w/(100-n.b)*100,v:100-n.b,a:n.a})},H2=function(n){var e=n.h,t=n.w,a=n.b,i=n.a,o=i===void 0?1:i;if(!ac(e)||!ac(t)||!ac(a))return null;var s=yg({h:Number(e),w:Number(t),b:Number(a),a:Number(o)});return bg(s)},W2=/^hwb\(\s*([+-]?\d*\.?\d+)(deg|rad|grad|turn)?\s+([+-]?\d*\.?\d+)%\s+([+-]?\d*\.?\d+)%\s*(?:\/\s*([+-]?\d*\.?\d+)(%)?\s*)?\)$/i,U2=function(n){var e=W2.exec(n);if(!e)return null;var t,a,i=yg({h:(t=e[1],a=e[2],a===void 0&&(a="deg"),Number(t)*(V2[a]||1)),w:Number(e[3]),b:Number(e[4]),a:e[5]===void 0?1:Number(e[5])/(e[6]?100:1)});return bg(i)};function K2(n,e){n.prototype.toHwb=function(){return qu(Fu(this.rgba))},n.prototype.toHwbString=function(){return t=qu(Fu(this.rgba)),a=t.h,i=t.w,o=t.b,(s=t.a)<1?"hwb("+a+" "+i+"% "+o+"% / "+s+")":"hwb("+a+" "+i+"% "+o+"%)";var t,a,i,o,s},e.string.push([U2,"hwb"]),e.object.push([H2,"hwb"])}k2([N2,I2,B2,q2,$2,K2]);const La=Array(12).fill(!0).map((n,e)=>Re(Yo(e)).toHex()),Ye=De({default:[...La],custom:ue("custom-colors",[...La]),isDefault:H(()=>Ye.custom.every((n,e)=>n==La[e])),customize:!1,reset(){Ye.custom=[...La]}});function Ve(n=0,e=2,t=1,a=1){e+=Math.floor(n/12);const i=e-2;if(Ye.custom[n]!=Ye.default[n]){let o=Re(Ye.custom[n]);return o=o.lighten(i*.1),o.alpha(a).toHex()}else return Yo(n,e,t,a)}const J2="101101011010";function yR(n,e,t="hsla(0,0%,100%,0.3)",a="hsla(0,0%,10%,0.3)"){return e==1?Ve((n+(qe==null?void 0:qe.tonic))%12,3):J2[(n+(qe==null?void 0:qe.tonic))%12]=="1"?t:a}function vt(n=0,e=12,t=1,a=20,i=60){let o=`lch(${i}% ${a} ${n*(360/e)} / ${t})`;return Re(o).toHslString()}function bR(n){const e=Re(n);return{dark:e.isDark(),hex:e.toHex(),rgb:e.toRgbString(),name:e.toName({closest:!0}),cmyk:e.toCmykString(),hsl:e.toHslString(),lab:e.toLab()}}function vR(n=0,e=3,t=.5,a=.8,i=.5,o=!1){return o&&(n=e-n-1),`hsla(${n*(360/e)}, ${a*100}%, ${i*100}%, ${t})`}function wR(n,e,t=.3){let a=Re(Yo(e)),i=Re(vt(e,12,1));return n.split("").forEach((o,s)=>{d2(n,e,s)&&(a=a.mix(Yo(s),t),i=i.mix(vt(s,12,1),t))}),{hsl:a.toHslString(),lch:i.toHslString()}}const Z2=n=>(mt("data-v-6f588906"),n=n(),pt(),n),Y2=Z2(()=>v("defs",null,[v("filter",{id:"shadowButton",x:"-50%",height:"200%",width:"300%"},[v("feDropShadow",{dx:"0",dy:"3",stdDeviation:"4","flood-color":"#2225"})])],-1)),X2={class:"white"},Q2=["transform","onMousedown"],eS=["fill"],tS=["fill"],nS=["fill"],aS=["font-weight"],iS={class:"black"},oS=["transform","onMousedown"],sS=["fill","data-check"],rS=["fill","stroke"],lS=["fill","font-weight"],cS={y:"111",x:"45"},hS={y:"40",x:"45"},dS={class:"absolute right-4"},uS={class:"font-bold text-lg flex-1 text-center"},mS={__name:"ChromaKeys",props:{chroma:{type:String,default:"100000000000"},letters:{type:Boolean,default:!0},pitch:{type:Number,default:0},scale:{type:String},roman:{type:String,default:""},title:{type:Boolean,default:!0},playAll:{type:Boolean,default:!1}},emits:["update:pitch"],setup(n,{emit:e}){const t=n,a=De({white:[3,5,7,8,10,0,2],black:[4,6,null,9,11,1],chroma:H(()=>Zn(t.chroma.split(""),-t.pitch)),scale:H(()=>Zn(qe.chroma.split(""),-t.pitch)),title:H(()=>{var l,c;return(l=wu.get(t.chroma))!=null&&l.empty?(c=Ko.get(t.chroma))!=null&&c.empty?"":Ko.get(t.chroma).aliases[0]:wu.get(t.chroma).aliases[0]})}),{midi:i}=cd();function o(l){return l!=null&&a.chroma[l]=="1"}function s(l){return t.scale&&l!=null&&a.chroma[l]=="1"}function r(l,c){return l==null?"transparent":l==t.pitch?Re(Ve(l,4)).toHex():o(l)&&!c?Re(Ve(l,3.5)).toHex():ua[l].length!=2?"#eee":"#999"}return(l,c)=>(_(),T("div",{class:"flex flex-col m-1 rounded-lg cursor-pointer transition-all duration-300 ease relative select-none touch-none",onMousedown:c[0]||(c[0]=h=>n.playAll&&rn(f(p2)(n.chroma,n.pitch))),onTouchend:c[1]||(c[1]=h=>n.playAll&&rn(f(zs)(n.chroma,n.pitch))),onTouchcancel:c[2]||(c[2]=h=>n.playAll&&rn(f(zs)(n.chroma,n.pitch))),onMouseup:c[3]||(c[3]=h=>n.playAll&&rn(f(zs)(n.chroma,n.pitch))),onMouseleave:c[4]||(c[4]=h=>n.playAll&&rn(f(zs)(n.chroma,n.pitch))),style:se({backgroundColor:f(Ve)(n.pitch,2,1,.5)})},[(_(),T("svg",{class:ae(["w-full",{letters:n.letters}]),id:"chroma-keys",version:"1.1",baseProfile:"full",viewBox:"-10 -20 720 250",xmlns:"http://www.w3.org/2000/svg","font-family":"Commissioner, sans-serif","font-weight":"200","font-size":"40","text-anchor":"middle","dominant-baseline":"middle"},[Y2,v("g",X2,[(_(!0),T(ke,null,Me(a.white,(h,d)=>(_(),T("g",{class:"key",key:h,transform:`translate(${d*100+5} 30)`,onMousedown:u=>l.$emit("update:pitch",h)},[v("rect",{class:"transition-all duration-300 ease-out",width:"90",height:"190",rx:"45",fill:r(h,!0),style:{filter:"url(#shadowButton)"}},null,8,eS),v("circle",{class:"transition-all duration-300 ease-out",cy:"145",cx:"45",r:"45",fill:r(h)},null,8,tS),F(v("text",{class:"pointer-events-none",y:"152",x:"45",fill:f(Re)(f(Ve)(h)).isDark()?"white":"black"},[v("tspan",{"font-weight":h==n.pitch?800:200},K(f(ua)[h]),9,aS)],8,nS),[[bt,o(h)&&n.letters]]),v("circle",{class:"transition",style:se({opacity:f(i).activeChromaMidi[h]?1:0}),cy:"245",cx:"45",r:"18",fill:"#3339"},null,4)],40,Q2))),128))]),v("g",iS,[(_(!0),T(ke,null,Me(a.black,(h,d)=>(_(),T("g",{class:"key",key:h,transform:`translate(${d*100+55} -10)`,onMousedown:u=>l.$emit("update:pitch",h)},[h?(_(),T("rect",{key:0,class:"transition-all duration-300 ease-out",width:"90",height:"150",rx:"45",style:{filter:"url(#shadowButton)"},fill:r(h,!0),"data-check":h},null,8,sS)):U("",!0),h?(_(),T("circle",{key:1,class:"transition-all duration-300 ease-out",cy:"105",cx:"45",r:"45",fill:r(h),"stroke-width":"8",stroke:s(h)?f(Ve)(h,3):"transparent"},null,8,rS)):U("",!0),F(v("text",{class:"pointer-events-none",fill:f(Re)(f(Ve)(h)).isDark()?"white":"black","font-weight":h==n.pitch?800:200},[v("tspan",cS,K(f(ua)[h]),1),v("tspan",hS,K(f(rg)[h]),1)],8,lS),[[bt,o(h)&&n.letters]]),v("circle",{class:"transition-all duration-100",style:se({opacity:f(i).activeChromaMidi[h]?1:0}),cy:"175",cx:"45",r:"18",fill:"#3339"},null,4)],40,oS))),128))])],2)),En(l.$slots,"default",{},()=>[n.title?(_(),T("div",{key:0,class:"flex justify-center my-2 px-2",style:se({color:f(Re)(f(Ve)(n.pitch,2,1,1)).isDark()?"white":"black"})},[v("div",dS,K(n.roman),1),v("div",uS,K(f(ua)[n.pitch])+K(a.title),1)],4)):U("",!0)],!0)],36))}},pS=Fe(mS,[["__scopeId","data-v-6f588906"]]),fS=["label"],gS=["value"],yS={__name:"ControlScale",setup(n){H(()=>Ko.all().sort((t,a)=>t.intervals.length>a.intervals.length?1:t.intervals.length<a.intervals.length?-1:t.name>a.name?1:-1));const e=H(()=>{let t={};Ko.all().forEach(a=>{let i=a.intervals.length;t[i]=t[i]||[],t[i].push(a)});for(let a in t)t[a].sort((i,o)=>i.intervals.length>o.intervals.length?1:i.intervals.length<o.intervals.length?-1:i.name>o.name?1:-1);return t});return(t,a)=>{const i=pS;return _(),At(i,{class:"w-300px",pitch:f(qe).tonic,"onUpdate:pitch":a[1]||(a[1]=o=>f(qe).tonic=o),chroma:f(qe).set.chroma,title:!1},{default:Ge(()=>[F(v("select",{class:"m-2 rounded-xl font-bold","onUpdate:modelValue":a[0]||(a[0]=o=>f(qe).chroma=o)},[(_(!0),T(ke,null,Me(e.value,(o,s)=>(_(),T("optgroup",{label:s+" notes",key:o},[(_(!0),T(ke,null,Me(o,r=>(_(),T("option",{key:r.chroma,value:r.chroma},K(f(ua)[f(qe).tonic])+" "+K(r.name),9,gS))),128))],8,fS))),128))],512),[[xo,f(qe).chroma]]),En(t.$slots,"default",{},void 0,!0)]),_:3},8,["pitch","chroma"])}}},bS=Fe(yS,[["__scopeId","data-v-17cbe54c"]]),X=De({initialized:!1,bpm:yt(ue("tempo-bpm",100),10,500),clock:null,midiClock:!1,tabSync:ue("tab-sync",!1),blink:!1,started:!1,playing:!1,stopped:!1,mute:ue("tempo-mute",!0),volume:yt(ue("tempo-volume",.5),0,1),progress:0,position:null,ticks:0,metre:{over:4,under:4,num:H(()=>(X.metre.over/(X.metre.under/4)).toFixed(2))},hz:H(()=>(X.bpm/60).toFixed(2)),note:H(()=>Ac.pitchClass(pr(X.hz).toNote())),tune:H(()=>Ac.pitchClass(X.note)+4),pitch:H(()=>og(Number(X.hz))),digit:H(()=>(pr(X.hz).toMidi()+12*10+3)%12),color:H(()=>Ve(X.digit)),tap:{last:0,diff:0,timeout:2e3,times:[],bpm:null,tap:Xs},set(n){X.bpm=Math.round(n+X.bpm)}});function vg(){if(X.initialized)return X;const n=zo({counter:0,pluck:null,channel:null,clock:null,loop:null});bn(()=>{const a=Uh(),{channel:i}=ci("tempo-tick");n.channel=i,n.pluck=new ri({urls:{E1:"logic/high.wav",E2:"logic/low.wav"},volume:-20,attack:.001,release:2,baseUrl:"/audio/metronome/"}).connect(i),n.clock=new Gi(o=>{X.midiClock&&a.schedule(()=>{R.outputs.forEach(s=>s.sendClock())},o)},"8i").start(0),n.loop=new Gi(o=>{let s=n.counter%2==0;s?a.schedule(()=>{X.blink=!1},o):a.schedule(()=>{X.blink=!0},o),X.mute||n.pluck.triggerAttackRelease(s?"E1":"E2","16n",o,s?1:.2),n.counter++},"8n").start(0),qr(()=>{X.position=pi().position,X.ticks=pi().ticks,X.progress=n.loop.progress}),Ro(" ",o=>{const s=o.target;["TEXTAREA","INPUT"].includes(s.nodeName)||(o.preventDefault(),X.playing=!X.playing)}),Ro("Enter",o=>{const s=o.target;["TEXTAREA","INPUT"].includes(s.nodeName)||(o.preventDefault(),X.stopped=Date.now())})}),De({playing:!1,stopped:!1});const{data:e,post:t}=Xy({name:"chromatone-tempo"});return de(e,a=>{X.tabSync&&(X.playing=!!(a!=null&&a.playing),X.stopped=!!(a!=null&&a.stopped))}),de(()=>X.volume,a=>n.pluck.volume.rampTo(ea(a))),de(()=>X.bpm,a=>pi().bpm.rampTo(a,"4n"),{immediate:!0}),de(()=>X.stopped,a=>{a&&(pi().stop(),B.stopAll(),X.playing=!1,X.tabSync&&t({stopped:a}))}),de(()=>X.playing,a=>{a?(X.started||(Ji(),X.started=!0),X.stopped=!1,pi().start(),B.playing=!0,X.tabSync&&t({playing:!0})):(B.playing=!1,pi().pause(),X.tabSync&&t({playing:!1}))},{immediate:!0}),de(()=>B.playing,a=>X.playing=a),de(()=>B.stopped,a=>X.stopped=a),X.initialized=!0,X}function Xs(){var n=performance.now();X.tap.last&&(X.tap.diff=n-X.tap.last,X.tap.times.push(X.tap.diff),vS()),X.tap.last=n,wS()}function vS(){if(X.tap.times.length>2){var n=X.tap.times.reduce((t,a)=>t+=a)/X.tap.times.length,e=1/(n/1e3)*60;X.tap.bpm=e}}let Lu=null;function wS(){clearTimeout(Lu),Lu=setTimeout(function(){X.tap.times=[X.tap.diff],X.tap.last=null},X.tap.timeout)}var wg={},Cl={};function _S(n){var e=new Dt(n),t=e.readChunk();if(t.id!="MThd")throw"Bad MIDI file.  Expected 'MHdr', got: '"+t.id+"'";for(var a=kS(t.data),i=[],o=0;!e.eof()&&o<a.numTracks;o++){var s=e.readChunk();if(s.id!="MTrk")throw"Bad MIDI file.  Expected 'MTrk', got: '"+s.id+"'";var r=TS(s.data);i.push(r)}return{header:a,tracks:i}}function kS(n){var e=new Dt(n),t=e.readUInt16(),a=e.readUInt16(),i={format:t,numTracks:a},o=e.readUInt16();return o&32768?(i.framesPerSecond=256-(o>>8),i.ticksPerFrame=o&255):i.ticksPerBeat=o,i}function TS(n){for(var e=new Dt(n),t=[];!e.eof();){var a=o();t.push(a)}return t;var i;function o(){var s={};s.deltaTime=e.readVarInt();var r=e.readUInt8();if((r&240)===240)if(r===255){s.meta=!0;var l=e.readUInt8(),c=e.readVarInt();switch(l){case 0:if(s.type="sequenceNumber",c!==2)throw"Expected length for sequenceNumber event is 2, got "+c;return s.number=e.readUInt16(),s;case 1:return s.type="text",s.text=e.readString(c),s;case 2:return s.type="copyrightNotice",s.text=e.readString(c),s;case 3:return s.type="trackName",s.text=e.readString(c),s;case 4:return s.type="instrumentName",s.text=e.readString(c),s;case 5:return s.type="lyrics",s.text=e.readString(c),s;case 6:return s.type="marker",s.text=e.readString(c),s;case 7:return s.type="cuePoint",s.text=e.readString(c),s;case 32:if(s.type="channelPrefix",c!=1)throw"Expected length for channelPrefix event is 1, got "+c;return s.channel=e.readUInt8(),s;case 33:if(s.type="portPrefix",c!=1)throw"Expected length for portPrefix event is 1, got "+c;return s.port=e.readUInt8(),s;case 47:if(s.type="endOfTrack",c!=0)throw"Expected length for endOfTrack event is 0, got "+c;return s;case 81:if(s.type="setTempo",c!=3)throw"Expected length for setTempo event is 3, got "+c;return s.microsecondsPerBeat=e.readUInt24(),s;case 84:if(s.type="smpteOffset",c!=5)throw"Expected length for smpteOffset event is 5, got "+c;var h=e.readUInt8(),d={0:24,32:25,64:29,96:30};return s.frameRate=d[h&96],s.hour=h&31,s.min=e.readUInt8(),s.sec=e.readUInt8(),s.frame=e.readUInt8(),s.subFrame=e.readUInt8(),s;case 88:if(s.type="timeSignature",c!=2&&c!=4)throw"Expected length for timeSignature event is 4 or 2, got "+c;return s.numerator=e.readUInt8(),s.denominator=1<<e.readUInt8(),c===4?(s.metronome=e.readUInt8(),s.thirtyseconds=e.readUInt8()):(s.metronome=36,s.thirtyseconds=8),s;case 89:if(s.type="keySignature",c!=2)throw"Expected length for keySignature event is 2, got "+c;return s.key=e.readInt8(),s.scale=e.readUInt8(),s;case 127:return s.type="sequencerSpecific",s.data=e.readBytes(c),s;default:return s.type="unknownMeta",s.data=e.readBytes(c),s.metatypeByte=l,s}}else if(r==240){s.type="sysEx";var c=e.readVarInt();return s.data=e.readBytes(c),s}else if(r==247){s.type="endSysEx";var c=e.readVarInt();return s.data=e.readBytes(c),s}else throw"Unrecognised MIDI event type byte: "+r;else{var u;if(r&128)u=e.readUInt8(),i=r;else{if(i===null)throw"Running status byte encountered before status byte";u=r,r=i,s.running=!0}var m=r>>4;switch(s.channel=r&15,m){case 8:return s.type="noteOff",s.noteNumber=u,s.velocity=e.readUInt8(),s;case 9:var p=e.readUInt8();return s.type=p===0?"noteOff":"noteOn",s.noteNumber=u,s.velocity=p,p===0&&(s.byte9=!0),s;case 10:return s.type="noteAftertouch",s.noteNumber=u,s.amount=e.readUInt8(),s;case 11:return s.type="controller",s.controllerType=u,s.value=e.readUInt8(),s;case 12:return s.type="programChange",s.programNumber=u,s;case 13:return s.type="channelAftertouch",s.amount=u,s;case 14:return s.type="pitchBend",s.value=u+(e.readUInt8()<<7)-8192,s;default:throw"Unrecognised MIDI event type: "+m}}}}function Dt(n){this.buffer=n,this.bufferLen=this.buffer.length,this.pos=0}Dt.prototype.eof=function(){return this.pos>=this.bufferLen};Dt.prototype.readUInt8=function(){var n=this.buffer[this.pos];return this.pos+=1,n};Dt.prototype.readInt8=function(){var n=this.readUInt8();return n&128?n-256:n};Dt.prototype.readUInt16=function(){var n=this.readUInt8(),e=this.readUInt8();return(n<<8)+e};Dt.prototype.readInt16=function(){var n=this.readUInt16();return n&32768?n-65536:n};Dt.prototype.readUInt24=function(){var n=this.readUInt8(),e=this.readUInt8(),t=this.readUInt8();return(n<<16)+(e<<8)+t};Dt.prototype.readInt24=function(){var n=this.readUInt24();return n&8388608?n-16777216:n};Dt.prototype.readUInt32=function(){var n=this.readUInt8(),e=this.readUInt8(),t=this.readUInt8(),a=this.readUInt8();return(n<<24)+(e<<16)+(t<<8)+a};Dt.prototype.readBytes=function(n){var e=this.buffer.slice(this.pos,this.pos+n);return this.pos+=n,e};Dt.prototype.readString=function(n){var e=this.readBytes(n);return String.fromCharCode.apply(null,e)};Dt.prototype.readVarInt=function(){for(var n=0;!this.eof();){var e=this.readUInt8();if(e&128)n+=e&127,n<<=7;else return n+e}return n};Dt.prototype.readChunk=function(){var n=this.readString(4),e=this.readUInt32(),t=this.readBytes(e);return{id:n,length:e,data:t}};var xS=_S;function SS(n,e){if(typeof n!="object")throw"Invalid MIDI data";e=e||{};var t=n.header||{},a=n.tracks||[],i,o=a.length,s=new it;for(AS(s,t,o),i=0;i<o;i++)CS(s,a[i],e);return s.buffer}function AS(n,e,t){var a=e.format==null?1:e.format,i=128;e.timeDivision?i=e.timeDivision:e.ticksPerFrame&&e.framesPerSecond?i=-(e.framesPerSecond&255)<<8|e.ticksPerFrame&255:e.ticksPerBeat&&(i=e.ticksPerBeat&32767);var o=new it;o.writeUInt16(a),o.writeUInt16(t),o.writeUInt16(i),n.writeChunk("MThd",o.buffer)}function CS(n,e,t){var a=new it,i,o=e.length,s=null;for(i=0;i<o;i++)(t.running===!1||!t.running&&!e[i].running)&&(s=null),s=MS(a,e[i],s,t.useByte9ForNoteOff);n.writeChunk("MTrk",a.buffer)}function MS(n,e,t,a){var i=e.type,o=e.deltaTime,s=e.text||"",r=e.data||[],l=null;switch(n.writeVarInt(o),i){case"sequenceNumber":n.writeUInt8(255),n.writeUInt8(0),n.writeVarInt(2),n.writeUInt16(e.number);break;case"text":n.writeUInt8(255),n.writeUInt8(1),n.writeVarInt(s.length),n.writeString(s);break;case"copyrightNotice":n.writeUInt8(255),n.writeUInt8(2),n.writeVarInt(s.length),n.writeString(s);break;case"trackName":n.writeUInt8(255),n.writeUInt8(3),n.writeVarInt(s.length),n.writeString(s);break;case"instrumentName":n.writeUInt8(255),n.writeUInt8(4),n.writeVarInt(s.length),n.writeString(s);break;case"lyrics":n.writeUInt8(255),n.writeUInt8(5),n.writeVarInt(s.length),n.writeString(s);break;case"marker":n.writeUInt8(255),n.writeUInt8(6),n.writeVarInt(s.length),n.writeString(s);break;case"cuePoint":n.writeUInt8(255),n.writeUInt8(7),n.writeVarInt(s.length),n.writeString(s);break;case"channelPrefix":n.writeUInt8(255),n.writeUInt8(32),n.writeVarInt(1),n.writeUInt8(e.channel);break;case"portPrefix":n.writeUInt8(255),n.writeUInt8(33),n.writeVarInt(1),n.writeUInt8(e.port);break;case"endOfTrack":n.writeUInt8(255),n.writeUInt8(47),n.writeVarInt(0);break;case"setTempo":n.writeUInt8(255),n.writeUInt8(81),n.writeVarInt(3),n.writeUInt24(e.microsecondsPerBeat);break;case"smpteOffset":n.writeUInt8(255),n.writeUInt8(84),n.writeVarInt(5);var c={24:0,25:32,29:64,30:96},h=e.hour&31|c[e.frameRate];n.writeUInt8(h),n.writeUInt8(e.min),n.writeUInt8(e.sec),n.writeUInt8(e.frame),n.writeUInt8(e.subFrame);break;case"timeSignature":n.writeUInt8(255),n.writeUInt8(88),n.writeVarInt(4),n.writeUInt8(e.numerator);var d=Math.floor(Math.log(e.denominator)/Math.LN2)&255;n.writeUInt8(d),n.writeUInt8(e.metronome),n.writeUInt8(e.thirtyseconds||8);break;case"keySignature":n.writeUInt8(255),n.writeUInt8(89),n.writeVarInt(2),n.writeInt8(e.key),n.writeUInt8(e.scale);break;case"sequencerSpecific":n.writeUInt8(255),n.writeUInt8(127),n.writeVarInt(r.length),n.writeBytes(r);break;case"unknownMeta":e.metatypeByte!=null&&(n.writeUInt8(255),n.writeUInt8(e.metatypeByte),n.writeVarInt(r.length),n.writeBytes(r));break;case"sysEx":n.writeUInt8(240),n.writeVarInt(r.length),n.writeBytes(r);break;case"endSysEx":n.writeUInt8(247),n.writeVarInt(r.length),n.writeBytes(r);break;case"noteOff":var u=a!==!1&&e.byte9||a&&e.velocity==0?144:128;l=u|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.noteNumber),n.writeUInt8(e.velocity);break;case"noteOn":l=144|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.noteNumber),n.writeUInt8(e.velocity);break;case"noteAftertouch":l=160|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.noteNumber),n.writeUInt8(e.amount);break;case"controller":l=176|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.controllerType),n.writeUInt8(e.value);break;case"programChange":l=192|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.programNumber);break;case"channelAftertouch":l=208|e.channel,l!==t&&n.writeUInt8(l),n.writeUInt8(e.amount);break;case"pitchBend":l=224|e.channel,l!==t&&n.writeUInt8(l);var m=8192+e.value,p=m&127,g=m>>7&127;n.writeUInt8(p),n.writeUInt8(g);break;default:throw"Unrecognized event type: "+i}return l}function it(){this.buffer=[]}it.prototype.writeUInt8=function(n){this.buffer.push(n&255)};it.prototype.writeInt8=it.prototype.writeUInt8;it.prototype.writeUInt16=function(n){var e=n>>8&255,t=n&255;this.writeUInt8(e),this.writeUInt8(t)};it.prototype.writeInt16=it.prototype.writeUInt16;it.prototype.writeUInt24=function(n){var e=n>>16&255,t=n>>8&255,a=n&255;this.writeUInt8(e),this.writeUInt8(t),this.writeUInt8(a)};it.prototype.writeInt24=it.prototype.writeUInt24;it.prototype.writeUInt32=function(n){var e=n>>24&255,t=n>>16&255,a=n>>8&255,i=n&255;this.writeUInt8(e),this.writeUInt8(t),this.writeUInt8(a),this.writeUInt8(i)};it.prototype.writeInt32=it.prototype.writeUInt32;it.prototype.writeBytes=function(n){this.buffer=this.buffer.concat(Array.prototype.slice.call(n,0))};it.prototype.writeString=function(n){var e,t=n.length,a=[];for(e=0;e<t;e++)a.push(n.codePointAt(e));this.writeBytes(a)};it.prototype.writeVarInt=function(n){if(n<0)throw"Cannot write negative variable-length integer";if(n<=127)this.writeUInt8(n);else{var e=n,t=[];for(t.push(e&127),e>>=7;e;){var a=e&127|128;t.push(a),e>>=7}this.writeBytes(t.reverse())}};it.prototype.writeChunk=function(n,e){this.writeString(n),this.writeUInt32(e.length),this.writeBytes(e)};var IS=SS;Cl.parseMidi=xS;Cl.writeMidi=IS;var Sr={},ti={};Object.defineProperty(ti,"__esModule",{value:!0});ti.insert=ti.search=void 0;function _g(n,e,t){t===void 0&&(t="ticks");var a=0,i=n.length,o=i;if(i>0&&n[i-1][t]<=e)return i-1;for(;a<o;){var s=Math.floor(a+(o-a)/2),r=n[s],l=n[s+1];if(r[t]===e){for(var c=s;c<n.length;c++){var h=n[c];h[t]===e&&(s=c)}return s}else{if(r[t]<e&&l[t]>e)return s;r[t]>e?o=s:r[t]<e&&(a=s+1)}}return-1}ti.search=_g;function ES(n,e,t){if(t===void 0&&(t="ticks"),n.length){var a=_g(n,e[t],t);n.splice(a+1,0,e)}else n.push(e)}ti.insert=ES;(function(n){Object.defineProperty(n,"__esModule",{value:!0}),n.Header=n.keySignatureKeys=void 0;var e=ti,t=new WeakMap;n.keySignatureKeys=["Cb","Gb","Db","Ab","Eb","Bb","F","C","G","D","A","E","B","F#","C#"];var a=function(){function i(o){var s=this;if(this.tempos=[],this.timeSignatures=[],this.keySignatures=[],this.meta=[],this.name="",t.set(this,480),o){t.set(this,o.header.ticksPerBeat),o.tracks.forEach(function(l){l.forEach(function(c){c.meta&&(c.type==="timeSignature"?s.timeSignatures.push({ticks:c.absoluteTime,timeSignature:[c.numerator,c.denominator]}):c.type==="setTempo"?s.tempos.push({bpm:6e7/c.microsecondsPerBeat,ticks:c.absoluteTime}):c.type==="keySignature"&&s.keySignatures.push({key:n.keySignatureKeys[c.key+7],scale:c.scale===0?"major":"minor",ticks:c.absoluteTime}))})});var r=0;o.tracks[0].forEach(function(l){r+=l.deltaTime,l.meta&&(l.type==="trackName"?s.name=l.text:(l.type==="text"||l.type==="cuePoint"||l.type==="marker"||l.type==="lyrics")&&s.meta.push({text:l.text,ticks:r,type:l.type}))}),this.update()}}return i.prototype.update=function(){var o=this,s=0,r=0;this.tempos.sort(function(l,c){return l.ticks-c.ticks}),this.tempos.forEach(function(l,c){var h=c>0?o.tempos[c-1].bpm:o.tempos[0].bpm,d=l.ticks/o.ppq-r,u=60/h*d;l.time=u+s,s=l.time,r+=d}),this.timeSignatures.sort(function(l,c){return l.ticks-c.ticks}),this.timeSignatures.forEach(function(l,c){var h=c>0?o.timeSignatures[c-1]:o.timeSignatures[0],d=(l.ticks-h.ticks)/o.ppq,u=d/h.timeSignature[0]/(h.timeSignature[1]/4);h.measures=h.measures||0,l.measures=u+h.measures})},i.prototype.ticksToSeconds=function(o){var s=(0,e.search)(this.tempos,o);if(s!==-1){var r=this.tempos[s],l=r.time,c=(o-r.ticks)/this.ppq;return l+60/r.bpm*c}else{var h=o/this.ppq;return 60/120*h}},i.prototype.ticksToMeasures=function(o){var s=(0,e.search)(this.timeSignatures,o);if(s!==-1){var r=this.timeSignatures[s],l=(o-r.ticks)/this.ppq;return r.measures+l/(r.timeSignature[0]/r.timeSignature[1])/4}else return o/this.ppq/4},Object.defineProperty(i.prototype,"ppq",{get:function(){return t.get(this)},enumerable:!1,configurable:!0}),i.prototype.secondsToTicks=function(o){var s=(0,e.search)(this.tempos,o,"time");if(s!==-1){var r=this.tempos[s],l=r.time,c=o-l,h=c/(60/r.bpm);return Math.round(r.ticks+h*this.ppq)}else{var d=o/.5;return Math.round(d*this.ppq)}},i.prototype.toJSON=function(){return{keySignatures:this.keySignatures,meta:this.meta,name:this.name,ppq:this.ppq,tempos:this.tempos.map(function(o){return{bpm:o.bpm,ticks:o.ticks}}),timeSignatures:this.timeSignatures}},i.prototype.fromJSON=function(o){this.name=o.name,this.tempos=o.tempos.map(function(s){return Object.assign({},s)}),this.timeSignatures=o.timeSignatures.map(function(s){return Object.assign({},s)}),this.keySignatures=o.keySignatures.map(function(s){return Object.assign({},s)}),this.meta=o.meta.map(function(s){return Object.assign({},s)}),t.set(this,o.ppq),this.update()},i.prototype.setTempo=function(o){this.tempos=[{bpm:o,ticks:0}],this.update()},i}();n.Header=a})(Sr);var Xo={},Td={};(function(n){Object.defineProperty(n,"__esModule",{value:!0}),n.ControlChange=n.controlChangeIds=n.controlChangeNames=void 0,n.controlChangeNames={1:"modulationWheel",2:"breath",4:"footController",5:"portamentoTime",7:"volume",8:"balance",10:"pan",64:"sustain",65:"portamentoTime",66:"sostenuto",67:"softPedal",68:"legatoFootswitch",84:"portamentoControl"},n.controlChangeIds=Object.keys(n.controlChangeNames).reduce(function(i,o){return i[n.controlChangeNames[o]]=o,i},{});var e=new WeakMap,t=new WeakMap,a=function(){function i(o,s){e.set(this,s),t.set(this,o.controllerType),this.ticks=o.absoluteTime,this.value=o.value}return Object.defineProperty(i.prototype,"number",{get:function(){return t.get(this)},enumerable:!1,configurable:!0}),Object.defineProperty(i.prototype,"name",{get:function(){return n.controlChangeNames[this.number]?n.controlChangeNames[this.number]:null},enumerable:!1,configurable:!0}),Object.defineProperty(i.prototype,"time",{get:function(){var o=e.get(this);return o.ticksToSeconds(this.ticks)},set:function(o){var s=e.get(this);this.ticks=s.secondsToTicks(o)},enumerable:!1,configurable:!0}),i.prototype.toJSON=function(){return{number:this.number,ticks:this.ticks,time:this.time,value:this.value}},i}();n.ControlChange=a})(Td);var Ml={};Object.defineProperty(Ml,"__esModule",{value:!0});Ml.createControlChanges=void 0;var Fs=Td;function DS(){return new Proxy({},{get:function(n,e){if(n[e])return n[e];if(Fs.controlChangeIds.hasOwnProperty(e))return n[Fs.controlChangeIds[e]]},set:function(n,e,t){return Fs.controlChangeIds.hasOwnProperty(e)?n[Fs.controlChangeIds[e]]=t:n[e]=t,!0}})}Ml.createControlChanges=DS;var Il={};Object.defineProperty(Il,"__esModule",{value:!0});Il.PitchBend=void 0;var oc=new WeakMap,PS=function(){function n(e,t){oc.set(this,t),this.ticks=e.absoluteTime,this.value=e.value}return Object.defineProperty(n.prototype,"time",{get:function(){var e=oc.get(this);return e.ticksToSeconds(this.ticks)},set:function(e){var t=oc.get(this);this.ticks=t.secondsToTicks(e)},enumerable:!1,configurable:!0}),n.prototype.toJSON=function(){return{ticks:this.ticks,time:this.time,value:this.value}},n}();Il.PitchBend=PS;var El={},ga={};Object.defineProperty(ga,"__esModule",{value:!0});ga.DrumKitByPatchID=ga.InstrumentFamilyByID=ga.instrumentByPatchID=void 0;ga.instrumentByPatchID=["acoustic grand piano","bright acoustic piano","electric grand piano","honky-tonk piano","electric piano 1","electric piano 2","harpsichord","clavi","celesta","glockenspiel","music box","vibraphone","marimba","xylophone","tubular bells","dulcimer","drawbar organ","percussive organ","rock organ","church organ","reed organ","accordion","harmonica","tango accordion","acoustic guitar (nylon)","acoustic guitar (steel)","electric guitar (jazz)","electric guitar (clean)","electric guitar (muted)","overdriven guitar","distortion guitar","guitar harmonics","acoustic bass","electric bass (finger)","electric bass (pick)","fretless bass","slap bass 1","slap bass 2","synth bass 1","synth bass 2","violin","viola","cello","contrabass","tremolo strings","pizzicato strings","orchestral harp","timpani","string ensemble 1","string ensemble 2","synthstrings 1","synthstrings 2","choir aahs","voice oohs","synth voice","orchestra hit","trumpet","trombone","tuba","muted trumpet","french horn","brass section","synthbrass 1","synthbrass 2","soprano sax","alto sax","tenor sax","baritone sax","oboe","english horn","bassoon","clarinet","piccolo","flute","recorder","pan flute","blown bottle","shakuhachi","whistle","ocarina","lead 1 (square)","lead 2 (sawtooth)","lead 3 (calliope)","lead 4 (chiff)","lead 5 (charang)","lead 6 (voice)","lead 7 (fifths)","lead 8 (bass + lead)","pad 1 (new age)","pad 2 (warm)","pad 3 (polysynth)","pad 4 (choir)","pad 5 (bowed)","pad 6 (metallic)","pad 7 (halo)","pad 8 (sweep)","fx 1 (rain)","fx 2 (soundtrack)","fx 3 (crystal)","fx 4 (atmosphere)","fx 5 (brightness)","fx 6 (goblins)","fx 7 (echoes)","fx 8 (sci-fi)","sitar","banjo","shamisen","koto","kalimba","bag pipe","fiddle","shanai","tinkle bell","agogo","steel drums","woodblock","taiko drum","melodic tom","synth drum","reverse cymbal","guitar fret noise","breath noise","seashore","bird tweet","telephone ring","helicopter","applause","gunshot"];ga.InstrumentFamilyByID=["piano","chromatic percussion","organ","guitar","bass","strings","ensemble","brass","reed","pipe","synth lead","synth pad","synth effects","world","percussive","sound effects"];ga.DrumKitByPatchID={0:"standard kit",8:"room kit",16:"power kit",24:"electronic kit",25:"tr-808 kit",32:"jazz kit",40:"brush kit",48:"orchestra kit",56:"sound fx kit"};Object.defineProperty(El,"__esModule",{value:!0});El.Instrument=void 0;var Ls=ga,Gu=new WeakMap,NS=function(){function n(e,t){if(this.number=0,Gu.set(this,t),this.number=0,e){var a=e.find(function(i){return i.type==="programChange"});a&&(this.number=a.programNumber)}}return Object.defineProperty(n.prototype,"name",{get:function(){return this.percussion?Ls.DrumKitByPatchID[this.number]:Ls.instrumentByPatchID[this.number]},set:function(e){var t=Ls.instrumentByPatchID.indexOf(e);t!==-1&&(this.number=t)},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"family",{get:function(){return this.percussion?"drums":Ls.InstrumentFamilyByID[Math.floor(this.number/8)]},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"percussion",{get:function(){var e=Gu.get(this);return e.channel===9},enumerable:!1,configurable:!0}),n.prototype.toJSON=function(){return{family:this.family,number:this.number,name:this.name}},n.prototype.fromJSON=function(e){this.number=e.number},n}();El.Instrument=NS;var Dl={};Object.defineProperty(Dl,"__esModule",{value:!0});Dl.Note=void 0;function BS(n){var e=Math.floor(n/12)-1;return kg(n)+e.toString()}function kg(n){var e=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"],t=n%12;return e[t]}function jS(n){var e=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"];return e.indexOf(n)}var zS=function(){var n=/^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,e={cbb:-2,cb:-1,c:0,"c#":1,cx:2,dbb:0,db:1,d:2,"d#":3,dx:4,ebb:2,eb:3,e:4,"e#":5,ex:6,fbb:3,fb:4,f:5,"f#":6,fx:7,gbb:5,gb:6,g:7,"g#":8,gx:9,abb:7,ab:8,a:9,"a#":10,ax:11,bbb:9,bb:10,b:11,"b#":12,bx:13};return function(t){var a=n.exec(t),i=a[1],o=a[2],s=e[i.toLowerCase()];return s+(parseInt(o,10)+1)*12}}(),yi=new WeakMap,RS=function(){function n(e,t,a){yi.set(this,a),this.midi=e.midi,this.velocity=e.velocity,this.noteOffVelocity=t.velocity,this.ticks=e.ticks,this.durationTicks=t.ticks-e.ticks}return Object.defineProperty(n.prototype,"name",{get:function(){return BS(this.midi)},set:function(e){this.midi=zS(e)},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"octave",{get:function(){return Math.floor(this.midi/12)-1},set:function(e){var t=e-this.octave;this.midi+=t*12},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"pitch",{get:function(){return kg(this.midi)},set:function(e){this.midi=12*(this.octave+1)+jS(e)},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"duration",{get:function(){var e=yi.get(this);return e.ticksToSeconds(this.ticks+this.durationTicks)-e.ticksToSeconds(this.ticks)},set:function(e){var t=yi.get(this),a=t.secondsToTicks(this.time+e);this.durationTicks=a-this.ticks},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"time",{get:function(){var e=yi.get(this);return e.ticksToSeconds(this.ticks)},set:function(e){var t=yi.get(this);this.ticks=t.secondsToTicks(e)},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"bars",{get:function(){var e=yi.get(this);return e.ticksToMeasures(this.ticks)},enumerable:!1,configurable:!0}),n.prototype.toJSON=function(){return{duration:this.duration,durationTicks:this.durationTicks,midi:this.midi,name:this.name,ticks:this.ticks,time:this.time,velocity:this.velocity}},n}();Dl.Note=RS;Object.defineProperty(Xo,"__esModule",{value:!0});Xo.Track=void 0;var sc=ti,OS=Td,qS=Ml,FS=Il,$u=El,LS=Dl,Gs=new WeakMap,GS=function(){function n(e,t){var a=this;if(this.name="",this.notes=[],this.controlChanges=(0,qS.createControlChanges)(),this.pitchBends=[],Gs.set(this,t),e){var i=e.find(function(u){return u.type==="trackName"});this.name=i?i.text:""}if(this.instrument=new $u.Instrument(e,this),this.channel=0,e){for(var o=e.filter(function(u){return u.type==="noteOn"}),s=e.filter(function(u){return u.type==="noteOff"}),r=function(){var u=o.shift();l.channel=u.channel;var m=s.findIndex(function(g){return g.noteNumber===u.noteNumber&&g.absoluteTime>=u.absoluteTime});if(m!==-1){var p=s.splice(m,1)[0];l.addNote({durationTicks:p.absoluteTime-u.absoluteTime,midi:u.noteNumber,noteOffVelocity:p.velocity/127,ticks:u.absoluteTime,velocity:u.velocity/127})}},l=this;o.length;)r();var c=e.filter(function(u){return u.type==="controller"});c.forEach(function(u){a.addCC({number:u.controllerType,ticks:u.absoluteTime,value:u.value/127})});var h=e.filter(function(u){return u.type==="pitchBend"});h.forEach(function(u){a.addPitchBend({ticks:u.absoluteTime,value:u.value/Math.pow(2,13)})});var d=e.find(function(u){return u.type==="endOfTrack"});this.endOfTrackTicks=d!==void 0?d.absoluteTime:void 0}}return n.prototype.addNote=function(e){var t=Gs.get(this),a=new LS.Note({midi:0,ticks:0,velocity:1},{ticks:0,velocity:0},t);return Object.assign(a,e),(0,sc.insert)(this.notes,a,"ticks"),this},n.prototype.addCC=function(e){var t=Gs.get(this),a=new OS.ControlChange({controllerType:e.number},t);return delete e.number,Object.assign(a,e),Array.isArray(this.controlChanges[a.number])||(this.controlChanges[a.number]=[]),(0,sc.insert)(this.controlChanges[a.number],a,"ticks"),this},n.prototype.addPitchBend=function(e){var t=Gs.get(this),a=new FS.PitchBend({},t);return Object.assign(a,e),(0,sc.insert)(this.pitchBends,a,"ticks"),this},Object.defineProperty(n.prototype,"duration",{get:function(){if(!this.notes.length)return 0;for(var e=this.notes[this.notes.length-1].time+this.notes[this.notes.length-1].duration,t=0;t<this.notes.length-1;t++){var a=this.notes[t].time+this.notes[t].duration;e<a&&(e=a)}return e},enumerable:!1,configurable:!0}),Object.defineProperty(n.prototype,"durationTicks",{get:function(){if(!this.notes.length)return 0;for(var e=this.notes[this.notes.length-1].ticks+this.notes[this.notes.length-1].durationTicks,t=0;t<this.notes.length-1;t++){var a=this.notes[t].ticks+this.notes[t].durationTicks;e<a&&(e=a)}return e},enumerable:!1,configurable:!0}),n.prototype.fromJSON=function(e){var t=this;this.name=e.name,this.channel=e.channel,this.instrument=new $u.Instrument(void 0,this),this.instrument.fromJSON(e.instrument),e.endOfTrackTicks!==void 0&&(this.endOfTrackTicks=e.endOfTrackTicks);for(var a in e.controlChanges)e.controlChanges[a]&&e.controlChanges[a].forEach(function(i){t.addCC({number:i.number,ticks:i.ticks,value:i.value})});e.notes.forEach(function(i){t.addNote({durationTicks:i.durationTicks,midi:i.midi,ticks:i.ticks,velocity:i.velocity})})},n.prototype.toJSON=function(){for(var e={},t=0;t<127;t++)this.controlChanges.hasOwnProperty(t)&&(e[t]=this.controlChanges[t].map(function(i){return i.toJSON()}));var a={channel:this.channel,controlChanges:e,pitchBends:this.pitchBends.map(function(i){return i.toJSON()}),instrument:this.instrument.toJSON(),name:this.name,notes:this.notes.map(function(i){return i.toJSON()})};return this.endOfTrackTicks!==void 0&&(a.endOfTrackTicks=this.endOfTrackTicks),a},n}();Xo.Track=GS;var Pl={};function $S(n){var e=[];return Tg(n,e),e}function Tg(n,e){for(var t=0;t<n.length;t++){var a=n[t];Array.isArray(a)?Tg(a,e):e.push(a)}}const VS=Object.freeze(Object.defineProperty({__proto__:null,flatten:$S},Symbol.toStringTag,{value:"Module"})),HS=kk(VS);var oa=Fa&&Fa.__spreadArray||function(n,e,t){if(t||arguments.length===2)for(var a=0,i=e.length,o;a<i;a++)(o||!(a in e))&&(o||(o=Array.prototype.slice.call(e,0,a)),o[a]=e[a]);return n.concat(o||Array.prototype.slice.call(e))};Object.defineProperty(Pl,"__esModule",{value:!0});Pl.encode=void 0;var WS=Cl,US=Sr,KS=HS;function JS(n,e){return[{absoluteTime:n.ticks,channel:e,deltaTime:0,noteNumber:n.midi,type:"noteOn",velocity:Math.floor(n.velocity*127)},{absoluteTime:n.ticks+n.durationTicks,channel:e,deltaTime:0,noteNumber:n.midi,type:"noteOff",velocity:Math.floor(n.noteOffVelocity*127)}]}function ZS(n){return(0,KS.flatten)(n.notes.map(function(e){return JS(e,n.channel)}))}function YS(n,e){return{absoluteTime:n.ticks,channel:e,controllerType:n.number,deltaTime:0,type:"controller",value:Math.floor(n.value*127)}}function XS(n){for(var e=[],t=0;t<127;t++)n.controlChanges.hasOwnProperty(t)&&n.controlChanges[t].forEach(function(a){e.push(YS(a,n.channel))});return e}function QS(n,e){return{absoluteTime:n.ticks,channel:e,deltaTime:0,type:"pitchBend",value:n.value}}function eA(n){var e=[];return n.pitchBends.forEach(function(t){e.push(QS(t,n.channel))}),e}function tA(n){return{absoluteTime:0,channel:n.channel,deltaTime:0,programNumber:n.instrument.number,type:"programChange"}}function nA(n){return{absoluteTime:0,deltaTime:0,meta:!0,text:n,type:"trackName"}}function aA(n){return{absoluteTime:n.ticks,deltaTime:0,meta:!0,microsecondsPerBeat:Math.floor(6e7/n.bpm),type:"setTempo"}}function iA(n){return{absoluteTime:n.ticks,deltaTime:0,denominator:n.timeSignature[1],meta:!0,metronome:24,numerator:n.timeSignature[0],thirtyseconds:8,type:"timeSignature"}}function oA(n){var e=US.keySignatureKeys.indexOf(n.key);return{absoluteTime:n.ticks,deltaTime:0,key:e+7,meta:!0,scale:n.scale==="major"?0:1,type:"keySignature"}}function sA(n){return{absoluteTime:n.ticks,deltaTime:0,meta:!0,text:n.text,type:n.type}}function rA(n){var e={header:{format:1,numTracks:n.tracks.length+1,ticksPerBeat:n.header.ppq},tracks:oa([oa(oa(oa(oa([{absoluteTime:0,deltaTime:0,meta:!0,text:n.header.name,type:"trackName"}],n.header.keySignatures.map(function(t){return oA(t)}),!0),n.header.meta.map(function(t){return sA(t)}),!0),n.header.tempos.map(function(t){return aA(t)}),!0),n.header.timeSignatures.map(function(t){return iA(t)}),!0)],n.tracks.map(function(t){return oa(oa(oa([nA(t.name),tA(t)],ZS(t),!0),XS(t),!0),eA(t),!0)}),!0)};return e.tracks=e.tracks.map(function(t){t=t.sort(function(i,o){return i.absoluteTime-o.absoluteTime});var a=0;return t.forEach(function(i){i.deltaTime=i.absoluteTime-a,a=i.absoluteTime,delete i.absoluteTime}),t.push({deltaTime:0,meta:!0,type:"endOfTrack"}),t}),new Uint8Array((0,WS.writeMidi)(e))}Pl.encode=rA;(function(n){var e=Fa&&Fa.__awaiter||function(d,u,m,p){function g(y){return y instanceof m?y:new m(function(b){b(y)})}return new(m||(m=Promise))(function(y,b){function x(w){try{k(p.next(w))}catch(C){b(C)}}function S(w){try{k(p.throw(w))}catch(C){b(C)}}function k(w){w.done?y(w.value):g(w.value).then(x,S)}k((p=p.apply(d,u||[])).next())})},t=Fa&&Fa.__generator||function(d,u){var m={label:0,sent:function(){if(y[0]&1)throw y[1];return y[1]},trys:[],ops:[]},p,g,y,b;return b={next:x(0),throw:x(1),return:x(2)},typeof Symbol=="function"&&(b[Symbol.iterator]=function(){return this}),b;function x(k){return function(w){return S([k,w])}}function S(k){if(p)throw new TypeError("Generator is already executing.");for(;m;)try{if(p=1,g&&(y=k[0]&2?g.return:k[0]?g.throw||((y=g.return)&&y.call(g),0):g.next)&&!(y=y.call(g,k[1])).done)return y;switch(g=0,y&&(k=[k[0]&2,y.value]),k[0]){case 0:case 1:y=k;break;case 4:return m.label++,{value:k[1],done:!1};case 5:m.label++,g=k[1],k=[0];continue;case 7:k=m.ops.pop(),m.trys.pop();continue;default:if(y=m.trys,!(y=y.length>0&&y[y.length-1])&&(k[0]===6||k[0]===2)){m=0;continue}if(k[0]===3&&(!y||k[1]>y[0]&&k[1]<y[3])){m.label=k[1];break}if(k[0]===6&&m.label<y[1]){m.label=y[1],y=k;break}if(y&&m.label<y[2]){m.label=y[2],m.ops.push(k);break}y[2]&&m.ops.pop(),m.trys.pop();continue}k=u.call(d,m)}catch(w){k=[6,w],g=0}finally{p=y=0}if(k[0]&5)throw k[1];return{value:k[0]?k[1]:void 0,done:!0}}};Object.defineProperty(n,"__esModule",{value:!0}),n.Header=n.Track=n.Midi=void 0;var a=Cl,i=Sr,o=Xo,s=Pl,r=function(){function d(u){var m=this,p=null;if(u){var g=u instanceof ArrayBuffer?new Uint8Array(u):u;p=(0,a.parseMidi)(g),p.tracks.forEach(function(y){var b=0;y.forEach(function(x){b+=x.deltaTime,x.absoluteTime=b})}),p.tracks=h(p.tracks)}this.header=new i.Header(p),this.tracks=[],u&&(this.tracks=p.tracks.map(function(y){return new o.Track(y,m.header)}),p.header.format===1&&this.tracks[0].duration===0&&this.tracks.shift())}return d.fromUrl=function(u){return e(this,void 0,void 0,function(){var m,p;return t(this,function(g){switch(g.label){case 0:return[4,fetch(u)];case 1:return m=g.sent(),m.ok?[4,m.arrayBuffer()]:[3,3];case 2:return p=g.sent(),[2,new d(p)];case 3:throw new Error("Could not load '".concat(u,"'"))}})})},Object.defineProperty(d.prototype,"name",{get:function(){return this.header.name},set:function(u){this.header.name=u},enumerable:!1,configurable:!0}),Object.defineProperty(d.prototype,"duration",{get:function(){var u=this.tracks.map(function(m){return m.duration});return Math.max.apply(Math,u)},enumerable:!1,configurable:!0}),Object.defineProperty(d.prototype,"durationTicks",{get:function(){var u=this.tracks.map(function(m){return m.durationTicks});return Math.max.apply(Math,u)},enumerable:!1,configurable:!0}),d.prototype.addTrack=function(){var u=new o.Track(void 0,this.header);return this.tracks.push(u),u},d.prototype.toArray=function(){return(0,s.encode)(this)},d.prototype.toJSON=function(){return{header:this.header.toJSON(),tracks:this.tracks.map(function(u){return u.toJSON()})}},d.prototype.fromJSON=function(u){var m=this;this.header=new i.Header,this.header.fromJSON(u.header),this.tracks=u.tracks.map(function(p){var g=new o.Track(void 0,m.header);return g.fromJSON(p),g})},d.prototype.clone=function(){var u=new d;return u.fromJSON(this.toJSON()),u},d}();n.Midi=r;var l=Xo;Object.defineProperty(n,"Track",{enumerable:!0,get:function(){return l.Track}});var c=Sr;Object.defineProperty(n,"Header",{enumerable:!0,get:function(){return c.Header}});function h(d){for(var u=[],m=0;m<d.length;m++)for(var p=u.length,g=new Map,y=Array(16).fill(0),b=0,x=d[m];b<x.length;b++){var S=x[b],k=p,w=S.channel;if(w!==void 0){S.type==="programChange"&&(y[w]=S.programNumber);var C=y[w],M="".concat(C," ").concat(w);g.has(M)?k=g.get(M):(k=p+g.size,g.set(M,k))}u[k]||u.push([]),u[k].push(S)}return u}})(wg);let Vu=["C","E","G","B","D","F","A","C#","D#","F#","G#","A#"];function _R(n){Ua(()=>import("./index.D5dKsnJE.js").then(e=>e.i),[]).then(e=>{let t=[];n.forEach((o,s)=>{var r;let l=512/((r=o==null?void 0:o.meter)===null||r===void 0?void 0:r.under),c=new e.Track;c.setTempo(X.bpm,0),c.addInstrumentName("116"),c.addTrackName("Chromatone beat "+s),c.setTimeSignature(4,4,24,8),o.steps.forEach((h,d)=>{h.forEach(u=>{if(o.mutes[d]||o.mutes[u])return;let[m,p]=u.split("-").map(Number),g=l/h.length,y=0;h.length>1&&(y=p*g),c.addEvent(new e.NoteEvent({pitch:o.accents[d]?Vu[s*2]+"2":Vu[s*2+1]+"2",duration:`T${g}`,startTick:l*m+y,velocity:o.accents[d]||o.accents[u]?100:64}))})}),t[s]=c});var a=new e.Writer(t);let i=new wg.Midi(a.buildFile());i.tracks.forEach((o,s)=>{i.tracks[s].instrument.number=119}),xg(i.toArray(),"Chromatone-beat")})}function xg(n,e,t="mid"){const a=new Blob([n]),i=`${e}.${t}`;if(navigator.msSaveBlob)navigator.msSaveBlob(a,i);else{const o=document.createElement("a");if(o.download!==void 0){const s=URL.createObjectURL(a);o.setAttribute("href",s),o.setAttribute("download",i),o.setAttribute("target","_blank"),o.style.visibility="hidden",document.body.appendChild(o),o.click(),document.body.removeChild(o)}}}const Bc=De([]);function kR(n=0){const e=De({pitch:H(()=>qe.tonic),chroma:H(()=>qe.set.chroma),metre:{over:ue(`grid-${n}-over`,4),under:ue(`grid-${n}-under`,4)},octave:ue(`grid-${n}-octave`,3),volume:ue(`grid-${n}-vol`,1),pan:ue(`grid-${n}-pan`,n%2==1?-.5:.5),probability:ue(`grid-${n}-probability`,1),tonic:H(()=>e.pitch+12*e.octave-3),steps:ue(`grid-${n}-steps`,[]),current:[],progress:H(()=>X.ticks?o==null?void 0:o.progress:0),clear(){e.steps.forEach((r,l)=>{e.steps[l]=[{}]})},rotate(r=1){e.steps=Zn(e.steps,r)}});Bc[n]=e;const{channel:t}=ci(`grid-loop-${n}`),a=new ks(e.pan,0).connect(t),i=new hl().connect(a);i.maxPolyphony=100;let o=new Ho((r,l)=>{s(l,r)},e.steps,e.metre.under+"n").start(0);de(()=>e.metre.under,()=>{o.stop().dispose(),o=new Ho((r,l)=>{s(l,r)},e.steps,e.metre.under+"n").start(0),o.probability=e.probability}),de(()=>e.metre.over,()=>{if(e.steps.length>e.metre.over)e.steps.length=e.metre.over;else for(let r=e.steps.length;r<e.metre.over;r++)e.steps.push([{}]);o.events=e.steps},{immediate:!0}),dn(()=>{o.events=e.steps}),dn(()=>{X.stopped&&(e.current=null)}),dn(()=>{o.probability=e.probability,a.volume.targetRampTo(ea(e.volume),1),a.pan.targetRampTo(e.pan,1)});function s(r,l){Ue().state=="suspended"&&Ji();let c=Object.entries(r).map(d=>{if(d[0]!="sub")return d[1]?kc(Number(d[0])+e.tonic):null}).filter(Number);i.triggerAttackRelease(c,{[e.metre.under+"n"]:1/(r.sub||1)},l),Uh().schedule(()=>{let d=V_({[e.metre.under+"n"]:1/(r.sub||1)}).toMilliseconds(),u=c.map(m=>m.toMidi());As(u,{duration:d,attack:e.volume})},l)}return Fr(()=>{Bc.splice(n,1),o.stop().dispose(),a.dispose(),i.dispose()}),e}function TR(){Ua(()=>import("./index.D5dKsnJE.js").then(n=>n.i),[]).then(n=>{let e=[];Bc.forEach((a,i)=>{let o=512/a.metre.under,s=new n.Track;s.setTempo(X.bpm,0),s.addInstrumentName("piano"),s.addTrackName("Chromatone grid "+i),s.setTimeSignature(4,4,24,8),a.steps.forEach((r,l)=>{r.forEach((c,h)=>{let d=h,u=l,m=o/r.length,p=Object.entries(c).map(g=>g[1]==!0?Number(g[0])+a.tonic:null).filter(g=>Number(g)).map(g=>pr(g,"midi").toNote());s.addEvent(new n.NoteEvent({pitch:p,duration:`T${m}`,startTick:o*u+d*m,velocity:a.volume*100}))})}),e[i]=s});var t=new n.Writer(e);xg(t.buildFile(),"Chromatone-grid")})}const xn=De({initiated:!1,open:!1,opened:!1,recording:!0,monitor:!1,meter:0,volume:yt(ue("mic-vol",1),0,5),gate:yt(ue("mic-gate",-60),-100,-40)});let bi,vi,$s,Hu;function lA(){if(!xn.initiated){bi=new _s,bi.normalRange=!0,vi=new Di,Hu=new Ts({threshold:-20,ratio:2}).connect(bi),$s=new Wh({threshold:-60,smoothing:1}),vi.connect($s),$s.connect(Hu);const{channel:n}=ci("mic");de(()=>xn.open,e=>{e?vi.open().then(()=>{xn.opened=!0,qr(()=>{xn.meter=bi.getValue()})}):(vi.close(),xn.opened=!1)}),de(()=>xn.monitor,e=>e?bi.connect(n):bi.disconnect(n)),de(()=>xn.volume,e=>vi.volume.rampTo(ea(e)),{immediate:!0}),de(()=>xn.gate,e=>$s.threshold=e,{immediate:!0})}return{mic:xn,input:vi}}function xR(){const n=ee(null),e=ee(null),{pressed:t}=Qy(),a=De({x:0,y:0,normX:0,normY:0,pressed:t,inside:!1});bn(()=>{n.value.addEventListener("mousemove",i);const{isOutside:o}=eb(e);de(o,s=>{a.inside=!s})});function i(o,s=n.value,r=e.value){if(!s)return;var l=s.createSVGPoint();l.x=o.clientX,l.y=o.clientY;let c=l.matrixTransform(s.getScreenCTM().inverse());if(r){let h=r.getBBox();a.x=c.x<h.width?c.x<0?0:c.x:h.width,a.y=c.y<h.height?c.y<0?0:c.y:h.height,a.normY=1-a.y/h.height,a.normX=a.x/h.width}else a.x=c.x,a.y=c.y}return{svg:n,area:e,mouse:a}}const cA={brown:"brown",pink:"pink",white:"white"},hA={lowpass:"LP",highpass:"HP",bandpass:"BP"},dA={sine:"SIN",triangle:"TRI",square:"SQR",sawtooth:"SAW"},wi=ue("noise-options",{noise:{type:"pink"},envelope:{attack:.1,decay:.1,sustain:.9,release:1},volume:1}),po=ue("filter-options",{on:!1,play:!1,volume:.5,baseFrequency:50,depth:.1,frequency:1,octaves:2,wet:1,type:"sine",filter:{Q:1,type:"lowpass"}}),fo=ue("panner-options",{on:!1,play:!1,wet:1,frequency:1,depth:1,volume:1}),go=ue("bit-options",{on:!1,bits:16,wet:1,volume:1});function SR(){const n=ee(!1),e=ee([]),t=ee([]),{channel:a}=ci("noise"),i=new Hh({size:512,smoothing:.2}).connect(a);for(let m=0;m<32;m++)t.value[m]=i.getFrequencyOfIndex(m);const o=new re(wi.value.volume).connect(i),s=new re(po.value.volume).connect(i),r=new re(fo.value.volume).connect(i),l=new re(go.value.volume).connect(i),c=new ml(fo.value).connect(r),h=new qh(go.value).connect(l).connect(c),d=new Rh(po.value).connect(s).connect(h),u=new Ph(wi.value).connect(o).connect(d);return qr(()=>{let m=i.getValue();for(let p=0;p<32;p++)e.value[p]=Go(m[p])*10}),Ro("a",m=>{m.preventDefault(),n.value=!0},{eventName:"keydown"}),Ro("a",()=>{n.value=!1},{eventName:"keyup"}),de(n,m=>{m?u.triggerAttack():u.triggerRelease()}),de(wi.value,()=>{u.set(wi.value)}),de(()=>wi.value.volume,m=>{o.gain.rampTo(m,1)}),Fr(()=>{u.triggerRelease()}),de(po.value,m=>{m.play?d.start():d.stop(),m.on?s.gain.rampTo(po.value.volume,.2):s.gain.rampTo(0,.2),d.set(m)}),de(fo.value,m=>{m.play?c.start():c.stop(),m.on?r.gain.rampTo(fo.value.volume,.2):r.gain.rampTo(0,.2),c.set(m)}),de(go.value,m=>{m.on?l.gain.rampTo(go.value.volume,.2):l.gain.rampTo(0,.2),h.set(m)}),{options:wi,filterOptions:po,pannerOptions:fo,crusherOptions:go,active:n,fftData:e,fftFreq:t,types:cA,filterTypes:hA,filterLFOTypes:dA}}let Ar;function uA(){if(Ji(),Ar)return;const{channel:n}=ci("piano");Ar=new ri({urls:{A0:"A0.mp3",C1:"C1.mp3","D#1":"Ds1.mp3","F#1":"Fs1.mp3",A1:"A1.mp3",C2:"C2.mp3","D#2":"Ds2.mp3","F#2":"Fs2.mp3",A2:"A2.mp3",C3:"C3.mp3","D#3":"Ds3.mp3","F#3":"Fs3.mp3",A3:"A3.mp3",C4:"C4.mp3","D#4":"Ds4.mp3","F#4":"Fs4.mp3",A4:"A4.mp3",C5:"C5.mp3","D#5":"Ds5.mp3","F#5":"Fs5.mp3",A5:"A5.mp3",C6:"C6.mp3","D#6":"Ds6.mp3","F#6":"Fs6.mp3",A6:"A6.mp3",C7:"C7.mp3","D#7":"Ds7.mp3","F#7":"Fs7.mp3",A7:"A7.mp3",C8:"C8.mp3"},release:1,volume:-10,baseUrl:"/audio/piano/"}).connect(n)}function AR(n="A4",e="8n",t){if(!Ar)return uA();Ar.triggerAttackRelease(n,e,t)}const Sg=De([]),CR=H(()=>{let n=0;return Sg.forEach(e=>{let t=e.meter.over/e.meter.under;t>n&&(n=t)}),n});function MR(n={over:4,under:4,sound:"A",volume:1},e=0,t="bar",a=64){let i;const o=De({meter:{over:yt(ue(`tempo-loop-${e} -${t}-over`,4),2,a),under:yt(ue(`tempo-loop-${e}-${t}-under`,4),1,a),sound:ue(`tempo-loop-${e}-${t}-sound`,"A"),volume:yt(ue(`tempo-loop-${e}-${t}-volume`,1),0,1)},current:"0-0",steps:[["0-1"],["1-1"],["2-1"],["3-1"]],mutes:ue(`metro-${t}-mutes-${e}`,[]),accents:ue(`metro-${t}-accents-${e}`,[!0]),volume:yt(ue(`metro-${t}-vol-${e}`,(n==null?void 0:n.volume)||1),0,1),mute:!1,pan:yt(ue(`metro-${t}-pan-${e}`,e%2==1?-.5:.5),-1,1),mutesCount:H(()=>o.mutes.reduce((u,m)=>(m||u++,u),0)),activeSteps:H(()=>o.steps.filter(u=>!o.mutes[u[0].split("-")[0]]).map(u=>Number(u[0].split("-")[0]))),currentSeq:H(()=>o.mutes.reduce((u,m)=>m?u+"0":u+"1","")),euclidSeq:H(()=>o.mutesCount>0&&o.mutesCount<o.steps.length?pA(o.mutesCount,o.steps.length).join(""):new Array(o.steps.length).fill("1").join("")),isEuclidean:H(()=>o.euclidSeq==o.currentSeq),reset(){let u=[];o.euclidSeq.split("").forEach((m,p)=>{u[p]=!(m!=!1&&m!=null)}),o.mutes=u},rotateAccents(u){o.accents=Zn(o.accents,u),o.mutes=Zn(o.mutes,u)}});Sg[e]=o,o.progress=H(()=>X.ticks?i==null?void 0:i.progress:0),de(()=>{var u;return(u=o==null?void 0:o.meter)==null?void 0:u.under},()=>{var u;(u=i==null?void 0:i.stop())==null||u.dispose(),i=new Ho(d,o.steps,o.meter.under+"n").start(0)},{immediate:!0}),de(()=>{var u;return(u=o==null?void 0:o.meter)==null?void 0:u.over},()=>{var u;o.steps.length=0;for(let m=0;m<((u=o.meter)==null?void 0:u.over);m++)o.steps.push([`${m}-1`]);i.events=o.steps},{immediate:!0}),dn(()=>{i.events=o.steps,o.accents.length=o.steps.length;const u=o.mutes.length;o.mutes.length=o.steps.length,o.mutes.length<o.steps.length&&o.mutes.fill(!1,u)}),dn(()=>{X.stopped&&(o.current="1000-1")});const s={A:"tongue",B:"synth",C:"seiko",D:"ping",E:"logic"},r={};for(let u in s)for(let m of[1,2])r[`${u}${m} `]=`${s[u]}/${m==1?"high":"low"}.wav`;const l=zo({...ci(`sequence-${t}-${e}`),panner:new ks(e%2==1?-.5:.5,0),synth:new ri({urls:r,volume:1,attack:.001,release:2,baseUrl:"/audio/metronome/"})});l.synth.connect(l.panner),l.panner.connect(l.channel);const{sampler:c,micRec:h}=mA(l.synth);de(()=>o.mute,u=>{l.volume.mute=u}),de(()=>o.meter.sound,u=>{u!="F"&&(c.main=!1,c.accent=!1)}),de(()=>o.volume,u=>{l.panner.volume.targetRampTo(ea(u),1)},{immediate:!0}),de(()=>o.pan,u=>{l.panner.pan.targetRampTo(u,1)},{immediate:!0});function d(u,m){var x,S,k,w;Ue().state=="suspended"&&Ji();let p=typeof m=="string"?+m.split("-")[0]:m;Uh().schedule(()=>{o.current=m},u);let y=o.accents[p]&&m.split("-")[1]=="1";if(o.mutes[p]||o.mutes[m]||((x=o.meter)==null?void 0:x.sound)=="F"&&!y&&!c.main||((S=o.meter)==null?void 0:S.sound)=="F"&&y&&!c.accent)return;let b=`${(k=o.meter)==null?void 0:k.sound}${y?2:1}`;l.synth.triggerAttackRelease(b,((w=o.meter)==null?void 0:w.under)+"n",u)}return Fr(()=>{i.stop().dispose(),[l,h].forEach(u=>{Object.values(u).forEach(m=>m.dispose())})}),{sampler:c,seq:o}}function mA(n){const e={mic:new Di(1),meter:new _s,recorder:new Uo};e.mic.connect(e.meter),e.meter.connect(e.recorder);const t=De({started:!1,recording:!1,main:!1,accent:!1,both:H(()=>t.main&&t.accent),async load(a="main",i){let o=await i.arrayBuffer(),s=await e.recorder.context.decodeAudioData(o);n.add(a=="main"?"F1":"F2",s),t[a]=!0,t.recording=!1},async rec(a="main"){if(!t.recording)t.started?(t.recording=a,e.recorder.start()):e.mic.open().then(()=>{t.started=!0,t.recording=a,e.recorder.start()}).catch(()=>{console.log("mic not open")});else{let o=await(await e.recorder.stop()).arrayBuffer(),s=await e.recorder.context.decodeAudioData(o);n.add(a=="main"?"F1":"F2",s),t[a]=!0,t.recording=!1}}});return{sampler:t,micRec:e}}function Ag(n,e,t){t=t||new Array(n).fill("1").concat(new Array(e).fill("0"));const a=[];for(let i=0;i<Math.min(n,e);i++)a.push(t.shift()+t.pop());return t.length>1?Ag(a.length,t.length,a.concat(t)):a.concat(t)}function pA(n,e){return Ag(n,e-n,null)}const fA=Zn(ua,3),jc={middleA:440,semitone:69},ye=De({initiated:!1,initiating:!1,stream:null,middleA:jc.middleA,semitone:jc.semitone,note:{name:"A",value:69,cents:0,octave:4,frequency:440,color:Mg(440),silent:!1},span:64,bufferSize:4096,tempoBufferSize:512,frequencyData:null,running:!1,frame:0,beat:0,bpm:0,confidence:0,listenBeat:!1,prevBeat:0,blink:!1,chroma:[0,0,0,0,0,0,0,0,0,0,0,0],aChroma:H(()=>Zn(ye.chroma,-3)),chromaAvg:H(()=>ye.chroma.reduce((n,e)=>n+e,0)/12),spec:[],rms:0}),ve={};function Cg(){return o2(),{init:gA,tuner:ye,chain:ve}}async function gA(){if(ye.initiated)return;ye.initiating=!0;const{master:n}=ud();ve.audioContext=n.context,ve.analyser=ve.audioContext.createAnalyser(),ve.scriptProcessor=ve.audioContext.createScriptProcessor(ye.bufferSize,1,1),ve.beatProcessor=ve.audioContext.createScriptProcessor(ye.tempoBufferSize,1,1),de(()=>ye.frame,()=>{ye.listen&&ye.beat>ye.prevBeat&&(ye.prevBeat=ye.beat,ye.blink=!0,setTimeout(()=>{ye.blink=!1},60))});const e=await Ua(()=>import("./meyda.min.CfWzP_tF.js").then(a=>a.m),[]);ve.meyda=e.createMeydaAnalyzer({audioContext:ve.audioContext,source:ve.analyser,bufferSize:4096,featureExtractors:["chroma","amplitudeSpectrum","rms"],callback:a=>{ye.rms=a.rms,ye.chroma=a.chroma,ye.spec=a.amplitudeSpectrum}}),ve.meyda.start(),ye.frequencyData=new Uint8Array(ve.analyser.frequencyBinCount);const{default:t}=await Ua(async()=>{const{default:a}=await import("./aubio.esm.ZLcMA8zk.js");return{default:a}},[]);t().then(function(a){ve.pitchDetector=new a.Pitch("default",ye.bufferSize*4,ye.bufferSize,ve.audioContext.sampleRate),ve.tempoAnalyzer=new a.Tempo(ye.tempoBufferSize*4,ye.tempoBufferSize,ve.audioContext.sampleRate),ye.running=!0,yA()}),ye.initiated=!0,ye.initiating=!1}function yA(){navigator.mediaDevices.getUserMedia({audio:!0}).then(function(n){ye.stream=n,ve.audioContext.createMediaStreamSource(n).connect(ve.analyser),ve.analyser.connect(ve.scriptProcessor),ve.analyser.connect(ve.beatProcessor),ve.scriptProcessor.connect(ve.audioContext.destination),ve.beatProcessor.connect(ve.audioContext.destination),ve.beatProcessor.addEventListener("audioprocess",e=>{if(!ve.tempoAnalyzer)return;ve.tempoAnalyzer.do(e.inputBuffer.getChannelData(0))&&(ye.beat++,ye.confidence=ve.tempoAnalyzer.getConfidence(),ye.bpm=ve.tempoAnalyzer.getBpm())}),ve.scriptProcessor.addEventListener("audioprocess",function(e){if(!ve.pitchDetector)return;const t=ve.pitchDetector.do(e.inputBuffer.getChannelData(0));if(ye.frame++,t){const a=bA(t);ye.note={name:fA[a%12],value:a,cents:wA(t,a),octave:Math.floor(a/12)-1,frequency:t,color:Mg(t),silent:!1}}else ye.note.silent=!0})}).catch(function(n){console.log(n.name+": "+n.message)})}function bA(n){const e=12*(Math.log(n/ye.middleA)/Math.log(2));return Math.round(e)+ye.semitone}function vA(n){return ye.middleA*Math.pow(2,(n-ye.semitone)/12)}function wA(n,e){return Math.floor(1200*Math.log(n/vA(e))/Math.log(2))}function Mg(n){const e=_A(n);if(!e)return"#333";const t=Math.floor(e/12)+2;return Ve(e,t)}function _A(n){return 12*(Math.log(n/jc.middleA)/Math.log(2))%12}function kA(){try{return"constructor"in GestureEvent}catch{return!1}}function Ig(){return typeof window<"u"&&"ontouchstart"in window}function Eg(n){return"pointerId"in n?null:n.type==="touchend"?n.changedTouches:n.targetTouches}function xd(n){return Array.from(Eg(n)).map(e=>e.identifier)}function Ht(n){const e="buttons"in n?n.buttons:0,{shiftKey:t,altKey:a,metaKey:i,ctrlKey:o}=n;return{buttons:e,shiftKey:t,altKey:a,metaKey:i,ctrlKey:o}}const Ms=n=>n;function Ii(n,e=Ms){const t=Eg(n),{clientX:a,clientY:i}=t?t[0]:n;return e([a,i])}function Wu(n,e,t=Ms){const[a,i]=Array.from(n.touches).filter(m=>e.includes(m.identifier));if(!a||!i)throw Error("The event doesn't have two pointers matching the pointerIds");const o=i.clientX-a.clientX,s=i.clientY-a.clientY,r=(i.clientX+a.clientX)/2,l=(i.clientY+a.clientY)/2,c=Math.hypot(o,s),h=-(Math.atan2(o,s)*180)/Math.PI,d=t([c,h]),u=t([r,l]);return{values:d,origin:u}}function TA(n,e=Ms){const{scrollX:t,scrollY:a,scrollLeft:i,scrollTop:o}=n.currentTarget;return e([t||i||0,a||o||0])}const Uu=40,Ku=800;function Dg(n,e=Ms){let{deltaX:t,deltaY:a,deltaMode:i}=n;return i===1?(t*=Uu,a*=Uu):i===2&&(t*=Ku,a*=Ku),e([t,a])}function Ju(n,e=Ms){return e([n.scale,n.rotation])}function Pg(){}function Ng(...n){return n.length===0?Pg:n.length===1?n[0]:function(){var e;for(let t of n)e=t.apply(this,arguments)||e;return e}}function da(n,e){if(n===void 0){if(e===void 0)throw new Error("Must define fallback value if undefined is expected");n=e}return Array.isArray(n)?n:[n,n]}function Zu(n,e){return Object.assign({},e,n||{})}function Cr(n,...e){return typeof n=="function"?n(...e):n}function yo(n){return{_active:!1,_blocked:!1,_intentional:[!1,!1],_movement:[0,0],_initial:[0,0],_bounds:[[-1/0,1/0],[-1/0,1/0]],_lastEventType:void 0,_dragStarted:!1,_dragPreventScroll:!1,_dragIsTap:!0,_dragDelayed:!1,event:void 0,intentional:!1,values:[0,0],velocities:[0,0],delta:[0,0],movement:[0,0],offset:[0,0],lastOffset:[0,0],direction:[0,0],initial:[0,0],previous:[0,0],first:!1,last:!1,active:!1,timeStamp:0,startTime:0,elapsedTime:0,cancel:Pg,canceled:!1,memo:void 0,args:void 0,...n}}function zc(){const n={hovering:!1,scrolling:!1,wheeling:!1,dragging:!1,moving:!1,pinching:!1,touches:0,buttons:0,down:!1,shiftKey:!1,altKey:!1,metaKey:!1,ctrlKey:!1,locked:!1},e=yo({_pointerId:void 0,axis:void 0,xy:[0,0],vxvy:[0,0],velocity:0,distance:0,tap:!1,swipe:[0,0]}),t=yo({_pointerIds:[],da:[0,0],vdva:[0,0],origin:void 0,turns:0}),a=yo({axis:void 0,xy:[0,0],vxvy:[0,0],velocity:0,distance:0}),i=yo({axis:void 0,xy:[0,0],vxvy:[0,0],velocity:0,distance:0}),o=yo({axis:void 0,xy:[0,0],vxvy:[0,0],velocity:0,distance:0});return{shared:n,drag:e,pinch:t,wheel:a,move:i,scroll:o}}var xA=Object.defineProperty,SA=(n,e,t)=>e in n?xA(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,Pt=(n,e,t)=>(SA(n,typeof e!="symbol"?e+"":e,t),t);class AA{constructor(e){this.classes=e,Pt(this,"nativeRefs"),Pt(this,"config"),Pt(this,"handlers"),Pt(this,"state"),Pt(this,"timeouts"),Pt(this,"domListeners"),Pt(this,"windowListeners"),Pt(this,"pointerIds",new Set),Pt(this,"touchIds",new Set),Pt(this,"supportsTouchEvents",Ig()),Pt(this,"supportsGestureEvents",kA()),Pt(this,"bind",(...t)=>{const a={};for(let i of this.classes)new i(this,t).addBindings(a);for(let i in this.nativeRefs)Oe(a,i,o=>this.nativeRefs[i]({...this.state.shared,event:o,args:t}));return this.config.domTarget?EA(this,a):DA(this,a)}),Pt(this,"clean",()=>{const{eventOptions:t,domTarget:a}=this.config,i=f(a);i&&Is(i,zg(this.domListeners),t),Object.values(this.timeouts).forEach(clearTimeout),CA(this)}),Pt(this,"reset",()=>{this.state=zc()}),this.classes=e,this.state=zc(),this.timeouts={},this.domListeners=[],this.windowListeners={}}}function Bg(n,e){"pointerId"in e?n.pointerIds.add(e.pointerId):n.touchIds=new Set(xd(e))}function jg(n,e){"pointerId"in e?n.pointerIds.delete(e.pointerId):xd(e).forEach(t=>n.touchIds.delete(t))}function CA(n){const{config:{window:e,eventOptions:t},windowListeners:a}=n,i=f(e);if(i){for(let o in a){const s=a[o];Is(i,s,t)}n.windowListeners={}}}function MA({config:n,windowListeners:e},t,a=n.eventOptions){const i=f(n.window);i&&(Is(i,e[t],a),delete e[t])}function IA({config:n,windowListeners:e},t,a=[],i=n.eventOptions){const o=f(n.window);o&&(Is(o,e[t],i),Rg(o,e[t]=a,i))}function EA({config:n,domListeners:e},t){const{eventOptions:a,domTarget:i}=n,o=f(i);if(!o)throw new Error("domTarget must be defined");Is(o,zg(e),a);for(let[s,r]of Object.entries(t)){const l=s.slice(2).toLowerCase();e.push([l,Ng(...r)])}Rg(o,e,a)}function DA({config:n},e){const t={},a=n.eventOptions.capture?"Capture":"";for(let[i,o]of Object.entries(e)){const s=Array.isArray(o)?o:[o],r=i+a;t[r]=Ng(...s)}return t}function zg(n=[]){return n.splice(0,n.length)}function Oe(n,e,t){n[e]||(n[e]=[]),n[e].push(t)}function Rg(n,e=[],t={}){if(n)for(let[a,i]of e)n.addEventListener(a,i,t)}function Is(n,e=[],t={}){if(n)for(let[a,i]of e)n.removeEventListener(a,i,t)}function Mr(n,e){return n.map((t,a)=>t+e[a])}function Sd(n,e){return n.map((t,a)=>t-e[a])}function Qo(n){return Math.hypot(...n)}function Og(n,e=n){const t=Qo(e),a=t===0?0:1/t,i=e.map(s=>a*s);return{distance:Qo(n),direction:i}}function qg(n,e,t){const a=Qo(e),i=a===0?0:1/a,o=t===0?0:1/t,s=o*a,r=e.map(h=>o*h),l=e.map(h=>i*h),c=Qo(n);return{velocities:r,velocity:s,distance:c,direction:l}}function Ir(n){return Math.sign?Math.sign(n):+(n>0)-+(n<0)||+n}function PA(n,e,t){return Math.max(e,Math.min(n,t))}function NA(n,e){return Math.pow(n,e*5)}function Yu(n,e,t){return e===0||Math.abs(e)===1/0?NA(n,t):n*e*t/(e+t*n)}function Xu(n,e,t,a=.15){return a===0?PA(n,e,t):n<e?-Yu(e-n,t-e,a)+e:n>t?+Yu(n-t,t-e,a)+t:n}var BA=Object.defineProperty,jA=(n,e,t)=>e in n?BA(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,Vs=(n,e,t)=>(jA(n,typeof e!="symbol"?e+"":e,t),t);const rt=new Map,zA=n=>n;class Fg{constructor(e,t=[]){this.controller=e,this.args=t,Vs(this,"debounced",!0),Vs(this,"setTimeout",(a,i=140,...o)=>{clearTimeout(this.controller.timeouts[this.stateKey]),this.controller.timeouts[this.stateKey]=window.setTimeout(a,i,...o)}),Vs(this,"clearTimeout",()=>{clearTimeout(this.controller.timeouts[this.stateKey])}),Vs(this,"fireGestureHandler",(a=!1)=>{if(this.state._blocked)return this.debounced||(this.state._active=!1,this.clean()),null;if(!a&&!this.state.intentional&&!this.config.triggerAllEvents)return null;if(this.state.intentional){const l=this.state.active,c=this.state._active;this.state.active=c,this.state.first=c&&!l,this.state.last=l&&!c,this.controller.state.shared[this.ingKey]=c}const i=this.controller.pointerIds.size||this.controller.touchIds.size,o=this.controller.state.shared.buttons>0||i>0,s={...this.controller.state.shared,...this.state,...this.mapStateValues(this.state),locked:!!document.pointerLockElement,touches:i,down:o},r=this.handler(s);return this.state.memo=r!==void 0?r:this.state.memo,s}),this.controller=e,this.args=t}get config(){return this.controller.config[this.stateKey]}get enabled(){return this.controller.config.enabled&&this.config.enabled}get state(){return this.controller.state[this.stateKey]}get handler(){return this.controller.handlers[this.stateKey]}get transform(){return this.config.transform||this.controller.config.transform||zA}updateSharedState(e){Object.assign(this.controller.state.shared,e)}updateGestureState(e){Object.assign(this.state,e)}checkIntentionality(e,t){return{_intentional:e,_blocked:!1}}getMovement(e){const{rubberband:t,threshold:a}=this.config,{_bounds:i,_initial:o,_active:s,_intentional:r,lastOffset:l,movement:c}=this.state,h=this.getInternalMovement(e,this.state),d=this.transform(a).map(Math.abs),u=r[0]===!1?Qu(h[0],d[0]):r[0],m=r[1]===!1?Qu(h[1],d[1]):r[1],p=this.checkIntentionality([u,m],h);if(p._blocked)return{...p,_movement:h,delta:[0,0]};const g=p._intentional,y=h;let b=[g[0]!==!1?h[0]-g[0]:0,g[1]!==!1?h[1]-g[1]:0];const x=Mr(b,l),S=s?t:[0,0];return b=em(i,Mr(b,o),S),{...p,intentional:g[0]!==!1||g[1]!==!1,_initial:o,_movement:y,movement:b,values:e,offset:em(i,x,S),delta:Sd(b,c)}}clean(){this.clearTimeout()}}function Qu(n,e){return Math.abs(n)>=e?Ir(n)*e:!1}function em(n,[e,t],[a,i]){const[[o,s],[r,l]]=n;return[Xu(e,o,s,a),Xu(t,r,l,i)]}function et({state:n},e,t){const{timeStamp:a,type:i}=e,o=n.values,s=t?0:a-n.startTime;return{_lastEventType:i,event:e,timeStamp:a,elapsedTime:s,previous:o}}function Wa({state:n,config:e,stateKey:t,args:a},i,o){const s=n.offset,r=o.timeStamp,{initial:l,bounds:c}=e,h={...zc()[t],_active:!0,args:a,values:i,initial:i,offset:s,lastOffset:s,startTime:r};return{...h,_initial:Cr(l,h),_bounds:Cr(c,h)}}class Nl extends Fg{getInternalMovement(e,t){return Sd(e,t.initial)}checkIntentionality(e,t){if(e[0]===!1&&e[1]===!1)return{_intentional:e,axis:this.state.axis};const[a,i]=t.map(Math.abs),o=this.state.axis||(a>i?"x":a<i?"y":void 0);return!this.config.axis&&!this.config.lockDirection?{_intentional:e,_blocked:!1,axis:o}:o?this.config.axis&&o!==this.config.axis?{_intentional:e,_blocked:!0,axis:o}:(e[o==="x"?1:0]=!1,{_intentional:e,_blocked:!1,axis:o}):{_intentional:[!1,!1],_blocked:!1,axis:o}}getKinematics(e,t){const a=this.getMovement(e);if(!a._blocked){const i=t.timeStamp-this.state.timeStamp;Object.assign(a,qg(a.movement,a.delta,i))}return a}mapStateValues(e){return{xy:e.values,vxvy:e.velocities}}}var RA=Object.defineProperty,OA=(n,e,t)=>e in n?RA(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,ut=(n,e,t)=>(OA(n,typeof e!="symbol"?e+"":e,t),t);const qA=3;function tm(n){"persist"in n&&typeof n.persist=="function"&&n.persist()}class Lg extends Nl{constructor(){super(...arguments),ut(this,"ingKey","dragging"),ut(this,"stateKey","drag"),ut(this,"setPointerCapture",e=>{if(this.config.useTouch||document.pointerLockElement)return;const{target:t,pointerId:a}=e;t&&"setPointerCapture"in t&&t.setPointerCapture(a),this.updateGestureState({_dragTarget:t,_dragPointerId:a})}),ut(this,"releasePointerCapture",()=>{if(this.config.useTouch||document.pointerLockElement)return;const{_dragTarget:e,_dragPointerId:t}=this.state;if(t&&e&&"releasePointerCapture"in e&&(!("hasPointerCapture"in e)||e.hasPointerCapture(t)))try{e.releasePointerCapture(t)}catch{}}),ut(this,"preventScroll",e=>{this.state._dragPreventScroll&&e.cancelable&&e.preventDefault()}),ut(this,"getEventId",e=>this.config.useTouch?e.changedTouches[0].identifier:e.pointerId),ut(this,"isValidEvent",e=>this.state._pointerId===this.getEventId(e)),ut(this,"shouldPreventWindowScrollY",this.config.preventWindowScrollY&&this.controller.supportsTouchEvents),ut(this,"setUpWindowScrollDetection",e=>{tm(e),IA(this.controller,this.stateKey,[["touchmove",this.preventScroll],["touchend",this.clean.bind(this)],["touchcancel",this.clean.bind(this)]],{passive:!1}),this.setTimeout(this.startDrag.bind(this),250,e)}),ut(this,"setUpDelayedDragTrigger",e=>{this.state._dragDelayed=!0,tm(e),this.setTimeout(this.startDrag.bind(this),this.config.delay,e)}),ut(this,"setStartState",e=>{const t=Ii(e,this.transform);this.updateSharedState(Ht(e)),this.updateGestureState({...Wa(this,t,e),...et(this,e,!0),_pointerId:this.getEventId(e)}),this.updateGestureState(this.getMovement(t))}),ut(this,"onDragStart",e=>{Bg(this.controller,e),!(!this.enabled||this.state._active)&&(this.setStartState(e),this.setPointerCapture(e),this.shouldPreventWindowScrollY?this.setUpWindowScrollDetection(e):this.config.delay>0?this.setUpDelayedDragTrigger(e):this.startDrag(e,!0))}),ut(this,"onDragChange",e=>{if(this.state.canceled||!this.state._active||!this.isValidEvent(e)||this.state._lastEventType===e.type&&e.timeStamp===this.state.timeStamp)return;let t;if(document.pointerLockElement){const{movementX:l,movementY:c}=e;t=Mr(this.transform([l,c]),this.state.values)}else t=Ii(e,this.transform);const a=this.getKinematics(t,e);if(!this.state._dragStarted){if(this.state._dragDelayed){this.startDrag(e);return}if(this.shouldPreventWindowScrollY)if(!this.state._dragPreventScroll&&a.axis)if(a.axis==="x")this.startDrag(e);else{this.state._active=!1;return}else return;else return}const i=Ht(e);this.updateSharedState(i);const o=et(this,e),s=Qo(a._movement);let{_dragIsTap:r}=this.state;r&&s>=qA&&(r=!1),this.updateGestureState({...o,...a,_dragIsTap:r}),this.fireGestureHandler()}),ut(this,"onDragEnd",e=>{if(jg(this.controller,e),!this.isValidEvent(e)||(this.clean(),!this.state._active))return;this.state._active=!1;const t=this.state._dragIsTap,[a,i]=this.state.velocities,[o,s]=this.state.movement,[r,l]=this.state._intentional,[c,h]=this.config.swipeVelocity,[d,u]=this.config.swipeDistance,m=this.config.swipeDuration,p={...et(this,e),...this.getMovement(this.state.values)},g=[0,0];p.elapsedTime<m&&(r!==!1&&Math.abs(a)>c&&Math.abs(o)>d&&(g[0]=Ir(a)),l!==!1&&Math.abs(i)>h&&Math.abs(s)>u&&(g[1]=Ir(i))),this.updateSharedState({buttons:0}),this.updateGestureState({...p,tap:t,swipe:g}),this.fireGestureHandler(this.config.filterTaps&&t===!0)}),ut(this,"clean",()=>{super.clean(),this.state._dragStarted=!1,this.releasePointerCapture(),MA(this.controller,this.stateKey)}),ut(this,"onCancel",()=>{this.state.canceled||(this.updateGestureState({canceled:!0,_active:!1}),this.updateSharedState({buttons:0}),rn(this.fireGestureHandler))}),ut(this,"onClick",e=>{this.state._dragIsTap||e.stopPropagation()})}startDrag(e,t=!1){!this.state._active||this.state._dragStarted||(t||this.setStartState(e),this.updateGestureState({_dragStarted:!0,_dragPreventScroll:!0,cancel:this.onCancel}),this.clearTimeout(),this.fireGestureHandler())}addBindings(e){if(this.config.useTouch?(Oe(e,"onTouchStart",this.onDragStart),Oe(e,"onTouchMove",this.onDragChange),Oe(e,"onTouchEnd",this.onDragEnd),Oe(e,"onTouchCancel",this.onDragEnd)):(Oe(e,"onPointerDown",this.onDragStart),Oe(e,"onPointerMove",this.onDragChange),Oe(e,"onPointerUp",this.onDragEnd),Oe(e,"onPointerCancel",this.onDragEnd)),this.config.filterTaps){const t=this.controller.config.eventOptions.capture?"onClick":"onClickCapture";Oe(e,t,this.onClick)}}}function no(n,e){let t,a=[],i,o=!1;function s(...r){return o&&t===this&&e(r,a)||(i=n.apply(this,r),o=!0,t=this,a=r),i}return s}function Qs(n,e){if(n===e)return!0;if(n&&e&&typeof n=="object"&&typeof e=="object"){if(n.constructor!==e.constructor)return!1;let t,a,i;if(Array.isArray(n)){if(t=n.length,t!==e.length)return!1;for(a=t;a--!==0;)if(!Qs(n[a],e[a]))return!1;return!0}let o;if(typeof Map=="function"&&n instanceof Map&&e instanceof Map){if(n.size!==e.size)return!1;for(o=n.entries();!(a=o.next()).done;)if(!e.has(a.value[0]))return!1;for(o=n.entries();!(a=o.next()).done;)if(!Qs(a.value[1],e.get(a.value[0])))return!1;return!0}if(typeof Set=="function"&&n instanceof Set&&e instanceof Set){if(n.size!==e.size)return!1;for(o=n.entries();!(a=o.next()).done;)if(!e.has(a.value[0]))return!1;return!0}if(n.constructor===RegExp)return n.source===e.source&&n.flags===e.flags;if(n.valueOf!==Object.prototype.valueOf)return n.valueOf()===e.valueOf();if(n.toString!==Object.prototype.toString)return n.toString()===e.toString();if(i=Object.keys(n),t=i.length,t!==Object.keys(e).length)return!1;for(a=t;a--!==0;)if(!Object.prototype.hasOwnProperty.call(e,i[a]))return!1;if(typeof Element<"u"&&n instanceof Element)return!1;for(a=t;a--!==0;)if(!(i[a]==="_owner"&&n.$$typeof)&&!Qs(n[i[a]],e[i[a]]))return!1;return!0}return n!==n&&e!==e}function ao(n,e){try{return Qs(n,e)}catch(t){if((t.message||"").match(/stack|recursion/i))return console.warn("react-fast-compare cannot handle circular refs"),!1;throw t}}function Es(n={},e){const t={};for(const[a,i]of Object.entries(e))switch(typeof i){case"function":t[a]=i.call(t,n[a],a,n);break;case"object":t[a]=Es(n[a],i);break;case"boolean":i&&(t[a]=n[a]);break}return t}const FA=180,LA=.15,GA=.5,$A=50,VA=250,Gg={threshold(n=0){return da(n)},rubberband(n=0){switch(n){case!0:return da(LA);case!1:return da(0);default:return da(n)}},enabled(n=!0){return n},triggerAllEvents(n=!1){return n},initial(n=0){return typeof n=="function"?n:da(n)},transform:!0},Ad={...Gg,axis:!0,lockDirection(n=!1){return n},bounds(n={}){if(typeof n=="function")return o=>Ad.bounds(n(o));const{left:e=-1/0,right:t=1/0,top:a=-1/0,bottom:i=1/0}=n;return[[e,t],[a,i]]}},HA=typeof window<"u"&&window.document&&window.document.createElement,WA={enabled(n=!0){return n},domTarget:!0,window(n=HA?window:void 0){return n},eventOptions({passive:n=!0,capture:e=!1}={}){return{passive:n,capture:e}},transform:!0},UA={...Gg,bounds(n,e,{distanceBounds:t={},angleBounds:a={}}){const i=s=>{const r=Zu(Cr(t,s),{min:-1/0,max:1/0});return[r.min,r.max]},o=s=>{const r=Zu(Cr(a,s),{min:-1/0,max:1/0});return[r.min,r.max]};return typeof t!="function"&&typeof a!="function"?[i(),o()]:s=>[i(s),o(s)]}},KA={...Ad,useTouch(n=!0){return n&&Ig()},preventWindowScrollY(n=!1){return n},threshold(n,e,{filterTaps:t=!1,lockDirection:a=!1,axis:i=void 0}){const o=da(n,t?3:a||i?1:0);return this.filterTaps=t,o},swipeVelocity(n=GA){return da(n)},swipeDistance(n=$A){return da(n)},swipeDuration(n=VA){return n},delay(n=0){switch(n){case!0:return FA;case!1:return 0;default:return n}}};function hi(n){return Es(n,WA)}function zi(n={}){return Es(n,Ad)}function $g(n={}){return Es(n,UA)}function Vg(n={}){return Es(n,KA)}function JA({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.move=zi(i),o}function ZA({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.hover={enabled:!0,...i},o}function YA({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.drag=Vg(i),o}function XA({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.pinch=$g(i),o}function QA({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.scroll=zi(i),o}function eC({domTarget:n,eventOptions:e,window:t,enabled:a,...i}){const o=hi({domTarget:n,eventOptions:e,window:t,enabled:a});return o.wheel=zi(i),o}function tC(n,e=new Set){const{drag:t,wheel:a,move:i,scroll:o,pinch:s,hover:r,eventOptions:l,window:c,transform:h,domTarget:d,enabled:u}=n,m=hi({domTarget:d,eventOptions:l,transform:h,window:c,enabled:u});return e.has("onDrag")&&(m.drag=Vg(t)),e.has("onWheel")&&(m.wheel=zi(a)),e.has("onScroll")&&(m.scroll=zi(o)),e.has("onMove")&&(m.move=zi(i)),e.has("onPinch")&&(m.pinch=$g(s)),e.has("onHover")&&(m.hover={enabled:!0,...r}),m}function di(n,e,t={}){const a=nC(n),i=new AA(a);return i.config=e,i.handlers=n,i.nativeRefs=t,tb()&&!e.manual&&(bn(i.bind),nb(i.clean)),i}function nC(n){const e=new Set;return n.drag&&e.add(rt.get("drag")),n.wheel&&e.add(rt.get("wheel")),n.scroll&&e.add(rt.get("scroll")),n.move&&e.add(rt.get("move")),n.pinch&&e.add(rt.get("pinch")),n.hover&&e.add(rt.get("hover")),e}function Hg(n,e={}){rt.set("drag",Lg);const t=ee();return t.value||(t.value=no(YA,ao)),di({drag:n},t.value(e))}var aC=Object.defineProperty,iC=(n,e,t)=>e in n?aC(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,Tn=(n,e,t)=>(iC(n,typeof e!="symbol"?e+"":e,t),t);class Er extends Nl{constructor(){super(...arguments),Tn(this,"ingKey","moving"),Tn(this,"stateKey","move"),Tn(this,"debounced",!0),Tn(this,"onMove",e=>{this.enabled&&(this.setTimeout(this.onMoveEnd),this.state._active?this.onMoveChange(e):this.onMoveStart(e))}),Tn(this,"onMoveStart",e=>{this.updateSharedState(Ht(e));const t=Ii(e,this.transform);this.updateGestureState({...Wa(this,t,e),...et(this,e,!0)}),this.updateGestureState(this.getMovement(t)),this.fireGestureHandler()}),Tn(this,"onMoveChange",e=>{this.updateSharedState(Ht(e));const t=Ii(e,this.transform);this.updateGestureState({...et(this,e),...this.getKinematics(t,e)}),this.fireGestureHandler()}),Tn(this,"onMoveEnd",()=>{if(this.clean(),!this.state._active)return;const e=this.state.values;this.updateGestureState(this.getMovement(e)),this.updateGestureState({velocities:[0,0],velocity:0,_active:!1}),this.fireGestureHandler()}),Tn(this,"hoverTransform",()=>this.controller.config.hover.transform||this.controller.config.transform),Tn(this,"onPointerEnter",e=>{if(this.controller.state.shared.hovering=!0,!!this.controller.config.enabled){if(this.controller.config.hover.enabled){const t=Ii(e,this.hoverTransform()),a={...this.controller.state.shared,...this.state,...et(this,e,!0),args:this.args,values:t,active:!0,hovering:!0};this.controller.handlers.hover({...a,...this.mapStateValues(a)})}"move"in this.controller.handlers&&this.onMoveStart(e)}}),Tn(this,"onPointerLeave",e=>{if(this.controller.state.shared.hovering=!1,"move"in this.controller.handlers&&this.onMoveEnd(),!this.controller.config.hover.enabled)return;const t=Ii(e,this.hoverTransform()),a={...this.controller.state.shared,...this.state,...et(this,e),args:this.args,values:t,active:!1};this.controller.handlers.hover({...a,...this.mapStateValues(a)})})}addBindings(e){"move"in this.controller.handlers&&Oe(e,"onPointerMove",this.onMove),"hover"in this.controller.handlers&&(Oe(e,"onPointerEnter",this.onPointerEnter),Oe(e,"onPointerLeave",this.onPointerLeave))}}class oC extends Fg{getInternalMovement(e,t){const a=t.values[1];let[i,o=a]=e,s=o-a,r=t.turns;return Math.abs(s)>270&&(r+=Ir(s)),Sd([i,o-360*r],t.initial)}getKinematics(e,t){const a=this.getMovement(e),i=(e[1]-a._movement[1]-this.state.initial[1])/360,o=t.timeStamp-this.state.timeStamp,{distance:s,velocity:r,...l}=qg(a.movement,a.delta,o);return{turns:i,...a,...l}}mapStateValues(e){return{da:e.values,vdva:e.velocities}}}var sC=Object.defineProperty,rC=(n,e,t)=>e in n?sC(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,xt=(n,e,t)=>(rC(n,typeof e!="symbol"?e+"":e,t),t);const lC=7,cC=260;class Wg extends oC{constructor(){super(...arguments),xt(this,"ingKey","pinching"),xt(this,"stateKey","pinch"),xt(this,"onPinchStart",e=>{Bg(this.controller,e);const t=this.controller.touchIds;if(!this.enabled||this.state._active&&this.state._pointerIds.every(s=>t.has(s))||t.size<2)return;const a=Array.from(t).slice(0,2),{values:i,origin:o}=Wu(e,a,this.transform);this.updateSharedState(Ht(e)),this.updateGestureState({...Wa(this,i,e),...et(this,e,!0),_pointerIds:a,cancel:this.onCancel,origin:o}),this.updateGestureState(this.getMovement(i)),this.fireGestureHandler()}),xt(this,"onPinchChange",e=>{const{canceled:t,_active:a}=this.state;if(t||!a||e.timeStamp===this.state.timeStamp)return;const i=Ht(e);this.updateSharedState(i);try{const{values:o,origin:s}=Wu(e,this.state._pointerIds,this.transform),r=this.getKinematics(o,e);this.updateGestureState({...et(this,e),...r,origin:s}),this.fireGestureHandler()}catch{this.onPinchEnd(e)}}),xt(this,"onPinchEnd",e=>{jg(this.controller,e);const t=xd(e);this.state._pointerIds.every(a=>!t.includes(a))||(this.clean(),this.state._active&&(this.updateGestureState({...et(this,e),...this.getMovement(this.state.values),_active:!1}),this.fireGestureHandler()))}),xt(this,"onCancel",()=>{this.state.canceled||(this.updateGestureState({_active:!1,canceled:!0}),this.fireGestureHandler())}),xt(this,"onGestureStart",e=>{if(!this.enabled)return;e.preventDefault();const t=Ju(e,this.transform);this.updateSharedState(Ht(e)),this.updateGestureState({...Wa(this,t,e),...et(this,e,!0),origin:[e.clientX,e.clientY],cancel:this.onCancel}),this.updateGestureState(this.getMovement(t)),this.fireGestureHandler()}),xt(this,"onGestureChange",e=>{const{canceled:t,_active:a}=this.state;if(t||!a)return;e.preventDefault();const i=Ht(e);this.updateSharedState(i);const o=Ju(e,this.transform);o[0]=(o[0]-this.state.event.scale)*cC+this.state.values[0];const s=this.getKinematics(o,e);this.updateGestureState({...et(this,e),...s,origin:[e.clientX,e.clientY]}),this.fireGestureHandler()}),xt(this,"onGestureEnd",e=>{this.clean(),this.state._active&&(this.updateGestureState({...et(this,e),...this.getMovement(this.state.values),_active:!1,origin:[e.clientX,e.clientY]}),this.fireGestureHandler())}),xt(this,"wheelShouldRun",e=>this.enabled&&e.ctrlKey),xt(this,"getWheelValuesFromEvent",e=>{const[,t]=Dg(e,this.transform),{values:[a,i]}=this.state;return{values:[a-t*lC,i!==void 0?i:0],origin:[e.clientX,e.clientY],delta:[0,t]}}),xt(this,"onWheel",e=>{this.wheelShouldRun(e)&&(this.setTimeout(this.onWheelEnd),this.state._active?this.onWheelChange(e):this.onWheelStart(e))}),xt(this,"onWheelStart",e=>{const{values:t,delta:a,origin:i}=this.getWheelValuesFromEvent(e);e.cancelable&&e.preventDefault(),this.updateSharedState(Ht(e)),this.updateGestureState({...Wa(this,t,e),...et(this,e,!0),initial:this.state.values,offset:t,delta:a,origin:i}),this.updateGestureState(this.getMovement(t)),this.fireGestureHandler()}),xt(this,"onWheelChange",e=>{e.cancelable&&e.preventDefault(),this.updateSharedState(Ht(e));const{values:t,origin:a,delta:i}=this.getWheelValuesFromEvent(e);this.updateGestureState({...et(this,e),...this.getKinematics(t,e),origin:a,delta:i}),this.fireGestureHandler()}),xt(this,"onWheelEnd",()=>{this.clean(),this.state._active&&(this.state._active=!1,this.updateGestureState(this.getMovement(this.state.values)),this.fireGestureHandler())})}addBindings(e){this.controller.config.domTarget&&!this.controller.supportsTouchEvents&&this.controller.supportsGestureEvents?(Oe(e,"onGestureStart",this.onGestureStart),Oe(e,"onGestureChange",this.onGestureChange),Oe(e,"onGestureEnd",this.onGestureEnd)):(Oe(e,"onTouchStart",this.onPinchStart),Oe(e,"onTouchMove",this.onPinchChange),Oe(e,"onTouchEnd",this.onPinchEnd),Oe(e,"onTouchCancel",this.onPinchEnd),Oe(e,"onWheel",this.onWheel))}}var hC=Object.defineProperty,dC=(n,e,t)=>e in n?hC(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,bo=(n,e,t)=>(dC(n,typeof e!="symbol"?e+"":e,t),t);class Ug extends Nl{constructor(){super(...arguments),bo(this,"ingKey","scrolling"),bo(this,"stateKey","scroll"),bo(this,"debounced",!0),bo(this,"handleEvent",e=>{if(!this.enabled)return;this.clearTimeout(),this.setTimeout(this.onEnd);const t=TA(e,this.transform);if(this.updateSharedState(Ht(e)),this.state._active)this.updateGestureState({...et(this,e),...this.getKinematics(t,e)});else{this.updateGestureState({...Wa(this,t,e),...et(this,e,!0),initial:this.state.values});const a=this.getMovement(t),i=Og(a.delta);this.updateGestureState(a),this.updateGestureState(i)}this.fireGestureHandler()}),bo(this,"onEnd",()=>{this.clean(),this.state._active&&(this.updateGestureState({...this.getMovement(this.state.values),_active:!1,velocities:[0,0],velocity:0}),this.fireGestureHandler())})}addBindings(e){Oe(e,"onScroll",this.handleEvent)}}var uC=Object.defineProperty,mC=(n,e,t)=>e in n?uC(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,vo=(n,e,t)=>(mC(n,typeof e!="symbol"?e+"":e,t),t);class Kg extends Nl{constructor(){super(...arguments),vo(this,"ingKey","wheeling"),vo(this,"stateKey","wheel"),vo(this,"debounced",!0),vo(this,"handleEvent",e=>{if(e.ctrlKey&&"pinch"in this.controller.handlers||!this.enabled)return;this.setTimeout(this.onEnd),this.updateSharedState(Ht(e));const t=Mr(Dg(e,this.transform),this.state.values);if(this.state._active)this.updateGestureState({...et(this,e),...this.getKinematics(t,e)});else{this.updateGestureState({...Wa(this,t,e),...et(this,e,!0),initial:this.state.values});const a=this.getMovement(t),i=Og(a.delta);this.updateGestureState(a),this.updateGestureState(i)}this.fireGestureHandler()}),vo(this,"onEnd",()=>{if(this.clean(),!this.state._active)return;const e=this.getMovement(this.state.values);this.updateGestureState(e),this.updateGestureState({_active:!1,velocities:[0,0],velocity:0}),this.fireGestureHandler()})}addBindings(e){Oe(e,"onWheel",this.handleEvent)}}const pC=/^on(Drag|Wheel|Scroll|Move|Pinch|Hover)/;function fC(n){const e={},t={},a=new Set;for(let i in n)pC.test(i)?(a.add(RegExp.lastMatch),t[i]=n[i]):e[i]=n[i];return[t,e,a]}function gC(n,e){const[t,a,i]=fC(n);rt.set("drag",Lg),rt.set("hover",Er),rt.set("move",Er),rt.set("pinch",Wg),rt.set("scroll",Ug),rt.set("wheel",Kg);const o=tC(e,i),s={};return i.has("onDrag")&&(s.drag=wo(t,"onDrag")),i.has("onWheel")&&(s.wheel=wo(t,"onWheel")),i.has("onScroll")&&(s.scroll=wo(t,"onScroll")),i.has("onMove")&&(s.move=wo(t,"onMove")),i.has("onPinch")&&(s.pinch=wo(t,"onPinch")),i.has("onHover")&&(s.hover=t.onHover),di(s,o,a)}function wo(n,e){const t=e+"Start",a=e+"End";return o=>{let s;return o.first&&t in n&&n[t](o),e in n&&(s=n[e](o)),o.last&&a in n&&n[a](o),s}}function yC(n,e={}){rt.set("hover",Er);const t=ee();return t.value||(t.value=no(ZA,ao)),di({hover:n},t.value(e))}function bC(n,e={}){rt.set("move",Er);const t=ee();return t.value||(t.value=no(JA,ao)),di({move:n},t.value(e))}function vC(n,e={}){rt.set("pinch",Wg);const t=ee();return t.value||(t.value=no(XA,ao)),di({pinch:n},t.value(e))}function wC(n,e={}){rt.set("scroll",Ug);const t=ee();return t.value||(t.value=no(QA,ao)),di({scroll:n},t.value(e))}function _C(n,e={}){rt.set("wheel",Kg);const t=ee();return t.value||(t.value=no(eC,ao)),di({wheel:n},t.value(e))}const io=(n,e)=>({created:n,unmounted:e,bind:n,unbind:e}),oo=n=>`Your v-${n} directive must have a handler specified as a value`,kC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("drag"));t.gestures||(t.gestures={});const o=Hg(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.drag=o},(t,a,i)=>{!t.gestures||!t.gestures.drag||t.gestures.drag.clean()}),TC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("move"));t.gestures||(t.gestures={});const o=bC(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.move=o},(t,a,i)=>{!t.gestures||!t.gestures.move||t.gestures.move.clean()}),xC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("hover"));t.gestures||(t.gestures={});const o=yC(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.hover=o},(t,a,i)=>{!t.gestures||!t.gestures.hover||t.gestures.hover.clean()}),SC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("pinch"));t.gestures||(t.gestures={});const o=vC(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.pinch=o},(t,a,i)=>{!t.gestures||!t.gestures.pinch||t.gestures.pinch.clean()}),AC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("wheel"));t.gestures||(t.gestures={});const o=_C(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.wheel=o},(t,a,i)=>{!t.gestures||!t.gestures.wheel||t.gestures.wheel.clean()}),CC=()=>io((t,a,i)=>{if(!a.value)throw new Error(oo("scroll"));t.gestures||(t.gestures={});const o=wC(a.value,{domTarget:t,manual:!0});o.bind(),t.gestures.drag=o},(t,a,i)=>{!t.gestures||!t.gestures.drag||t.gestures.drag.clean()}),MC={install(n,e){Object.entries({drag:kC,hover:xC,move:TC,pinch:SC,scroll:CC,wheel:AC}).forEach(([a,i])=>n.directive(a,i()))}},Cd=n=>(mt("data-v-5f41c603"),n=n(),pt(),n),IC=Cd(()=>v("div",{class:"i-ph-arrows-horizontal absolute text-10px top-14px opacity-70"},null,-1)),EC={viewBox:"0 0 100 120"},DC={stroke:"currentColor"},PC=Cd(()=>v("path",{d:"M25,90 a 45,45,1,1,1,50,0",fill:"none",stroke:"#9996","stroke-width":"8","stroke-linecap":"round"},null,-1)),NC=["stroke","stroke-dashoffset"],BC=["transform"],jC=Cd(()=>v("circle",{"stroke-width":"2",fill:"none",r:38,opacity:"0.6"},null,-1)),zC=[jC],RC={transform:"translate(50,50)","text-anchor":"middle","dominant-baseline":"middle",fill:"currentColor"},OC=["transform"],qC={transform:"translate(0,20)"},FC={class:"font-bold",transform:"translate(0,58)"},LC=45,GC={__name:"ControlRotary",props:{max:{type:Number,default:100},min:{type:Number,default:0},modelValue:{type:Number,default:50},step:{type:Number,default:1},param:{type:String,default:"param"},unit:{type:String,default:""},fixed:{type:Number,default:1},cc:{type:Number,default:0},channel:{type:Number,default:0}},emits:["update:modelValue"],setup(n,{emit:e}){const t=n,a=e,i=De({active:!1,internal:yt(0,0,100),initial:0,external:H(()=>c(i.internal))});bn(()=>{i.initial=l(t.modelValue)});const o=Jf({param:t.param,number:t.cc,channel:t.channel});de(o,u=>{i.internal=u*100,a("update:modelValue",i.external)});const s=ee();gC({onDrag({delta:[u,m],dragging:p,shiftKey:g}){i.active=p;let y=g?12:2;i.internal-=m/y,i.internal+=u/y,a("update:modelValue",i.external)},onWheel({delta:[u,m],dragging:p,shiftKey:g,event:y}){i.active=p,y.preventDefault();let b=g?12:8;i.internal+=m/b,i.internal-=u/b,a("update:modelValue",i.external)}},{drag:{preventWindowScrollY:!0},wheel:{preventWindowScrollY:!0},eventOptions:{capture:!1,passive:!1},domTarget:s}),dn(()=>{i.internal=l(t.modelValue)});function r(){i.internal=i.initial,a("update:modelValue",i.external)}function l(u){return h(u,t.min,t.max,0,100,t.step)}function c(u){return Math.round(h(u,0,100,t.min,t.max,t.step)/t.step)*t.step}function h(u,m=0,p=100,g=0,y=100,b=1){return(u-m)*(y-g)/(p-m)+g}const d=Math.PI*2*LC-50;return(u,m)=>(_(),T("div",{class:"knob",ref_key:"knob",ref:s,onDblclick:m[0]||(m[0]=p=>r())},[IC,(_(),T("svg",EC,[v("g",DC,[PC,v("path",{d:"M25,90 a 45,45,1,1,1,50,0",fill:"none",stroke:`hsla(${i.internal*3.6}deg,70%,50%,0.8)`,"stroke-width":"12","stroke-linecap":"round","stroke-dasharray":d,"stroke-dashoffset":d-d*(i.internal/100)},null,8,NC),v("g",{transform:`translate(50,52.5) rotate(${i.internal*2.9}) `},zC,8,BC)]),v("g",RC,[v("text",{class:"font-bold text-2xl",transform:`translate(0,${n.unit?-3:5})`},[En(u.$slots,"default",{},()=>[v("tspan",null,K(n.modelValue.toFixed(n.fixed)),1)],!0)],8,OC),v("text",qC,[v("tspan",null,K(n.unit),1)]),v("text",FC,[v("tspan",null,K(n.param.toUpperCase()),1)])])]))],544))}},Jg=Fe(GC,[["__scopeId","data-v-5f41c603"]]),$C={class:"py-2 px-1"},VC={class:"text-md"},HC={class:"text-sm"},WC={__name:"ControlKnob",props:{max:{type:Number,default:100},min:{type:Number,default:0},modelValue:{type:Number,default:50},step:{type:Number,default:1},param:{type:String,default:"param"},unit:{type:String,default:""},fixed:{type:Number,default:1},cc:{type:Number,default:0},channel:{type:Number,default:0}},emits:["update:modelValue"],setup(n,{emit:e}){const t=n,a=e,i=ee();Hg(u=>{r(u)},{domTarget:i,preventWindowScrollY:!0});const o=De({active:!1,internal:0,initial:0,external:H(()=>h(o.internal))}),s=Jf({number:t.cc,channel:t.channel});de(s,u=>{o.internal=u*100,a("update:modelValue",o.external)});function r(u){const{delta:[m,p],dragging:g,shiftKey:y}=u;o.active=g;let b=y?12:4;o.internal-=p/b,o.internal+=m/b,o.internal>100&&(o.internal=100),o.internal<0&&(o.internal=0),a("update:modelValue",o.external)}dn(()=>{o.internal=c(t.modelValue)});function l(){o.internal=o.initial,a("update:modelValue",o.external)}function c(u){return d(u,t.min,t.max,0,100,t.step)}function h(u){return d(u,0,100,t.min,t.max,t.step)}function d(u,m=0,p=100,g=0,y=100,b=1){y=Number(y),g=Number(g),p=Number(p),m=Number(m);let x=(u-m)*(y-g)/(p-m)+g;return Math.round(x/b)*b}return(u,m)=>(_(),T("div",{class:"knob",ref_key:"knob",ref:i,onDblclick:m[0]||(m[0]=p=>l())},[v("div",{class:"level",style:se({height:o.internal+"%"})},null,4),v("div",$C,[v("div",VC,K(n.modelValue.toFixed(n.fixed))+K(n.unit),1),v("div",HC,K(n.param.toUpperCase()),1)])],544))}},Zg=Fe(WC,[["__scopeId","data-v-891dc91f"]]),UC=["viewBox","stroke-width"],KC=["r","stroke"],JC={__name:"BeatMove",props:{color:String,progress:Number,size:{type:Number,default:10},stroke:{type:Number,default:2}},setup(n){const e=n,t=H(()=>e.size/2-1),a=H(()=>t.value*Math.PI*2);return(i,o)=>(_(),T("svg",{version:"1.1",baseProfile:"full",viewBox:`${-n.size/2} ${-n.size/2} ${n.size} ${n.size}`,xmlns:"http://www.w3.org/2000/svg","stroke-width":n.stroke},[v("circle",{r:t.value,fill:"none",stroke:n.color,transform:"rotate(-90)",style:se({strokeDasharray:`${a.value/2}, ${a.value/2}`,strokeDashoffset:1.5*a.value-n.progress*a.value})},null,12,KC)],8,UC))}},Ea=n=>(mt("data-v-9daa55b3"),n=n(),pt(),n),ZC={class:"flex flex-col w-full mx-auto justify-center gap-2"},YC={class:"tempo-grid text-xl"},XC=["transform"],QC={key:0,class:"i-la-play"},eM={key:1,class:"i-la-pause"},tM=Ea(()=>v("div",{class:"i-la-stop"},null,-1)),nM=[tM],aM=Ea(()=>v("div",{class:"i-la-minus"},null,-1)),iM=[aM],oM=Ea(()=>v("div",{class:"i-la-plus"},null,-1)),sM=[oM],rM=Ea(()=>v("div",{class:"i-la-slash"},null,-1)),lM=[rM],cM=Ea(()=>v("div",{class:"i-la-times"},null,-1)),hM=[cM],dM={class:"font-bold font-mono flex-1 -mt-4 flex justify-center items-end",style:{"font-variant-numeric":"tabular-nums"}},uM={class:"text-4xl"},mM={class:"m-0"},pM=Ea(()=>v("div",{class:"text-sm mt-1px ml-1 absolute bottom-3"},"BPM",-1)),fM={class:"text-4xl font-bold"},gM={class:"flex-1 -mt-2 font-bold font-mono"},yM=Ea(()=>v("div",{class:"text-sm mt-1px absolute bottom-3"},"Hz",-1)),bM=Ea(()=>v("div",{class:"i-fluent-tap-double-20-regular mt-1"},null,-1)),vM=[bM],wM={key:0,class:"font-bold"},_M={key:1,class:"opacity-40"},kM={key:0,class:"i-tabler-ear"},TM={key:1,class:"i-tabler-ear-off"},xM={key:0,class:"font-bold"},SM={key:1,class:"opacity-40"},AM={class:"flex font-mono text-sm gap-4"},CM={class:"flex-1"},MM={class:"flex-1"},IM={__name:"StateTransport",props:{secondary:Boolean},setup(n){const e=vg(),{init:t,tuner:a}=Cg();function i(o){e.bpm+=(o.delta[0]-o.delta[1])/16}return(o,s)=>{const r=JC,l=Zg,c=pn("tooltip"),h=pn("drag");return _(),T("div",ZC,[v("div",YC,[F((_(),T("button",{class:"relative overflow-hidden",style:se([{"grid-area":"CLICK"},{color:f(e).blink?f(e).color:"currentColor"}]),onClick:s[0]||(s[0]=d=>f(e).mute=!f(e).mute),"aria-label":"Toggle metronome"},[v("div",{class:"i-mdi-metronome z-4",style:se([{transition:"all 300ms ease-out"},{opacity:f(e).mute?.3:1}]),transform:`scale(${!f(e).mute&&f(e).blink?1.1:1})`},null,12,XC),Q(r,{class:"opacity-30 z-2 absolute top-0 bottom-0 w-full h-full",progress:f(e).progress,color:f(e).color,stroke:10},null,8,["progress","color"])],4)),[[c,"Toggle metronome",void 0,{top:!0}]]),F((_(),T("button",{style:{"grid-area":"PLAY"},onClick:s[1]||(s[1]=d=>f(e).playing=!f(e).playing)},[f(e).playing?(_(),T("div",eM)):(_(),T("div",QC))])),[[c,"Play",void 0,{top:!0}]]),F((_(),T("button",{style:{"grid-area":"STOP"},onClick:s[2]||(s[2]=d=>f(e).stopped=Date.now())},nM)),[[c,"Stop",void 0,{bottom:!0}]]),F((_(),T("button",{style:{"grid-area":"MINUS"},onClick:s[3]||(s[3]=d=>f(e).set(-1))},iM)),[[c,"Subtract 1 BPM",void 0,{bottom:!0}]]),F((_(),T("button",{style:{"grid-area":"PLUS"},onClick:s[4]||(s[4]=d=>f(e).set(1))},sM)),[[c,"Add 1 BPM",void 0,{bottom:!0}]]),F((_(),T("button",{style:{"grid-area":"DIVIDE"},onClick:s[5]||(s[5]=d=>f(e).set(-f(e).bpm/2))},lM)),[[c,"Half speed",void 0,{top:!0}]]),F((_(),T("button",{style:{"grid-area":"MULTIPLY"},onClick:s[6]||(s[6]=d=>f(e).set(f(e).bpm))},hM)),[[c,"Double speed",void 0,{top:!0}]]),F((_(),T("button",{class:ae(["relative touch-none text-center flex",{active:f(a).blink}]),style:se([{"grid-area":"BPM"},{borderColor:f(e).blink?f(e).color:"currentColor"}])},[v("div",dM,[v("div",uM,K(f(e).bpm.toFixed(0)),1),v("div",mM,K((f(e).bpm-Math.floor(f(e).bpm)).toFixed(1).substring(1)),1)]),pM],6)),[[h,i]]),F((_(),T("button",{class:"relative flex flex-col gap-2 touch-none",style:se([{"grid-area":"Hz"},{color:f(e).color,borderColor:f(e).color}])},[v("div",fM,K(f(e).note),1),v("div",gM,K(f(e).hz),1),yM],4)),[[h,i],[c,"Tempo frequency and pitch class",void 0,{top:!0}]]),F(Q(l,{class:"font-bold w-full",style:{"grid-area":"NOTE"},modelValue:f(e).volume,"onUpdate:modelValue":s[7]||(s[7]=d=>f(e).volume=d),min:0,max:1,step:.01,param:"VOL",cc:16},null,8,["modelValue"]),[[c,"Metronome volume",void 0,{top:!0}]]),F((_(),T("button",{style:{"grid-area":"TAP"},onMousedown:s[8]||(s[8]=nr(d=>f(Xs)(),["stop","prevent"])),onTouchstart:s[9]||(s[9]=nr(d=>f(Xs)(),["stop","prevent"])),class:ae({active:f(e).tap.last})},vM,34)),[[c,"Tap tempo",void 0,{bottom:!0}]]),F((_(),T("button",{style:{"grid-area":"TAPPED"},onClick:s[10]||(s[10]=d=>f(e).tap.bpm&&f(e).tap.last?f(e).bpm=f(e).tap.bpm:f(Xs)())},[f(e).tap.bpm&&f(e).tap.last?(_(),T("div",wM,K(f(e).tap.bpm.toFixed(1)),1)):(_(),T("div",_M,"TAP"))])),[[c,"Click to set tap tempo",void 0,{bottom:!0}]]),F((_(),T("button",{style:{"grid-area":"GUESS"},onClick:s[11]||(s[11]=d=>f(a).initiated?f(a).listen=!f(a).listen:f(t)())},[f(a).listen?(_(),T("div",TM)):(_(),T("div",kM))])),[[c,"Guess tempo from audio",void 0,{top:!0}]]),F((_(),T("button",{class:ae(["duration-100",{active:f(a).blink}]),style:{"grid-area":"GUESSED"},onClick:s[12]||(s[12]=d=>f(a).initiated?f(a).listen&&f(a).bpm?f(e).bpm=f(a).bpm:f(a).listen=!0:f(t)())},[f(a).listen?(_(),T("div",xM,K(f(a).bpm.toFixed(0)),1)):(_(),T("div",SM,"GUESS"))],2)),[[c,"Click to set guessed tempo",void 0,{top:!0}]])]),v("div",AM,[v("div",CM,"POS "+K(f(e).position),1),v("div",MM,"TICK "+K(f(e).ticks),1)])])}}},EM=Fe(IM,[["__scopeId","data-v-9daa55b3"]]),DM={style:{"vertical-align":"middle"},viewBox:"0 0 32 32",width:"1.2em",height:"1.2em"},PM=v("path",{fill:"currentColor",d:"m13.188 3l-.157.813l-.594 2.968a9.939 9.939 0 0 0-2.593 1.532l-2.906-1l-.782-.25l-.406.718l-2 3.438l-.406.719l.594.53l2.25 1.97C6.104 14.948 6 15.46 6 16s.105 1.05.188 1.563l-2.25 1.968l-.594.532l.406.718l2 3.438l.406.718l.782-.25l2.906-1a9.939 9.939 0 0 0 2.594 1.532l.593 2.968l.156.813h5.626l.156-.813l.593-2.968a9.939 9.939 0 0 0 2.594-1.532l2.907 1l.78.25l.407-.718l2-3.438l.406-.718l-.593-.532l-2.25-1.968C25.895 17.05 26 16.538 26 16c0-.54-.105-1.05-.188-1.563l2.25-1.968l.594-.531l-.406-.72l-2-3.437l-.406-.718l-.782.25l-2.906 1a9.939 9.939 0 0 0-2.593-1.532l-.594-2.968L18.812 3zm1.624 2h2.376l.5 2.594l.125.593l.562.188a8.017 8.017 0 0 1 3.031 1.75l.438.406l.562-.187l2.532-.875l1.187 2.031l-2 1.781l-.469.375l.157.594c.128.57.187 1.152.187 1.75c0 .598-.059 1.18-.188 1.75l-.125.594l.438.375l2 1.781l-1.188 2.031l-2.53-.875l-.563-.187l-.438.406a8.017 8.017 0 0 1-3.031 1.75l-.563.188l-.125.593l-.5 2.594h-2.375l-.5-2.594l-.124-.593l-.563-.188a8.017 8.017 0 0 1-3.031-1.75l-.438-.406l-.562.187l-2.531.875L5.875 20.5l2-1.781l.469-.375l-.156-.594A7.901 7.901 0 0 1 8 16c0-.598.059-1.18.188-1.75l.156-.594l-.469-.375l-2-1.781l1.188-2.031l2.53.875l.563.187l.438-.406a8.017 8.017 0 0 1 3.031-1.75l.563-.188l.124-.593zM16 11c-2.75 0-5 2.25-5 5s2.25 5 5 5s5-2.25 5-5s-2.25-5-5-5m0 2c1.668 0 3 1.332 3 3s-1.332 3-3 3s-3-1.332-3-3s1.332-3 3-3"},null,-1),NM=[PM];function BM(n,e){return _(),T("svg",DM,[...NM])}const jM={name:"la-cog",render:BM},zM={style:{"vertical-align":"middle"},viewBox:"0 0 32 32",width:"1.2em",height:"1.2em"},RM=v("path",{fill:"currentColor",d:"M13 4c-1.094 0-2 .906-2 2v12c0 1.094.906 2 2 2h6c1.094 0 2-.906 2-2V6c0-1.094-.906-2-2-2zm0 2h6v12h-6zm-6 8v4c0 3.3 2.7 6 6 6h2v2h-4v2h10v-2h-4v-2h2c3.3 0 6-2.7 6-6v-4h-2v4c0 2.219-1.781 4-4 4h-6c-2.219 0-4-1.781-4-4v-4z"},null,-1),OM=[RM];function qM(n,e){return _(),T("svg",zM,[...OM])}const FM={name:"la-microphone",render:qM},Fn=n=>(mt("data-v-24cf6503"),n=n(),pt(),n),LM={class:"max-h-80vh relative flex items-center flex-col justify-center"},GM=Fn(()=>v("div",{class:"i-la-copy text-xl"},null,-1)),$M=Fn(()=>v("div",{class:"p-0"},"COPY",-1)),VM=[GM,$M],HM={key:1,class:"absolute opacity-50 hover-opacity-100 transition bottom-0 right-5 flex items-center gap-1 bg-light-100 dark-bg-dark-100 rounded-xl shadow-lg","aria-label":"Paste custom schema"},WM=Fn(()=>v("div",{class:"i-la-paste text-xl absolute ml-1"},null,-1)),UM=["viewBox"],KM=Fn(()=>v("defs",null,[v("filter",{id:"shadow"},[v("feDropShadow",{dx:"0",dy:"0",stdDeviation:"8","flood-opacity":"0.3"})]),v("filter",{id:"blur",x:"-1",y:"-1",width:"300",height:"300"},[v("feGaussianBlur",{i:"",n:"SourceGraphic",stdDeviation:20})]),v("filter",{id:"blur-less",x:"-1",y:"-1",width:"300",height:"300"},[v("feGaussianBlur",{i:"",n:"SourceGraphic",stdDeviation:15})])],-1)),JM=["transform"],ZM=["onMousedownPassive","onMouseupPassive","onTouchstart","onTouchend","onMouseleave"],YM=["transform","fill","opacity"],XM=Fn(()=>v("path",{d:"M 0,0 a 30,30,0,0,0,25,-20 l 70 -260 a 120,120,0,0,0,2,-20 a 100,100,0,0,0,-200,0 a 120,120,0,0,0,2,20 l 70,260 a 30,30,0,0,0,25,20z"},null,-1)),QM=[XM],eI=["transform","onClick"],tI=["fill","opacity"],nI=Fn(()=>v("g",{"stroke-width":"4","stroke-linecap":"round"},[v("line",{stroke:"black",x1:"-10",y1:"-10",x2:"10",y2:"10"}),v("line",{stroke:"black",x1:"10",y1:"-10",x2:"-10",y2:"10"})],-1)),aI=["transform"],iI={x:"10",y:"10",width:"100",height:"100"},oI=["onUpdate:modelValue"],sI=["transform"],rI=["fill","r"],lI={key:0},cI=["fill","r"],hI=["font-size","fill"],dI={dy:"5","text-anchor":"middle","dominant-baseline":"middle"},uI={class:"spiral pointer-events-none"},mI=["x1","y1","x2","y2","stroke"],pI=["cx","cy","fill"],fI={class:"controls"},gI=Fn(()=>v("circle",{class:"transition",r:"32",cy:"-68",fill:"#3331"},null,-1)),yI={key:1,class:"tuner transition","aria-label":"Calculated fundamental frequency"},bI=["fill"],vI=Fn(()=>v("circle",{r:"32",cy:"70",fill:"#3333"},null,-1)),wI=["aria-label"],_I=Fn(()=>v("rect",{fill:"#0001",x:"-100",y:"-32",width:"200",height:"70",rx:"10"},null,-1)),kI={y:"6","font-size":"40",fill:"currentColor"},TI={key:1,class:"center"},xI=Fn(()=>v("circle",{r:"3",fill:"currentColor"},null,-1)),SI=[xI],AI={__name:"ChromaFlower",props:{letters:{type:Boolean,default:!0},size:{type:Number,default:1e3},pad:{type:Number,default:50}},setup(n){const e=n,t=H(()=>ua.map((u,m)=>({note:u,pitch:m,coord:o(m,.42),middle:o(m,.28),inside:o(m,.15)}))),a=Ti();bn(()=>{a.value=Cg()});function i(u){return u>a.value.tuner.chromaAvg?a.value.tuner.note.silent?0:u:0}H(()=>new Array(127).fill(null).map((u,m)=>(m+3)%12));function o(u=0,m=.5){return u2(u%12,12,e.size*m,0)}const s=ee();function r(u,m,p,g){s.value=!p,_r(t.value[u].note,u>=3?0:-1,p,g)}const{copy:l,copied:c}=ab(),h=ee(""),d=ee(null);return ib(h,u=>{try{let m=JSON.parse(u);if(m.length==12&&m.every(p=>Re(p).isValid()))Ye.custom=m,h.value="",Ye.customize=!1;else throw"Invalid scheme"}catch{d.value=!0,setTimeout(()=>d.value=null,1e3),console.error("Loaded color scheme is not valid")}}),(u,m)=>{var b,x,S,k,w,C,M;const p=FM,g=jM,y=pn("tooltip");return _(),T("div",LM,[f(Ye).customize?F((_(),T("button",{key:0,class:ae(["absolute opacity-50 hover-opacity-100 transition cursor-pointer bottom-0 left-5 flex items-center gap-1 bg-light-100 dark-bg-dark-100 rounded-xl p-2 shadow-lg",{customize:f(c)}]),"aria-label":"Copy custom schema",onClick:m[0]||(m[0]=A=>f(l)(JSON.stringify(f(Ye).custom)))},VM,2)),[[y,"Copy custom schema",void 0,{bottom:!0}]]):U("",!0),f(Ye).customize?F((_(),T("div",HM,[WM,F(v("input",{class:"w-25 p-2 pl-8 rounded-xl","onUpdate:modelValue":m[1]||(m[1]=A=>h.value=A),placeholder:"PASTE",style:se({backgroundColor:d.value?"red":""})},null,4),[[ar,h.value]])])),[[y,"Paste custom schema",void 0,{bottom:!0}]]):U("",!0),(_(),T("svg",{class:"w-full min-w-full",version:"1.1",baseProfile:"full",viewBox:`${-n.pad} ${-n.pad} ${n.size+2*n.pad} ${n.size+2*n.pad}`,xmlns:"http://www.w3.org/2000/svg","text-anchor":"middle","dominant-baseline":"middle"},[KM,v("g",{transform:`translate(${n.size/2}, ${n.size/2}) `},[(_(!0),T(ke,null,Me(t.value,(A,I)=>{var D,P;return _(),T("g",{class:"keys",key:A},[v("g",{class:"key cursor-pointer",onMousedownPassive:E=>{r(I)},onMouseupPassive:E=>r(I,E,!0),onTouchstart:nr(E=>r(I),["prevent","stop"]),onTouchend:nr(E=>r(I,E,!0),["prevent","stop"]),onMouseleave:E=>r(I,E,!0)},[v("g",{class:"petal",transform:`rotate(${I*30}) translate(2,-120) `,fill:A.note.length>1?"#222":"#eee",opacity:f(B).activeChromaMidi[I]?1:.9,style:{transition:"all 100ms ease-out"},filter:"url(#shadow)"},QM,8,YM),v("g",null,[f(Ye).custom[I]!=f(La)[I]?(_(),T("g",{key:0,class:"note select-none","stroke-width":"4","stroke-linecap":"round",transform:`translate(${A.inside.x}, ${A.inside.y})`,onClick:E=>f(Ye).custom[I]=f(La)[I]},[v("circle",{class:"transition",fill:f(La)[I],r:"20",opacity:f(Ye).customize?1:.1},null,8,tI),nI],8,eI)):U("",!0),f(Ye).customize?(_(),T("g",{key:1,class:"note select-none",transform:`translate(${A.middle.x-36}, ${A.middle.y-36})`},[(_(),T("foreignObject",iI,[F(v("input",{class:"h-30 w-30 rounded-xl",type:"color","onUpdate:modelValue":E=>f(Ye).custom[I]=E},null,8,oI),[[ar,f(Ye).custom[I]]])]))],8,aI)):U("",!0)]),v("g",{class:"note select-none",transform:`translate(${A.coord.x}, ${A.coord.y})`},[v("circle",{style:{transition:"all 100ms ease-out"},fill:f(Ve)(I,f(B).activeChromaMidi[I]?4:3),r:n.size/12},null,8,rI),(P=(D=a.value)==null?void 0:D.tuner)!=null&&P.initiated?(_(),T("g",lI,[v("circle",{style:{transition:"all 80ms ease-out"},fill:f(Ve)(I,7,2,i(a.value.tuner.aChroma[I])),r:n.size/12,filter:"url(#blur)"},null,8,cI)])):U("",!0),n.letters?(_(),T("text",{key:1,class:"transition","font-size":n.size/20,"font-weight":"bold",fill:f(B).activeChromaMidi[I]?"black":"white"},[v("tspan",dI,K(A.note),1)],8,hI)):U("",!0)],8,sI)],40,ZM)])}),128)),v("g",uI,[(_(!0),T(ke,null,Me(f(B).activeNotes,(A,I)=>(_(),T("g",{class:"interval",key:I},[Q(dc,{name:"fade"},{default:Ge(()=>[(_(!0),T(ke,null,Me(f(B).activeNotes,(D,P)=>(_(),T("line",{key:P,x1:o((I-9)%12,I/700+.145).x,y1:o((I-9)%12,I/700+.145).y,x2:o((P-9)%12,P/700+.145).x,y2:o((P-9)%12,P/700+.145).y,stroke:f(Re)(f(Ve)(I-9,2)).mix(f(Ve)(P-9,2)).toHex(),"stroke-width":"20","stroke-linecap":"round",style:se({filter:`drop-shadow(0px 0px 4px ${f(Re)(f(Ve)(I-9,3)).mix(f(Ve)(P-9,3)).alpha(.5).toHex()}`})},null,12,mI))),128))]),_:2},1024)]))),128)),Q(dc,{name:"fade"},{default:Ge(()=>[(_(!0),T(ke,null,Me(f(B).activeNotes,(A,I)=>(_(),T("g",{class:"note",key:I},[v("circle",{style:{transition:"all 100ms ease-out"},cx:o((I-9)%12,I/700+.145).x,cy:o((I-9)%12,I/700+.145).y,fill:f(Ye).custom[(I-9)%12],r:12},null,8,pI)]))),128))]),_:1})]),v("g",fI,[(b=a.value)!=null&&b.tuner&&!a.value.tuner.initiated?F((_(),T("g",{key:0,class:"mic transition cursor-pointer opacity-40 hover-opacity-100","aria-label":"Start input audio analysis",onClick:m[2]||(m[2]=A=>a.value.init())},[gI,Q(p,{"font-size":"42",x:"-25",y:"-90"})])),[[y,"Start input audio analysis",void 0,{top:!0}]]):U("",!0),(S=(x=a.value)==null?void 0:x.tuner)!=null&&S.initiated?(_(),T("g",yI,[v("circle",{class:"transition",filter:"url(#blur)",style:{transition:"all 500ms ease"},r:"32",cy:"0",fill:!((k=a.value.tuner.note)!=null&&k.silent)&&a.value.tuner.initiated?f(Ve)((a.value.tuner.note.value+3)%12,4):"transparent"},null,8,bI),(C=(w=a.value)==null?void 0:w.tuner)!=null&&C.initiated?F((_(),T("text",{key:0,class:"opacity-50 select-none",y:"-67","font-size":"28",fill:"currentColor"},K(a.value.tuner.note.name),513)),[[bt,!((M=a.value.tuner.note)!=null&&M.silent)]]):U("",!0)])):U("",!0),F((_(),T("g",{class:"customize opacity-20 hover-opacity-100 transition cursor-pointer",onClick:m[3]||(m[3]=A=>f(Ye).customize=!f(Ye).customize),"aria-label":"Customize colors sitewide"},[vI,Q(g,{"font-size":"42",x:"-25",y:"44",class:ae({customize:f(Ye).customize})},null,8,["class"])])),[[y,"Customize colors",void 0,{top:!0}]])]),f(B).guessChords[0]?F((_(),T("g",{key:0,class:"chord cursor-pointer","aria-label":"Guessed chord: "+f(B).guessChords[0],onClick:m[4]||(m[4]=A=>f(l)(f(B).guessChords[0]))},[_I,v("text",kI,K(f(B).guessChords[0]),1)],8,wI)),[[y,f(B).guessChords.length>1&&"or "+f(B).guessChords.slice(1).join(", ")||f(c)?"Copied!":"Click to copy",void 0,{top:!0}]]):(_(),T("g",TI,SI))],8,JM)],8,UM))])}}},CI=Fe(AI,[["__scopeId","data-v-24cf6503"]]),MI=n=>(mt("data-v-01994688"),n=n(),pt(),n),II={class:"flex is-group p-2 items-center flex-wrap justify-between"},EI={class:"flex flex-col gap-1"},DI=MI(()=>v("div",{class:"font-bold mr-2"},"Channel filter",-1)),PI={class:"grid grid-cols-8"},NI=["onClick"],BI={__name:"MidiFilterChannels",setup(n){function e(){let t=B.filter[1];for(let a=1;a<=16;a++)B.filter[a]=!t;t&&hd()}return(t,a)=>(_(),T("div",II,[v("div",EI,[DI,v("div",{class:"channel filtered flex items-center justify-center",onClick:a[0]||(a[0]=i=>e())},"TOGGLE ALL")]),v("div",PI,[(_(),T(ke,null,Me(16,i=>v("div",{class:ae(["channel",{filtered:!f(B).filter[i],active:f(B).note.channel==i}]),key:i,onClick:o=>f(B).filter[i]=!f(B).filter[i]},K(i),11,NI)),64))])]))}},jI=Fe(BI,[["__scopeId","data-v-01994688"]]),Tt=n=>(mt("data-v-bc8e288d"),n=n(),pt(),n),zI={class:"layer w-full z-40 flex flex-col"},RI={key:0,class:"p-2 border border-red-500 text-red-500 flex flex-wrap gap-2 w-full"},OI=Tt(()=>v("a",{class:"font-normal underline",href:"https://caniuse.com/?search=midi",target:"_blank"},"use a compatible browser",-1)),qI=Tt(()=>v("span",null,"or ",-1)),FI=Tt(()=>v("a",{class:"font-normal underline",href:"https://apps.apple.com/ru/app/web-midi-browser/id953846217",target:"_blank"},"Web MIDI Browser on iOS",-1)),LI=Tt(()=>v("span",null,"or ",-1)),GI=Tt(()=>v("div",{class:"font-normal text-dark-200 dark-text-light-100"},"just use your PC keyboard",-1)),$I={key:1,class:"flex flex-col gap-1 justify-center flex-wrap bg-light-400 dark-bg-dark-400"},VI={class:"flex is-group"},HI={class:"flex m-2"},WI={class:"font-normal p-2 border border-green-500 text-green-500 select-none rounded-lg",href:"/practice/midi/monitor/"},UI={key:0},KI={key:1},JI={class:"flex"},ZI={class:"is-group flex"},YI={key:0,class:"i-la-play"},XI={key:1,class:"i-la-pause"},QI=Tt(()=>v("div",{class:"i-la-stop"},null,-1)),eE=[QI],tE={class:"w-2em"},nE={class:"flex-1"},aE={class:"is-group flex flex-wrap"},iE={class:"text-button border"},oE={class:"flex flex-wrap is-group"},sE=Tt(()=>v("div",{class:"i-tabler-keyboard"},null,-1)),rE=Tt(()=>v("div",{class:"m-0"},"PC keyboard",-1)),lE=[sE,rE],cE=Tt(()=>v("div",{class:"i-fad-midiplug"},null,-1)),hE=Tt(()=>v("div",{class:"m-0"},"MIDI OUT",-1)),dE=[cE,hE],uE=Tt(()=>v("div",{class:"i-la-clock"},null,-1)),mE=Tt(()=>v("div",{class:"m-0"},"CLOCK OUT",-1)),pE=[uE,mE],fE=Tt(()=>v("div",{class:"i-la-sync"},null,-1)),gE=Tt(()=>v("div",{class:"m-0"},"SYNC TABS",-1)),yE=[fE,gE],bE={key:0,class:"i-bi-volume-up"},vE={key:1,class:"i-bi-volume-off"},wE=Tt(()=>v("div",{class:"m-0"},"MIDI Synth",-1)),_E={class:"flex-button"},kE=Tt(()=>v("span",null,"OUT CH",-1)),TE=["value"],xE={__name:"MidiPanel",setup(n){const e=vg(),{midi:t,stopAll:a,midiAttack:i,midiRelease:o}=cd();return navigator.userAgent.toLowerCase().indexOf("firefox")>-1,(s,r)=>{var h;const l=jI,c=pn("tooltip");return _(),T("div",zI,[f(t).enabled?(_(),T("div",$I,[v("div",VI,[v("div",HI,[v("a",WI,[f(t).available?(_(),T("span",UI,"MIDI ")):(_(),T("span",KI,"Plug in your MIDI device"))])]),v("div",JI,[v("div",ZI,[v("button",{class:"play text-button",onClick:r[0]||(r[0]=d=>f(t).playing=!f(t).playing)},[f(t).playing?(_(),T("div",XI)):(_(),T("div",YI))]),v("button",{class:"text-button border",onClick:r[1]||(r[1]=d=>f(a)())},eE)]),(h=f(t).note)!=null&&h._name?(_(),T("div",{key:0,class:"text-button items-center flex w-4em transition-all duration-50 cursor-pointer flex",onMousedown:r[2]||(r[2]=d=>f(i)(f(t).note)),onMouseup:r[3]||(r[3]=d=>f(o)(f(t).note)),style:se({borderColor:f(Ve)(f(t).note.pitch,f(t).note.octA),color:f(Ve)(f(t).note.pitch,f(t).note.octA)})},[v("div",tE,K(f(t).note._name),1),v("div",nE,K(f(t).note._accidental),1)],36)):U("",!0)])]),v("div",aE,[(_(!0),T(ke,null,Me(f(t).outputs,d=>(_(),T("button",iE,[v("span",null,K(d.name),1)]))),256))]),v("div",oE,[F((_(),T("button",{class:ae(["flex-button border opacity-30",{active:f(t).keyboard}]),onClick:r[4]||(r[4]=d=>f(t).keyboard=!f(t).keyboard),"aria-label":"Play MIDI with PC keyboard"},lE,2)),[[c,"Play MIDI with PC keyboard",void 0,{bottom:!0}]]),F((_(),T("button",{class:ae(["flex-button opacity-30",{active:f(t).out}]),onClick:r[5]||(r[5]=d=>f(t).out=!f(t).out)},dE,2)),[[c,"Output MIDI to external devices",void 0,{bottom:!0}]]),F((_(),T("button",{class:ae(["flex-button opacity-30",{active:f(e).midiClock}]),onClick:r[6]||(r[6]=d=>f(e).midiClock=!f(e).midiClock)},pE,2)),[[c,"Output MIDI CLOCK to external devices",void 0,{bottom:!0}]]),F((_(),T("button",{class:ae(["flex-button opacity-30",{active:f(e).tabSync}]),onClick:r[7]||(r[7]=d=>f(e).tabSync=!f(e).tabSync)},yE,2)),[[c,"Sync multiple tabs transpost",void 0,{bottom:!0}]]),F((_(),T("button",{class:ae(["flex-button border opacity-30",{active:f(oe).state.midi}]),onClick:r[8]||(r[8]=d=>f(oe).state.midi=!f(oe).state.midi)},[f(oe).state.midi?(_(),T("div",bE)):(_(),T("div",vE)),wE],2)),[[c,"Play synth on MIDI input",void 0,{bottom:!0}]]),F((_(),T("button",_E,[kE,F(v("select",{class:"bg-transparent text-xl font-bold","onUpdate:modelValue":r[9]||(r[9]=d=>f(t).channel=d)},[(_(),T(ke,null,Me(16,d=>v("option",{key:d,value:d},K(d),9,TE)),64))],512),[[xo,f(t).channel]])])),[[c,"Output MIDI channel",void 0,{bottom:!0}]])]),Q(l,{style:{flex:"1 1 100px"}}),En(s.$slots,"default",{class:"is-group mx-1 p-1"},void 0,!0)])):(_(),T("div",RI,[uc("MIDI is not available. Please "),OI,qI,FI,LI,GI]))])}}},SE=Fe(xE,[["__scopeId","data-v-bc8e288d"]]),AE={class:"iframe-container shadow-lg rounded-lg"},CE=["src"],ME={__name:"YoutubeEmbed",props:["video"],setup(n){return(e,t)=>(_(),T("div",AE,[v("iframe",{class:"overflow-hidden",loading:"lazy",src:`https://www.youtube-nocookie.com/embed/${n.video}`,title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,8,CE)]))}},IE=Fe(ME,[["__scopeId","data-v-3ee43710"]]),EE=["top","right","bottom","left"],nm=["start","end"],am=EE.reduce((n,e)=>n.concat(e,e+"-"+nm[0],e+"-"+nm[1]),[]),es=Math.min,Na=Math.max,DE={left:"right",right:"left",bottom:"top",top:"bottom"},PE={start:"end",end:"start"};function Rc(n,e,t){return Na(n,es(e,t))}function ui(n,e){return typeof n=="function"?n(e):n}function zn(n){return n.split("-")[0]}function un(n){return n.split("-")[1]}function Yg(n){return n==="x"?"y":"x"}function Md(n){return n==="y"?"height":"width"}function Ds(n){return["top","bottom"].includes(zn(n))?"y":"x"}function Id(n){return Yg(Ds(n))}function Xg(n,e,t){t===void 0&&(t=!1);const a=un(n),i=Id(n),o=Md(i);let s=i==="x"?a===(t?"end":"start")?"right":"left":a==="start"?"bottom":"top";return e.reference[o]>e.floating[o]&&(s=Pr(s)),[s,Pr(s)]}function NE(n){const e=Pr(n);return[Dr(n),e,Dr(e)]}function Dr(n){return n.replace(/start|end/g,e=>PE[e])}function BE(n,e,t){const a=["left","right"],i=["right","left"],o=["top","bottom"],s=["bottom","top"];switch(n){case"top":case"bottom":return t?e?i:a:e?a:i;case"left":case"right":return e?o:s;default:return[]}}function jE(n,e,t,a){const i=un(n);let o=BE(zn(n),t==="start",a);return i&&(o=o.map(s=>s+"-"+i),e&&(o=o.concat(o.map(Dr)))),o}function Pr(n){return n.replace(/left|right|bottom|top/g,e=>DE[e])}function zE(n){return{top:0,right:0,bottom:0,left:0,...n}}function Qg(n){return typeof n!="number"?zE(n):{top:n,right:n,bottom:n,left:n}}function Do(n){return{...n,top:n.y,left:n.x,right:n.x+n.width,bottom:n.y+n.height}}function im(n,e,t){let{reference:a,floating:i}=n;const o=Ds(e),s=Id(e),r=Md(s),l=zn(e),c=o==="y",h=a.x+a.width/2-i.width/2,d=a.y+a.height/2-i.height/2,u=a[r]/2-i[r]/2;let m;switch(l){case"top":m={x:h,y:a.y-i.height};break;case"bottom":m={x:h,y:a.y+a.height};break;case"right":m={x:a.x+a.width,y:d};break;case"left":m={x:a.x-i.width,y:d};break;default:m={x:a.x,y:a.y}}switch(un(e)){case"start":m[s]-=u*(t&&c?-1:1);break;case"end":m[s]+=u*(t&&c?-1:1);break}return m}const RE=async(n,e,t)=>{const{placement:a="bottom",strategy:i="absolute",middleware:o=[],platform:s}=t,r=o.filter(Boolean),l=await(s.isRTL==null?void 0:s.isRTL(e));let c=await s.getElementRects({reference:n,floating:e,strategy:i}),{x:h,y:d}=im(c,a,l),u=a,m={},p=0;for(let g=0;g<r.length;g++){const{name:y,fn:b}=r[g],{x,y:S,data:k,reset:w}=await b({x:h,y:d,initialPlacement:a,placement:u,strategy:i,middlewareData:m,rects:c,platform:s,elements:{reference:n,floating:e}});if(h=x??h,d=S??d,m={...m,[y]:{...m[y],...k}},w&&p<=50){p++,typeof w=="object"&&(w.placement&&(u=w.placement),w.rects&&(c=w.rects===!0?await s.getElementRects({reference:n,floating:e,strategy:i}):w.rects),{x:h,y:d}=im(c,u,l)),g=-1;continue}}return{x:h,y:d,placement:u,strategy:i,middlewareData:m}};async function Bl(n,e){var t;e===void 0&&(e={});const{x:a,y:i,platform:o,rects:s,elements:r,strategy:l}=n,{boundary:c="clippingAncestors",rootBoundary:h="viewport",elementContext:d="floating",altBoundary:u=!1,padding:m=0}=ui(e,n),p=Qg(m),y=r[u?d==="floating"?"reference":"floating":d],b=Do(await o.getClippingRect({element:(t=await(o.isElement==null?void 0:o.isElement(y)))==null||t?y:y.contextElement||await(o.getDocumentElement==null?void 0:o.getDocumentElement(r.floating)),boundary:c,rootBoundary:h,strategy:l})),x=d==="floating"?{...s.floating,x:a,y:i}:s.reference,S=await(o.getOffsetParent==null?void 0:o.getOffsetParent(r.floating)),k=await(o.isElement==null?void 0:o.isElement(S))?await(o.getScale==null?void 0:o.getScale(S))||{x:1,y:1}:{x:1,y:1},w=Do(o.convertOffsetParentRelativeRectToViewportRelativeRect?await o.convertOffsetParentRelativeRectToViewportRelativeRect({rect:x,offsetParent:S,strategy:l}):x);return{top:(b.top-w.top+p.top)/k.y,bottom:(w.bottom-b.bottom+p.bottom)/k.y,left:(b.left-w.left+p.left)/k.x,right:(w.right-b.right+p.right)/k.x}}const OE=n=>({name:"arrow",options:n,async fn(e){const{x:t,y:a,placement:i,rects:o,platform:s,elements:r,middlewareData:l}=e,{element:c,padding:h=0}=ui(n,e)||{};if(c==null)return{};const d=Qg(h),u={x:t,y:a},m=Id(i),p=Md(m),g=await s.getDimensions(c),y=m==="y",b=y?"top":"left",x=y?"bottom":"right",S=y?"clientHeight":"clientWidth",k=o.reference[p]+o.reference[m]-u[m]-o.floating[p],w=u[m]-o.reference[m],C=await(s.getOffsetParent==null?void 0:s.getOffsetParent(c));let M=C?C[S]:0;(!M||!await(s.isElement==null?void 0:s.isElement(C)))&&(M=r.floating[S]||o.floating[p]);const A=k/2-w/2,I=M/2-g[p]/2-1,D=es(d[b],I),P=es(d[x],I),E=D,O=M-g[p]-P,j=M/2-g[p]/2+A,W=Rc(E,j,O),L=!l.arrow&&un(i)!=null&&j!=W&&o.reference[p]/2-(j<E?D:P)-g[p]/2<0,z=L?j<E?j-E:j-O:0;return{[m]:u[m]+z,data:{[m]:W,centerOffset:j-W-z,...L&&{alignmentOffset:z}},reset:L}}});function qE(n,e,t){return(n?[...t.filter(i=>un(i)===n),...t.filter(i=>un(i)!==n)]:t.filter(i=>zn(i)===i)).filter(i=>n?un(i)===n||(e?Dr(i)!==i:!1):!0)}const FE=function(n){return n===void 0&&(n={}),{name:"autoPlacement",options:n,async fn(e){var t,a,i;const{rects:o,middlewareData:s,placement:r,platform:l,elements:c}=e,{crossAxis:h=!1,alignment:d,allowedPlacements:u=am,autoAlignment:m=!0,...p}=ui(n,e),g=d!==void 0||u===am?qE(d||null,m,u):u,y=await Bl(e,p),b=((t=s.autoPlacement)==null?void 0:t.index)||0,x=g[b];if(x==null)return{};const S=Xg(x,o,await(l.isRTL==null?void 0:l.isRTL(c.floating)));if(r!==x)return{reset:{placement:g[0]}};const k=[y[zn(x)],y[S[0]],y[S[1]]],w=[...((a=s.autoPlacement)==null?void 0:a.overflows)||[],{placement:x,overflows:k}],C=g[b+1];if(C)return{data:{index:b+1,overflows:w},reset:{placement:C}};const M=w.map(D=>{const P=un(D.placement);return[D.placement,P&&h?D.overflows.slice(0,2).reduce((E,O)=>E+O,0):D.overflows[0],D.overflows]}).sort((D,P)=>D[1]-P[1]),I=((i=M.filter(D=>D[2].slice(0,un(D[0])?2:3).every(P=>P<=0))[0])==null?void 0:i[0])||M[0][0];return I!==r?{data:{index:b+1,overflows:w},reset:{placement:I}}:{}}}},LE=function(n){return n===void 0&&(n={}),{name:"flip",options:n,async fn(e){var t,a;const{placement:i,middlewareData:o,rects:s,initialPlacement:r,platform:l,elements:c}=e,{mainAxis:h=!0,crossAxis:d=!0,fallbackPlacements:u,fallbackStrategy:m="bestFit",fallbackAxisSideDirection:p="none",flipAlignment:g=!0,...y}=ui(n,e);if((t=o.arrow)!=null&&t.alignmentOffset)return{};const b=zn(i),x=zn(r)===r,S=await(l.isRTL==null?void 0:l.isRTL(c.floating)),k=u||(x||!g?[Pr(r)]:NE(r));!u&&p!=="none"&&k.push(...jE(r,g,p,S));const w=[r,...k],C=await Bl(e,y),M=[];let A=((a=o.flip)==null?void 0:a.overflows)||[];if(h&&M.push(C[b]),d){const E=Xg(i,s,S);M.push(C[E[0]],C[E[1]])}if(A=[...A,{placement:i,overflows:M}],!M.every(E=>E<=0)){var I,D;const E=(((I=o.flip)==null?void 0:I.index)||0)+1,O=w[E];if(O)return{data:{index:E,overflows:A},reset:{placement:O}};let j=(D=A.filter(W=>W.overflows[0]<=0).sort((W,L)=>W.overflows[1]-L.overflows[1])[0])==null?void 0:D.placement;if(!j)switch(m){case"bestFit":{var P;const W=(P=A.map(L=>[L.placement,L.overflows.filter(z=>z>0).reduce((z,Y)=>z+Y,0)]).sort((L,z)=>L[1]-z[1])[0])==null?void 0:P[0];W&&(j=W);break}case"initialPlacement":j=r;break}if(i!==j)return{reset:{placement:j}}}return{}}}};async function GE(n,e){const{placement:t,platform:a,elements:i}=n,o=await(a.isRTL==null?void 0:a.isRTL(i.floating)),s=zn(t),r=un(t),l=Ds(t)==="y",c=["left","top"].includes(s)?-1:1,h=o&&l?-1:1,d=ui(e,n);let{mainAxis:u,crossAxis:m,alignmentAxis:p}=typeof d=="number"?{mainAxis:d,crossAxis:0,alignmentAxis:null}:{mainAxis:0,crossAxis:0,alignmentAxis:null,...d};return r&&typeof p=="number"&&(m=r==="end"?p*-1:p),l?{x:m*h,y:u*c}:{x:u*c,y:m*h}}const $E=function(n){return n===void 0&&(n=0),{name:"offset",options:n,async fn(e){const{x:t,y:a}=e,i=await GE(e,n);return{x:t+i.x,y:a+i.y,data:i}}}},VE=function(n){return n===void 0&&(n={}),{name:"shift",options:n,async fn(e){const{x:t,y:a,placement:i}=e,{mainAxis:o=!0,crossAxis:s=!1,limiter:r={fn:y=>{let{x:b,y:x}=y;return{x:b,y:x}}},...l}=ui(n,e),c={x:t,y:a},h=await Bl(e,l),d=Ds(zn(i)),u=Yg(d);let m=c[u],p=c[d];if(o){const y=u==="y"?"top":"left",b=u==="y"?"bottom":"right",x=m+h[y],S=m-h[b];m=Rc(x,m,S)}if(s){const y=d==="y"?"top":"left",b=d==="y"?"bottom":"right",x=p+h[y],S=p-h[b];p=Rc(x,p,S)}const g=r.fn({...e,[u]:m,[d]:p});return{...g,data:{x:g.x-t,y:g.y-a}}}}},HE=function(n){return n===void 0&&(n={}),{name:"size",options:n,async fn(e){const{placement:t,rects:a,platform:i,elements:o}=e,{apply:s=()=>{},...r}=ui(n,e),l=await Bl(e,r),c=zn(t),h=un(t),d=Ds(t)==="y",{width:u,height:m}=a.floating;let p,g;c==="top"||c==="bottom"?(p=c,g=h===(await(i.isRTL==null?void 0:i.isRTL(o.floating))?"start":"end")?"left":"right"):(g=c,p=h==="end"?"top":"bottom");const y=m-l[p],b=u-l[g],x=!e.middlewareData.shift;let S=y,k=b;if(d){const C=u-l.left-l.right;k=h||x?es(b,C):C}else{const C=m-l.top-l.bottom;S=h||x?es(y,C):C}if(x&&!h){const C=Na(l.left,0),M=Na(l.right,0),A=Na(l.top,0),I=Na(l.bottom,0);d?k=u-2*(C!==0||M!==0?C+M:Na(l.left,l.right)):S=m-2*(A!==0||I!==0?A+I:Na(l.top,l.bottom))}await s({...e,availableWidth:k,availableHeight:S});const w=await i.getDimensions(o.floating);return u!==w.width||m!==w.height?{reset:{rects:!0}}:{}}}};function Zt(n){var e;return((e=n.ownerDocument)==null?void 0:e.defaultView)||window}function Mn(n){return Zt(n).getComputedStyle(n)}const om=Math.min,Po=Math.max,Nr=Math.round;function ey(n){const e=Mn(n);let t=parseFloat(e.width),a=parseFloat(e.height);const i=n.offsetWidth,o=n.offsetHeight,s=Nr(t)!==i||Nr(a)!==o;return s&&(t=i,a=o),{width:t,height:a,fallback:s}}function ka(n){return ny(n)?(n.nodeName||"").toLowerCase():""}let Hs;function ty(){if(Hs)return Hs;const n=navigator.userAgentData;return n&&Array.isArray(n.brands)?(Hs=n.brands.map(e=>e.brand+"/"+e.version).join(" "),Hs):navigator.userAgent}function In(n){return n instanceof Zt(n).HTMLElement}function ya(n){return n instanceof Zt(n).Element}function ny(n){return n instanceof Zt(n).Node}function sm(n){return typeof ShadowRoot>"u"?!1:n instanceof Zt(n).ShadowRoot||n instanceof ShadowRoot}function jl(n){const{overflow:e,overflowX:t,overflowY:a,display:i}=Mn(n);return/auto|scroll|overlay|hidden|clip/.test(e+a+t)&&!["inline","contents"].includes(i)}function WE(n){return["table","td","th"].includes(ka(n))}function Oc(n){const e=/firefox/i.test(ty()),t=Mn(n),a=t.backdropFilter||t.WebkitBackdropFilter;return t.transform!=="none"||t.perspective!=="none"||!!a&&a!=="none"||e&&t.willChange==="filter"||e&&!!t.filter&&t.filter!=="none"||["transform","perspective"].some(i=>t.willChange.includes(i))||["paint","layout","strict","content"].some(i=>{const o=t.contain;return o!=null&&o.includes(i)})}function ay(){return!/^((?!chrome|android).)*safari/i.test(ty())}function Ed(n){return["html","body","#document"].includes(ka(n))}function iy(n){return ya(n)?n:n.contextElement}const oy={x:1,y:1};function Ri(n){const e=iy(n);if(!In(e))return oy;const t=e.getBoundingClientRect(),{width:a,height:i,fallback:o}=ey(e);let s=(o?Nr(t.width):t.width)/a,r=(o?Nr(t.height):t.height)/i;return s&&Number.isFinite(s)||(s=1),r&&Number.isFinite(r)||(r=1),{x:s,y:r}}function ts(n,e,t,a){var i,o;e===void 0&&(e=!1),t===void 0&&(t=!1);const s=n.getBoundingClientRect(),r=iy(n);let l=oy;e&&(a?ya(a)&&(l=Ri(a)):l=Ri(n));const c=r?Zt(r):window,h=!ay()&&t;let d=(s.left+(h&&((i=c.visualViewport)==null?void 0:i.offsetLeft)||0))/l.x,u=(s.top+(h&&((o=c.visualViewport)==null?void 0:o.offsetTop)||0))/l.y,m=s.width/l.x,p=s.height/l.y;if(r){const g=Zt(r),y=a&&ya(a)?Zt(a):a;let b=g.frameElement;for(;b&&a&&y!==g;){const x=Ri(b),S=b.getBoundingClientRect(),k=getComputedStyle(b);S.x+=(b.clientLeft+parseFloat(k.paddingLeft))*x.x,S.y+=(b.clientTop+parseFloat(k.paddingTop))*x.y,d*=x.x,u*=x.y,m*=x.x,p*=x.y,d+=S.x,u+=S.y,b=Zt(b).frameElement}}return{width:m,height:p,top:u,right:d+m,bottom:u+p,left:d,x:d,y:u}}function ba(n){return((ny(n)?n.ownerDocument:n.document)||window.document).documentElement}function zl(n){return ya(n)?{scrollLeft:n.scrollLeft,scrollTop:n.scrollTop}:{scrollLeft:n.pageXOffset,scrollTop:n.pageYOffset}}function sy(n){return ts(ba(n)).left+zl(n).scrollLeft}function ns(n){if(ka(n)==="html")return n;const e=n.assignedSlot||n.parentNode||sm(n)&&n.host||ba(n);return sm(e)?e.host:e}function ry(n){const e=ns(n);return Ed(e)?e.ownerDocument.body:In(e)&&jl(e)?e:ry(e)}function Br(n,e){var t;e===void 0&&(e=[]);const a=ry(n),i=a===((t=n.ownerDocument)==null?void 0:t.body),o=Zt(a);return i?e.concat(o,o.visualViewport||[],jl(a)?a:[]):e.concat(a,Br(a))}function rm(n,e,t){return e==="viewport"?Do(function(a,i){const o=Zt(a),s=ba(a),r=o.visualViewport;let l=s.clientWidth,c=s.clientHeight,h=0,d=0;if(r){l=r.width,c=r.height;const u=ay();(u||!u&&i==="fixed")&&(h=r.offsetLeft,d=r.offsetTop)}return{width:l,height:c,x:h,y:d}}(n,t)):ya(e)?Do(function(a,i){const o=ts(a,!0,i==="fixed"),s=o.top+a.clientTop,r=o.left+a.clientLeft,l=In(a)?Ri(a):{x:1,y:1};return{width:a.clientWidth*l.x,height:a.clientHeight*l.y,x:r*l.x,y:s*l.y}}(e,t)):Do(function(a){const i=ba(a),o=zl(a),s=a.ownerDocument.body,r=Po(i.scrollWidth,i.clientWidth,s.scrollWidth,s.clientWidth),l=Po(i.scrollHeight,i.clientHeight,s.scrollHeight,s.clientHeight);let c=-o.scrollLeft+sy(a);const h=-o.scrollTop;return Mn(s).direction==="rtl"&&(c+=Po(i.clientWidth,s.clientWidth)-r),{width:r,height:l,x:c,y:h}}(ba(n)))}function lm(n){return In(n)&&Mn(n).position!=="fixed"?n.offsetParent:null}function cm(n){const e=Zt(n);let t=lm(n);for(;t&&WE(t)&&Mn(t).position==="static";)t=lm(t);return t&&(ka(t)==="html"||ka(t)==="body"&&Mn(t).position==="static"&&!Oc(t))?e:t||function(a){let i=ns(a);for(;In(i)&&!Ed(i);){if(Oc(i))return i;i=ns(i)}return null}(n)||e}function UE(n,e,t){const a=In(e),i=ba(e),o=ts(n,!0,t==="fixed",e);let s={scrollLeft:0,scrollTop:0};const r={x:0,y:0};if(a||!a&&t!=="fixed")if((ka(e)!=="body"||jl(i))&&(s=zl(e)),In(e)){const l=ts(e,!0);r.x=l.x+e.clientLeft,r.y=l.y+e.clientTop}else i&&(r.x=sy(i));return{x:o.left+s.scrollLeft-r.x,y:o.top+s.scrollTop-r.y,width:o.width,height:o.height}}const KE={getClippingRect:function(n){let{element:e,boundary:t,rootBoundary:a,strategy:i}=n;const o=t==="clippingAncestors"?function(c,h){const d=h.get(c);if(d)return d;let u=Br(c).filter(y=>ya(y)&&ka(y)!=="body"),m=null;const p=Mn(c).position==="fixed";let g=p?ns(c):c;for(;ya(g)&&!Ed(g);){const y=Mn(g),b=Oc(g);(p?b||m:b||y.position!=="static"||!m||!["absolute","fixed"].includes(m.position))?m=y:u=u.filter(x=>x!==g),g=ns(g)}return h.set(c,u),u}(e,this._c):[].concat(t),s=[...o,a],r=s[0],l=s.reduce((c,h)=>{const d=rm(e,h,i);return c.top=Po(d.top,c.top),c.right=om(d.right,c.right),c.bottom=om(d.bottom,c.bottom),c.left=Po(d.left,c.left),c},rm(e,r,i));return{width:l.right-l.left,height:l.bottom-l.top,x:l.left,y:l.top}},convertOffsetParentRelativeRectToViewportRelativeRect:function(n){let{rect:e,offsetParent:t,strategy:a}=n;const i=In(t),o=ba(t);if(t===o)return e;let s={scrollLeft:0,scrollTop:0},r={x:1,y:1};const l={x:0,y:0};if((i||!i&&a!=="fixed")&&((ka(t)!=="body"||jl(o))&&(s=zl(t)),In(t))){const c=ts(t);r=Ri(t),l.x=c.x+t.clientLeft,l.y=c.y+t.clientTop}return{width:e.width*r.x,height:e.height*r.y,x:e.x*r.x-s.scrollLeft*r.x+l.x,y:e.y*r.y-s.scrollTop*r.y+l.y}},isElement:ya,getDimensions:function(n){return In(n)?ey(n):n.getBoundingClientRect()},getOffsetParent:cm,getDocumentElement:ba,getScale:Ri,async getElementRects(n){let{reference:e,floating:t,strategy:a}=n;const i=this.getOffsetParent||cm,o=this.getDimensions;return{reference:UE(e,await i(t),a),floating:{x:0,y:0,...await o(t)}}},getClientRects:n=>Array.from(n.getClientRects()),isRTL:n=>Mn(n).direction==="rtl"},JE=(n,e,t)=>{const a=new Map,i={platform:KE,...t},o={...i.platform,_c:a};return RE(n,e,{...i,platform:o})};function ly(n,e){for(const t in e)Object.prototype.hasOwnProperty.call(e,t)&&(typeof e[t]=="object"&&n[t]?ly(n[t],e[t]):n[t]=e[t])}const mn={disabled:!1,distance:5,skidding:0,container:"body",boundary:void 0,instantMove:!1,disposeTimeout:150,popperTriggers:[],strategy:"absolute",preventOverflow:!0,flip:!0,shift:!0,overflowPadding:0,arrowPadding:0,arrowOverflow:!0,autoHideOnMousedown:!1,themes:{tooltip:{placement:"top",triggers:["hover","focus","touch"],hideTriggers:n=>[...n,"click"],delay:{show:200,hide:0},handleResize:!1,html:!1,loadingContent:"..."},dropdown:{placement:"bottom",triggers:["click"],delay:0,handleResize:!0,autoHide:!0},menu:{$extend:"dropdown",triggers:["hover","focus"],popperTriggers:["hover"],delay:{show:0,hide:400}}}};function as(n,e){let t=mn.themes[n]||{},a;do a=t[e],typeof a>"u"?t.$extend?t=mn.themes[t.$extend]||{}:(t=null,a=mn[e]):t=null;while(t);return a}function ZE(n){const e=[n];let t=mn.themes[n]||{};do t.$extend&&!t.$resetCss?(e.push(t.$extend),t=mn.themes[t.$extend]||{}):t=null;while(t);return e.map(a=>`v-popper--theme-${a}`)}function hm(n){const e=[n];let t=mn.themes[n]||{};do t.$extend?(e.push(t.$extend),t=mn.themes[t.$extend]||{}):t=null;while(t);return e}let $i=!1;if(typeof window<"u"){$i=!1;try{const n=Object.defineProperty({},"passive",{get(){$i=!0}});window.addEventListener("test",null,n)}catch{}}let cy=!1;typeof window<"u"&&typeof navigator<"u"&&(cy=/iPad|iPhone|iPod/.test(navigator.userAgent)&&!window.MSStream);const hy=["auto","top","bottom","left","right"].reduce((n,e)=>n.concat([e,`${e}-start`,`${e}-end`]),[]),dm={hover:"mouseenter",focus:"focus",click:"click",touch:"touchstart",pointer:"pointerdown"},um={hover:"mouseleave",focus:"blur",click:"click",touch:"touchend",pointer:"pointerup"};function mm(n,e){const t=n.indexOf(e);t!==-1&&n.splice(t,1)}function rc(){return new Promise(n=>requestAnimationFrame(()=>{requestAnimationFrame(n)}))}const ln=[];let Pa=null;const pm={};function fm(n){let e=pm[n];return e||(e=pm[n]=[]),e}let qc=function(){};typeof window<"u"&&(qc=window.Element);function we(n){return function(e){return as(e.theme,n)}}const lc="__floating-vue__popper",dy=()=>Lr({name:"VPopper",provide(){return{[lc]:{parentPopper:this}}},inject:{[lc]:{default:null}},props:{theme:{type:String,required:!0},targetNodes:{type:Function,required:!0},referenceNode:{type:Function,default:null},popperNode:{type:Function,required:!0},shown:{type:Boolean,default:!1},showGroup:{type:String,default:null},ariaId:{default:null},disabled:{type:Boolean,default:we("disabled")},positioningDisabled:{type:Boolean,default:we("positioningDisabled")},placement:{type:String,default:we("placement"),validator:n=>hy.includes(n)},delay:{type:[String,Number,Object],default:we("delay")},distance:{type:[Number,String],default:we("distance")},skidding:{type:[Number,String],default:we("skidding")},triggers:{type:Array,default:we("triggers")},showTriggers:{type:[Array,Function],default:we("showTriggers")},hideTriggers:{type:[Array,Function],default:we("hideTriggers")},popperTriggers:{type:Array,default:we("popperTriggers")},popperShowTriggers:{type:[Array,Function],default:we("popperShowTriggers")},popperHideTriggers:{type:[Array,Function],default:we("popperHideTriggers")},container:{type:[String,Object,qc,Boolean],default:we("container")},boundary:{type:[String,qc],default:we("boundary")},strategy:{type:String,validator:n=>["absolute","fixed"].includes(n),default:we("strategy")},autoHide:{type:[Boolean,Function],default:we("autoHide")},handleResize:{type:Boolean,default:we("handleResize")},instantMove:{type:Boolean,default:we("instantMove")},eagerMount:{type:Boolean,default:we("eagerMount")},popperClass:{type:[String,Array,Object],default:we("popperClass")},computeTransformOrigin:{type:Boolean,default:we("computeTransformOrigin")},autoMinSize:{type:Boolean,default:we("autoMinSize")},autoSize:{type:[Boolean,String],default:we("autoSize")},autoMaxSize:{type:Boolean,default:we("autoMaxSize")},autoBoundaryMaxSize:{type:Boolean,default:we("autoBoundaryMaxSize")},preventOverflow:{type:Boolean,default:we("preventOverflow")},overflowPadding:{type:[Number,String],default:we("overflowPadding")},arrowPadding:{type:[Number,String],default:we("arrowPadding")},arrowOverflow:{type:Boolean,default:we("arrowOverflow")},flip:{type:Boolean,default:we("flip")},shift:{type:Boolean,default:we("shift")},shiftCrossAxis:{type:Boolean,default:we("shiftCrossAxis")},noAutoFocus:{type:Boolean,default:we("noAutoFocus")},disposeTimeout:{type:Number,default:we("disposeTimeout")}},emits:{show:()=>!0,hide:()=>!0,"update:shown":n=>!0,"apply-show":()=>!0,"apply-hide":()=>!0,"close-group":()=>!0,"close-directive":()=>!0,"auto-hide":()=>!0,resize:()=>!0},data(){return{isShown:!1,isMounted:!1,skipTransition:!1,classes:{showFrom:!1,showTo:!1,hideFrom:!1,hideTo:!0},result:{x:0,y:0,placement:"",strategy:this.strategy,arrow:{x:0,y:0,centerOffset:0},transformOrigin:null},randomId:`popper_${[Math.random(),Date.now()].map(n=>n.toString(36).substring(2,10)).join("_")}`,shownChildren:new Set,lastAutoHide:!0,pendingHide:!1,containsGlobalTarget:!1,isDisposed:!0,mouseDownContains:!1}},computed:{popperId(){return this.ariaId!=null?this.ariaId:this.randomId},shouldMountContent(){return this.eagerMount||this.isMounted},slotData(){return{popperId:this.popperId,isShown:this.isShown,shouldMountContent:this.shouldMountContent,skipTransition:this.skipTransition,autoHide:typeof this.autoHide=="function"?this.lastAutoHide:this.autoHide,show:this.show,hide:this.hide,handleResize:this.handleResize,onResize:this.onResize,classes:{...this.classes,popperClass:this.popperClass},result:this.positioningDisabled?null:this.result,attrs:this.$attrs}},parentPopper(){var n;return(n=this[lc])==null?void 0:n.parentPopper},hasPopperShowTriggerHover(){var n,e;return((n=this.popperTriggers)==null?void 0:n.includes("hover"))||((e=this.popperShowTriggers)==null?void 0:e.includes("hover"))}},watch:{shown:"$_autoShowHide",disabled(n){n?this.dispose():this.init()},async container(){this.isShown&&(this.$_ensureTeleport(),await this.$_computePosition())},triggers:{handler:"$_refreshListeners",deep:!0},positioningDisabled:"$_refreshListeners",...["placement","distance","skidding","boundary","strategy","overflowPadding","arrowPadding","preventOverflow","shift","shiftCrossAxis","flip"].reduce((n,e)=>(n[e]="$_computePosition",n),{})},created(){this.autoMinSize&&console.warn('[floating-vue] `autoMinSize` option is deprecated. Use `autoSize="min"` instead.'),this.autoMaxSize&&console.warn("[floating-vue] `autoMaxSize` option is deprecated. Use `autoBoundaryMaxSize` instead.")},mounted(){this.init(),this.$_detachPopperNode()},activated(){this.$_autoShowHide()},deactivated(){this.hide()},beforeUnmount(){this.dispose()},methods:{show({event:n=null,skipDelay:e=!1,force:t=!1}={}){var a,i;(a=this.parentPopper)!=null&&a.lockedChild&&this.parentPopper.lockedChild!==this||(this.pendingHide=!1,(t||!this.disabled)&&(((i=this.parentPopper)==null?void 0:i.lockedChild)===this&&(this.parentPopper.lockedChild=null),this.$_scheduleShow(n,e),this.$emit("show"),this.$_showFrameLocked=!0,requestAnimationFrame(()=>{this.$_showFrameLocked=!1})),this.$emit("update:shown",!0))},hide({event:n=null,skipDelay:e=!1}={}){var t;if(!this.$_hideInProgress){if(this.shownChildren.size>0){this.pendingHide=!0;return}if(this.hasPopperShowTriggerHover&&this.$_isAimingPopper()){this.parentPopper&&(this.parentPopper.lockedChild=this,clearTimeout(this.parentPopper.lockedChildTimer),this.parentPopper.lockedChildTimer=setTimeout(()=>{this.parentPopper.lockedChild===this&&(this.parentPopper.lockedChild.hide({skipDelay:e}),this.parentPopper.lockedChild=null)},1e3));return}((t=this.parentPopper)==null?void 0:t.lockedChild)===this&&(this.parentPopper.lockedChild=null),this.pendingHide=!1,this.$_scheduleHide(n,e),this.$emit("hide"),this.$emit("update:shown",!1)}},init(){var n;this.isDisposed&&(this.isDisposed=!1,this.isMounted=!1,this.$_events=[],this.$_preventShow=!1,this.$_referenceNode=((n=this.referenceNode)==null?void 0:n.call(this))??this.$el,this.$_targetNodes=this.targetNodes().filter(e=>e.nodeType===e.ELEMENT_NODE),this.$_popperNode=this.popperNode(),this.$_innerNode=this.$_popperNode.querySelector(".v-popper__inner"),this.$_arrowNode=this.$_popperNode.querySelector(".v-popper__arrow-container"),this.$_swapTargetAttrs("title","data-original-title"),this.$_detachPopperNode(),this.triggers.length&&this.$_addEventListeners(),this.shown&&this.show())},dispose(){this.isDisposed||(this.isDisposed=!0,this.$_removeEventListeners(),this.hide({skipDelay:!0}),this.$_detachPopperNode(),this.isMounted=!1,this.isShown=!1,this.$_updateParentShownChildren(!1),this.$_swapTargetAttrs("data-original-title","title"))},async onResize(){this.isShown&&(await this.$_computePosition(),this.$emit("resize"))},async $_computePosition(){if(this.isDisposed||this.positioningDisabled)return;const n={strategy:this.strategy,middleware:[]};(this.distance||this.skidding)&&n.middleware.push($E({mainAxis:this.distance,crossAxis:this.skidding}));const e=this.placement.startsWith("auto");if(e?n.middleware.push(FE({alignment:this.placement.split("-")[1]??""})):n.placement=this.placement,this.preventOverflow&&(this.shift&&n.middleware.push(VE({padding:this.overflowPadding,boundary:this.boundary,crossAxis:this.shiftCrossAxis})),!e&&this.flip&&n.middleware.push(LE({padding:this.overflowPadding,boundary:this.boundary}))),n.middleware.push(OE({element:this.$_arrowNode,padding:this.arrowPadding})),this.arrowOverflow&&n.middleware.push({name:"arrowOverflow",fn:({placement:a,rects:i,middlewareData:o})=>{let s;const{centerOffset:r}=o.arrow;return a.startsWith("top")||a.startsWith("bottom")?s=Math.abs(r)>i.reference.width/2:s=Math.abs(r)>i.reference.height/2,{data:{overflow:s}}}}),this.autoMinSize||this.autoSize){const a=this.autoSize?this.autoSize:this.autoMinSize?"min":null;n.middleware.push({name:"autoSize",fn:({rects:i,placement:o,middlewareData:s})=>{var r;if((r=s.autoSize)!=null&&r.skip)return{};let l,c;return o.startsWith("top")||o.startsWith("bottom")?l=i.reference.width:c=i.reference.height,this.$_innerNode.style[a==="min"?"minWidth":a==="max"?"maxWidth":"width"]=l!=null?`${l}px`:null,this.$_innerNode.style[a==="min"?"minHeight":a==="max"?"maxHeight":"height"]=c!=null?`${c}px`:null,{data:{skip:!0},reset:{rects:!0}}}})}(this.autoMaxSize||this.autoBoundaryMaxSize)&&(this.$_innerNode.style.maxWidth=null,this.$_innerNode.style.maxHeight=null,n.middleware.push(HE({boundary:this.boundary,padding:this.overflowPadding,apply:({availableWidth:a,availableHeight:i})=>{this.$_innerNode.style.maxWidth=a!=null?`${a}px`:null,this.$_innerNode.style.maxHeight=i!=null?`${i}px`:null}})));const t=await JE(this.$_referenceNode,this.$_popperNode,n);Object.assign(this.result,{x:t.x,y:t.y,placement:t.placement,strategy:t.strategy,arrow:{...t.middlewareData.arrow,...t.middlewareData.arrowOverflow}})},$_scheduleShow(n,e=!1){if(this.$_updateParentShownChildren(!0),this.$_hideInProgress=!1,clearTimeout(this.$_scheduleTimer),Pa&&this.instantMove&&Pa.instantMove&&Pa!==this.parentPopper){Pa.$_applyHide(!0),this.$_applyShow(!0);return}e?this.$_applyShow():this.$_scheduleTimer=setTimeout(this.$_applyShow.bind(this),this.$_computeDelay("show"))},$_scheduleHide(n,e=!1){if(this.shownChildren.size>0){this.pendingHide=!0;return}this.$_updateParentShownChildren(!1),this.$_hideInProgress=!0,clearTimeout(this.$_scheduleTimer),this.isShown&&(Pa=this),e?this.$_applyHide():this.$_scheduleTimer=setTimeout(this.$_applyHide.bind(this),this.$_computeDelay("hide"))},$_computeDelay(n){const e=this.delay;return parseInt(e&&e[n]||e||0)},async $_applyShow(n=!1){clearTimeout(this.$_disposeTimer),clearTimeout(this.$_scheduleTimer),this.skipTransition=n,!this.isShown&&(this.$_ensureTeleport(),await rc(),await this.$_computePosition(),await this.$_applyShowEffect(),this.positioningDisabled||this.$_registerEventListeners([...Br(this.$_referenceNode),...Br(this.$_popperNode)],"scroll",()=>{this.$_computePosition()}))},async $_applyShowEffect(){if(this.$_hideInProgress)return;if(this.computeTransformOrigin){const e=this.$_referenceNode.getBoundingClientRect(),t=this.$_popperNode.querySelector(".v-popper__wrapper"),a=t.parentNode.getBoundingClientRect(),i=e.x+e.width/2-(a.left+t.offsetLeft),o=e.y+e.height/2-(a.top+t.offsetTop);this.result.transformOrigin=`${i}px ${o}px`}this.isShown=!0,this.$_applyAttrsToTarget({"aria-describedby":this.popperId,"data-popper-shown":""});const n=this.showGroup;if(n){let e;for(let t=0;t<ln.length;t++)e=ln[t],e.showGroup!==n&&(e.hide(),e.$emit("close-group"))}ln.push(this),document.body.classList.add("v-popper--some-open");for(const e of hm(this.theme))fm(e).push(this),document.body.classList.add(`v-popper--some-open--${e}`);this.$emit("apply-show"),this.classes.showFrom=!0,this.classes.showTo=!1,this.classes.hideFrom=!1,this.classes.hideTo=!1,await rc(),this.classes.showFrom=!1,this.classes.showTo=!0,this.noAutoFocus||this.$_popperNode.focus()},async $_applyHide(n=!1){if(this.shownChildren.size>0){this.pendingHide=!0,this.$_hideInProgress=!1;return}if(clearTimeout(this.$_scheduleTimer),!this.isShown)return;this.skipTransition=n,mm(ln,this),ln.length===0&&document.body.classList.remove("v-popper--some-open");for(const t of hm(this.theme)){const a=fm(t);mm(a,this),a.length===0&&document.body.classList.remove(`v-popper--some-open--${t}`)}Pa===this&&(Pa=null),this.isShown=!1,this.$_applyAttrsToTarget({"aria-describedby":void 0,"data-popper-shown":void 0}),clearTimeout(this.$_disposeTimer);const e=this.disposeTimeout;e!==null&&(this.$_disposeTimer=setTimeout(()=>{this.$_popperNode&&(this.$_detachPopperNode(),this.isMounted=!1)},e)),this.$_removeEventListeners("scroll"),this.$emit("apply-hide"),this.classes.showFrom=!1,this.classes.showTo=!1,this.classes.hideFrom=!0,this.classes.hideTo=!1,await rc(),this.classes.hideFrom=!1,this.classes.hideTo=!0},$_autoShowHide(){this.shown?this.show():this.hide()},$_ensureTeleport(){if(this.isDisposed)return;let n=this.container;if(typeof n=="string"?n=window.document.querySelector(n):n===!1&&(n=this.$_targetNodes[0].parentNode),!n)throw new Error("No container for popover: "+this.container);n.appendChild(this.$_popperNode),this.isMounted=!0},$_addEventListeners(){const n=t=>{this.isShown&&!this.$_hideInProgress||(t.usedByTooltip=!0,!this.$_preventShow&&this.show({event:t}))};this.$_registerTriggerListeners(this.$_targetNodes,dm,this.triggers,this.showTriggers,n),this.$_registerTriggerListeners([this.$_popperNode],dm,this.popperTriggers,this.popperShowTriggers,n);const e=t=>{t.usedByTooltip||this.hide({event:t})};this.$_registerTriggerListeners(this.$_targetNodes,um,this.triggers,this.hideTriggers,e),this.$_registerTriggerListeners([this.$_popperNode],um,this.popperTriggers,this.popperHideTriggers,e)},$_registerEventListeners(n,e,t){this.$_events.push({targetNodes:n,eventType:e,handler:t}),n.forEach(a=>a.addEventListener(e,t,$i?{passive:!0}:void 0))},$_registerTriggerListeners(n,e,t,a,i){let o=t;a!=null&&(o=typeof a=="function"?a(o):a),o.forEach(s=>{const r=e[s];r&&this.$_registerEventListeners(n,r,i)})},$_removeEventListeners(n){const e=[];this.$_events.forEach(t=>{const{targetNodes:a,eventType:i,handler:o}=t;!n||n===i?a.forEach(s=>s.removeEventListener(i,o)):e.push(t)}),this.$_events=e},$_refreshListeners(){this.isDisposed||(this.$_removeEventListeners(),this.$_addEventListeners())},$_handleGlobalClose(n,e=!1){this.$_showFrameLocked||(this.hide({event:n}),n.closePopover?this.$emit("close-directive"):this.$emit("auto-hide"),e&&(this.$_preventShow=!0,setTimeout(()=>{this.$_preventShow=!1},300)))},$_detachPopperNode(){this.$_popperNode.parentNode&&this.$_popperNode.parentNode.removeChild(this.$_popperNode)},$_swapTargetAttrs(n,e){for(const t of this.$_targetNodes){const a=t.getAttribute(n);a&&(t.removeAttribute(n),t.setAttribute(e,a))}},$_applyAttrsToTarget(n){for(const e of this.$_targetNodes)for(const t in n){const a=n[t];a==null?e.removeAttribute(t):e.setAttribute(t,a)}},$_updateParentShownChildren(n){let e=this.parentPopper;for(;e;)n?e.shownChildren.add(this.randomId):(e.shownChildren.delete(this.randomId),e.pendingHide&&e.hide()),e=e.parentPopper},$_isAimingPopper(){const n=this.$_referenceNode.getBoundingClientRect();if(No>=n.left&&No<=n.right&&Bo>=n.top&&Bo<=n.bottom){const e=this.$_popperNode.getBoundingClientRect(),t=No-ra,a=Bo-la,i=e.left+e.width/2-ra+(e.top+e.height/2)-la+e.width+e.height,o=ra+t*i,s=la+a*i;return Ws(ra,la,o,s,e.left,e.top,e.left,e.bottom)||Ws(ra,la,o,s,e.left,e.top,e.right,e.top)||Ws(ra,la,o,s,e.right,e.top,e.right,e.bottom)||Ws(ra,la,o,s,e.left,e.bottom,e.right,e.bottom)}return!1}},render(){return this.$slots.default(this.slotData)}});if(typeof document<"u"&&typeof window<"u"){if(cy){const n=$i?{passive:!0,capture:!0}:!0;document.addEventListener("touchstart",e=>gm(e,!0),n),document.addEventListener("touchend",e=>ym(e,!0),n)}else window.addEventListener("mousedown",n=>gm(n,!1),!0),window.addEventListener("click",n=>ym(n,!1),!0);window.addEventListener("resize",XE)}function gm(n,e){if(mn.autoHideOnMousedown)uy(n,e);else for(let t=0;t<ln.length;t++){const a=ln[t];try{a.mouseDownContains=a.popperNode().contains(n.target)}catch{}}}function ym(n,e){mn.autoHideOnMousedown||uy(n,e)}function uy(n,e){const t={};for(let a=ln.length-1;a>=0;a--){const i=ln[a];try{const o=i.containsGlobalTarget=i.mouseDownContains||i.popperNode().contains(n.target);i.pendingHide=!1,requestAnimationFrame(()=>{if(i.pendingHide=!1,!t[i.randomId]&&bm(i,o,n)){if(i.$_handleGlobalClose(n,e),!n.closeAllPopover&&n.closePopover&&o){let r=i.parentPopper;for(;r;)t[r.randomId]=!0,r=r.parentPopper;return}let s=i.parentPopper;for(;s&&bm(s,s.containsGlobalTarget,n);)s.$_handleGlobalClose(n,e),s=s.parentPopper}})}catch{}}}function bm(n,e,t){return t.closeAllPopover||t.closePopover&&e||YE(n,t)&&!e}function YE(n,e){if(typeof n.autoHide=="function"){const t=n.autoHide(e);return n.lastAutoHide=t,t}return n.autoHide}function XE(){for(let n=0;n<ln.length;n++)ln[n].$_computePosition()}let ra=0,la=0,No=0,Bo=0;typeof window<"u"&&window.addEventListener("mousemove",n=>{ra=No,la=Bo,No=n.clientX,Bo=n.clientY},$i?{passive:!0}:void 0);function Ws(n,e,t,a,i,o,s,r){const l=((s-i)*(e-o)-(r-o)*(n-i))/((r-o)*(t-n)-(s-i)*(a-e)),c=((t-n)*(e-o)-(a-e)*(n-i))/((r-o)*(t-n)-(s-i)*(a-e));return l>=0&&l<=1&&c>=0&&c<=1}const QE={extends:dy()},Rl=(n,e)=>{const t=n.__vccOpts||n;for(const[a,i]of e)t[a]=i;return t};function eD(n,e,t,a,i,o){return _(),T("div",{ref:"reference",class:ae(["v-popper",{"v-popper--shown":n.slotData.isShown}])},[En(n.$slots,"default",sb(rb(n.slotData)))],2)}const tD=Rl(QE,[["render",eD]]);function nD(){var n=window.navigator.userAgent,e=n.indexOf("MSIE ");if(e>0)return parseInt(n.substring(e+5,n.indexOf(".",e)),10);var t=n.indexOf("Trident/");if(t>0){var a=n.indexOf("rv:");return parseInt(n.substring(a+3,n.indexOf(".",a)),10)}var i=n.indexOf("Edge/");return i>0?parseInt(n.substring(i+5,n.indexOf(".",i)),10):-1}let er;function Fc(){Fc.init||(Fc.init=!0,er=nD()!==-1)}var Ol={name:"ResizeObserver",props:{emitOnMount:{type:Boolean,default:!1},ignoreWidth:{type:Boolean,default:!1},ignoreHeight:{type:Boolean,default:!1}},emits:["notify"],mounted(){Fc(),rn(()=>{this._w=this.$el.offsetWidth,this._h=this.$el.offsetHeight,this.emitOnMount&&this.emitSize()});const n=document.createElement("object");this._resizeObject=n,n.setAttribute("aria-hidden","true"),n.setAttribute("tabindex",-1),n.onload=this.addResizeHandlers,n.type="text/html",er&&this.$el.appendChild(n),n.data="about:blank",er||this.$el.appendChild(n)},beforeUnmount(){this.removeResizeHandlers()},methods:{compareAndNotify(){(!this.ignoreWidth&&this._w!==this.$el.offsetWidth||!this.ignoreHeight&&this._h!==this.$el.offsetHeight)&&(this._w=this.$el.offsetWidth,this._h=this.$el.offsetHeight,this.emitSize())},emitSize(){this.$emit("notify",{width:this._w,height:this._h})},addResizeHandlers(){this._resizeObject.contentDocument.defaultView.addEventListener("resize",this.compareAndNotify),this.compareAndNotify()},removeResizeHandlers(){this._resizeObject&&this._resizeObject.onload&&(!er&&this._resizeObject.contentDocument&&this._resizeObject.contentDocument.defaultView.removeEventListener("resize",this.compareAndNotify),this.$el.removeChild(this._resizeObject),this._resizeObject.onload=null,this._resizeObject=null)}}};const aD=ob();mt("data-v-b329ee4c");const iD={class:"resize-observer",tabindex:"-1"};pt();const oD=aD((n,e,t,a,i,o)=>(_(),At("div",iD)));Ol.render=oD;Ol.__scopeId="data-v-b329ee4c";Ol.__file="src/components/ResizeObserver.vue";const my=(n="theme")=>({computed:{themeClass(){return ZE(this[n])}}}),sD=Lr({name:"VPopperContent",components:{ResizeObserver:Ol},mixins:[my()],props:{popperId:String,theme:String,shown:Boolean,mounted:Boolean,skipTransition:Boolean,autoHide:Boolean,handleResize:Boolean,classes:Object,result:Object},emits:["hide","resize"],methods:{toPx(n){return n!=null&&!isNaN(n)?`${n}px`:null}}}),rD=["id","aria-hidden","tabindex","data-popper-placement"],lD={ref:"inner",class:"v-popper__inner"},cD=v("div",{class:"v-popper__arrow-outer"},null,-1),hD=v("div",{class:"v-popper__arrow-inner"},null,-1),dD=[cD,hD];function uD(n,e,t,a,i,o){const s=Jn("ResizeObserver");return _(),T("div",{id:n.popperId,ref:"popover",class:ae(["v-popper__popper",[n.themeClass,n.classes.popperClass,{"v-popper__popper--shown":n.shown,"v-popper__popper--hidden":!n.shown,"v-popper__popper--show-from":n.classes.showFrom,"v-popper__popper--show-to":n.classes.showTo,"v-popper__popper--hide-from":n.classes.hideFrom,"v-popper__popper--hide-to":n.classes.hideTo,"v-popper__popper--skip-transition":n.skipTransition,"v-popper__popper--arrow-overflow":n.result&&n.result.arrow.overflow,"v-popper__popper--no-positioning":!n.result}]]),style:se(n.result?{position:n.result.strategy,transform:`translate3d(${Math.round(n.result.x)}px,${Math.round(n.result.y)}px,0)`}:void 0),"aria-hidden":n.shown?"false":"true",tabindex:n.autoHide?0:void 0,"data-popper-placement":n.result?n.result.placement:void 0,onKeyup:e[2]||(e[2]=Vm(r=>n.autoHide&&n.$emit("hide"),["esc"]))},[v("div",{class:"v-popper__backdrop",onClick:e[0]||(e[0]=r=>n.autoHide&&n.$emit("hide"))}),v("div",{class:"v-popper__wrapper",style:se(n.result?{transformOrigin:n.result.transformOrigin}:void 0)},[v("div",lD,[n.mounted?(_(),T(ke,{key:0},[v("div",null,[En(n.$slots,"default")]),n.handleResize?(_(),At(s,{key:0,onNotify:e[1]||(e[1]=r=>n.$emit("resize",r))})):U("",!0)],64)):U("",!0)],512),v("div",{ref:"arrow",class:"v-popper__arrow-container",style:se(n.result?{left:n.toPx(n.result.arrow.x),top:n.toPx(n.result.arrow.y)}:void 0)},dD,4)],4)],46,rD)}const py=Rl(sD,[["render",uD]]),fy={methods:{show(...n){return this.$refs.popper.show(...n)},hide(...n){return this.$refs.popper.hide(...n)},dispose(...n){return this.$refs.popper.dispose(...n)},onResize(...n){return this.$refs.popper.onResize(...n)}}};let Lc=function(){};typeof window<"u"&&(Lc=window.Element);const mD=Lr({name:"VPopperWrapper",components:{Popper:tD,PopperContent:py},mixins:[fy,my("finalTheme")],props:{theme:{type:String,default:null},referenceNode:{type:Function,default:null},shown:{type:Boolean,default:!1},showGroup:{type:String,default:null},ariaId:{default:null},disabled:{type:Boolean,default:void 0},positioningDisabled:{type:Boolean,default:void 0},placement:{type:String,default:void 0},delay:{type:[String,Number,Object],default:void 0},distance:{type:[Number,String],default:void 0},skidding:{type:[Number,String],default:void 0},triggers:{type:Array,default:void 0},showTriggers:{type:[Array,Function],default:void 0},hideTriggers:{type:[Array,Function],default:void 0},popperTriggers:{type:Array,default:void 0},popperShowTriggers:{type:[Array,Function],default:void 0},popperHideTriggers:{type:[Array,Function],default:void 0},container:{type:[String,Object,Lc,Boolean],default:void 0},boundary:{type:[String,Lc],default:void 0},strategy:{type:String,default:void 0},autoHide:{type:[Boolean,Function],default:void 0},handleResize:{type:Boolean,default:void 0},instantMove:{type:Boolean,default:void 0},eagerMount:{type:Boolean,default:void 0},popperClass:{type:[String,Array,Object],default:void 0},computeTransformOrigin:{type:Boolean,default:void 0},autoMinSize:{type:Boolean,default:void 0},autoSize:{type:[Boolean,String],default:void 0},autoMaxSize:{type:Boolean,default:void 0},autoBoundaryMaxSize:{type:Boolean,default:void 0},preventOverflow:{type:Boolean,default:void 0},overflowPadding:{type:[Number,String],default:void 0},arrowPadding:{type:[Number,String],default:void 0},arrowOverflow:{type:Boolean,default:void 0},flip:{type:Boolean,default:void 0},shift:{type:Boolean,default:void 0},shiftCrossAxis:{type:Boolean,default:void 0},noAutoFocus:{type:Boolean,default:void 0},disposeTimeout:{type:Number,default:void 0}},emits:{show:()=>!0,hide:()=>!0,"update:shown":n=>!0,"apply-show":()=>!0,"apply-hide":()=>!0,"close-group":()=>!0,"close-directive":()=>!0,"auto-hide":()=>!0,resize:()=>!0},computed:{finalTheme(){return this.theme??this.$options.vPopperTheme}},methods:{getTargetNodes(){return Array.from(this.$el.children).filter(n=>n!==this.$refs.popperContent.$el)}}});function pD(n,e,t,a,i,o){const s=Jn("PopperContent"),r=Jn("Popper");return _(),At(r,Hm({ref:"popper"},n.$props,{theme:n.finalTheme,"target-nodes":n.getTargetNodes,"popper-node":()=>n.$refs.popperContent.$el,class:[n.themeClass],onShow:e[0]||(e[0]=()=>n.$emit("show")),onHide:e[1]||(e[1]=()=>n.$emit("hide")),"onUpdate:shown":e[2]||(e[2]=l=>n.$emit("update:shown",l)),onApplyShow:e[3]||(e[3]=()=>n.$emit("apply-show")),onApplyHide:e[4]||(e[4]=()=>n.$emit("apply-hide")),onCloseGroup:e[5]||(e[5]=()=>n.$emit("close-group")),onCloseDirective:e[6]||(e[6]=()=>n.$emit("close-directive")),onAutoHide:e[7]||(e[7]=()=>n.$emit("auto-hide")),onResize:e[8]||(e[8]=()=>n.$emit("resize"))}),{default:Ge(({popperId:l,isShown:c,shouldMountContent:h,skipTransition:d,autoHide:u,show:m,hide:p,handleResize:g,onResize:y,classes:b,result:x})=>[En(n.$slots,"default",{shown:c,show:m,hide:p}),Q(s,{ref:"popperContent","popper-id":l,theme:n.finalTheme,shown:c,mounted:h,"skip-transition":d,"auto-hide":u,"handle-resize":g,classes:b,result:x,onHide:p,onResize:y},{default:Ge(()=>[En(n.$slots,"popper",{shown:c,hide:p})]),_:2},1032,["popper-id","theme","shown","mounted","skip-transition","auto-hide","handle-resize","classes","result","onHide","onResize"])]),_:3},16,["theme","target-nodes","popper-node","class"])}const Dd=Rl(mD,[["render",pD]]),fD={...Dd,name:"VDropdown",vPopperTheme:"dropdown"},gD={...Dd,name:"VMenu",vPopperTheme:"menu"},yD={...Dd,name:"VTooltip",vPopperTheme:"tooltip"},bD=Lr({name:"VTooltipDirective",components:{Popper:dy(),PopperContent:py},mixins:[fy],inheritAttrs:!1,props:{theme:{type:String,default:"tooltip"},html:{type:Boolean,default:n=>as(n.theme,"html")},content:{type:[String,Number,Function],default:null},loadingContent:{type:String,default:n=>as(n.theme,"loadingContent")},targetNodes:{type:Function,required:!0}},data(){return{asyncContent:null}},computed:{isContentAsync(){return typeof this.content=="function"},loading(){return this.isContentAsync&&this.asyncContent==null},finalContent(){return this.isContentAsync?this.loading?this.loadingContent:this.asyncContent:this.content}},watch:{content:{handler(){this.fetchContent(!0)},immediate:!0},async finalContent(){await this.$nextTick(),this.$refs.popper.onResize()}},created(){this.$_fetchId=0},methods:{fetchContent(n){if(typeof this.content=="function"&&this.$_isShown&&(n||!this.$_loading&&this.asyncContent==null)){this.asyncContent=null,this.$_loading=!0;const e=++this.$_fetchId,t=this.content(this);t.then?t.then(a=>this.onResult(e,a)):this.onResult(e,t)}},onResult(n,e){n===this.$_fetchId&&(this.$_loading=!1,this.asyncContent=e)},onShow(){this.$_isShown=!0,this.fetchContent()},onHide(){this.$_isShown=!1}}}),vD=["innerHTML"],wD=["textContent"];function _D(n,e,t,a,i,o){const s=Jn("PopperContent"),r=Jn("Popper");return _(),At(r,Hm({ref:"popper"},n.$attrs,{theme:n.theme,"target-nodes":n.targetNodes,"popper-node":()=>n.$refs.popperContent.$el,onApplyShow:n.onShow,onApplyHide:n.onHide}),{default:Ge(({popperId:l,isShown:c,shouldMountContent:h,skipTransition:d,autoHide:u,hide:m,handleResize:p,onResize:g,classes:y,result:b})=>[Q(s,{ref:"popperContent",class:ae({"v-popper--tooltip-loading":n.loading}),"popper-id":l,theme:n.theme,shown:c,mounted:h,"skip-transition":d,"auto-hide":u,"handle-resize":p,classes:y,result:b,onHide:m,onResize:g},{default:Ge(()=>[n.html?(_(),T("div",{key:0,innerHTML:n.finalContent},null,8,vD)):(_(),T("div",{key:1,textContent:K(n.finalContent)},null,8,wD))]),_:2},1032,["class","popper-id","theme","shown","mounted","skip-transition","auto-hide","handle-resize","classes","result","onHide","onResize"])]),_:1},16,["theme","target-nodes","popper-node","onApplyShow","onApplyHide"])}const kD=Rl(bD,[["render",_D]]),gy="v-popper--has-tooltip";function TD(n,e){let t=n.placement;if(!t&&e)for(const a of hy)e[a]&&(t=a);return t||(t=as(n.theme||"tooltip","placement")),t}function yy(n,e,t){let a;const i=typeof e;return i==="string"?a={content:e}:e&&i==="object"?a=e:a={content:!1},a.placement=TD(a,t),a.targetNodes=()=>[n],a.referenceNode=()=>n,a}let cc,is,xD=0;function SD(){if(cc)return;is=ee([]),cc=lb({name:"VTooltipDirectiveApp",setup(){return{directives:is}},render(){return this.directives.map(e=>cb(kD,{...e.options,shown:e.shown||e.options.shown,key:e.id}))},devtools:{hide:!0}});const n=document.createElement("div");document.body.appendChild(n),cc.mount(n)}function AD(n,e,t){SD();const a=ee(yy(n,e,t)),i=ee(!1),o={id:xD++,options:a,shown:i};return is.value.push(o),n.classList&&n.classList.add(gy),n.$_popper={options:a,item:o,show(){i.value=!0},hide(){i.value=!1}}}function by(n){if(n.$_popper){const e=is.value.indexOf(n.$_popper.item);e!==-1&&is.value.splice(e,1),delete n.$_popper,delete n.$_popperOldShown,delete n.$_popperMountTarget}n.classList&&n.classList.remove(gy)}function vm(n,{value:e,modifiers:t}){const a=yy(n,e,t);if(!a.content||as(a.theme||"tooltip","disabled"))by(n);else{let i;n.$_popper?(i=n.$_popper,i.options.value=a):i=AD(n,e,t),typeof e.shown<"u"&&e.shown!==n.$_popperOldShown&&(n.$_popperOldShown=e.shown,e.shown?i.show():i.hide())}}const CD={beforeMount:vm,updated:vm,beforeUnmount(n){by(n)}};function wm(n){n.addEventListener("mousedown",jr),n.addEventListener("click",jr),n.addEventListener("touchstart",vy,$i?{passive:!0}:!1)}function _m(n){n.removeEventListener("mousedown",jr),n.removeEventListener("click",jr),n.removeEventListener("touchstart",vy),n.removeEventListener("touchend",wy),n.removeEventListener("touchcancel",_y)}function jr(n){const e=n.currentTarget;n.closePopover=!e.$_vclosepopover_touch,n.closeAllPopover=e.$_closePopoverModifiers&&!!e.$_closePopoverModifiers.all}function vy(n){if(n.changedTouches.length===1){const e=n.currentTarget;e.$_vclosepopover_touch=!0;const t=n.changedTouches[0];e.$_vclosepopover_touchPoint=t,e.addEventListener("touchend",wy),e.addEventListener("touchcancel",_y)}}function wy(n){const e=n.currentTarget;if(e.$_vclosepopover_touch=!1,n.changedTouches.length===1){const t=n.changedTouches[0],a=e.$_vclosepopover_touchPoint;n.closePopover=Math.abs(t.screenY-a.screenY)<20&&Math.abs(t.screenX-a.screenX)<20,n.closeAllPopover=e.$_closePopoverModifiers&&!!e.$_closePopoverModifiers.all}}function _y(n){const e=n.currentTarget;e.$_vclosepopover_touch=!1}const MD={beforeMount(n,{value:e,modifiers:t}){n.$_closePopoverModifiers=t,(typeof e>"u"||e)&&wm(n)},updated(n,{value:e,oldValue:t,modifiers:a}){n.$_closePopoverModifiers=a,e!==t&&(typeof e>"u"||e?wm(n):_m(n))},beforeUnmount(n){_m(n)}};function ID(n,e={}){n.$_vTooltipInstalled||(n.$_vTooltipInstalled=!0,ly(mn,e),n.directive("tooltip",CD),n.directive("close-popper",MD),n.component("VTooltip",yD),n.component("VDropdown",fD),n.component("VMenu",gD))}const ED={version:"5.2.2",install:ID,options:mn};var DD=Object.defineProperty,km=Object.getOwnPropertySymbols,PD=Object.prototype.hasOwnProperty,ND=Object.prototype.propertyIsEnumerable,Tm=(n,e,t)=>e in n?DD(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,Gc=(n,e)=>{for(var t in e||(e={}))PD.call(e,t)&&Tm(n,t,e[t]);if(km)for(var t of km(e))ND.call(e,t)&&Tm(n,t,e[t]);return n},BD=()=>({emit(n,...e){for(let t=0,a=this.events[n]||[],i=a.length;t<i;t++)a[t](...e)},events:{},on(n,e){var t;return((t=this.events)[n]||(t[n]=[])).push(e),()=>{var a;this.events[n]=(a=this.events[n])==null?void 0:a.filter(i=>e!==i)}}});function xm(n,e,t,a=i=>i){return n*a(.5-e*(.5-t))}function jD(n){return[-n[0],-n[1]]}function on(n,e){return[n[0]+e[0],n[1]+e[1]]}function Vt(n,e){return[n[0]-e[0],n[1]-e[1]]}function an(n,e){return[n[0]*e,n[1]*e]}function zD(n,e){return[n[0]/e,n[1]/e]}function _o(n){return[n[1],-n[0]]}function Sm(n,e){return n[0]*e[0]+n[1]*e[1]}function RD(n,e){return n[0]===e[0]&&n[1]===e[1]}function OD(n){return Math.hypot(n[0],n[1])}function qD(n){return n[0]*n[0]+n[1]*n[1]}function Am(n,e){return qD(Vt(n,e))}function ky(n){return zD(n,OD(n))}function FD(n,e){return Math.hypot(n[1]-e[1],n[0]-e[0])}function ko(n,e,t){let a=Math.sin(t),i=Math.cos(t),o=n[0]-e[0],s=n[1]-e[1],r=o*i-s*a,l=o*a+s*i;return[r+e[0],l+e[1]]}function $c(n,e,t){return on(n,an(Vt(e,n),t))}function Cm(n,e,t){return on(n,an(e,t))}var{min:_i,PI:LD}=Math,Mm=.275,To=LD+1e-4;function GD(n,e={}){let{size:t=16,smoothing:a=.5,thinning:i=.5,simulatePressure:o=!0,easing:s=z=>z,start:r={},end:l={},last:c=!1}=e,{cap:h=!0,easing:d=z=>z*(2-z)}=r,{cap:u=!0,easing:m=z=>--z*z*z+1}=l;if(n.length===0||t<=0)return[];let p=n[n.length-1].runningLength,g=r.taper===!1?0:r.taper===!0?Math.max(t,p):r.taper,y=l.taper===!1?0:l.taper===!0?Math.max(t,p):l.taper,b=Math.pow(t*a,2),x=[],S=[],k=n.slice(0,10).reduce((z,Y)=>{let V=Y.pressure;if(o){let J=_i(1,Y.distance/t),ie=_i(1,1-J);V=_i(1,z+(ie-z)*(J*Mm))}return(z+V)/2},n[0].pressure),w=xm(t,i,n[n.length-1].pressure,s),C,M=n[0].vector,A=n[0].point,I=A,D=A,P=I,E=!1;for(let z=0;z<n.length;z++){let{pressure:Y}=n[z],{point:V,vector:J,distance:ie,runningLength:ge}=n[z];if(z<n.length-1&&p-ge<3)continue;if(i){if(o){let dt=_i(1,ie/t),kn=_i(1,1-dt);Y=_i(1,k+(kn-k)*(dt*Mm))}w=xm(t,i,Y,s)}else w=t/2;C===void 0&&(C=w);let ot=ge<g?d(ge/g):1,Ee=p-ge<y?m((p-ge)/y):1;w=Math.max(.01,w*Math.min(ot,Ee));let le=(z<n.length-1?n[z+1]:n[z]).vector,Te=z<n.length-1?Sm(J,le):1,Je=Sm(J,M)<0&&!E,te=Te!==null&&Te<0;if(Je||te){let dt=an(_o(M),w);for(let kn=1/13,tn=0;tn<=1;tn+=kn)D=ko(Vt(V,dt),V,To*tn),x.push(D),P=ko(on(V,dt),V,To*-tn),S.push(P);A=D,I=P,te&&(E=!0);continue}if(E=!1,z===n.length-1){let dt=an(_o(J),w);x.push(Vt(V,dt)),S.push(on(V,dt));continue}let Ot=an(_o($c(le,J,Te)),w);D=Vt(V,Ot),(z<=1||Am(A,D)>b)&&(x.push(D),A=D),P=on(V,Ot),(z<=1||Am(I,P)>b)&&(S.push(P),I=P),k=Y,M=J}let O=n[0].point.slice(0,2),j=n.length>1?n[n.length-1].point.slice(0,2):on(n[0].point,[1,1]),W=[],L=[];if(n.length===1){if(!(g||y)||c){let z=Cm(O,ky(_o(Vt(O,j))),-(C||w)),Y=[];for(let V=1/13,J=V;J<=1;J+=V)Y.push(ko(z,O,To*2*J));return Y}}else{if(!(g||y&&n.length===1))if(h)for(let Y=1/13,V=Y;V<=1;V+=Y){let J=ko(S[0],O,To*V);W.push(J)}else{let Y=Vt(x[0],S[0]),V=an(Y,.5),J=an(Y,.51);W.push(Vt(O,V),Vt(O,J),on(O,J),on(O,V))}let z=_o(jD(n[n.length-1].vector));if(y||g&&n.length===1)L.push(j);else if(u){let Y=Cm(j,z,w);for(let V=1/29,J=V;J<1;J+=V)L.push(ko(Y,j,To*3*J))}else L.push(on(j,an(z,w)),on(j,an(z,w*.99)),Vt(j,an(z,w*.99)),Vt(j,an(z,w)))}return x.concat(L,S.reverse(),W)}function $D(n,e={}){var t;let{streamline:a=.5,size:i=16,last:o=!1}=e;if(n.length===0)return[];let s=.15+(1-a)*.85,r=Array.isArray(n[0])?n:n.map(({x:m,y:p,pressure:g=.5})=>[m,p,g]);if(r.length===2){let m=r[1];r=r.slice(0,-1);for(let p=1;p<5;p++)r.push($c(r[0],m,p/4))}r.length===1&&(r=[...r,[...on(r[0],[1,1]),...r[0].slice(2)]]);let l=[{point:[r[0][0],r[0][1]],pressure:r[0][2]>=0?r[0][2]:.25,vector:[1,1],distance:0,runningLength:0}],c=!1,h=0,d=l[0],u=r.length-1;for(let m=1;m<r.length;m++){let p=o&&m===u?r[m].slice(0,2):$c(d.point,r[m],s);if(RD(d.point,p))continue;let g=FD(p,d.point);if(h+=g,m<u&&!c){if(h<i)continue;c=!0}d={point:p,pressure:r[m][2]>=0?r[m][2]:.5,vector:ky(Vt(d.point,p)),distance:g,runningLength:h},l.push(d)}return l[0].vector=((t=l[1])==null?void 0:t.vector)||[0,0],l}function VD(n,e={}){return GD($D(n,e),e)}function zr(n,e){return n-e}function HD(n){return n<0?-1:1}function Rr(n){return[Math.abs(n),HD(n)]}function Ty(){const n=()=>((1+Math.random())*65536|0).toString(16).substring(1);return`${n()+n()}-${n()}-${n()}-${n()}-${n()}${n()}${n()}`}var WD=2,$n=WD,so=class{constructor(n){this.drauu=n,this.event=void 0,this.point=void 0,this.start=void 0,this.el=null}onSelected(n){}onUnselected(){}onStart(n){}onMove(n){return!1}onEnd(n){}get brush(){return this.drauu.brush}get shiftPressed(){return this.drauu.shiftPressed}get altPressed(){return this.drauu.altPressed}get svgElement(){return this.drauu.el}getMousePosition(n){var e,t,a;const i=this.drauu.el,o=(e=this.drauu.options.coordinateScale)!=null?e:1,s=(t=this.drauu.options.offset)!=null?t:{x:0,y:0};if(this.drauu.options.coordinateTransform===!1){const r=this.drauu.el.getBoundingClientRect();return{x:(n.pageX-r.left+s.x)*o,y:(n.pageY-r.top+s.y)*o,pressure:n.pressure}}else{const r=this.drauu.svgPoint;r.x=n.clientX+s.x,r.y=n.clientY+s.y;const l=r.matrixTransform((a=i.getScreenCTM())==null?void 0:a.inverse());return{x:l.x*o,y:l.y*o,pressure:n.pressure}}}createElement(n,e){var t;const a=document.createElementNS("http://www.w3.org/2000/svg",n),i=e?Gc(Gc({},this.brush),e):this.brush;return a.setAttribute("fill",(t=i.fill)!=null?t:"transparent"),a.setAttribute("stroke",i.color),a.setAttribute("stroke-width",i.size.toString()),a.setAttribute("stroke-linecap","round"),i.dasharray&&a.setAttribute("stroke-dasharray",i.dasharray),a}attr(n,e){this.el.setAttribute(n,typeof e=="string"?e:e.toFixed($n))}_setEvent(n){this.event=n,this.point=this.getMousePosition(n)}_eventDown(n){return this._setEvent(n),this.start=this.point,this.onStart(this.point)}_eventMove(n){return this._setEvent(n),this.onMove(this.point)}_eventUp(n){return this._setEvent(n),this.onEnd(this.point)}},UD=class xy extends so{constructor(){super(...arguments),this.points=[]}onStart(e){return this.el=document.createElementNS("http://www.w3.org/2000/svg","path"),this.points=[e],this.attr("fill",this.brush.color),this.attr("d",this.getSvgData(this.points)),this.el}onMove(e){return this.el||this.onStart(e),this.points[this.points.length-1]!==e&&this.points.push(e),this.attr("d",this.getSvgData(this.points)),!0}onEnd(){const e=this.el;return this.el=null,!!e}getSvgData(e){return xy.getSvgData(e,this.brush)}static getSvgData(e,t){const a=VD(e,Gc({size:t.size,thinning:.9,simulatePressure:!1,start:{taper:5},end:{taper:5}},t.stylusOptions));if(!a.length)return"";const i=a.reduce((o,[s,r],l,c)=>{const[h,d]=c[(l+1)%c.length];return o.push(s,r,(s+h)/2,(r+d)/2),o},["M",...a[0],"Q"]);return i.push("Z"),i.map(o=>typeof o=="number"?o.toFixed(2):o).join(" ")}},KD=class extends so{onStart(n){return this.el=this.createElement("ellipse"),this.attr("cx",n.x),this.attr("cy",n.y),this.el}onMove(n){if(!this.el||!this.start)return!1;let[e,t]=Rr(n.x-this.start.x),[a,i]=Rr(n.y-this.start.y);if(this.shiftPressed){const o=Math.min(e,a);e=o,a=o}if(this.altPressed)this.attr("cx",this.start.x),this.attr("cy",this.start.y),this.attr("rx",e),this.attr("ry",a);else{const[o,s]=[this.start.x,this.start.x+e*t].sort(zr),[r,l]=[this.start.y,this.start.y+a*i].sort(zr);this.attr("cx",(o+s)/2),this.attr("cy",(r+l)/2),this.attr("rx",(s-o)/2),this.attr("ry",(l-r)/2)}return!0}onEnd(){const n=this.el;return this.el=null,!(!n||!n.getTotalLength())}};function Sy(n,e){const t=document.createElementNS("http://www.w3.org/2000/svg","defs"),a=document.createElementNS("http://www.w3.org/2000/svg","marker"),i=document.createElementNS("http://www.w3.org/2000/svg","path");return i.setAttribute("fill",e),a.setAttribute("id",n),a.setAttribute("viewBox","0 -5 10 10"),a.setAttribute("refX","5"),a.setAttribute("refY","0"),a.setAttribute("markerWidth","4"),a.setAttribute("markerHeight","4"),a.setAttribute("orient","auto"),i.setAttribute("d","M0,-5L10,0L0,5"),a.appendChild(i),t.appendChild(a),t}var JD=class extends so{onStart(n){if(this.el=this.createElement("line",{fill:"transparent"}),this.attr("x1",n.x),this.attr("y1",n.y),this.attr("x2",n.x),this.attr("y2",n.y),this.brush.arrowEnd){const e=Ty(),t=document.createElementNS("http://www.w3.org/2000/svg","g");return t.append(Sy(e,this.brush.color)),t.append(this.el),this.attr("marker-end",`url(#${e})`),t}return this.el}onMove(n){if(!this.el)return!1;let{x:e,y:t}=n;if(this.shiftPressed){const a=n.x-this.start.x,i=n.y-this.start.y;if(i!==0){let o=a/i;o=Math.round(o),Math.abs(o)<=1?(e=this.start.x+i*o,t=this.start.y+i):(e=this.start.x+a,t=this.start.y)}}return this.altPressed?(this.attr("x1",this.start.x*2-e),this.attr("y1",this.start.y*2-t),this.attr("x2",e),this.attr("y2",t)):(this.attr("x1",this.start.x),this.attr("y1",this.start.y),this.attr("x2",e),this.attr("y2",t)),!0}onEnd(){const n=this.el;return this.el=null,!(!n||n.getTotalLength()<5)}},ZD=class extends so{onStart(n){return this.el=this.createElement("rect"),this.brush.cornerRadius&&(this.attr("rx",this.brush.cornerRadius),this.attr("ry",this.brush.cornerRadius)),this.attr("x",n.x),this.attr("y",n.y),this.el}onMove(n){if(!this.el||!this.start)return!1;let[e,t]=Rr(n.x-this.start.x),[a,i]=Rr(n.y-this.start.y);if(this.shiftPressed){const o=Math.min(e,a);e=o,a=o}if(this.altPressed)this.attr("x",this.start.x-e),this.attr("y",this.start.y-a),this.attr("width",e*2),this.attr("height",a*2);else{const[o,s]=[this.start.x,this.start.x+e*t].sort(zr),[r,l]=[this.start.y,this.start.y+a*i].sort(zr);this.attr("x",o),this.attr("y",r),this.attr("width",s-o),this.attr("height",l-r)}return!0}onEnd(){const n=this.el;return this.el=null,!(!n||!n.getTotalLength())}};function YD(n,e){const t=n.x-e.x,a=n.y-e.y;return t*t+a*a}function XD(n,e,t){let a=e.x,i=e.y,o=t.x-a,s=t.y-i;if(o!==0||s!==0){const r=((n.x-a)*o+(n.y-i)*s)/(o*o+s*s);r>1?(a=t.x,i=t.y):r>0&&(a+=o*r,i+=s*r)}return o=n.x-a,s=n.y-i,o*o+s*s}function QD(n,e){let t=n[0];const a=[t];let i;for(let o=1,s=n.length;o<s;o++)i=n[o],YD(i,t)>e&&(a.push(i),t=i);return t!==i&&i&&a.push(i),a}function Vc(n,e,t,a,i){let o=a,s=0;for(let r=e+1;r<t;r++){const l=XD(n[r],n[e],n[t]);l>o&&(s=r,o=l)}o>a&&(s-e>1&&Vc(n,e,s,a,i),i.push(n[s]),t-s>1&&Vc(n,s,t,a,i))}function eP(n,e){const t=n.length-1,a=[n[0]];return Vc(n,0,t,e,a),a.push(n[t]),a}function Im(n,e,t=!1){if(n.length<=2)return n;const a=e!==void 0?e*e:1;return n=t?n:QD(n,a),n=eP(n,a),n}var tP=class Ba extends so{constructor(){super(...arguments),this.points=[],this.count=0}onStart(e){if(this.el=this.createElement("path",{fill:"transparent"}),this.points=[e],this.brush.arrowEnd){this.arrowId=Ty();const t=Sy(this.arrowId,this.brush.color);this.el.appendChild(t)}return this.el}onMove(e){return this.el||this.onStart(e),this.points[this.points.length-1]!==e&&(this.points.push(e),this.count+=1),this.count>5&&(this.points=Im(this.points,1,!0),this.count=0),this.attr("d",Ba.toSvgData(this.points)),!0}onEnd(){const e=this.el;return this.el=null,!(!e||(e.setAttribute("d",Ba.toSvgData(Im(this.points,1,!0))),!e.getTotalLength()))}static line(e,t){const a=t.x-e.x,i=t.y-e.y;return{length:Math.sqrt(a**2+i**2),angle:Math.atan2(i,a)}}static controlPoint(e,t,a,i){const o=t||e,s=a||e,r=.2,l=Ba.line(o,s),c=l.angle+(i?Math.PI:0),h=l.length*r,d=e.x+Math.cos(c)*h,u=e.y+Math.sin(c)*h;return{x:d,y:u}}static bezierCommand(e,t,a){const i=Ba.controlPoint(a[t-1],a[t-2],e),o=Ba.controlPoint(e,a[t-1],a[t+1],!0);return`C ${i.x.toFixed($n)},${i.y.toFixed($n)} ${o.x.toFixed($n)},${o.y.toFixed($n)} ${e.x.toFixed($n)},${e.y.toFixed($n)}`}static toSvgData(e){return e.reduce((t,a,i,o)=>i===0?`M ${a.x.toFixed($n)},${a.y.toFixed($n)}`:`${t} ${Ba.bezierCommand(a,i,o)}`,"")}},nP=class extends so{constructor(){super(...arguments),this.pathSubFactor=20,this.pathFragments=[],this._erased=[]}onSelected(n){const e=(t,a)=>{if(t&&t.length)for(let i=0;i<t.length;i++){const o=t[i];if(o.getTotalLength){const s=o.getTotalLength();for(let r=0;r<this.pathSubFactor;r++){const l=o.getPointAtLength(s*r/this.pathSubFactor),c=o.getPointAtLength(s*(r+1)/this.pathSubFactor);this.pathFragments.push({x1:l.x,x2:c.x,y1:l.y,y2:c.y,segment:r,element:a||o})}}else o.children&&e(o.children,o)}};n&&e(n.children)}onUnselected(){this.pathFragments=[]}onStart(n){this.svgPointPrevious=this.svgElement.createSVGPoint(),this.svgPointPrevious.x=n.x,this.svgPointPrevious.y=n.y}onMove(n){this.svgPointCurrent=this.svgElement.createSVGPoint(),this.svgPointCurrent.x=n.x,this.svgPointCurrent.y=n.y;const e=this.checkAndEraseElement();return this.svgPointPrevious=this.svgPointCurrent,e}onEnd(){this.svgPointPrevious=void 0,this.svgPointCurrent=void 0;const n=this._erased;return this._erased=[],{undo:()=>n.forEach(e=>this.drauu._restoreNode(e)),redo:()=>n.forEach(e=>this.drauu._removeNode(e))}}checkAndEraseElement(){if(this.pathFragments.length)for(let n=0;n<this.pathFragments.length;n++){const e=this.pathFragments[n],t={x1:this.svgPointPrevious.x,x2:this.svgPointCurrent.x,y1:this.svgPointPrevious.y,y2:this.svgPointCurrent.y};this.lineLineIntersect(e,t)&&(this.drauu._removeNode(e.element),this._erased.push(e.element))}return this._erased.length&&(this.pathFragments=this.pathFragments.filter(n=>!this._erased.includes(n.element))),this._erased.length>0}lineLineIntersect(n,e){const t=n.x1,a=n.x2,i=e.x1,o=e.x2,s=n.y1,r=n.y2,l=e.y1,c=e.y2,h=(t-a)*(l-c)-(s-r)*(i-o),d=(t*r-s*a)*(i-o)-(t-a)*(i*c-l*o),u=(t*r-s*a)*(l-c)-(s-r)*(i*c-l*o),m=(p,g,y)=>p>=g&&p<=y?!0:p>=y&&p<=g;if(h===0)return!1;{const p={x:d/h,y:u/h};return m(p.x,t,a)&&m(p.y,s,r)&&m(p.x,i,o)&&m(p.y,l,c)}}};function aP(n){return{draw:new tP(n),stylus:new UD(n),line:new JD(n),rectangle:new ZD(n),ellipse:new KD(n),eraseLine:new nP(n)}}var iP=class{constructor(n={}){this.options=n,this.el=null,this.svgPoint=null,this.eventEl=null,this.shiftPressed=!1,this.altPressed=!1,this.drawing=!1,this._emitter=BD(),this._originalPointerId=null,this._models=aP(this),this._opStack=[],this._opIndex=0,this._disposables=[],this._elements=[],this.options.brush||(this.options.brush={color:"black",size:3,mode:"stylus"}),n.el&&this.mount(n.el,n.eventTarget,n.window)}get model(){return this._models[this.mode]}get mounted(){return!!this.el}get mode(){return this.options.brush.mode||"stylus"}set mode(n){this._models[this.mode].onUnselected(),this.options.brush.mode=n,this.model.onSelected(this.el)}get brush(){return this.options.brush}set brush(n){this.options.brush=n}resolveSelector(n){return typeof n=="string"?document.querySelector(n):n||null}mount(n,e,t=window){if(this.el)throw new Error("[drauu] already mounted, unmount previous target first");if(this.el=this.resolveSelector(n),!this.el)throw new Error("[drauu] target element not found");if(this.el.tagName.toLocaleLowerCase()!=="svg")throw new Error("[drauu] can only mount to a SVG element");if(!this.el.createSVGPoint)throw new Error("[drauu] SVG element must be create by document.createElementNS('http://www.w3.org/2000/svg', 'svg')");this.svgPoint=this.el.createSVGPoint();const a=this.resolveSelector(e)||this.el,i=this.eventStart.bind(this),o=this.eventMove.bind(this),s=this.eventEnd.bind(this),r=this.eventKeyboard.bind(this);a.addEventListener("pointerdown",i,{passive:!1}),t.addEventListener("pointermove",o,{passive:!1}),t.addEventListener("pointerup",s,{passive:!1}),t.addEventListener("pointercancel",s,{passive:!1}),t.addEventListener("keydown",r,!1),t.addEventListener("keyup",r,!1),this._disposables.push(()=>{a.removeEventListener("pointerdown",i),t.removeEventListener("pointermove",o),t.removeEventListener("pointerup",s),t.removeEventListener("pointercancel",s),t.removeEventListener("keydown",r,!1),t.removeEventListener("keyup",r,!1)}),this._emitter.emit("mounted")}unmount(){this._disposables.forEach(n=>n()),this._disposables.length=0,this._elements.length=0,this.el=null,this._emitter.emit("unmounted")}on(n,e){return this._emitter.on(n,e)}undo(){return!this.canUndo()||this.drawing?!1:(this._opStack[--this._opIndex].undo(),this._emitter.emit("changed"),!0)}redo(){return!this.canRedo()||this.drawing?!1:(this._opStack[this._opIndex++].redo(),this._emitter.emit("changed"),!0)}canRedo(){return this._opIndex<this._opStack.length}canUndo(){return this._opIndex>0}eventMove(n){!this.acceptsInput(n)||!this.drawing||this.model._eventMove(n)&&(n.stopPropagation(),n.preventDefault(),this._emitter.emit("changed"))}eventStart(n){this.acceptsInput(n)&&(n.stopPropagation(),n.preventDefault(),this._currentNode&&this.cancel(),this.drawing=!0,this._originalPointerId=n.pointerId,this._emitter.emit("start"),this._currentNode=this.model._eventDown(n),this._currentNode&&this.mode!=="eraseLine"&&this.el.appendChild(this._currentNode),this._emitter.emit("changed"))}eventEnd(n){if(!this.acceptsInput(n)||!this.drawing)return;const e=this.model._eventUp(n);if(!e)this.cancel();else if(e===!0){const t=this._currentNode;this._appendNode(t),this.commit({undo:()=>this._removeNode(t),redo:()=>this._restoreNode(t)})}else this.commit(e);this.drawing=!1,this._emitter.emit("end"),this._emitter.emit("changed"),this._originalPointerId=null}acceptsInput(n){return(!this.options.acceptsInputTypes||this.options.acceptsInputTypes.includes(n.pointerType))&&!(this._originalPointerId&&this._originalPointerId!==n.pointerId)}eventKeyboard(n){this.shiftPressed===n.shiftKey&&this.altPressed===n.altKey||(this.shiftPressed=n.shiftKey,this.altPressed=n.altKey,this.model.point&&this.model.onMove(this.model.point)&&this._emitter.emit("changed"))}commit(n){this._opStack.length=this._opIndex,this._opStack.push(n),this._opIndex++;const e=this._currentNode;this._currentNode=void 0,this._emitter.emit("committed",e)}clear(){this._opStack.length=0,this._opIndex=0,this.cancel(),this.el.innerHTML="",this._emitter.emit("changed")}cancel(){this._currentNode&&(this.el.removeChild(this._currentNode),this._currentNode=void 0,this._emitter.emit("canceled"))}dump(){return this.el.innerHTML}load(n){this.clear(),this.el.innerHTML=n}_appendNode(n){const e=this._elements.at(-1);e?e.after(n):this.el.append(n);const t=this._elements.push(n)-1;n.dataset.drauu_index=t.toString()}_removeNode(n){n.remove(),this._elements[+n.dataset.drauu_index]=null}_restoreNode(n){const e=+n.dataset.drauu_index;this._elements[e]=n;for(let t=e-1;t>=0;t--){const a=this._elements[t];if(a){a.after(n);return}}this.el.prepend(n)}};function oP(n){return new iP(n)}const tr=["#000000",...new Array(12).fill(!0).map((n,e)=>`hsl(${e*30}, 100%,50%)`),"#ffffff"],sP=Yc([4,8,16,24]);ee();const nn=Wm(ue("drawings",{})),ja=ee("/");ee();const va=ee(!1),Ay=ue("drawing-pinned",!1),Cy=ee(!1),My=ee(!1),Iy=ee(!1),Em=ee(!1),Dm=ee(!1),Ga=Wm(ue("drawing-brush",{color:tr[0],size:10,mode:"stylus"})),Pm=ee("stylus");let jo=!1;const rP=H({get(){return Pm.value},set(n){Pm.value=n,n==="arrow"?(Ga.mode="line",Ga.arrowEnd=!0):(Ga.mode=n,Ga.arrowEnd=!1)}}),lP=De({brush:Ga,acceptsInputTypes:H(()=>va.value?void 0:["pen"]),coordinateTransform:!0}),St=xi(oP(lP));function Nm(){St.clear()}function Bm(){var n;My.value=St.canRedo(),Cy.value=St.canUndo(),Iy.value=!!((n=St.el)!=null&&n.children.length)}function jm(n){jo=!0;const e=nn[n||ja.value];e!=null?St.load(e):St.clear(),jo=!1}function Ey(){return Dm.value||(St.on("changed",()=>{if(Bm(),!jo){const n=St.dump(),e=ja.value;(nn[e]||"")!==n&&(nn[e]=n)}}),bn(()=>{rn(()=>{(nn==null?void 0:nn[ja.value])!=null&&St.load((nn==null?void 0:nn[ja.value])||"")})}),de(ja,n=>{jo=!0,nn[n]!=null&&St.load(nn[n]||""),jo=!1,Bm()}),rn(()=>{de(ja,()=>{jm()},{immediate:!0})}),St.on("start",()=>Em.value=!0),St.on("end",()=>Em.value=!1),window.addEventListener("keydown",n=>{if(!va.value)return;const e=!n.ctrlKey&&!n.altKey&&!n.shiftKey&&!n.metaKey;let t=!0;n.code==="KeyZ"&&(n.ctrlKey||n.metaKey)?n.shiftKey?St.redo():St.undo():n.code==="Escape"?va.value=!1:n.code==="KeyC"&&(n.ctrlKey||n.metaKey)?Nm():n.code.startsWith("Digit")&&e&&+n.code[5]<=tr.length?Ga.color=tr[+n.code[5]-1]:t=!1,t&&(n.preventDefault(),n.stopPropagation())},!1)),Dm.value=!0,{brush:Ga,brushColors:tr,brushSizes:sP,canClear:Iy,canRedo:My,canUndo:Cy,clearDrauu:Nm,currentPage:ja,drauu:St,drawingEnabled:va,drawingMode:rP,drawingPinned:Ay,loadCanvas:jm}}const na=n=>(mt("data-v-86455f2f"),n=n(),pt(),n),cP={class:"is-group flex gap-2 px-2 py-1"},hP=na(()=>v("div",{class:"i-carbon-pen"},null,-1)),dP=[hP],uP=na(()=>v("svg",{class:"-mt-1",width:"1em",height:"1em",preserveAspectRatio:"xMidYMid meet",viewBox:"0 0 24 24"},[v("path",{d:"M21.71 3.29a1 1 0 0 0-1.42 0l-18 18a1 1 0 0 0 0 1.42a1 1 0 0 0 1.42 0l18-18a1 1 0 0 0 0-1.42z",fill:"currentColor"})],-1)),mP=[uP],pP=na(()=>v("div",{class:"i-carbon-arrow-up-right"},null,-1)),fP=[pP],gP=na(()=>v("div",{class:"i-carbon-radio-button"},null,-1)),yP=[gP],bP=na(()=>v("div",{class:"i-carbon-checkbox"},null,-1)),vP=[bP],wP={class:"is-group flex flex-wrap"},_P=["onClick"],kP={class:"is-group flex gap-2 px-2"},TP=na(()=>v("div",{class:"i-carbon-undo"},null,-1)),xP=[TP],SP=na(()=>v("div",{class:"i-carbon-redo"},null,-1)),AP=[SP],CP=na(()=>v("div",{class:"i-carbon-delete"},null,-1)),MP=[CP],IP=na(()=>v("div",{class:"flex-1"},null,-1)),EP={class:"i-carbon-pin-filled transform -rotate-45"},DP={class:"i-carbon-pin"},PP={class:"i-carbon-error"},NP={class:"i-carbon-close-outline"},BP={__name:"DrawControls",setup(n){const e=Ta(),{brush:t,brushColors:a,canClear:i,canRedo:o,canUndo:s,clearDrauu:r,drauu:l,drawingEnabled:c,drawingMode:h,brushSizes:d,drawingPinned:u,currentPage:m}=Ey();bn(()=>{de(e,x=>m.value=x.path,{immediate:!0})});function p(){l.undo()}function g(){l.redo()}function y(x){h.value=x,c.value=!0}function b(x){t.color=x,c.value=!0}return de(()=>B.note,x=>{t.color=Ve(x.pitch)}),(x,S)=>(_(),T("div",{class:ae(["panel",f(c)?"":f(u)?"opacity-40 hover-opacity-90":"opacity-0 pointer-events-none"]),"storage-key":"slidev-drawing-pos","initial-x":10,"initial-y":10},[v("button",{class:"w-6 flex items-center justify-center",onClick:S[0]||(S[0]=k=>f(t).size=f(d).next())},[v("div",{class:"bg-current rounded-full",style:se({width:f(t).size+4+"px",height:f(t).size+4+"px",backgroundColor:f(t).color})},null,4)]),v("div",cP,[v("button",{class:ae({active:f(h)=="stylus"}),onClick:S[1]||(S[1]=k=>y("stylus"))},dP,2),v("button",{class:ae({active:f(h)=="line"}),onClick:S[2]||(S[2]=k=>y("line"))},mP,2),v("button",{class:ae({active:f(h)=="arrow"}),onClick:S[3]||(S[3]=k=>y("arrow"))},fP,2),v("button",{class:ae({active:f(h)=="ellipse"}),onClick:S[4]||(S[4]=k=>y("ellipse"))},yP,2),v("button",{class:ae({active:f(h)=="rectangle"}),onClick:S[5]||(S[5]=k=>y("rectangle"))},vP,2)]),v("div",wP,[(_(!0),T(ke,null,Me(f(a),k=>(_(),T("button",{key:k,class:ae(f(t).color===k?"active":"shallow"),onClick:w=>b(k)},[v("div",{class:ae(["w-6 h-6 transition-all transform border border-gray-400 border-opacity-50",f(t).color!==k?"rounded-1/2 scale-85":"rounded-md"]),style:se(f(c)?{background:k}:{borderColor:k})},null,6)],10,_P))),128))]),v("div",kP,[v("button",{class:ae({disabled:!f(s)}),onClick:S[6]||(S[6]=k=>p())},xP,2),v("button",{class:ae({disabled:!f(o)}),onClick:S[7]||(S[7]=k=>g())},AP,2),v("button",{class:ae({disabled:!f(i)}),onClick:S[8]||(S[8]=k=>f(r)())},MP,2)]),IP,v("button",{class:ae({shallow:!f(u)}),onClick:S[9]||(S[9]=k=>u.value=!f(u))},[F(v("div",EP,null,512),[[bt,f(u)]]),F(v("div",DP,null,512),[[bt,!f(u)]])],2),f(c)?(_(),T("button",{key:0,class:ae({shallow:!f(c)}),onClick:S[10]||(S[10]=k=>c.value=!f(c))},[F(v("div",PP,null,512),[[bt,f(u)]]),F(v("div",NP,null,512),[[bt,!f(u)]])],2)):U("",!0)],2))}},jP=Fe(BP,[["__scopeId","data-v-86455f2f"]]),zP={__name:"CastCamera",setup(n){const e=yt(ue("cast-cam-size",Math.round(Math.min(window.innerHeight,window.innerWidth/4))),140,600),t=yt(ue("cast-cam-zoom",1),1,3),a=ee({x:window.innerWidth-e.value-30,y:window.innerHeight-e.value-30}),i=ee(),o=ee();ee();const s=ee(),{streamCamera:r,showAvatar:l}=ng,{style:c}=Od(i,{initialValue:a}),{isDragging:h}=Od(o,{onMove({x:y,y:b}){e.value=Math.max(10,Math.min(y-a.value.x,b-a.value.y)/.8536)}});function d(y){t.value-=y.delta[1]/100}dn(()=>{s.value&&(s.value.srcObject=r.value)},{flush:"post"});const u=H(()=>({width:`${e.value}px`,height:`${e.value}px`})),m=H(()=>({width:"14px",height:"14px",top:`${e.value*.8536-7}px`,left:`${e.value*.8536-7}px`,cursor:"nwse-resize"})),p=H(()=>({width:"14px",height:"14px",top:`${(1-(t.value-1)/2)*e.value}px`,right:"12px",cursor:"ns-resize"}));function g(){a.value.x>=window.innerWidth&&(a.value.x=window.innerWidth-e.value-30),a.value.y>=window.innerHeight&&(a.value.y=window.innerHeight-e.value-30)}return Gm("resize",g),bn(g),(y,b)=>{const x=pn("drag");return f(r)&&f(l)&&f(Wt)!=="none"?(_(),T("div",{key:0,class:"avatar fixed z-1000",style:se(f(c))},[v("div",{class:"rounded-full shadow bg-gray-400 bg-opacity-10 overflow-hidden object-cover shadow-lg",ref_key:"frame",ref:i,style:se(u.value)},[v("video",{class:"object-cover min-w-full min-h-full rounded-full",ref_key:"video",ref:s,autoplay:"",muted:"",volume:"0",style:se(`transform: rotateY(180deg) scale(${f(t)})`)},null,4)],4),F(v("div",{class:"absolute bottom-0 right-0 rounded-full shadow-lg shadow z-30 p-2 bg-violet-500 bg-opacity-40 hover-bg-opacity-100",style:se(p.value)},null,4),[[x,d]]),v("div",{class:ae(["absolute bottom-0 right-0 rounded-full shadow-lg shadow z-300 p-2 bg-purple-500 bg-opacity-40 hover-bg-opacity-100",f(h)?"!opacity-100":""]),ref_key:"handler",ref:o,style:se(m.value)},null,6)],4)):U("",!0)}}},RP={__name:"DrawLayer",setup(n){const e=ee(),{drauu:t,drawingEnabled:a,loadCanvas:i}=Ey();return bn(()=>{t.mount(e.value,e.value.parentElement),i()}),Fr(()=>{t.unmount()}),(o,s)=>(_(),T("svg",{class:ae(["absolute w-full h-full top-0 bottom-0 left-0 right-0",{"pointer-events-none":!f(a),"touch-none":f(a)}]),ref_key:"svg",ref:e},null,2))}};function Pd(n,e){const t=ee(e),a=H(()=>Nd(t.value)),i=H(()=>a.value[Ce(n.path)]),o=H(()=>FP(n.path,t.value)),s=H(()=>LP(n.path,t.value));return{pages:a,siblings:s,children:i,parents:o}}function Dy(n,e){return H(()=>Nd(e)[Ce(n.path)])}function OP(n,e){return H(()=>qP(n.path,e))}function qP(n,e){return e.find(t=>Ce(t.url)==Ce(n))}function Nd(n){let e={};for(let t of n){const a=Bd(t.url.split("/").slice(0,-2).join("/"));e[a]=e[a]||[],e[a].push(t)}for(let t in e)e[t].sort((a,i)=>{var o,s;return(o=a.frontmatter)!=null&&o.date&&((s=i.frontmatter)!=null&&s.date)?a.frontmatter.date>i.frontmatter.date?-1:1:0});return e}function FP(n,e){n=Ce(n);const t=[],a=n.split("/").filter(Boolean);for(let i=0;i<=a.length;i++){const o=Bd("/"+a.slice(0,i).join("/"));t.push(e.find(s=>Ce(s.url)==o))}return t.filter(Boolean)}function LP(n,e){let t=null,a=null,i=0,o=0;const s=Bd(n.split("/").slice(0,-2).join("/")),r=Nd(e)[s];return r&&(o=r.length,i=r.findIndex(l=>Ce(l.url)==Ce(n)),i>=0&&i<=r.length&&(a=r[i+1]),i>0&&(t=r[i-1])),{next:a,prev:t,index:i,total:o}}function Bd(n){return n+=n.endsWith("/")?"":"/"}function Ce(n){return(n||"").replace(/\/[^/]*\.(html)$/,"/")}const jd=n=>(mt("data-v-f00778be"),n=n(),pt(),n),GP={class:"next-and-prev-link"},$P=["href"],VP={class:"link"},HP=jd(()=>v("div",{class:"i-carbon-arrow-left icon icon-prev"},null,-1)),WP={class:"text"},UP=["href"],KP={class:"link"},JP={class:"text"},ZP=jd(()=>v("div",{class:"i-carbon-arrow-right icon icon-next"},null,-1)),YP={class:"flex flex-col items-justify"},XP={class:"flex flex-col items-justify mx-4"},QP=["href"],e3={class:"link"},t3=jd(()=>v("div",{class:"i-carbon-arrow-up mr-1"},null,-1)),n3={class:"text"},a3={__name:"NavNextPrev",props:["parents","siblings"],setup(n){const e=n,t=De({current:H(()=>vt(e.siblings.index,e.siblings.total,.9,20,50)),prev:H(()=>vt(e.siblings.index-1,e.siblings.total,.8,20,50)),next:H(()=>vt(e.siblings.index+1,e.siblings.total,.8,20,50))});return(a,i)=>{var o,s,r,l,c,h,d,u;return _(),T("div",GP,[v("div",{class:"row",style:se({borderColor:t.current})},[n.siblings.prev?(_(),T("a",{key:0,class:"pad prev",href:f(Ce)(n.siblings.prev.url),style:se({backgroundColor:t.prev,backgroundImage:`url(${(s=(o=n.siblings.prev)==null?void 0:o.frontmatter)==null?void 0:s.cover})`})},[v("div",VP,[HP,v("span",WP,K((l=(r=n.siblings.prev)==null?void 0:r.frontmatter)==null?void 0:l.title),1)])],12,$P)):U("",!0),n.siblings.next?(_(),T("a",{key:1,class:"pad next",href:f(Ce)(n.siblings.next.url),style:se({backgroundColor:t.next,backgroundImage:`url(${(h=(c=n.siblings.next)==null?void 0:c.frontmatter)==null?void 0:h.cover})`})},[v("div",KP,[v("span",JP,K((u=(d=n.siblings.next)==null?void 0:d.frontmatter)==null?void 0:u.title),1),ZP])],12,UP)):U("",!0)],4),v("div",YP,[v("div",XP,[(_(!0),T(ke,null,Me([...n.parents].slice(1,-1),(m,p)=>{var g,y;return _(),T("a",{class:"pad",style:se([{flex:"1 1"},{order:100-p,backgroundColor:t.next,backgroundImage:`url(${(g=m==null?void 0:m.frontmatter)==null?void 0:g.cover})`}]),key:m,href:f(Ce)(m.url)},[v("div",e3,[t3,v("div",n3,K((y=m==null?void 0:m.frontmatter)==null?void 0:y.title),1)])],12,QP)}),128))])])])}}},i3=Fe(a3,[["__scopeId","data-v-f00778be"]]),o3={key:0,class:"flex flex-wrap mt-4"},s3=["href"],r3={key:0,class:"i-la-link"},l3={key:1,class:"i-la-github"},c3={key:2,class:"i-la-instagram"},h3={key:3,class:"i-la-heart"},d3={key:4,class:"i-la-discord"},u3={key:5,class:"i-la-reddit"},m3={__name:"PageButtons",props:{buttons:Array,color:{type:String,default:""}},setup(n){return(e,t)=>n.buttons&&n.buttons.length>0?(_(),T("div",o3,[(_(!0),T(ke,null,Me(n.buttons,a=>(_(),T("a",{class:"button",key:a.url,href:a.url,target:"_blank",style:se({backgroundColor:n.color})},[(a==null?void 0:a.type)=="primary"?(_(),T("div",r3)):U("",!0),(a==null?void 0:a.type)=="github"?(_(),T("div",l3)):U("",!0),(a==null?void 0:a.type)=="instagram"?(_(),T("div",c3)):U("",!0),(a==null?void 0:a.type)=="heart"?(_(),T("div",h3)):U("",!0),(a==null?void 0:a.type)=="discord"?(_(),T("div",d3)):U("",!0),(a==null?void 0:a.type)=="reddit"?(_(),T("div",u3)):U("",!0),v("span",null,K(a.text),1)],12,s3))),128))])):U("",!0)}},Py=Fe(m3,[["__scopeId","data-v-c522640e"]]),p3={key:0,class:"text-sm rounded-full flex items-center"},f3={key:0,class:"i-mdi-watering-can can"},g3={key:1,class:"i-mdi-watering-can-outline can"},y3={class:"flex-1 font-normal"},b3={__name:"CardDate",props:{date:String},setup(n){const e=n,t=H(()=>Date.now()-new Date(e.date).getTime()),a=H(()=>t.value<1e3*60*60*24),i=H(()=>t.value<1e3*60*60*24*7),o=hb(new Date(e.date),{messages:{justNow:" now",past:s=>s.match(/\d/)?`${s}`:s,future:s=>s.match(/\d/)?`in ${s}`:s,month:s=>`${s} mo`,year:s=>`${s} y`,day:s=>`${s} d`,week:s=>`${s} w`,hour:s=>`${s} h`,minute:s=>`${s} m`,second:s=>`${s} s`}});return(s,r)=>i.value?(_(),T("div",p3,[a.value?(_(),T("div",f3)):(_(),T("div",g3)),v("div",y3,K(f(o)),1)])):U("",!0)}},v3=Fe(b3,[["__scopeId","data-v-fcdd3eb4"]]),ni=JSON.parse(`[{"src":"---\\ntitle: Elementary synth\\ndescription: MIDI enabled synthesizer built with Elementary audio library\\ndate: 2024-06-23\\ncover: lockup.svg\\nlayout: app\\nlinks:\\n  - https://www.elementary.audio/docs/guides/Understanding_Keys\\n  - https://www.elementary.audio/docs/reference/Math\\n  - https://github.com/elemaudio/web-examples\\n  - https://github.com/bgins/coincident-spectra/blob/main/src/lib/audio/audio.ts\\n  - https://github.com/teetow/elementary_grid\\n  - https://www.nickwritesablog.com/drum-synthesis-in-javascript/\\n  - https://github.com/elemaudio/web-examples/blob/master/planets/app.js\\n  - https://github.com/teetow/elementary_grid/blob/master/src/lib/useSynth.tsx\\n---\\n\\n\\n<client-only>\\n<AudioSynthMain />\\n<MidiKeys />\\n</client-only>\\n","frontmatter":{"title":"Elementary synth","description":"MIDI enabled synthesizer built with Elementary audio library","date":"2024-06-23T00:00:00.000Z","cover":"/media_files/cover/practice-synth-elementary-lockup.svg","layout":"app","links":["https://www.elementary.audio/docs/guides/Understanding_Keys","https://www.elementary.audio/docs/reference/Math","https://github.com/elemaudio/web-examples","https://github.com/bgins/coincident-spectra/blob/main/src/lib/audio/audio.ts","https://github.com/teetow/elementary_grid","https://www.nickwritesablog.com/drum-synthesis-in-javascript/","https://github.com/elemaudio/web-examples/blob/master/planets/app.js","https://github.com/teetow/elementary_grid/blob/master/src/lib/useSynth.tsx"]},"url":"/practice/synth/elementary/"},{"src":"---\\ntitle: Bouncing sinusoids\\ndescription: Polyrhythmic explorations\\ndate: 2024-06-18\\nlayout: app\\ncover: cover.png\\nlinks: \\n  - http://travisrtaylor.com/pendulum-explainer/\\n  - https://www.particleincell.com/2012/bezier-splines/\\n  - https://gist.github.com/AndreVallestero/bfd2037d10cd975b9854888df530b98a\\n  - https://blindsvg.com/pages/curves/\\n  - https://francoisromain.medium.com/smooth-a-svg-path-with-cubic-bezier-curves-e37b49d46c74\\n  - https://minus-ze.ro/posts/morphing-arbitrary-paths-in-svg/?ck_subscriber_id=2246502080\\n---\\n\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst Bounce = defineClientComponent(() => {\\n  return import('./Bounce.vue')\\n})\\n<\/script>\\n\\n<Bounce/>\\n","frontmatter":{"title":"Bouncing sinusoids","description":"Polyrhythmic explorations","date":"2024-06-18T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sequencing-bounce-cover.png","links":["http://travisrtaylor.com/pendulum-explainer/","https://www.particleincell.com/2012/bezier-splines/","https://gist.github.com/AndreVallestero/bfd2037d10cd975b9854888df530b98a","https://blindsvg.com/pages/curves/","https://francoisromain.medium.com/smooth-a-svg-path-with-cubic-bezier-curves-e37b49d46c74","https://minus-ze.ro/posts/morphing-arbitrary-paths-in-svg/?ck_subscriber_id=2246502080"]},"url":"/practice/sequencing/bounce/"},{"src":"---\\ntitle: Pendulums\\ndescription: Polyrhythmic explorations\\ndate: 2024-06-17\\nlayout: app\\ncover: cover.png\\nlinks: \\n  - http://travisrtaylor.com/pendulum-explainer/\\n---\\n\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst Pendulums = defineClientComponent(() => {\\n  return import('./Pendulums.vue')\\n})\\n<\/script>\\n\\n<Pendulums/>\\n","frontmatter":{"title":"Pendulums","description":"Polyrhythmic explorations","date":"2024-06-17T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sequencing-pendulums-cover.png","links":["http://travisrtaylor.com/pendulum-explainer/"]},"url":"/practice/sequencing/pendulums/"},{"src":"---\\ntitle: ZZFX\\ndescription:  Zuper Zmall Zound Zynth\\ndate: 2024-06-16\\nlayout: app\\ncover: cover.png\\nlinks:\\n  - https://github.com/KilledByAPixel/ZzFX\\n  - https://killedbyapixel.github.io/ZzFX/\\n  - https://keithclark.github.io/ZzFXM/#note-code-1\\n  - https://github.com/keithclark/ZzFXM\\n  - https://github.com/js13kGames\\n---\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst SynthZzfx = defineClientComponent(() => {\\n  return import('./SynthZzfx.vue')\\n})\\n<\/script>\\n\\n<SynthZzfx/>\\n\\n\\n## ZzFX\\n\\n### A Tiny JavaScript Sound FX System\\n\\nZzFX is a tiny sound generator designed to produce a wide variety of sound effects with minimal code overhead. It's perfect for games, prototypes, and any web application that needs sound without the bulk of traditional sound files.\\n\\nhttps://zzfx.3d2k.com \\n\\nhttps://github.com/KilledByAPixel/ZzFX\\n\\n### Features\\n\\n- Compact: Less than 1 kilobyte when compressed!\\n- Versatile: 20 controllable parameters for diverse sound effects.\\n- No Dependencies: Standalone with no external libraries.\\n- Cross-Browser: Compatible with nearly all web browsers.\\n- Open Source: MIT licensed, use it anywhere!\\n","frontmatter":{"title":"ZZFX","description":"Zuper Zmall Zound Zynth","date":"2024-06-16T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-synth-zzfx-cover.png","links":["https://github.com/KilledByAPixel/ZzFX","https://killedbyapixel.github.io/ZzFX/","https://keithclark.github.io/ZzFXM/#note-code-1","https://github.com/keithclark/ZzFXM","https://github.com/js13kGames"]},"url":"/practice/synth/zzfx/"},{"src":"---\\ntitle: Soundfont sampler synth\\ndescription: Open source sample-based online synthesizer\\ndate: 2024-06-10\\nlayout: app\\ncover: cover.png\\nlinks:\\n  - https://github.com/danigb/smplr\\n---\\n\\n<script setup>\\nimport { synth as AppSynth } from \\"#/use\\";\\n  import { onBeforeUnmount, onMounted } from \\"vue\\";\\n\\nonMounted(() => {\\n  AppSynth.state.midi = false\\n})\\n\\nonBeforeUnmount(() => {\\n  AppSynth.state.midi = true\\n})\\n<\/script>\\n\\n<client-only>\\n<Synth-font class=\\"m-2\\" />\\n<MidiKeys >\\n\\n</MidiKeys>\\n</client-only>\\n","frontmatter":{"title":"Soundfont sampler synth","description":"Open source sample-based online synthesizer","date":"2024-06-10T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-synth-soundfont-cover.png","links":["https://github.com/danigb/smplr"]},"url":"/practice/synth/soundfont/"},{"src":"---\\ntitle: Karplus–Strong synthesis\\ndescription: Pratical KS synth\\ndate: 2024-06-01\\ncover: ksa.png\\nlayout: app\\n---\\n\\n<AudioStringSynth />\\n","frontmatter":{"title":"Karplus–Strong synthesis","description":"Pratical KS synth","date":"2024-06-01T00:00:00.000Z","cover":"/media_files/cover/practice-synth-karplus-strong-ksa.png","layout":"app"},"url":"/practice/synth/karplus-strong/"},{"src":"---\\ntitle: Chord Sheets Lab\\ndescription: Chordsheetjs experiments\\ndate: 2024-05-25\\ncover: cover.png\\nlayout: app\\nlinks:\\n  - https://snyk.io/advisor/npm-package/chordsheetjs/example\\n  - https://martijnversluis.github.io/ChordFiddle/\\n  - https://github.com/martijnversluis/ChordSheetJS\\n  - https://www.chordpro.org/chordpro/chordpro6-relnotes/\\n---\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst ChordSheets = defineClientComponent(() => {\\n  return import('./ChordSheets.vue')\\n})\\n<\/script>\\n\\n<ChordSheets/>\\n\\n[ChordSheetJS Playground](https://github.com/martijnversluis/ChordSheetJS)\\n","frontmatter":{"title":"Chord Sheets Lab","description":"Chordsheetjs experiments","date":"2024-05-25T00:00:00.000Z","cover":"/media_files/cover/practice-chord-chord-sheets-cover.png","layout":"app","links":["https://snyk.io/advisor/npm-package/chordsheetjs/example","https://martijnversluis.github.io/ChordFiddle/","https://github.com/martijnversluis/ChordSheetJS","https://www.chordpro.org/chordpro/chordpro6-relnotes/"]},"url":"/practice/chord/chord-sheets/"},{"src":"---\\ntitle: Physical sequencer\\ndescription: 2D rigid body physics simulator\\ndate: 2024-05-24\\nlayout: app\\ncover: matter.png\\nlinks: \\n  - https://codepen.io/tt9/pen/xxEmmRO\\n  - https://www.paulie.dev/posts/2020/08/react-hooks-and-matter-js/\\n  - https://github.com/liabru/matter-js/blob/master/src/geometry/Bounds.js\\n  - https://brm.io/matter-js/\\n  - https://github.com/liabru/matter-js/wiki/Getting-started#usage-example\\n  - https://brm.io/matter-js/docs/classes/Body.html#property_torque\\n  - https://github.com/liabru/matter-js/wiki/Getting-started\\n  - https://github.com/kyte3/game-project/blob/main/src/components/PhysicsGame.vue\\n---\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst Matter = defineClientComponent(() => {\\n  return import('./Matter.vue')\\n})\\n<\/script>\\n\\n<Matter/>\\n","frontmatter":{"title":"Physical sequencer","description":"2D rigid body physics simulator","date":"2024-05-24T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sequencing-matter-matter.png","links":["https://codepen.io/tt9/pen/xxEmmRO","https://www.paulie.dev/posts/2020/08/react-hooks-and-matter-js/","https://github.com/liabru/matter-js/blob/master/src/geometry/Bounds.js","https://brm.io/matter-js/","https://github.com/liabru/matter-js/wiki/Getting-started#usage-example","https://brm.io/matter-js/docs/classes/Body.html#property_torque","https://github.com/liabru/matter-js/wiki/Getting-started","https://github.com/kyte3/game-project/blob/main/src/components/PhysicsGame.vue"]},"url":"/practice/sequencing/matter/"},{"src":"---\\ntitle: Chroma Touch\\ndescription: Intuitive and performant WebMIDI intstrument\\ndate: 2024-05-20\\nlayout: app\\ncover: cover.png\\n---\\n\\n<ChromaTouch  />\\n","frontmatter":{"title":"Chroma Touch","description":"Intuitive and performant WebMIDI intstrument","date":"2024-05-20T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-chroma-touch-cover.png"},"url":"/practice/chroma/touch/"},{"src":"---\\ntitle: Random Jam\\ndescription: A simple randomizer for basic jam parameters - BPM, Tonic and Scale.\\ndate: 2024-04-30\\ntopContent: true\\ncover: jam.png\\nlayout: app\\n---\\n\\n\\n<client-only>\\n  <jam-random />\\n</client-only>\\n","frontmatter":{"title":"Random Jam","description":"A simple randomizer for basic jam parameters - BPM, Tonic and Scale.","date":"2024-04-30T00:00:00.000Z","topContent":true,"cover":"/media_files/cover/practice-jam-random-jam.png","layout":"app"},"url":"/practice/jam/random/"},{"src":"---\\ntitle: Number Sequences\\ndescription: Playing with mathematical wonders\\ndate: 2024-04-08\\nlayout: app\\ncover: cover.png\\nlinks: \\n  - https://www.npmjs.com/package/jisg\\n---\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst Numbers = defineClientComponent(() => {\\n  return import('./Numbers.vue')\\n})\\n<\/script>\\n\\n<Numbers/>\\n","frontmatter":{"title":"Number Sequences","description":"Playing with mathematical wonders","date":"2024-04-08T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sequencing-numbers-cover.png","links":["https://www.npmjs.com/package/jisg"]},"url":"/practice/sequencing/numbers/"},{"src":"---\\ntitle: MIDI Keys\\ndescription: Reactive colorful virtual piano keyboard\\ndate: 2023-10-06\\nlayout: app\\ncover: cover.png\\n---\\n\\n\\n<MidiKeys />\\n","frontmatter":{"title":"MIDI Keys","description":"Reactive colorful virtual piano keyboard","date":"2023-10-06T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-midi-keys-cover.png"},"url":"/practice/midi/keys/"},{"src":"---\\ntitle: Printable A4 piano chords\\ndescription: All chords for all scales on one page\\ncover: piano.png\\ndate: 2023-08-02\\nlayout: app\\nproduct:\\n  price: 10\\n  id: print-piano-a4\\n  digital: true\\n---\\n\\n<script setup>\\nimport PianoChords from './PianoChords.vue'\\n<\/script>\\n\\n## Diatonic scales and modes\\n\\n<piano-chords width=\\"100%\\" class=\\"max-w-55ch\\" />\\n<save-buttons svg=\\"diatonic\\" password=\\"piano-a4-Vr74E\\"/>\\n","frontmatter":{"title":"Printable A4 piano chords","description":"All chords for all scales on one page","cover":"/media_files/cover/practice-experiments-printables-piano-a4-piano.png","date":"2023-08-02T00:00:00.000Z","layout":"app","product":{"price":10,"id":"print-piano-a4","digital":true}},"url":"/practice/experiments/printables/piano-a4/"},{"src":"---\\ntitle: Jam table\\ndescription: A visual guide for jamming to be placed on the table and accessible from both sides\\ndate: 2023-01-01\\ncover: cover.png\\nlayout: app\\n---\\n\\n<client-only>\\n  <jam-table />\\n</client-only>\\n","frontmatter":{"title":"Jam table","description":"A visual guide for jamming to be placed on the table and accessible from both sides","date":"2023-01-01T00:00:00.000Z","cover":"/media_files/cover/practice-jam-table-cover.png","layout":"app"},"url":"/practice/jam/table/"},{"src":"---\\ntitle: Tuner\\ndescription: Fast and precise instrument tuner web-app\\nlayout: app\\ncover: tuner.svg\\ndate: 2022-06-18\\n---\\n\\n<ClientOnly>\\n  <pitch-tuner class=\\"max-h-98dvh\\" />\\n</ClientOnly>\\n\\nStart the tuner with the button at the center and produce the sound you want to find the pitch for. It may be your guitar, ukulele or any other string instrument. It may be your voice. The app will show the base frequency of the sound as well as the cents difference with the closes 12-TET note. The color of the background gradient corresponds to the exact frequency the app has detected.\\n","frontmatter":{"title":"Tuner","description":"Fast and precise instrument tuner web-app","layout":"app","cover":"/media_files/cover/practice-pitch-tuner-tuner.svg","date":"2022-06-18T00:00:00.000Z"},"url":"/practice/pitch/tuner/"},{"src":"---\\ntitle: See Chroma\\ndescription: Let's look at the relative amounts of all pitch class frequencies in any audio signal in real time.\\ncover: chroma.png\\ndate: 2022-06-16\\nlayout: app\\n---\\n\\n<client-only>\\n  <chroma-see />\\n</client-only>\\n\\n---\\n\\nFeatures:\\n\\n- Drag over the scene horizontally to adjust circles blur\\n- Drag over the scene vertically to adjust circles size\\n\\nStandalone visualizer at [see.chromatone.center](https://see.chromatone.center/)\\n","frontmatter":{"title":"See Chroma","description":"Let's look at the relative amounts of all pitch class frequencies in any audio signal in real time.","cover":"/media_files/cover/practice-chroma-see-chroma.png","date":"2022-06-16T00:00:00.000Z","layout":"app"},"url":"/practice/chroma/see/"},{"src":"---\\ntitle: MIDI Roll\\ndescription: Record all MIDI notes on an infinite roll\\nlayout: app\\ncover: midi-roll.png\\ndate: 2022-06-16\\n---\\n\\n<client-only >\\n  <midi-roll />\\n</client-only>\\n\\n1. Play some notes on your MIDI controller or computer keyboard and watch them appear on the endless roll.\\n2. Drag or scroll over the canvas to change the roll speed.\\n3. Press the <i class=\\"p-3 mr-1 i-la-arrow-up\\"></i> (<i class=\\"p-3 mr-1 i-la-arrow-left\\"></i> ) button to change the plot direction\\n4. Press the <i class=\\"p-3 mr-1 i-la-expand\\"></i> button to expand the app to full screen\\n5. Press the <i class=\\"p-3 mr-1 i-la-play\\"></i>/<i class=\\"p-3 mr-1 i-la-pause\\"></i> icon or anywhere on the canvas to send MIDI play/pause signal to all connected MIDI devices\\n6. Press the <i class=\\"p-3 mr-1 i-la-stop\\"></i> icon or double click on the canvas to send MIDI play/pause signal to all connected MIDI devices\\n7. Use MIDI channel filter to show only the desired channels.\\n","frontmatter":{"title":"MIDI Roll","description":"Record all MIDI notes on an infinite roll","layout":"app","cover":"/media_files/cover/practice-midi-roll-midi-roll.png","date":"2022-06-16T00:00:00.000Z"},"url":"/practice/midi/roll/"},{"src":"---\\ntitle: Spectrogram\\ndescription: 2.5D representation on frequency domain in time\\nlayout: app\\ndate: 2022-06-16\\ncover: spectrogram.png\\nusefulLinks:\\n  - https://codepen.io/hvianna/pen/ZEKWWJb\\n  - https://www.npmjs.com/package/audiomotion-analyzer\\n  - https://github.com/ListeningToWaves/SpectrogramTesting/blob/master/src/components/spectrogram.js\\n---\\n\\n\\n<client-only>\\n  <PitchSpectrogram />\\n</client-only>\\n\\nThe colorful spectrogram is a powerful tool for visual audio analysis. Each particular frequency in the spectrum gets it's own position on the vertical axis along with the corresponding Chromatone color. The pitch spectrum is continous and the graph shows all the partials in a rather high resolution. The colors of the lines help differentiate pitches and overtones in any incoming audio signal. The quality of analysis is based primarily on the quality of the signal – thus a good microphone is recommended for best experience.\\n\\n## How to use the spectrogram\\n\\n1. Drag across <i class=\\"p-3 mr-1 i-la-hand-rock\\"></i> the spectrogram top change the roll speed. The actual setting is at the top-left corner.\\n2. Press the <i class=\\"p-3 mr-1 i-la-expand\\"></i> icon at the bottom-right corner make the spectrogram go full screen. Very useful mode for deep explorations and teaching.\\n3. You can pause <i class=\\"p-3 mr-1 i-la-pause\\"></i> and resume <i class=\\"p-3 mr-1 i-la-play\\"></i> the roll either by clicking anywhere at the spectrogram or by pressing the \`Spacebar\` button on your keyboard. Useful when comparing two or more sound spectrums – record a sound spectrum on the roll, then pause it, take another instrument and record another. The roll can fit up to 10 segments or even more.\\n4. Clear the canvas with the <i class=\\"p-3 mr-1 i-la-trash-alt\\"></i> button at the top-right corner or by pressing the \`Enter\` button on your keyboard.\\n5. POW control changes the Power to which we raise the value of each band. It accentuates louder frequencies and dampens noise.\\n6. OFFSET control is for tuning the values before the raising to the power. It can help adjust the brightness and sensitivity of the spectroscope.\\n7. Right click the small video to open the spectrogram in Picture-In-Picture mode. You may need to press play in the floating window to see the spectrogram running.\\n","frontmatter":{"title":"Spectrogram","description":"2.5D representation on frequency domain in time","layout":"app","date":"2022-06-16T00:00:00.000Z","cover":"/media_files/cover/practice-pitch-spectrogram-spectrogram.png","usefulLinks":["https://codepen.io/hvianna/pen/ZEKWWJb","https://www.npmjs.com/package/audiomotion-analyzer","https://github.com/ListeningToWaves/SpectrogramTesting/blob/master/src/components/spectrogram.js"]},"url":"/practice/pitch/spectrogram/"},{"src":"---\\ntitle: Сhromagram\\ndescription: Visual representation of any audio chroma content\\ndate: 2022-06-12\\ncover: chromagram.png\\nlayout: app\\n---\\n\\n<client-only >\\n  <chroma-gram />\\n</client-only>\\n\\nThis app shows the [chromagram](https://en.wikipedia.org/wiki/Chroma_feature) or the [12 tone harmonic pitch class profile](https://en.wikipedia.org/wiki/Harmonic_pitch_class_profiles) of the incoming signal. It means is analyzes the frequency spectrum and sums them according to one of the 12 pitch classes. The relative power of every pitch class is plotted, showing the primary tones of the audio signal. Pure sine tone will give us one line filled and noise will make all the bands glow equally bright.\\n\\n1. <i class=\\"p-3 mr-1 i-fluent-drag-24-regular\\"></i> Drag the canvas graph to change the roll speed.\\n2. Press the <i class=\\"p-3 i-la-arrow-up\\"></i> (<i class=\\"p-3 i-la-arrow-left\\"></i>) button to change the plot direction\\n3. Press the <i class=\\"p-3 mr-1 i-la-expand\\"></i>button to expand the app to full screen\\n","frontmatter":{"title":"Сhromagram","description":"Visual representation of any audio chroma content","date":"2022-06-12T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-gram-chromagram.png","layout":"app"},"url":"/practice/chroma/gram/"},{"src":"---\\ntitle: MIDI Monitor\\ndescription: See everything that's happening on your MIDI-bus right in the browser\\nlayout: app\\ncover: monitor.png\\ndate: 2022-06-12\\n---\\n\\n\\n\\n<client-only>\\n  <midi-monitor />\\n  <midi-panel :to-channel=\\"false\\" />\\n</client-only>\\n","frontmatter":{"title":"MIDI Monitor","description":"See everything that's happening on your MIDI-bus right in the browser","layout":"app","cover":"/media_files/cover/practice-midi-monitor-monitor.png","date":"2022-06-12T00:00:00.000Z"},"url":"/practice/midi/monitor/"},{"src":"---\\ntitle: Pitch roll\\ndescription: Plot main pitch of any incoming audio on an endless roll\\nlayout: app\\ncover: roll.png\\ndate: 2022-06-12\\n---\\n\\n<client-only>\\n  <pitch-roll />\\n</client-only>\\n\\nThis app listens to the incoming audio and analyzes it for the base pitch and tempo. The note with the cents difference is show at the top left. Tempo is shown at the top right. The pitch is plotted on the vertical axis with colored circles while beats are drawn as vertical lines.\\n\\n1. Press <i class=\\"p-3 mr-1 i-la-play\\"></i> to start plotting the audio parameters. Press <i class=\\"p-3 mr-1 i-la-pause\\"></i> to pause the process. You can also do this by clicking the graph itself or by pressing the **Spacebar** key on your keyboard.\\n2. Press <i class=\\"p-3 mr-1 i-la-times\\"></i> to clear the graph. Double clicking the graph and pressing the **Enter** key will have the same effect\\n3. Drag across the graph plain left or right to increase or decrease the speed of the plot head.\\n4. If you see the <i class=\\"p-3 mr-1 i-la-expand\\"></i> button at the bottom right, you browser is capable of stretching the graph to the full screen. Have fun!\\n","frontmatter":{"title":"Pitch roll","description":"Plot main pitch of any incoming audio on an endless roll","layout":"app","cover":"/media_files/cover/practice-pitch-roll-roll.png","date":"2022-06-12T00:00:00.000Z"},"url":"/practice/pitch/roll/"},{"src":"---\\ntitle: MIDI Router\\ndescription: Forward all MIDI messages from one device to another\\nlayout: app\\ncover: midi-router.png\\ndate: 2022-06-08\\n---\\n\\n<client-only>\\n<div id=\\"screen\\">\\n\\n  <midi-router class=\\"mb-20\\" />\\n   <midi-panel class=\\"mb-4\\" />\\n</div>\\n</client-only>\\n\\nClick on the desired output under the input you want to send signals from.\\n","frontmatter":{"title":"MIDI Router","description":"Forward all MIDI messages from one device to another","layout":"app","cover":"/media_files/cover/practice-midi-router-midi-router.png","date":"2022-06-08T00:00:00.000Z"},"url":"/practice/midi/router/"},{"src":"---\\ntitle: Drone\\ndescription: Digital shruti box or tanpura tool online\\nlayout: app\\ndate: 2022-06-06\\ncover: drone.png\\n---\\n\\n<client-only >\\n  <pitch-drone class=\\"max-w-55ch m-2\\" />\\n</client-only >\\n\\n## Multipurpose rich harmonic sound generator\\n\\nYou choose the pitch and the app plays 3 octaves and 3 fifths intervals for it. The sound is generated with [sawtooth](https://en.wikipedia.org/wiki/Sawtooth_wave) oscillator synth and this gives the incredible amount of harmonic material to play with. Consider it as an electronic version of [indian tanpura](https://en.wikipedia.org/wiki/Tanpura) or simply the [Shruti box](https://en.wikipedia.org/wiki/Shruti_box).\\n\\n### How to use the drone app\\n\\n1. Choose the root note – the Sa note of the performance – either by tapping on the note name at the bottom, or by dragging the colored note section with your mouse or touch. With it you can adjust and finetune the exact frequency you need to play. This section shows the note as well as cents difference with the pure 12-TET tone and with the A2 note. And also there's the exact frequency in Hz.\\n2. Next tap the note rectangles to turn the sound on. The bottom row holds the root note in 3 lower octaves to create a deep base for the sound. The top row consists of three pads of the higher fifth intervals of that base frequency.\\n3. Drag each of the pads up and down to set the maximum level of that note. Each note has a random speed LFO, that is modulating it's volume from 0 to this upper limit. Reload the page to get a new LFO speed composition.\\n4. Drag each pad horizontally to set the middle point for the slow;y moving panning of the voice.\\n5. Listen to the tone to evolve and breathe with harmonics. Try singing to it, tuning your instruments or just feeling the vibrations.\\n6. If the it's too much of the high frequency content you can adjust it with the **LP** slider – it sets the frequency of the drone Low-pass filter.\\n7. Press **stop** button to mute the voices and press **play** to unmute them back. The **spacebar** key of your keyboard does exactly the same here.\\n","frontmatter":{"title":"Drone","description":"Digital shruti box or tanpura tool online","layout":"app","date":"2022-06-06T00:00:00.000Z","cover":"/media_files/cover/practice-pitch-drone-drone.png"},"url":"/practice/pitch/drone/"},{"src":"---\\ntitle: Circle of fifths\\ndescription: 12 major chords organized in a sequence of perfect fifths along with their relative minors\\ndate: 2022-06-02\\ncover: fifths.png\\nlayout: app\\n---\\n\\n<client-only>\\n<chord-fifths />\\n</client-only>\\n\\n## The double circle of fifths as a tool to explore chords in tonal space\\n\\nThe circle of fifths organizes pitches in a sequence of perfect fifths, generally shown as a circle with the pitches (and their corresponding keys) in a clockwise progression. Musicians and composers often use the circle of fifths to describe the musical relationships between pitches. Its design is helpful in composing and harmonizing melodies, building chords, and modulating to different keys within a composition.\\n\\nMoving counterclockwise, the pitches descend by a fifth, but ascending by a perfect fourth will lead to the same note an octave higher (therefore in the same pitch class). Moving counter-clockwise from C could be thought of as descending by a fifth to F, or ascending by a fourth to F.\\n\\nHere we have two circles of fifths rotated by a minor third interval. With this placement we get quite a useful tool. Considering each position of the circle as a scale we instantly get two parallel major and minor keys. It has the same notes, but start from another tonic and have the opposite tonal quality. Take C major and get A minor. Take C# minor and get E major at one glimpse.\\n\\nThe highlighted sector of 90 degrees includes 6 points of the circle that represent 6 main degrees of the scale starting from the notes in the middle of the sector. You can choose either major or minor basic scale by pressing on the little circles outside or inside the rings. Choose the one on the outside and you'll get the scale degrees numbers for the major scale. On the outer circle to the left of it you find the IV degree - the subdominant – the major chord starting from the note a fourth apart from the tonic. To the right lays the dominant V major chord. The inner circle shows the minor chords of the major scale – the ii, the vi and the iii degrees show in a clockwise succession. The vi diminished chord of a major scale isn't shown in the main sector, but you can find a reminder of it one step to the right in the inner circle.\\n\\nSo for C major scale you'll get C major chord as the tonic I degree, F major to the left as the IV subdominant degree, and G major chord as the dominant V degree to the right of the tonic. The inner circle will show you the Dm chord for the ii degree, Am as the vi degree and the tonic of the parallel minor scale and Em as the iii degree of the C major scale. The next step of the inner circle shows Bm and it can represent the vi degree – the leading tone and it's diminished chord Bdim (Bb5).\\n\\nThis scheme helps find interesting chord progressions either in one predefined key or traversing different keys in complex modulation movements. Neighbouring sectors include scales that are easy to borrow chords from and to travel to with simple moves like common-chord modulation. Once you find any other path from one key to another you can trace it's form on the circle and transpose it to any key you're in or you want to move to. The article about [secondary chords](https://en.wikipedia.org/wiki/Secondary_chord) is a good starting poing in this exploration.\\n","frontmatter":{"title":"Circle of fifths","description":"12 major chords organized in a sequence of perfect fifths along with their relative minors","date":"2022-06-02T00:00:00.000Z","cover":"/media_files/cover/practice-chord-fifths-fifths.png","layout":"app"},"url":"/practice/chord/fifths/"},{"src":"---\\ntitle: Table\\ndescription: Every possible note in a huge expandable table\\nlayout: app\\ncover: table.png\\ndate: 2022-06-02\\n---\\n\\n\\n<client-only>\\n  <pitch-table />\\n</client-only>\\n","frontmatter":{"title":"Table","description":"Every possible note in a huge expandable table","layout":"app","cover":"/media_files/cover/practice-pitch-table-table.png","date":"2022-06-02T00:00:00.000Z"},"url":"/practice/pitch/table/"},{"src":"---\\ntitle: Ambient drone box\\ndescription: A generative instrument for creating meditative sound landscapes\\ndate: 2022-04-28\\ncover: ambience.png\\nlayout: app\\n---\\n\\n<script setup>\\nimport AmbientDrone from './ambience.vue'\\n<\/script>\\n\\n<client-only>\\n<ambient-drone />\\n</client-only>\\n\\n### Work in progress\\n","frontmatter":{"title":"Ambient drone box","description":"A generative instrument for creating meditative sound landscapes","date":"2022-04-28T00:00:00.000Z","cover":"/media_files/cover/practice-sequencing-ambience-ambience.png","layout":"app"},"url":"/practice/sequencing/ambience/"},{"src":"---\\ntitle: MIDI Log\\ndescription: Inspect all the messages going through the MIDI bus, online in the browser\\ndate: 2022-04-05\\ncover: log.png\\nlayout: app\\n---\\n\\n\\n\\n<client-only>\\n  <midi-log />\\n</client-only>\\n","frontmatter":{"title":"MIDI Log","description":"Inspect all the messages going through the MIDI bus, online in the browser","date":"2022-04-05T00:00:00.000Z","cover":"/media_files/cover/practice-midi-log-log.png","layout":"app"},"url":"/practice/midi/log/"},{"src":"---\\ntitle: Tonal array\\ndescription: Harmonic table note layout - symmetrical hexagonal pattern of interval sequences\\ncover: array.png\\ndate: 2022-02-01\\nlayout: app\\n---\\n\\n<client-only>\\n  <tonal-space />\\n</client-only>\\n\\n[wiki](https://en.wikipedia.org/wiki/Harmonic_table_note_layout)\\n","frontmatter":{"title":"Tonal array","description":"Harmonic table note layout - symmetrical hexagonal pattern of interval sequences","cover":"/media_files/cover/practice-chord-array-array.png","date":"2022-02-01T00:00:00.000Z","layout":"app"},"url":"/practice/chord/array/"},{"src":"---\\ntitle: Color\\ndescription: Tools to work with color models\\ncover: daniel-apodaca.jpg\\ndate: 2021-12-28\\n---\\n\\n\\nHere anyone can explore the differenced between different color models with their own eyes. Starting from basic [RGB](./rgb/index.md) and [CMYK](./cmyk/index.md) we come to the more humane and pleasing cicular [HSL](./hsl/index.md) and 3D [LAB](./lab/index.md) color models.\\n","frontmatter":{"title":"Color","description":"Tools to work with color models","cover":"/media_files/cover/practice-color-daniel-apodaca.jpg","date":"2021-12-28T00:00:00.000Z"},"url":"/practice/color/"},{"src":"---\\ntitle: Sound\\ndescription: Exploration of sound and hearing\\ncover: dylann-hendricks.jpg\\ndate: 2021-12-18\\n---\\n\\nExperience the basic observations about sound physics and human sound perception phenomena yourself. You can build your own [Equal loudness contour](./loudness/index.md) with the tool to match any pitch and volume.\\n\\nYou can imagine youself exploring basic music maths with Pythagoras and his [Monochord](./monochord/index.md) without going any where in space and time. \\n\\nVisualized [String overtones](./overtones/index.md) can teach about the shapes of an oscillating string or column of air gets and how it affects the sound. And then by superimposing two complex sounds overtones we can establish the [Sensory dissonance curve](./dissonance/index.md) that lays in the basis of all modern music harmony.","frontmatter":{"title":"Sound","description":"Exploration of sound and hearing","cover":"/media_files/cover/practice-sound-dylann-hendricks.jpg","date":"2021-12-18T00:00:00.000Z"},"url":"/practice/sound/"},{"src":"---\\ntitle: Rhythm\\ndescription: Delicate patterns of beat and groove\\ndate: 2021-11-15\\ncover: abimael-ahumada.jpg\\n---\\n\\nExplore beats loops with the [Horizontal bars](./bars/index.md) or [Circlular](./circle/index.md) metronomes.\\n","frontmatter":{"title":"Rhythm","description":"Delicate patterns of beat and groove","date":"2021-11-15T00:00:00.000Z","cover":"/media_files/cover/practice-rhythm-abimael-ahumada.jpg"},"url":"/practice/rhythm/"},{"src":"---\\ntitle: Equal loudness contour\\ndescription: Build you own loudness contours\\ndate: 2021-11-12\\nlayout: app\\ncover: loudness.png\\n---\\n\\n\\n<sound-loudness />\\n\\n> **Find your own equal loudness contour**  \\n> Place sine oscillators on the 2D-plane where vertical axis is the volume and horizontal is the frequency of the sounds being played. You can build up a curve for your absolute threshold of hearing, or explore your own feeling of really loud sounds. **Be careful clicking at the top of the graph!**\\n","frontmatter":{"title":"Equal loudness contour","description":"Build you own loudness contours","date":"2021-11-12T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sound-loudness-loudness.png"},"url":"/practice/sound/loudness/"},{"src":"---\\ntitle: MIDI Radar\\ndescription: Circular MIDI visualisation experiment\\nlayout: app\\ndate: 2021-11-09\\ncover: geometry.png\\n---\\n\\n<client-only >\\n\\n  <midi-radar />\\n  <midi-panel class=\\"mb-4\\" />\\n</client-only>\\n\\n### See all the MIDI signals on the clock\\n\\nPress play on your sequencer to start run the radar by incoming MIDI-clock signal, or just press \`spacebar\` to start internal metronome, that will drive the radar clocks.\\n\\nDrag across the circle up and down to adjust temporal zoom - ther higher the zoom, the longer the loop (from one to 8 measures).\\n\\nUse MIDI channel filter section to cut visualize the exact voices of a multichannel MIDI signal.\\n\\nYou can toggle the internal synth on and off for using your MIDI-controller or enable audio input monitoring for your using your synths and sequencers.\\n","frontmatter":{"title":"MIDI Radar","description":"Circular MIDI visualisation experiment","layout":"app","date":"2021-11-09T00:00:00.000Z","cover":"/media_files/cover/practice-midi-radar-geometry.png"},"url":"/practice/midi/radar/"},{"src":"---\\ntitle: Chroma Grid\\ndescription: Write note sequences in flexible grids\\nlayout: app\\ndate: 2021-11-02\\ncover: grid.png\\ntodo:\\n  - MIDI out channels\\n  - midi out on-off\\n  - solo\\n  - mutes\\n  - synth\\n---\\n\\n\\n<client-only >\\n  \\n  <chroma-grids />\\n  <div class=\\"flex flex-wrap\\">\\n  <control-scale style=\\"flex: 1 1 20px\\" />\\n  <state-transport style=\\"flex: 1 1 20px\\" />\\n</div>\\n</client-only>\\n","frontmatter":{"title":"Chroma Grid","description":"Write note sequences in flexible grids","layout":"app","date":"2021-11-02T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-grid-grid.png","todo":["MIDI out channels","midi out on-off","solo","mutes","synth"]},"url":"/practice/chroma/grid/"},{"src":"---\\ntitle: Color\\ndescription: The features of human light perception and modern color theory\\ndate: 2021-11-01\\ncover: evie-s.jpg\\n---\\n\\nHere's very start of our journey to the visual music theory. First we learn about the phenomenon of [Light](./light/index.md), it's sources and it's main properties as an electromagnetic emission.\\n\\nThen we dive deep into the physiology of [Human color perception](./perception/index.md) that defines the way we interpret colors of the nature.\\n\\n[Color models](./models/index.md) study shows the research and the maths behind modern methods of reproducing any given color on the screen or on printed media.\\n\\nWe list 12 [Main colors names](./names/index.md) to make sure we can use them later as 12 notes correspondents.\\n\\n<YoutubeEmbed video=\\"1i8s8knHFTs\\" />\\n","frontmatter":{"title":"Color","description":"The features of human light perception and modern color theory","date":"2021-11-01T00:00:00.000Z","cover":"/media_files/cover/theory-color-evie-s.jpg"},"url":"/theory/color/"},{"src":"---\\ntitle: RGB\\ndescription: Additive color mixer\\ndate: 2021-10-22\\nlayout: app\\ncover: rgb.png\\n---\\n\\n<client-only>\\n<color-rgb class=\\"max-h-100svh\\" />\\n</client-only>\\n\\nMix Red, Green and Blue lights in the dark to get any given color accessible whithin this color space\\n","frontmatter":{"title":"RGB","description":"Additive color mixer","date":"2021-10-22T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-color-rgb-rgb.png"},"url":"/practice/color/rgb/"},{"src":"---\\ntitle: CMYK\\ndescription: Subtractive color mixer\\ndate: 2021-10-20\\nlayout: app\\ncover: cmyk.png\\n---\\n<client-only>\\n\\n<color-cmyk />\\n\\n</client-only>\\n","frontmatter":{"title":"CMYK","description":"Subtractive color mixer","date":"2021-10-20T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-color-cmyk-cmyk.png"},"url":"/practice/color/cmyk/"},{"src":"---\\ntitle: HSL, Lch, HWB\\ndescription: Circular color mixer\\ndate: 2021-10-18\\nlayout: app\\ncover: lch.png\\n---\\n\\n<client-only>\\n<color-hsl />\\n</client-only>\\n","frontmatter":{"title":"HSL, Lch, HWB","description":"Circular color mixer","date":"2021-10-18T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-color-hsl-lch.png"},"url":"/practice/color/hsl/"},{"src":"---\\ntitle: Lab\\ndescription: Lightness + A and B components color mixer\\ndate: 2021-10-16\\nlayout: app\\ncover: lab.png\\n---\\n<client-only>\\n\\n<color-lab class=\\"max-h-90svh\\" />\\n\\n</client-only>\\n","frontmatter":{"title":"Lab","description":"Lightness + A and B components color mixer","date":"2021-10-16T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-color-lab-lab.png"},"url":"/practice/color/lab/"},{"src":"---\\ntitle: Chord progressions\\ndescription: Successive chord loops as the foundation of modern music\\ndate: 2021-10-12\\ncover: progressions.png\\nlayout: app\\nweb:\\n  - https://autochords.com/\\n  - https://schollz.github.io/chords/ - https://github.com/schollz/chords\\n  - https://chordchord.com/\\n  - https://www.hooktheory.com/\\n  - https://fanzhangg.github.io/chord-master/\\n  - https://github.com/tonaljs/tonal/tree/9622ec8fa4031f0c80515d278dfa06424bf159e5/packages/progression\\n  - https://darosh.github.io/progression/ - https://github.com/darosh/progression\\n  - https://github.com/ology/Data-Dataset-ChordProgressions/blob/master/share/Chord-Progressions.csv\\n---\\n\\n<script setup>\\n  import progressions from '#/db/chord/progressions.yaml'\\n<\/script>\\n\\n<chord-progressions :list=\\"progressions\\" />\\n","frontmatter":{"title":"Chord progressions","description":"Successive chord loops as the foundation of modern music","date":"2021-10-12T00:00:00.000Z","cover":"/media_files/cover/practice-chord-progressions-progressions.png","layout":"app","web":["https://autochords.com/","https://schollz.github.io/chords/ - https://github.com/schollz/chords","https://chordchord.com/","https://www.hooktheory.com/","https://fanzhangg.github.io/chord-master/","https://github.com/tonaljs/tonal/tree/9622ec8fa4031f0c80515d278dfa06424bf159e5/packages/progression","https://darosh.github.io/progression/ - https://github.com/darosh/progression","https://github.com/ology/Data-Dataset-ChordProgressions/blob/master/share/Chord-Progressions.csv"]},"url":"/practice/chord/progressions/"},{"src":"---\\ntitle: Circular metronome\\ndescription: Looped rhythm and polyrhythm exploration tool\\ndate: 2021-10-02\\nlayout: app\\ncover: tempo.png\\nlinks:\\n  - https://habr.com/ru/post/278265/\\n---\\n\\n<client-only >\\n\\n  <rhythm-circle />\\n\\n</client-only >\\n\\n## Welcome to the all-mighty Chromatone circular metronome\\n\\nIt's the center for deep exploration of any kind of rhythmic patterns. We have two independent wheels ready to hold any variety of looping beats. Here's how you operate it:\\n\\n1. Set the **number of steps** with the top left slider. The external loop takes up to 48 steps for long sequences. The internal loop is smaller and can hold up to 16 steps.\\n2. Set the **number of subdivisions** of a measure with the top right slider. If the left and right numbers are equal you get a full loop cycle equal to one measure. But many more combinations are possible!\\n3. Turn steps **on and off** by clicking the colored wheel segments. The colorful lines connect all active steps of a sequence.\\n4. Use the <i class=\\"p-3 mr-1 i-ic-baseline-refresh\\"></i> button to reset the mutes distribution to the [Euclidean rhythm](./../../../theory/rhythm/system/euclidean/index.md) given the number of mutes and given the loop steps count.\\n5. You can **set accents** on certain steps by clicking the step number. Filled circles produce an accented sound, hollow ones are regular beats.\\n6. Of course you can choose one of **5 sound kits** for the wheels independently. Just drag or click the bottom left slider (that one with the letters A-E).\\n7. If you want your own sounds to be played by the metronome – choose the last letter **F**. It'll open the two recorders and loaders for that. **Record any sound** from your microphone or **upload any sound file** for both regular and accented beats.\\n8. Adjust the **panning** <i class=\\"p-3 mr-1 i-mdi-pan-horizontal\\"></i> and the **volume** <i class=\\"p-3 mr-1 i-la-volume-up\\"></i> of each loop with the sliders on the bottom right. You can even set two independent rhythms to play in two separate channels (left and right).\\n9. Press **play** button <i class=\\"p-3 mr-1 i-la-play\\"></i> in the top right corner and listen to the patterns you've created. The playback may be paused <i class=\\"p-3 mr-1 i-la-pause\\"></i> and resumed from that place or stopped and reset with the stop button <i class=\\"p-3 mr-1 i-la-stop\\"></i>. If you don't hear any sound on you mobile – just turn off the silent mode. Tested on iOS, it works!\\n10. There are two arrows <i class=\\"p-3 mr-1 i-la-angle-left\\"></i> and <i class=\\"p-3 mr-1 i-la-angle-right\\"></i> near the meter numbers at the top of the loops. With them you can **rotate the pattern** left or right at any moment, producing even more complex and evolving sequences.\\n11. The center circle of the metronome is very interactive. Use the <i class=\\"p-3 mr-1 i-la-minus\\"></i> and <i class=\\"p-3 mr-1 i-la-plus\\"></i> buttons to incrementally **change the tempo** by one BPM. Or press <i class=\\"p-3 mr-1 i-la-slash\\"></i> and <i class=\\"p-3 mr-1 i-la-times\\"></i> sectors to divide/multiply the tempo by two. It's like traversing the octaves of sound pitches. Notice that you get the same 'note' and starting color for these tempos.\\n12. You can also just tap and drag the center circle to change the tempo gradually, either with touch on mobile or mouse pointer on desktop.\\n13. The top left corner with the tempo information works the same – **drag it** to set the tempo you want.\\n14. At the bottom of the screen you can find buttons to get the tempo from the world around you to the app. The bottom left ear button <i class=\\"p-3 mr-1 i-tabler-ear\\"></i> activates the sophisticated **analyser that can determine the tempo** from any incoming audio signal. Turn it on and let the microphone hear your rhythm: clap it, stomp it, sign it or just turn the music on. The app will listen to the audio and show it's guess in the box near the 'ear' button. If you like what you get just press the number and the tempo will be set to the metronome itself.\\n15. The bottom right hand button <i class=\\"p-3 mr-1 i-fluent-tap-double-20-regular\\"></i>is just good old **tap tempo**. Tap it three times or more to see the tempo you've imagined or hear playing. The more you tap – the more precise the result gets. Then tap the number to set the main tempo to the new value.\\n16. If you see a square icon <i class=\\"p-3 mr-1 i-la-expand\\"></i> at the bottom left corner, you are able to open the circle metronome to the **full screen**. What an immense experience!\\n17. Once you build some interesting patterns you can **export them as a MIDI file** to use in any DAW or other MIDI-compatible tool. Just press the <i class=\\"p-3 mr-1 i-la-file-download\\"></i> button at the right bottom corner and choose a place to save it to your system. Then you can drag and drop it to your DAW timeline, choose intrument for the tracks and transpose the notes to desired notes.\\n18. Explore our [rhythm theory section](../../../theory/rhythm/index.md) for inspiration about what to dial into the loops. This app can act as a simple visual and audial cue for your music practice or become a tool to explore the enormous space of possible rhythmic combinations. Polyrhythms have never been so easy to see and internalise. The colors and the form of the metronome can help sticking to the tempo even in silence. Be creative and feel the power of this rhythm visualisation tool.\\n19. You can also control all the parameters of the metronome with your MIDI-controller. Use the knobs to send the **CC messages number 1-16** on **channel 1** for it. Two loops are independently controlled by these MIDI commands. You can easily change the CC numbers here.\\n\\n<client-only >\\n  <rhythm-circle-midi-controls />\\n</client-only >\\n","frontmatter":{"title":"Circular metronome","description":"Looped rhythm and polyrhythm exploration tool","date":"2021-10-02T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-rhythm-circle-tempo.png","links":["https://habr.com/ru/post/278265/"]},"url":"/practice/rhythm/circle/"},{"src":"---\\ntitle: Rhythm bars\\ndescription: A linear metronome and polyrhythm exploration tool\\nlayout: app\\ndate: 2021-10-01\\ncover: metro-bars.png\\ncomponent: beat-bars\\n---\\n\\n<client-only >\\n  <beat-bars />\\n</client-only >\\n\\n## Flexible metronome bars to construct any possible rhythm\\n\\nHere you have a linear version of the colorful metronome to play with.\\n\\n1. You can add any number of tracks to explore different rhythm combinations.\\n2. For each bar you can set a number of beats (1-16) with the top left slider. It's corresponding to the top number of a meter.\\n3. Set the number of subdivisions (1-16) of a measure with the top right slider. If the left and right numbers are equal you get a full loop cycle equal to one measure. But many more combinations are possible!\\n4. Turn steps on and off by clicking the colored segments. The colorful lines connect all active steps of the sequence.\\n5. You can set accents on certain steps by clicking the step number. Filled circles produce an accented sound, hollow ones are regular beats.\\n6. The most powerful thing is the **subdivisions** of any step – just click and **drag the bottom of any beat** to subdivide it into any number of steps. Compose very complex patterns with triplets, quadriplets, quintuplets and more. You can even mute any of the subdivisions – pure rhythmic freedom to play and to see. Change the BPM by dragging across the tempo information at the top right. Or by clicking the add/multiply buttons.\\n7. You can choose one of 5 sound kits for the bar independently. Just drag or click the bottom right slider (that one with the letters A-D).\\n8. Adjust the panning <i class=\\"p-3 mr-1 i-mdi-pan-horizontal\\"></i> and the volume <i class=\\"p-3 mr-1 i-la-volume-up\\"></i> of each loop with the sliders on the bottom left. You can even set two independent rhythms to play in two separate channels (left and right).\\n9. Press play button <i class=\\"p-3 mr-1 i-la-play\\"></i> at the top left of the control bar and listen to the patterns you've created. The playback may be paused <i class=\\"p-3 mr-1 i-la-pause\\"></i> and resumed from that place or stopped and reset with the stop button <i class=\\"p-3 mr-1 i-la-stop\\"></i>. If you don't hear any sound on you mobile – just turn off the silent mode. Tested on iOS, it works!\\n10. There are two arrows <i class=\\"p-3 mr-1 i-la-angle-left\\"></i> and <i class=\\"p-3 mr-1 i-la-angle-right\\"></i> near the meter numbers at the top of the loops. With them you can rotate the pattern left or right at any moment, producing even more complex and evolving sequences.\\n11. Use the <i class=\\"p-3 mr-1 i-la-minus\\"></i> and <i class=\\"p-3 mr-1 i-la-plus\\"></i> buttons of the control bar at the top to incrementally change the tempo by one BPM. Or press <i class=\\"p-3 mr-1 i-la-slash\\"></i> and <i class=\\"p-3 mr-1 i-la-times\\"></i> button to divide/multiply the tempo by two. It's like traversing the octaves of sound pitches. Notice that you get the same 'note' and starting color for these tempos.\\n12. You can also just tap and drag the section with the BPM numbers to change the tempo gradually, either with touch on mobile or mouse pointer on desktop.\\n13. At the control bar you can find buttons to get the tempo from the world around you. The ear button <i class=\\"p-3 mr-1 i-tabler-ear\\"></i> activates the sophisticated analyser that can determine the tempo from any incoming audio signal. Turn it on and let the microphone hear your rhythm: clap it, stomp it, sign it or just turn the music on. The app will listen to the audio and show it's guess in the box near the <i class=\\"p-3 mr-1 i-tabler-ear\\"></i> button. If you like what you get just press the number and the tempo will be set to the metronome itself.\\n14. The hand button <i class=\\"p-3 mr-1 i-fluent-tap-double-20-regular\\"></i> is just good old tap tempo. Tap it three times or more to see the tempo you've imagined or hear playing. The more you tap – the more precise the result gets. Then tap the number to set the main tempo to the new value.\\n15. If you see a square icon <i class=\\"p-3 mr-1 i-la-expand\\"></i> at the bottom left corner, you are able to open the circle metronome to the full screen. What an immense experience!\\n16. Once you build some interesting patterns you can export them as a MIDI file to use in any DAW or other MIDI-compatible tool. Just press the <i class=\\"p-3 mr-1 i-la-file-download\\"></i> button at the bottom and choose a place to save it to your system. Then you can drag and drop it to your DAW timeline, choose intrument for the tracks and transpose the notes to desired notes.\\n17. Explore our [rhythm theory section](../../../theory/rhythm/index.md) for inspiration about what to dial into the loops. This app can act as a simple visual and audial cue for your music practice or become a tool to explore the enormous space of possible rhythmic combinations. Polyrhythms have never been so easy to see and internalise. The colors and the form of the metronome can help sticking to the tempo even in silence. Be creative and feel the power of this rhythm visualisation tool.\\n","frontmatter":{"title":"Rhythm bars","description":"A linear metronome and polyrhythm exploration tool","layout":"app","date":"2021-10-01T00:00:00.000Z","cover":"/media_files/cover/practice-rhythm-bars-metro-bars.png","component":"beat-bars"},"url":"/practice/rhythm/bars/"},{"src":"---\\ntitle: Light\\ndescription: The nature and properies of electromagnatic radiation\\ncover: prism-light.jpg\\n\\ndate: 2021-10-01\\n---\\n\\nWhat is [Sun](./sun/index.md) and how does it's [EM-waves](./em-waves/index.md) split into the whole [Waves spectrum](./spectrum/index.md).\\n","frontmatter":{"title":"Light","description":"The nature and properies of electromagnatic radiation","cover":"/media_files/cover/theory-color-light-prism-light.jpg","date":"2021-10-01T00:00:00.000Z"},"url":"/theory/color/light/"},{"src":"---\\ntitle: Pitch\\ndescription: Explorations of the acoustic frequency domain\\ncover: paulette-wooten.jpg\\ndate: 2021-09-30\\n---\\n\\nFind any giver pitch on any giver instrument with the colorful [Tuner](./tuner/index.md) that analyzes incoming audio and exactly shows you the main pitch. \\n\\nOr you may start plotting the detected pitch an endless [Pitch Roll](./roll/index.md) and have fun drawing ups and downs with sound. Much more complex and information rich plot is produced by the [Spectrograph](./spectrogram/index.md) that draws FFT frequency content of any incoming audio.\\n\\nWe can not only analyze, but produce different pitches with this web-site. There's a traditional [Drone machine](./drone/index.md) that will generate a rich in upper harmonics sound of any desired pitch and a fifth above it to generate a pleasant background for vocal practice and instrument tuning.\\n\\nIf you want to combine more simultaneous drone pitches - feel free to browse the [Pitch table](./table/index.md) of all audible audio frequencies and beyond! ","frontmatter":{"title":"Pitch","description":"Explorations of the acoustic frequency domain","cover":"/media_files/cover/practice-pitch-paulette-wooten.jpg","date":"2021-09-30T00:00:00.000Z"},"url":"/practice/pitch/"},{"src":"---\\ntitle: Chords\\ndescription: Three and more note collections\\ndate: 2021-09-25\\ncover: roberta-sorge.jpg\\n---\\n\\nThere are thousands of possible 3-5 notes combinations, that are used as chords in modern music.  If you need the get the shape of chords on a string instument - try the [Chord Tabs app](./tabs/index.md).\\n\\nTo navigate the multitude of chord combinations and sequences you can explore their [Modal functions](./modes/index.md) in different scales. The relations between chords really shine in multiaxis interpretations like the Tonnetz [Tonal array](./array/index.md) or the interactive [Circle of fifths](./fifths/index.md) chords wheel.","frontmatter":{"title":"Chords","description":"Three and more note collections","date":"2021-09-25T00:00:00.000Z","cover":"/media_files/cover/practice-chord-roberta-sorge.jpg"},"url":"/practice/chord/"},{"src":"---\\ntitle: Triads\\ndescription: Chords consisting of three notes\\ncover: austin-prock.jpg\\ndate: 2021-09-22\\n\\n---\\n\\n<script setup>\\n  import triad from '#/db/chord/triads.yaml'\\n<\/script>\\n\\n## Major and minor\\n\\nA major triad can also be described by its intervals: the interval between the bottom and middle notes is a major third and the interval between the middle and top notes is a minor third.\\n\\nIn Western classical music from 1600 to 1820 and in Western pop, folk and rock music, a major chord is usually played as a triad. Along with the minor triad, the major triad is one of the basic building blocks of tonal music in the Western common practice period and Western pop, folk and rock music. It is considered consonant, stable, or not requiring resolution. In Western music, a minor chord \\"sounds darker than a major chord\\", giving off a sense of sadness or somber feeling.\\n\\n<chroma-profile-collection :collection=\\"triad.majmin\\" />\\n\\nA unique particularity of the minor chord is that this is the only chord of three notes in which the three notes have one harmonic – hearable and with a not too high row – in common (more or less exactly, depending on the tuning system used). This harmonic, common to the three notes, is situated 2 octaves above the high note of the chord. This is the sixth harmonic of the root of the chord, the fifth of the middle note, and the fourth of the high note:\\n\\n> In the example C, E♭, G, the common harmonic is a G 2 octaves above.\\n\\nDemonstration:\\n\\n- Minor third = 6:5 = 12:10\\n- Major third = 5:4 = 15:12\\n- So the ratios of minor chord are 10:12:15\\n- And the explication of the unique harmonic in common, between the three notes, is verified by : 10 × 6 = 12 × 5 = 15 × 4\\n\\n---\\n\\n## Suspended chords\\n\\nA suspended chord (or sus chord) is a musical chord in which the (major or minor) third is omitted and replaced with a perfect fourth or, less commonly, a major second. The lack of a minor or a major third in the chord creates an open sound, while the dissonance between the fourth and fifth or second and root creates tension. When using popular-music symbols, they are indicated by the symbols \\"sus4\\" and \\"sus2\\".\\n\\nThe term is borrowed from the contrapuntal technique of suspension, where a note from a previous chord is carried over to the next chord, and then resolved down to the third or tonic, suspending a note from the previous chord. However, in modern usage, the term concerns only the notes played at a given time; in a suspended chord, the added tone does not necessarily resolve and is not necessarily \\"prepared\\" (i.e., held over) from the prior chord. As such, in C–F–G, F would resolve to E (or E♭, in the case of C minor), but in rock and popular music, \\"the term is used to indicate only the harmonic structure, with no implications about what comes before or after,\\" though preparation of the fourth occurs about half the time and traditional resolution of the fourth occurs usually. In modern jazz, a third can be added to the chord voicing, as long as it is above the fourth.\\n\\nEach suspended chord has two inversions. Suspended second chords are inversions of suspended fourth chords, and vice versa. For example, Gsus2 (G–A–D) is the first inversion of Dsus4 (D–G–A) which is the second inversion of Gsus2 (G–A–D). The sus2 and sus4 chords both have an inversion that creates a quartal chord (A–D–G) with two stacked perfect fourths.\\n\\nSevenths on suspended chords are \\"virtually always minor sevenths\\", while the 9sus4 chord is similar to an eleventh chord and may be notated as such. For example, C9sus4 (C–F–G–B♭–D) may be notated C11 (C–G–B♭–D–F).\\n\\n<chroma-profile-collection :collection=\\"triad.sus\\" />\\n\\n---\\n\\n## Augmented and diminished\\n\\nA diminished triad (also known as the minor flatted fifth) is a triad consisting of two minor thirds above the root. It is a minor triad with a lowered (flattened) fifth. When using chord symbols, it may be indicated by the symbols \\"dim\\", \\"o\\", \\"m♭5\\", or \\"MI(♭5)\\". However, in most popular-music chord books, the symbol \\"dim\\" and \\"o\\" represents a diminished seventh chord (a four-tone chord), which in some modern jazz books and music theory books is represented by the \\"dim7\\" or \\"o7\\" symbols.\\n\\nIn major scales, a diminished triad occurs only on the seventh scale degree. For instance, in the key of C, this is a B diminished triad (B, D, F). Since the triad is built on the seventh scale degree, it is also called the leading-tone triad. This chord has a dominant function. Unlike the dominant triad or dominant seventh, the leading-tone triad functions as a prolongational chord rather than a structural chord since the strong root motion by fifth is absent.\\n\\nOn the other hand, in natural minor scales, the diminished triad occurs on the second scale degree; in the key of C minor, this is the D diminished triad (D, F, A♭). This triad is consequently called the supertonic diminished triad. Like the supertonic triad found in a major key, the supertonic diminished triad has a predominant function, almost always resolving to a dominant functioning chord.\\n\\nIf the music is in a minor key, diminished triads can also be found on the raised seventh note, ♯viio. This is because the ascending melodic minor scale has a raised sixth and seventh degree. For example, the chord progression ♯viio–i is common.\\n\\nThe leading-tone diminished triad and supertonic diminished triad are usually found in first inversion (viio6 and iio6, respectively) since the spelling of the chord forms a diminished fifth with the bass. This differs from the fully diminished seventh chord, which commonly occurs in root position. In both cases, the bass resolves up and the upper voices move downwards in contrary motion.\\n\\n<chroma-profile-collection :collection=\\"triad.mod\\" />\\n\\nThe term augmented triad arises from an augmented triad being considered a major chord whose top note (fifth) is raised. When using popular-music symbols, it is indicated by the symbol \\"+\\" or \\"aug\\". For example, the augmented triad built on C, written as C+, has pitches C–E–G♯:\\n\\nWhereas a major triad, such as C–E–G, contains a major third (C–E) and a minor third (E–G), with the interval of the fifth (C–G) being perfect, the augmented triad has an augmented fifth, becoming C–E–G♯. In other words, the top note is raised a semitone.\\n\\nThe augmented triad on the V may be used as a substitute dominant, and may also be considered as ♭III+. The example below shows ♭III+ as a substitute dominant in a ii-V-I turnaround in C major.\\n\\nThough rare, the augmented chord occurs in rock music, \\"almost always as a linear embellishment linking an opening tonic chord with the next chord,\\" for example John Lennon's \\"(Just Like) Starting Over\\" and The Beatles' \\"All My Loving\\". Thus, with an opening tonic chord, an augmented chord results from ascending or descending movement between the fifth and sixth degrees, such as in the chord progression I – I+ – vi. This progression forms the verse for Oasis's 2005 single \\"Let There Be Love\\" (I – I+ – vi – IV)\\n\\n## Synthetic triads\\n\\nA synthetic chord is a made-up or non-traditional (synthetic) chord (collection of pitches) which cannot be analyzed in terms of traditional harmonic structures, such as the triad or seventh chord.\\n\\n> This title is applied to a group of notes, usually a scale-like succession of pitches, with a fixed progression of tones and semitones. This scale can obviously be transposed to any pitch, and depending on its intervallic makeup, will have a fixed number of possible transpositions. Furthermore, the sintetakkord can be used either vertically or horizontally; Roslavets' music is not concerned with the order of the pitches, but rather with the whole 'field' thus created, so that the system is less oriented toward themes and more toward harmonic fields.\\n>\\n> — Sitsky (1994)\\n\\n<chroma-profile-collection :collection=\\"triad.synthetic\\" />\\n","frontmatter":{"title":"Triads","description":"Chords consisting of three notes","cover":"/media_files/cover/theory-chords-triads-austin-prock.jpg","date":"2021-09-22T00:00:00.000Z"},"url":"/theory/chords/triads/"},{"src":"---\\ntitle: Chroma\\ndescription: Explore all possible combinations of all the 12 chromatic notes\\ndate: 2021-09-20\\ncover: compass.svg\\n---\\n\\nNavigating the multifarious space of pitch class combinations is a wonderful journey that may be accompanied with different tools we've made. Plot a mathematically perfect [Chroma Waveform](./waveform/index.md) of a sine wave pitch oscillations collections. \\n\\nOr just explore the collections of all possible note combinations of chroma with the [Chroma profile](./profile/index.md). Or construct any note collection with the [Chroma Compass](./compass/index.md). And in case you'll need to organize all those notes in loops in time - that's what the [Chroma grid](./grid/index.md) is designed for.\\n\\nThere's another endless [Chroma Roll](./gram/index.md) that will plot the relative pitch class power for any incoming audio. The same data may help you see the pitch class content of any sound with the [Chroma See](./see/index.md). ","frontmatter":{"title":"Chroma","description":"Explore all possible combinations of all the 12 chromatic notes","date":"2021-09-20T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-compass.svg"},"url":"/practice/chroma/"},{"src":"---\\ntitle: Monochord\\ndescription: Virtual string for frequency and length ratio explorations\\nlayout: app\\ndate: 2021-09-12\\ncover: monochord.png\\n---\\n\\n\\n<client-only>\\n  <sound-monochord />\\n</client-only>\\n\\nDrag the divider to explore the string divisions of a monochord, just like Pythagoras did.\\n","frontmatter":{"title":"Monochord","description":"Virtual string for frequency and length ratio explorations","layout":"app","date":"2021-09-12T00:00:00.000Z","cover":"/media_files/cover/practice-sound-monochord-monochord.png"},"url":"/practice/sound/monochord/"},{"src":"---\\ntitle: MIDI\\ndescription: Seeing digital music information streams\\ncover: puk-khantho.jpg\\ndate: 2021-09-10\\n---\\n\\nMIDI is the global standard for transfering music information. It's a protocol, that consists of small realtime commands, that you can observe with any MIDI-enabled browser and MIDI conroller connected to your device with the [MIDI Log app](./log/index.md).\\n\\n[MIDI Router](./router/index.md) may help you transfer messages from certain inputs to certain outputs for building even quite complex setups. All the notes played and all the knobs changed are nicely visualised in the [MIDI monitor](./monitor/index.md) or drawn on an endless [MIDI Roll](./roll/index.md). And if we loop the roll around a central axis, we get the [MIDI radar](./radar/index.md) that spins at the speed of current clock signal and marks all events on the circular timeline.\\n\\nIf you've found some nice melodic or harmonic moves and want to save it for later - try the [MIDI Recorder](./recorder/index.md). Save the .mid files to your device and analyze them later with the experimental [MIDI File Visualizer](./visualizer/index.md).\\n\\n## How to output MIDI from Chromatone web-apps to your DAW\\n\\n### 1. Set up the MIDI Driver\\n   - On a Mac:\\n      - Open the \\"Audio-Midi Setup\\" app.\\n      - In the menu, select Window -> Midi-Studio.\\n      - Double Click \\"IAC Driver\\".\\n      - Make sure \\"Device is ready\\" is checked.\\n   - On a Windows PC: Install [loopMidi](http://www.tobias-erichsen.de/software/loopmidi.html)\\n  \\nCheck out [Ableton's guide](https://help.ableton.com/hc/en-us/articles/209774225-Setting-up-a-virtual-MIDI-bus) for more information and screenshots (applies to all DAWs).\\n\\n### 2. Enable the Midi device in your DAW\\nDepending on the DAW you use, there might be additional steps you have to take.\\n\\nIn Ableton Live, open up Preferences ->  Link | Tempo | Midi. Under \\"Midi Ports\\" there is an entry called \\"In: IAC Driver\\". Make sure \\"Track\\" and \\"Remote\\" is checked.\\n\\n### 3. Make sure MIDI OUT is enabled in Chromatone\\n","frontmatter":{"title":"MIDI","description":"Seeing digital music information streams","cover":"/media_files/cover/practice-midi-puk-khantho.jpg","date":"2021-09-10T00:00:00.000Z"},"url":"/practice/midi/"},{"src":"---\\ntitle: Chords\\ndescription: Harmonic sets of pitches/frequencies consisting of multiple notes that are heard as if sounding simultaneously\\ncover: am7-res.svg\\n\\ndate: 2021-09-10\\n---\\n\\nFor many practical and theoretical purposes, arpeggios and broken chords (in which the notes of the chord are sounded one after the other, rather than simultaneously), or sequences of chord tones, may also be considered as chords in the right musical context.\\n\\nChords and sequences of chords are frequently used in modern West African and Oceanic music, Western classical music, and Western popular music; yet, they are absent from the music of many other parts of the world.\\n\\nIn tonal Western classical music (music with a tonic key or \\"home key\\"), the most frequently encountered chords are [triads](./triads/index.md), so called because they consist of three distinct notes: the root note, and intervals of a third and a fifth above the root note. Chords with more than three notes include [added tone chords](./tetrads/index.md), [extended chords](./pentads/index.md), [even more extended chords](./more/index.md) and [tone clusters](./clusters/index.md), which are used in contemporary classical music, jazz and almost any other genre.\\n","frontmatter":{"title":"Chords","description":"Harmonic sets of pitches/frequencies consisting of multiple notes that are heard as if sounding simultaneously","cover":"/media_files/cover/theory-chords-am7-res.svg","date":"2021-09-10T00:00:00.000Z"},"url":"/theory/chords/"},{"src":"---\\ntitle: Tetrads\\ndescription: All musically meaningful combinations of 4 notes\\ncover: kelly-sikkema.jpg\\ndate: 2021-09-10\\n---\\n## Seventh chords\\n\\nA seventh chord is a chord consisting of a triad plus a note forming an interval of a seventh above the chord's root. When not otherwise specified, a \\"seventh chord\\" usually means a dominant seventh chord: a major triad together with a minor seventh. However, a variety of sevenths may be added to a variety of triads, resulting in many different types of seventh chords.\\n\\nIn its earliest usage, the seventh was introduced solely as an embellishing or nonchord tone. The seventh destabilized the triad, and allowed the composer to emphasize movement in a given direction. As time passed and the collective ear of the western world became more accustomed to dissonance, the seventh was allowed to become a part of the chord itself, and in some modern music, jazz in particular, nearly every chord is a seventh chord. Additionally, the general acceptance of equal temperament during the 19th century reduced the dissonance of some earlier forms of sevenths.\\n\\nMost textbooks name these chords formally by the type of triad and type of seventh; hence, a chord consisting of a major triad and a minor seventh above the root is referred to as a major/minor seventh chord. When the triad type and seventh type are identical (i.e. they are both major, minor, or diminished), the name is shortened. For instance, a major/major seventh is generally referred to as a major seventh. This rule is not valid for augmented chords: since the augmented/augmented chord is not commonly used, the abbreviation augmented is used for augmented/minor, rather than augmented/augmented. Additionally, half-diminished stands for diminished/minor, and dominant stands for major/minor. When the type is not specified at all, the triad is assumed to be major, and the seventh is understood as a minor seventh (e.g. a \\"C\\" chord is a \\"C major triad\\", and a \\"C7\\" chord is a \\"C major/minor seventh chord\\", also known as a \\"C dominant seventh chord\\").\\n\\n## Tertian\\n\\nThe most common chords are tertian, constructed using a sequence of major thirds (spanning 4 semitones) and/or minor thirds (3 semitones). Since there are 3 third intervals in a seventh chord (4 notes) and each can be major or minor, there are 8 possible combinations, however, only seven of them are commonly found in western music. The augmented augmented seventh chord, defined by a root, a major third, an augmented fifth, and an augmented seventh (i.e., a sequence of 3 major thirds, such as C–E–G♯–B♯), is a rarely used tertian seventh chord. The reason is that the augmented seventh interval is enharmonically equivalent to one entire octave (in equal temperament, 3 major thirds = 12 semitones = 1 octave) and is hence perfectly consonant with the chord root.\\n\\n<script setup>\\n  import tetrad from '#/db/chord/tetrad.yaml'\\n<\/script>\\n<chroma-profile-collection :collection=\\"tetrad.tertian\\" />\\n\\n---\\n\\n## Non-tertian\\n\\nSeventh chords can also be constructed using augmented or diminished thirds. These chords are not tertian and can be used in non-tertian harmony. There are many (mathematically, 64) chords that can be built, however, only few of them are used.\\n\\n<chroma-profile-collection :collection=\\"tetrad.nontertian\\" />\\n","frontmatter":{"title":"Tetrads","description":"All musically meaningful combinations of 4 notes","cover":"/media_files/cover/theory-chords-tetrads-kelly-sikkema.jpg","date":"2021-09-10T00:00:00.000Z"},"url":"/theory/chords/tetrads/"},{"src":"---\\ntitle: Hexads and more\\ndescription: Extended chords, added tone chords and other complex interval combinations\\ncover: jacek-dylag.jpg\\ndate: 2021-09-01\\n\\n---\\n\\n\\n<script setup>\\n\\nimport {ChordType} from 'tonal'\\n\\nconst more = ChordType.all().filter((get) => get.intervals.length>5)\\n  .filter(get=>get)\\n  .sort((a,b)=>a.chroma>b.chroma ? -1 :1)\\n  .map((get) => ({\\n    chroma: get.chroma,\\n    title: get.name || get.aliases?.[0]\\n  }));\\n<\/script>\\n\\n## Chords with 6 and more notes\\n\\n<chroma-profile-collection :collection=\\"more\\" />\\n","frontmatter":{"title":"Hexads and more","description":"Extended chords, added tone chords and other complex interval combinations","cover":"/media_files/cover/theory-chords-more-jacek-dylag.jpg","date":"2021-09-01T00:00:00.000Z"},"url":"/theory/chords/more/"},{"src":"---\\ntitle: Pentads\\ndescription: 11th diatonic chord extensions and other 5-note chords\\ncover: gabriel-gurrola.jpg\\ndate: 2021-09-01\\n\\n---\\n\\n\\n<script setup>\\nimport pentad from '#/db/chord/pentad.yaml'\\n<\/script>\\n\\n## Pentads – the five note chords\\n\\n<chroma-profile-collection :collection=\\"pentad\\" />\\n\\n<youtube-embed video=\\"RFH1LD4KdWs\\" />\\n","frontmatter":{"title":"Pentads","description":"11th diatonic chord extensions and other 5-note chords","cover":"/media_files/cover/theory-chords-pentads-gabriel-gurrola.jpg","date":"2021-09-01T00:00:00.000Z"},"url":"/theory/chords/pentads/"},{"src":"---\\ntitle: The Sun\\ndescription: The Sun is the center of our Solar system and is the main source of all light on Earth.\\n\\ndate: 2021-08-30\\ncover: sun.jpg\\n---\\n\\nThe Sun, a 4.5 billion-year-old yellow dwarf star, is the center of our Solar system and is the main source of light on Earth.\\n\\nThe Sun has an absolute magnitude of +4.83, estimated to be brighter than about 85% of the stars in the Milky Way, most of which are red dwarfs.\\n\\nThe Sun is a G-type main-sequence star that comprises about 99.86% of the mass of the Solar System. It's mass is estimated at 2 octillion tons, while it's losing 5 million tons of material each second in form of radiation and ionized corona flares that cool down in space and propagate as solar wind.\\n\\n![svg](./images/sun.svg)\\n\\nThe Sun is by far the brightest object in the Earth's sky, with an apparent magnitude of −26.74. This is about 13 billion times brighter than the next brightest star, Sirius, which has an apparent magnitude of −1.46.\\n\\n![wind](./wind.gif)\\n\\nThe Sun is about 149.6 million kilometers away from Earth. Light travels at a speed of about 299,792 kilometers per second. So, it takes about 8 minutes and 20 seconds for light to travel from the Sun to Earth.\\n\\n![](./images/sun-granules.jpg)\\n\\nThermonuclear reactions at temperatures about 14 million Kelvin in its core produce high energy gamma-rays that are absorbed and converted into lower energy radiation by ionized atoms in its relatively thin and much cooler (4000 - 6000 K) photosphere and chromosphere layers.\\n\\n![](./images/Sunspot.jpg)\\n\\n## UV radiation of the Sun\\n\\n![](./images/extreme_ultraviolet_sun.jpg)\\n","frontmatter":{"title":"The Sun","description":"The Sun is the center of our Solar system and is the main source of all light on Earth.","date":"2021-08-30T00:00:00.000Z","cover":"/media_files/cover/theory-color-light-sun-sun.jpg"},"url":"/theory/color/light/sun/"},{"src":"---\\ntitle: Human color perception\\ndescription: Physiology and features of the eyes\\n\\ndate: 2021-08-30\\ncover: color-sensitivity.jpg\\n---\\n\\n## Human eye\\n\\nThe perception of color derives from the stimulation of cone cells in the human eye by visible light. Light, containing all spectral colors is perceived white. Color of an object depends on the range of wavelengths of light that are absorbed or reflected by its surface. The sense of a particular color is produced in nervous system by combining signal from three types of cones, sensitive to red, green and blue ranges of the spectrum.\\n\\n<img src=\\"./images/Eyesection.svg\\" />\\n\\n<img src=\\"./images/retina.jpg\\" />\\n\\n<img src=\\"./images/Human-visual-pathway.svg\\" />\\n\\n![](./images/Distribution_of_Cones_and_Rods_on_Human_Retina.png)\\n\\nThe human eye with normal vision has three kinds of cone cells that sense light, having peaks of spectral sensitivity in short (\\"S\\", 420 nm – 440 nm), middle (\\"M\\", 530 nm – 540 nm), and long (\\"L\\", 560 nm – 580 nm) wavelengths. These cone cells underlie human color perception in conditions of medium and high brightness; in very dim light color vision diminishes, and the low-brightness, monochromatic \\"night vision\\" receptors, denominated \\"rod cells\\", become effective. Thus, three parameters corresponding to levels of stimulus of the three kinds of cone cells, in principle describe any human color sensation. Weighting a total light power spectrum by the individual spectral sensitivities of the three kinds of cone cells renders three effective values of stimulus; these three values compose a tristimulus specification of the objective color of the light spectrum. The three parameters, denoted \\"S\\", \\"M\\", and \\"L\\", are indicated using a 3-dimensional space denominated the \\"LMS color space\\", which is one of many color spaces devised to quantify human color vision.\\n\\n<img src=\\"./color-sensitivity.jpg\\" />\\n\\n<img src=\\"./images/Cone-fundamentals-with-srgb-spectrum.svg\\" />\\n\\n> <img src=\\"./images/cie-1931.svg\\">\\n>\\n> The CIE XYZ standard observer color matching functions\\n\\n![](./images/Eyesensitivity.svg)\\n\\n![](./images/Line_of_purples.png)\\n\\n## Opposite color vision theory\\n\\n<img src=\\"./images/Diagram_of_the_opponent_process.png\\" />\\n\\n## Just noticable difference\\n\\nTolerancing concerns the question \\"What is a set of colors that are imperceptibly/acceptably close to a given reference?\\" If the distance measure is perceptually uniform, then the answer is simply \\"the set of points whose distance to the reference is less than the just-noticeable-difference (JND) threshold.\\" This requires a perceptually uniform metric in order for the threshold to be constant throughout the gamut (range of colors). Otherwise, the threshold will be a function of the reference color—cumbersome as a practical guide.\\n\\nIn the CIE 1931 color space, for example, the tolerance contours are defined by the MacAdam ellipse, which holds L\\\\* (lightness) fixed. As can be observed on the adjacent diagram, the ellipses denoting the tolerance contours vary in size. It is partly this non-uniformity that led to the creation of CIELUV and CIELAB.\\n\\n> ![](./images/CIExy1931_MacAdam.png)\\n>\\n> A MacAdam diagram in the CIE 1931 color space. The ellipses are shown ten times their actual size.\\n","frontmatter":{"title":"Human color perception","description":"Physiology and features of the eyes","date":"2021-08-30T00:00:00.000Z","cover":"/media_files/cover/theory-color-perception-color-sensitivity.jpg"},"url":"/theory/color/perception/"},{"src":"---\\ntitle: Light spectrum\\ndescription: Spectrum of solar radiation\\n\\ndate: 2021-08-29\\ncover: sun-spectrum.svg\\n---\\n\\n![svg](./images/em-spectrum.svg)\\n\\n## Black body emission\\n\\nBlack-body radiation is the thermal electromagnetic radiation within or surrounding a body in thermodynamic equilibrium with its environment, emitted by a black body (an idealized opaque, non-reflective body). It has a specific spectrum of wavelengths, inversely related to intensity that depend only on the body's temperature, which is assumed for the sake of calculations and theory to be uniform and constant.\\n\\n![svg](./images/Color_temperature_black_body_800-12200K.svg)\\n\\nBlack-body radiation has a characteristic, continuous frequency spectrum that depends only on the body's temperature, called the Planck spectrum or Planck's law. The spectrum is peaked at a characteristic frequency that shifts to higher frequencies with increasing temperature, and at room temperature most of the emission is in the infrared region of the electromagnetic spectrum. As the temperature increases past about 500 degrees Celsius, black bodies start to emit significant amounts of visible light. Viewed in the dark by the human eye, the first faint glow appears as a \\"ghostly\\" grey (the visible light is actually red, but low intensity light activates only the eye's grey-level sensors). With rising temperature, the glow becomes visible even when there is some background surrounding light: first as a dull red, then yellow, and eventually a \\"dazzling bluish-white\\" as the temperature rises. When the body appears white, it is emitting a substantial fraction of its energy as ultraviolet radiation. The Sun, with an effective temperature of approximately 5800 K, is an approximate black body with an emission spectrum peaked in the central, yellow-green part of the visible spectrum, but with significant power in the ultraviolet as well.\\n\\n![svg](./images/Wiens_law.svg)\\n\\n![](./images/PlanckianLocus.png)\\n\\nIn the longer wavelengths this deviation is not so noticeable, as hv are very small. In the shorter wavelengths of the ultraviolet range, however, classical theory predicts the energy emitted tends to infinity, hence the ultraviolet catastrophe. The theory even predicted that all bodies would emit most of their energy in the ultraviolet range, clearly contradicted by the experimental data which showed a different peak wavelength at different temperatures (see also Wien's law).\\n\\n![svg](./images/Black_body.svg)\\n\\nAs the temperature increases, the peak of the emitted black-body radiation curve moves to higher intensities and shorter wavelengths. The black-body radiation graph is also compared with the classical model of Rayleigh and Jeans.\\n\\nInstead, in the quantum treatment of this problem, the numbers of the energy modes are quantized, attenuating the spectrum at high frequency in agreement with experimental observation and resolving the catastrophe. The modes that had more energy than the thermal energy of the substance itself were not considered, and because of quantization modes having infinitesimally little energy were excluded.\\n\\nThus for shorter wavelengths very few modes (having energy more than hν) were allowed, supporting the data that the energy emitted is reduced for wavelengths less than the wavelength of the observed peak of emission.\\n\\nNotice that there are two factors responsible for the shape of the graph. Firstly, longer wavelengths have a larger number of modes associated with them. Secondly, shorter wavelengths have more energy associated per mode. The two factors combined give the characteristic maximum wavelength.\\n\\nCalculating the black-body curve was a major challenge in theoretical physics during the late nineteenth century. The problem was solved in 1901 by Max Planck in the formalism now known as Planck's law of black-body radiation. By making changes to Wien's radiation law (not to be confused with Wien's displacement law) consistent with thermodynamics and electromagnetism, he found a mathematical expression fitting the experimental data satisfactorily. Planck had to assume that the energy of the oscillators in the cavity was quantized, i.e., it existed in integer multiples of some quantity. Einstein built on this idea and proposed the quantization of electromagnetic radiation itself in 1905 to explain the photoelectric effect. These theoretical advances eventually resulted in the superseding of classical electromagnetism by quantum electrodynamics. These quanta were called photons and the black-body cavity was thought of as containing a gas of photons. In addition, it led to the development of quantum probability distributions, called Fermi–Dirac statistics and Bose–Einstein statistics, each applicable to a different class of particles, fermions and bosons.\\n\\n## Earth atmosphere EM radiation absorption\\n\\n<img src=\\"./sun-spectrum.svg\\">\\n\\n<img src=\\"./images/spectral-lines.svg\\">\\n\\n\\n<youtube-embed video=\\"-Xx7sPPTu3Y\\" />","frontmatter":{"title":"Light spectrum","description":"Spectrum of solar radiation","date":"2021-08-29T00:00:00.000Z","cover":"/media_files/cover/theory-color-light-spectrum-sun-spectrum.svg"},"url":"/theory/color/light/spectrum/"},{"src":"---\\ntitle: Electromagnetic fields\\ndescription: EM-waves propagationg through space\\n\\ndate: 2021-08-24\\ncover: Results_of_Michael_Faraday's_iron_filings_experiment._Wellcome_M0000164.jpg\\nlinks: \\n  - https://en.wikipedia.org/wiki/Electromagnetic_field\\n  - https://en.wikipedia.org/wiki/Ionosphere#D_layer\\n  - https://en.wikipedia.org/wiki/Electric_field#Electrostatic_fields\\n---\\n\\n\\nAn electromagnetic field (also EM field) is a physical field, mathematical functions of position and time, representing the influences on and due to electric charges. The field at any point in space and time can be regarded as a combination of an electric field and a magnetic field. Because of the interrelationship between the fields, a disturbance in the electric field can create a disturbance in the magnetic field which in turn affects the electric field, leading to an oscillation that propagates through space, known as an electromagnetic wave.\\n\\nThe way in which charges and currents (i.e. streams of charges) interact with the electromagnetic field is described by Maxwell's equation and the Lorentz force law. Maxwell's equations detail how the electric field converges towards or diverges away from electric charges, how the magnetic field curls around electrical currents, and how changes in the electric and magnetic fields influence each other. The Lorentz force law states that a charge subject to an electric field feels a force along the direction of the field, and a charge moving through a magnetic field feels a force that is perpendicular both to the magnetic field and to its direction of motion.\\n\\nThe electromagnetic field is described by classical electrodynamics, an example of a classical field theory. This theory describes many macroscopic physical phenomena accurately. However, it was unable to explain the photoelectric effect and atomic absorption spectroscopy, experiments at the atomic scale. That required the use of quantum mechanics, specifically the quantization of the electromagnetic field and the development of quantum electrodynamics.\\n\\nStrongly magnetic materials (i.e., ferromagnetic, ferrimagnetic or paramagnetic) have a magnetization that is primarily due to electron spin.\\n\\n## Transformations of electromagnetic fields\\n\\nWhether a physical effect is attributable to an electric field or to a magnetic field is dependent upon the observer, in a way that special relativity makes mathematically precise. For example, suppose that a laboratory contains a long straight wire that carries an electrical current. In the frame of reference where the laboratory is at rest, the wire is motionless and electrically neutral: the current, composed of negatively charged electrons, moves against a background of positively charged ions, and the densities of positive and negative charges cancel each other out. A test charge near the wire would feel no electrical force from the wire. However, if the test charge is in motion parallel to the current, the situation changes. In the rest frame of the test charge, the positive and negative charges in the wire are moving at different speeds, and so the positive and negative charge distributions are Lorentz-contracted by different amounts. Consequently, the wire has a nonzero net charge density, and the test charge must experience a nonzero electric field and thus a nonzero force. In the rest frame of the laboratory, there is no electric field to explain the test charge being pulled towards or pushed away from the wire. So, an observer in the laboratory rest frame concludes that a magnetic field must be present.\\n\\nIn general, a situation that one observer describes using only an electric field will be described by an observer in a different inertial frame using a combination of electric and magnetic fields. Analogously, a phenomenon that one observer describes using only a magnetic field will be, in a relatively moving reference frame, described by a combination of fields. The rules for relating the fields required in different reference frames are the Lorentz transformations of the fields.\\n\\nThus, electrostatics and magnetostatics are now seen as studies of the static EM field when a particular frame has been selected to suppress the other type of field, and since an EM field with both electric and magnetic will appear in any other frame, these \\"simpler\\" effects are merely a consequence of different frames of measurement. The fact that the two field variations can be reproduced just by changing the motion of the observer is further evidence that there is only a single actual field involved which is simply being observed differently.\\n\\n## Reciprocal behavior of electric and magnetic fields\\n\\nThe two Maxwell equations, Faraday's Law and the Ampère–Maxwell Law, illustrate a very practical feature of the electromagnetic field. Faraday's Law may be stated roughly as \\"a changing magnetic field inside a loop creates an electric voltage around the loop\\". This is the principle behind the electric generator.\\n\\nAmpere's Law roughly states that \\"an electrical current around a loop creates a magnetic field through the loop\\". Thus, this law can be applied to generate a magnetic field and run an electric motor.\\n\\n## Behavior of the fields in the absence of charges or currents\\n\\nA linearly polarized electromagnetic plane wave propagating parallel to the z-axis is a possible solution for the electromagnetic wave equations in free space. The electric field, E, and the magnetic field, B, are perpendicular to each other and the direction of propagation.\\n\\nMaxwell's equations can be combined to derive wave equations. The solutions of these equations take the form of an electromagnetic wave. In a volume of space not containing charges or currents (free space) – that is, where ρ and J are zero, the electric and magnetic fields satisfy these electromagnetic wave equations:\\n\\nJames Clerk Maxwell was the first to obtain this relationship by his completion of Maxwell's equations with the addition of a displacement current term to Ampere's circuital law. This unified the physical understanding of electricity, magnetism, and light: visible light is but one portion of the full range of electromagnetic waves, the electromagnetic spectrum.\\n\\n## Time-varying EM fields in Maxwell's equations\\n\\nAn electromagnetic field very far from currents and charges (sources) is called electromagnetic radiation (EMR) since it radiates from the charges and currents in the source. Such radiation can occur across a wide range of frequencies called the electromagnetic spectrum, including radio waves, microwave, infrared, visible light, ultraviolet light, X-rays, and gamma rays. The many commercial applications of these radiations are discussed in the named and linked articles.\\n\\nA notable application of visible light is that this type of energy from the Sun powers all life on Earth that either makes or uses oxygen.\\n\\nA changing electromagnetic field which is physically close to currents and charges (see near and far field for a definition of \\"close\\") will have a dipole characteristic that is dominated by either a changing electric dipole, or a changing magnetic dipole. This type of dipole field near sources is called an electromagnetic near-field.\\n\\nChanging electric dipole fields, as such, are used commercially as near-fields mainly as a source of dielectric heating. Otherwise, they appear parasitically around conductors which absorb EMR, and around antennas which have the purpose of generating EMR at greater distances.\\n\\nChanging magnetic dipole fields (i.e., magnetic near-fields) are used commercially for many types of magnetic induction devices. These include motors and electrical transformers at low frequencies, and devices such as RFID tags, metal detectors, and MRI scanner coils at higher frequencies.\\n\\n## Health and safety\\n\\nThe potential effects of electromagnetic fields on human health vary widely depending on the frequency, intensity of the fields, and the length of the exposure. Low frequency, low intensity, and short duration exposure to electromagnetic radiation is generally considered safe. On the other hand, radiation from other parts of the electromagnetic spectrum, such as ultraviolet light and gamma rays, are known to cause significant harm in some circumstances.\\n","frontmatter":{"title":"Electromagnetic fields","description":"EM-waves propagationg through space","date":"2021-08-24T00:00:00.000Z","cover":"/media_files/cover/theory-color-light-em-field-Results_of_Michael_Faraday's_iron_filings_experiment._Wellcome_M0000164.jpg","links":["https://en.wikipedia.org/wiki/Electromagnetic_field","https://en.wikipedia.org/wiki/Ionosphere#D_layer","https://en.wikipedia.org/wiki/Electric_field#Electrostatic_fields"]},"url":"/theory/color/light/em-field/"},{"src":"---\\ntitle: Electromagnetic radiation\\ndescription: EM-waves propagationg through space\\n\\ndate: 2021-08-24\\ncover: emwavepropagation.jpg\\n---\\n\\n<youtube-embed video=\\"FWCN_uI5ygY\\" />\\n\\nSynchronised oscillations (or their quanta, photons) of the electric and magnetic fields, propagating through space at the speed of ~300,000 km/s.\\n\\n![](./emwavepropagation.jpg)\\n\\nVisible light is a certain portion of electromagnetic spectrum between infrared (too weak to excite electrons in molecules) and ultraviolet (powerful enough to cause irreversible chemical reactions in organic matter).\\n\\n<img src=\\"./em-acoustic.svg\\" >\\n\\n<youtube-embed video=\\"V_jYXQFjCmA\\" />\\n","frontmatter":{"title":"Electromagnetic radiation","description":"EM-waves propagationg through space","date":"2021-08-24T00:00:00.000Z","cover":"/media_files/cover/theory-color-light-em-waves-emwavepropagation.jpg"},"url":"/theory/color/light/em-waves/"},{"src":"---\\ntitle: Sensory dissonance curve\\ndescription: The harmonic relations of notes\\nlayout: app\\ndate: 2021-08-22\\ncover: dissonance.svg\\nlinks:\\n  - url: https://sethares.engr.wisc.edu/consemi.html\\n    title: Calculations of the dissonant curves\\n  - url: https://www.juliabloggers.com/consonant-triads/\\n    title: Python formulas for dissonance curves\\n---\\n\\n<client-only>\\n  <sound-dissonance />\\n</client-only>\\n\\nA simple curve for two sine waves is readily established and then we can calculate and explore sensory dissonance curves for complex sounds as the sum of interactions between their partials.\\n\\nTry dragging the note to hear the exact interval. Toggle the plain sine and rich sawtooth waveforms. Compare the feeling of consonance and the dips in the curve yourself.\\n\\n[More info in the Theory research](../../../theory/intervals/dissonance/index.md).\\n","frontmatter":{"title":"Sensory dissonance curve","description":"The harmonic relations of notes","layout":"app","date":"2021-08-22T00:00:00.000Z","cover":"/media_files/cover/practice-sound-dissonance-dissonance.svg","links":[{"url":"https://sethares.engr.wisc.edu/consemi.html","title":"Calculations of the dissonant curves"},{"url":"https://www.juliabloggers.com/consonant-triads/","title":"Python formulas for dissonance curves"}]},"url":"/practice/sound/dissonance/"},{"src":"---\\ntitle: Tone clusters\\ndescription: Multiple adjacent tones played simultaneously\\ndate: 2021-08-20\\ncover: matthew-ball.jpg\\n---\\n\\nA tone cluster is a musical chord comprising at least three adjacent tones in a scale. Prototypical tone clusters are based on the chromatic scale and are separated by semitones. For instance, three adjacent piano keys (such as C, C♯, and D) struck simultaneously produce a tone cluster. Variants of the tone cluster include chords comprising adjacent tones separated diatonically, pentatonically, or microtonally. On the piano, such clusters often involve the simultaneous striking of neighboring white or black keys.\\n\\nThe early years of the twentieth century saw tone clusters elevated to central roles in pioneering works by ragtime artists Jelly Roll Morton and Scott Joplin. In the 1910s, two classical avant-gardists, composer-pianists Leo Ornstein and Henry Cowell, were recognized as making the first extensive explorations of the tone cluster. During the same period, Charles Ives employed them in several compositions that were not publicly performed until the late 1920s or 1930s. Composers such as Béla Bartók and, later, Lou Harrison and Karlheinz Stockhausen became proponents of the tone cluster, which feature in the work of many 20th- and 21st-century classical composers. Tone clusters also play a significant role in the work of free jazz musicians such as Cecil Taylor and Matthew Shipp.\\n\\nIn most Western music, tone clusters tend to be heard as dissonant. Clusters may be performed with almost any individual instrument on which three or more notes can be played simultaneously, as well as by most groups of instruments or voices. Keyboard instruments are particularly suited to the performance of tone clusters because it is relatively easy to play multiple notes in unison on them.\\n\\nIn standard Western classical music practice, all tone clusters are classifiable as secundal chords—that is, they are constructed from minor seconds (intervals of one semitone), major seconds (intervals of two semitones), or, in the case of certain pentatonic clusters, augmented seconds (intervals of three semitones). Stacks of adjacent microtonal pitches also constitute tone clusters.\\n\\nIn tone clusters, the notes are sounded fully and in unison, distinguishing them from ornamented figures involving acciaccaturas and the like. Their effect also tends to be different: where ornamentation is used to draw attention to the harmony or the relationship between harmony and melody, tone clusters are for the most part employed as independent sounds. While, by definition, the notes that form a cluster must sound at the same time, there is no requirement that they must all begin sounding at the same moment. For example, in R. Murray Schafer's choral Epitaph for Moonlight (1968), a tone cluster is constructed by dividing each choir section (soprano/alto/tenor/bass) into four parts. Each of the sixteen parts enters separately, humming a note one semitone lower than the note hummed by the previous part, until all sixteen are contributing to the cluster.\\n\\nTone clusters have generally been thought of as dissonant musical textures, and even defined as such. As noted by Alan Belkin, however, instrumental timbre can have a significant impact on their effect: \\"Clusters are quite aggressive on the organ, but soften enormously when played by strings (possibly because slight, continuous fluctuations of pitch in the latter provide some inner mobility).\\" In his first published work on the topic, Henry Cowell observed that a tone cluster is \\"more pleasing\\" and \\"acceptable to the ear if its outer limits form a consonant interval.\\" Cowell explains, \\"the natural spacing of so-called dissonances is as seconds, as in the overtone series, rather than sevenths and ninths....Groups spaced in seconds may be made to sound euphonious, particularly if played in conjunction with fundamental chord notes taken from lower in the same overtone series. Blends them together and explains them to the ear.\\" Tone clusters have also been considered noise. As Mauricio Kagel says, \\"clusters have generally been used as a kind of anti-harmony, as a transition between sound and noise.\\" Tone clusters thus also lend themselves to use in a percussive manner. Historically, they were sometimes discussed with a hint of disdain. One 1969 textbook defines the tone cluster as \\"an extra-harmonic clump of notes.\\n\\n## Notation and execution\\n\\nIn his 1917 piece The Tides of Manaunaun, Cowell introduced a new notation for tone clusters on the piano and other keyboard instruments. In this notation, only the top and bottom notes of a cluster, connected by a single line or a pair of lines, are represented. This developed into the solid-bar style seen in the image on the right. Here, the first chord—stretching two octaves from D2 to D4—is a diatonic (so-called white-note) cluster, indicated by the natural sign below the staff. The second is a pentatonic (so-called black-note) cluster, indicated by the flat sign; a sharp sign would be required if the notes showing the limit of the cluster were spelled as sharps. A chromatic cluster—black and white keys together—is shown in this method by a solid bar with no sign at all. In scoring the large, dense clusters of the solo organ work Volumina in the early 1960s, György Ligeti, using graphical notation, blocked in whole sections of the keyboard.\\n\\n![](./Cowell_tone_clusters.png)\\n\\nThe performance of keyboard tone clusters is widely considered an \\"extended technique\\"—large clusters require unusual playing methods often involving the fist, the flat of the hand, or the forearm. Thelonious Monk and Karlheinz Stockhausen each performed clusters with their elbows; Stockhausen developed a method for playing cluster glissandi with special gloves. Don Pullen would play moving clusters by rolling the backs of his hands over the keyboard. Boards of various dimension are sometimes employed, as in the Concord Sonata (c. 1904–19) of Charles Ives; they can be weighted down to execute clusters of long duration. Several of Lou Harrison's scores call for the use of an \\"octave bar\\", crafted to facilitate high-speed keyboard cluster performance. Designed by Harrison with his partner William Colvig, the octave bar is\\n\\n> a flat wooden device approximately two inches high with a grip on top and sponge rubber on the bottom, with which the player strikes the keys. Its length spans an octave on a grand piano. The sponge rubber bottom is sculpted so that its ends are slightly lower than its center, making the outer tones of the octave sound with greater force than the intermediary pitches. The pianist can thus rush headlong through fearfully rapid passages, precisely spanning an octave at each blow.\\n\\n## In jazz\\n\\nScott Joplin wrote the first known published composition to include a musical sequence built around specifically notated tone clusters.\\n\\nTone clusters have been employed by jazz artists in a variety of styles, since the very beginning of the form. Around the turn of the twentieth century, Storyville pianist Jelly Roll Morton began performing a ragtime adaptation of a French quadrille, introducing large chromatic tone clusters played by his left forearm. The growling effect led Morton to dub the piece his \\"Tiger Rag\\". In 1909, Scott Joplin's deliberately experimental \\"Wall Street Rag\\" included a section prominently featuring notated tone clusters.\\n\\nThe fourth of Artie Matthews's Pastime Rags (1913–20) features dissonant right-hand clusters. Thelonious Monk, in pieces such as \\"Bright Mississippi\\" (1962), \\"Introspection\\" (1946) and \\"Off Minor\\" (1947), uses clusters as dramatic figures within the central improvisation and to accent the tension at its conclusion. They are heard on Art Tatum's \\"Mr. Freddy Blues\\" (1950), undergirding the cross-rhythms. By 1953, Dave Brubeck was employing piano tone clusters and dissonance in a manner anticipating the style free jazz pioneer Cecil Taylor would soon develop. The approach of hard bop pianist Horace Silver is an even clearer antecedent to Taylor's use of clusters. During the same era, clusters appear as punctuation marks in the lead lines of Herbie Nichols. In \\"The Gig\\" (1955), described by Francis Davis as Nichols's masterpiece, \\"clashing notes and tone clusters depic[t] a pickup band at odds with itself about what to play.\\" Recorded examples of Duke Ellington's piano cluster work include \\"Summertime\\" (1961) and ...And His Mother Called Him Bill (1967) and This One's for Blanton!, his tribute to a former bass player, recorded in 1972 with bassist Ray Brown. Bill Evans' interpretation of “Come Rain or Come Shine” from the album Portrait in Jazz (1960), opens with a striking 5-tone cluster.\\n\\nIn jazz, as in classical music, tone clusters have not been restricted to the keyboard. In the 1930s, the Jimmie Lunceford Orchestra's \\"Stratosphere\\" included ensemble clusters among an array of progressive elements. The Stan Kenton Orchestra's April 1947 recording of \\"If I Could Be With You One Hour Tonight,\\" arranged by Pete Rugolo, features a dramatic four-note trombone cluster at the end of the second chorus. As described by critic Fred Kaplan, a 1950 performance by the Duke Ellington Orchestra features arrangements with the collective \\"blowing rich, dark, tone clusters that evoke Ravel.\\" Chord clusters also feature in the scores of arranger Gil Evans. In his characteristically imaginative arrangement of George Gershwin's \\"There's a boat that's leaving soon for New York\\" from the album Porgy and Bess, Evans contributes chord clusters orchestrated on flutes, alto saxophone and muted trumpets as a background to accompany Miles Davis' solo improvisation. In the early 1960s, arrangements by Bob Brookmeyer and Gerry Mulligan for Mulligan's Concert Jazz Band employed tone clusters in a dense style bringing to mind both Ellington and Ravel. Eric Dolphy's bass clarinet solos would often feature \\"microtonal clusters summoned by frantic overblowing.\\" Critic Robert Palmer called the \\"tart tone cluster\\" that \\"pierces a song's surfaces and penetrates to its heart\\" a specialty of guitarist Jim Hall's.\\n\\nClusters are especially prevalent in the realm of free jazz. Cecil Taylor has used them extensively as part of his improvisational method since the mid-1950s. Like much of his musical vocabulary, his clusters operate \\"on a continuum somewhere between melody and percussion.\\" One of Taylor's primary purposes in adopting clusters was to avoid the dominance of any specific pitch. Leading free jazz composer, bandleader, and pianist Sun Ra often used them to rearrange the musical furniture, as described by scholar John F. Szwed:\\n\\n> When he sensed that [a] piece needed an introduction or an ending, a new direction or fresh material, he would call for a space chord, a collectively improvised tone cluster at high volume which \\"would suggest a new melody, maybe a rhythm.\\" It was a pianistically conceived device which created another context for the music, a new mood, opening up fresh tonal areas.[105]\\n\\nAs free jazz spread in the 1960s, so did the use of tone clusters. In comparison with what John Litweiler describes as Taylor's \\"endless forms and contrasts,\\" the solos of Muhal Richard Abrams employ tone clusters in a similarly free, but more lyrical, flowing context. Guitarist Sonny Sharrock made them a central part of his improvisations; in Palmer's description, he executed \\"glass-shattering tone clusters that sounded like someone was ripping the pickups out of the guitar without having bothered to unplug it from its overdriven amplifier.\\" Pianist Marilyn Crispell has been another major free jazz proponent of the tone cluster, frequently in collaboration with Anthony Braxton, who played with Abrams early in his career. Since the 1990s, Matthew Shipp has built on Taylor's innovations with the form. European free jazz pianists who have contributed to the development of the tone cluster palette include Gunter Hampel and Alexander von Schlippenbach.\\n\\nDon Pullen, who bridged free and mainstream jazz, \\"had a technique of rolling his wrists as he improvised—the outside edges of his hands became scarred from it—to create moving tone clusters,\\" writes critic Ben Ratliff. \\"Building up from arpeggios, he could create eddies of noise on the keyboard...like concise Cecil Taylor outbursts.\\" In the description of Joachim Berendt, Pullen \\"uniquely melodized cluster playing and made it tonal. He phrases impulsively raw clusters with his right hand and yet embeds them in clear, harmonically functional tonal chords simultaneously played with the left hand.\\" John Medeski employs tone clusters as keyboardist for Medeski, Martin, and Wood, which mixes free jazz elements into its soul jazz/jam band style.\\n\\n## In popular music\\n\\nLike jazz, rock and roll has made use of tone clusters since its birth, if characteristically in a less deliberate manner—most famously, Jerry Lee Lewis's live-performance piano technique of the 1950s, involving fists, feet, and derrière. Since the 1960s, much drone music, which crosses the lines between rock, electronic, and experimental music, has been based on tone clusters. On The Velvet Underground's \\"Sister Ray,\\" recorded in September 1967, organist John Cale uses tone clusters within the context of a drone; the song is apparently the closest approximation on record of the band's early live sound. Around the same time, Doors keyboardist Ray Manzarek began introducing clusters into his solos during live performances of the band's hit \\"Light My Fire.\\"\\n\\nKraftwerk's self-titled 1970 debut album employs organ clusters to add variety to its repeated tape sequences. In 1971, critic Ed Ward lauded the \\"tone-cluster vocal harmonies\\" created by Jefferson Airplane's three lead singers, Grace Slick, Marty Balin, and Paul Kantner. Tangerine Dream's 1972 double album Zeit is replete with clusters performed on synthesizer. In later rock practice, the D add9 chord characteristic of jangle pop involves a three-note set separated by major seconds (D, E, F♯), the sort of guitar cluster that may be characterized as a harp effect. The Beatles' 1965 song \\"We Can Work It Out\\" features a momentarily grating tone cluster with voices singing A sharp and C sharp against the accompanying keyboard playing a sustained chord on B to the word \\"time.\\" The Band's 1968 song \\"The Weight\\" from their debut album Music from Big Pink features a dissonant vocal refrain with suspensions culminating in a 3-note cluster to the words \\"you put the load right on me.\\"\\n\\nThe sound of tone clusters played on the organ became a convention in radio drama for dreams. Clusters are often used in the scoring of horror and science-fiction films. For a 2004 production of the play Tone Clusters by Joyce Carol Oates, composer Jay Clarke—a member of the indie rock bands Dolorean and The Standard—employed clusters to \\"subtly build the tension\\", in contrast to what he perceived in the cluster pieces by Cowell and Ives suggested by Oates: “Some of it was like music to murder somebody to; it was like horror-movie music”.\\n\\n## Use in other music\\n\\n<youtube-embed video=\\"0T1pyZZiBO0\\" />\\n\\nIn traditional Japanese gagaku, the imperial court music, a tone cluster performed on shō (a type of mouth organ) is generally employed as a harmonic matrix. Yoritsune Matsudaira, active from the late 1920s to the early 2000s, merged gagaku's harmonies and tonalities with avant-garde Western techniques. Much of his work is built on the shō's ten traditional cluster formations. Lou Harrison's Pacifika Rondo, which mixes Eastern and Western instrumentation and styles, mirrors the gagaku approach—sustained organ clusters emulate the sound and function of the shō. The shō also inspired Benjamin Britten in creating the instrumental texture of his 1964 dramatic church parable Curlew River. Its sound pervades the characteristically sustained cluster chords played on a chamber organ. Traditional Korean court and aristocratic music employs passages of simultaneous ornamentation on multiple instruments, creating dissonant clusters; this technique is reflected in the work of twentieth-century Korean German composer Isang Yun.\\n\\nSeveral East Asian free reed instruments, including the shō, were modeled on the sheng, an ancient Chinese folk instrument later incorporated into more formal musical contexts. Wubaduhesheng, one of the traditional chord formations played on the sheng, involves a three-pitch cluster. Malayan folk musicians employ an indigenous mouth organ that, like the shō and sheng, produces tone clusters. The characteristic musical form played on the bin-baja, a strummed harp of central India's Pardhan people, has been described as a \\"rhythmic ostinato on a tone cluster.\\"\\n\\nAmong the Asante, in the region that is today encompassed by Ghana, tone clusters are used in traditional trumpet music. A distinctive \\"tongue-rattling technique gives a greater vibrancy to...already dissonant tonal cluster[s].... [I]ntentional dissonance dispels evil spirits, and the greater the clangor, the greater the sound barrage.\\n\\n<youtube-embed video=\\"L9Z8Ty2-3xk?t=213\\" />\\n\\nWendy Carlos used essentially the exact reverse of this methodology to derive her Alpha scale, Beta scale and Gamma scale; they are the most consonant scales one can derive by treating tone clusters as the only type of triad that really exists, which is paradoxically an anti-harmonic monistic method.\\n","frontmatter":{"title":"Tone clusters","description":"Multiple adjacent tones played simultaneously","date":"2021-08-20T00:00:00.000Z","cover":"/media_files/cover/theory-chords-clusters-matthew-ball.jpg"},"url":"/theory/chords/clusters/"},{"src":"---\\ntitle: Subtractive color models\\ndescription: The colors produced by materials absorbing certain light frequencies. RYB and CMYK\\n\\ndate: 2021-08-20\\ncover: cmyk.svg\\n---\\n\\nSubtractive means that color is produced by absorbing some parts of white light spectrum by the material. Subtractive models are used in painting and printing, where different pigment mixtures make up different colors.\\n\\nA color model is subtractive in the sense that mixtures of dyes subtract specific wavelengths from the spectral power distribution of the illuminating light which is scattered back into the viewer's eye and is perceived as colored. Mixing of dyes is used to reproduce a gamut of colors, the resultant color from this layer is predicted by multiplying (not subtracting) the absorbance profiles of the dyes.\\n\\n### RYB\\n\\n<img src=\\"./chromatography_1841.png\\">\\n\\n> An RYB color chart from George Field's 1841 Chromatography; or, A treatise on colours and pigments: and of their powers in painting.\\n\\n**RYB** (an abbreviation of red–yellow–blue) is a subtractive color model used in art and applied design in which red, yellow, and blue pigments are considered primary colors.\\n\\nIn this context, the term primary color refers to three exemplar colors (red, yellow, and blue) as opposed to specific pigments. As illustrated, in the RYB color model, red, yellow, and blue are intermixed to create secondary color segments of orange, green, and purple. This set of primary colors emerged at a time when access to a large range of pigments was limited by availability and cost, and it encouraged artists and designers to explore the many nuances of color through mixing and intermixing a limited range of pigment colors. In art and design education, red, yellow, and blue pigments were usually augmented with white and black pigments, enabling the creation of a larger gamut of color nuances including tints and shades.\\n\\n![](./tint-tone-shade.svg)\\n\\n> **Jacob Christoph Le Blon** was the first to apply the RYB color model to printing, specifically mezzotint printing, and he used separate plates for each color: yellow, red and blue plus black to add shades and contrast. In 'Coloritto', Le Blon asserted that “the art of mixing colours…(in) painting can represent all visible objects with three colours: yellow, red and blue; for all colours can be composed of these three, which I call Primitive”. Le Blon added that red and yellow make orange; red and blue, make purple; and blue and yellow make green (Le Blon, 1725, p6).\\n\\n### CMY and CMYK\\n\\nThe **CMY** color model is a subtractive color model in which cyan, magenta and yellow pigments or dyes are added together in various ways to reproduce a broad array of colors.\\n\\nWhen the intensities for all the components are the same, the result is a shade of gray, lighter, or darker depending on the intensity. When the intensities are different, the result is a colorized hue, more or less saturated depending on the difference of the strongest and weakest of the intensities of the primary colors employed.\\n\\n### Interactive CMYK mixer\\n\\nDrag any of the color components up or right to increase it's value.\\n\\n<color-cmyk />\\n\\n**CMYK** color model is a subtractive color model, based on the CMY color model, used in color printing, and is also used to describe the printing process itself, that is used in the layering technique by printers to create different colors on a white paper. CMYK refers to the four inks used in some color printing: cyan, magenta, yellow, and key. It uses K, black ink, since C, M, and Y inks are translucent and will only produce a gray color when laid on top of each other.\\n\\nWith CMYK printing, halftoning (also called screening) allows for less than full saturation of the primary colors; tiny dots of each primary color are printed in a pattern small enough that humans perceive a solid color.\\n\\nLight, saturated colors often cannot be created with CMYK, and light colors in general may make visible the halftone pattern. Using a CcMmYK process, with the addition of light cyan and magenta inks to CMYK, can solve these problems.\\n","frontmatter":{"title":"Subtractive color models","description":"The colors produced by materials absorbing certain light frequencies. RYB and CMYK","date":"2021-08-20T00:00:00.000Z","cover":"/media_files/cover/theory-color-models-subtractive-cmyk.svg"},"url":"/theory/color/models/subtractive/"},{"src":"---\\ntitle: Step sequencer\\ndescription: A simple tool to build up melodies and chord progressions\\nlayout: app\\ndate: 2021-08-19\\ncover: sequencer.png\\n---\\n\\n\\n<step-sequencer />\\n","frontmatter":{"title":"Step sequencer","description":"A simple tool to build up melodies and chord progressions","layout":"app","date":"2021-08-19T00:00:00.000Z","cover":"/media_files/cover/practice-chord-sequencer-sequencer.png"},"url":"/practice/chord/sequencer/"},{"src":"---\\ntitle: Additive color models\\ndescription: The colors created by combining colored lights\\ndate: 2021-08-18\\ncover: rgb.svg\\n---\\n\\nA color model is additive in the sense that the three light beams are added together, and their light spectra add, wavelength for wavelength, to make the final color's spectrum. Because of properties, these three colors create white, this is in stark contrast to physical colors, such as dyes which create black when mixed.\\n\\n## Interactive RGB color mixer\\n\\nDrag any of the color components up or right to increase it's value.\\n\\n<color-rgb />\\n\\nZero intensity for each component gives the darkest color (no light, considered the black), and full intensity of each gives a white; the quality of this white depends on the nature of the primary light sources, but if they are properly balanced, the result is a neutral white matching the system's white point. When the intensities for all the components are the same, the result is a shade of gray, darker or lighter depending on the intensity. When the intensities are different, the result is a colorized hue, more or less saturated depending on the difference of the strongest and weakest of the intensities of the primary colors employed.\\n\\n### RGB\\n\\nTo form a color with RGB, three light beams (one red, one green, and one blue) must be superimposed (for example by emission from a black screen or by reflection from a white screen). Each of the three beams is called a component of that color, and each of them can have an arbitrary intensity, from fully off to fully on, in the mixture.\\n\\nThe RGB color model itself does not define what is meant by red, green, and blue colorimetrically, and so the results of mixing them are not specified as absolute, but relative to the primary colors. When the exact chromaticities of the red, green, and blue primaries are defined, the color model then becomes an absolute color space, such as sRGB or Adobe RGB.\\n\\n![](./rgb_color_solid_cube.png)\\n\\nUse of the three primary colors is not sufficient to reproduce all colors; only colors within the color triangle defined by the chromaticities of the primaries can be reproduced by additive mixing of non-negative amounts of those colors of light.\\n","frontmatter":{"title":"Additive color models","description":"The colors created by combining colored lights","date":"2021-08-18T00:00:00.000Z","cover":"/media_files/cover/theory-color-models-additive-rgb.svg"},"url":"/theory/color/models/additive/"},{"src":"---\\ntitle: String overtones\\ndescription: String standing waves interactive visualization\\ndate: 2021-08-12\\nlayout: app\\ncover: overtones.png\\n---\\n\\n\\n<sound-overtones />\\n\\nA string fixed from both ends produces a harmonic set of incremental frequency partials, also called harmonics.\\n","frontmatter":{"title":"String overtones","description":"String standing waves interactive visualization","date":"2021-08-12T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-sound-overtones-overtones.png"},"url":"/practice/sound/overtones/"},{"src":"---\\ntitle: Color models\\ndescription: Different ways to measure and quantify colors\\n\\ndate: 2021-08-10\\ncover: color-models.svg\\n---\\n\\n![](./colors-exp-1.svg)\\n\\n![](./color-models.svg)\\n\\nLet's explore [Additive](./additive/index.md), [Subtractive](./subtractive/index.md) and [Perceptual](./perceptual/index.md) color models deeper.","frontmatter":{"title":"Color models","description":"Different ways to measure and quantify colors","date":"2021-08-10T00:00:00.000Z","cover":"/media_files/cover/theory-color-models-color-models.svg"},"url":"/theory/color/models/"},{"src":"---\\ntitle: A4 cheat-sheet\\ndescription: A comprehesive guide to colorful notes - WIP\\ncover: cover.png\\nlayout: app\\ndate: 2021-08-09\\nproduct:\\n  price: 10\\n  id: print-circles-a4\\n  digital: true\\n---\\n\\n<script setup>\\nimport PrintScales from './PrintScales.vue'\\n<\/script>\\n\\n## Diatonic scales and modes\\n\\n<print-scales   width=\\"100%\\" class=\\"max-w-55ch\\" />\\n<save-buttons svg=\\"diatonic\\" password=\\"circle-a4-99tuD\\"/>\\n","frontmatter":{"title":"A4 cheat-sheet","description":"A comprehesive guide to colorful notes - WIP","cover":"/media_files/cover/practice-experiments-printables-circles-a4-cover.png","layout":"app","date":"2021-08-09T00:00:00.000Z","product":{"price":10,"id":"print-circles-a4","digital":true}},"url":"/practice/experiments/printables/circles-a4/"},{"src":"---\\ntitle: Perceptual color models\\ndescription: Color spaces based on the \\"standard observer\\" perception of colors\\n\\ndate: 2021-08-08\\ncover: CIE_1976_UCS.png\\n---\\n\\n<script setup>\\nimport colorTable from './table.vue'\\n<\/script>\\n\\n## Munsell color system\\n\\nIn colorimetry, the Munsell color system is a color space that specifies colors based on three properties of color: hue (basic color), chroma (color intensity), and value (lightness). It was created by Professor Albert H. Munsell in the first decade of the 20th century and adopted by the United States Department of Agriculture (USDA) as the official color system for soil research in the 1930s.\\n\\n![](./images/Munsell-system.svg)\\n\\nSeveral earlier color order systems had placed colors into a three-dimensional color solid of one form or another, but Munsell was the first to separate hue, value, and chroma into perceptually uniform and independent dimensions, and he was the first to illustrate the colors systematically in three-dimensional space. Munsell's system, particularly the later renotations, is based on rigorous measurements of human subjects' visual responses to color, putting it on a firm experimental scientific basis. Because of this basis in human visual perception, Munsell's system has outlasted its contemporary color models, and though it has been superseded for some uses by models such as CIELAB (L*a*b\\\\*) and CIECAM02, it is still in wide use today.\\n\\n> ![](./images/munsell_1943_color_solid_cylindrical_coordinates.png)\\n> Three-dimensional representation of the 1943 Munsell renotations (with portion cut away).\\n\\n## HSL, HSV and HSB color models\\n\\nHSL (for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers to more closely align with the way human vision perceives color-making attributes. In these models, colors of each hue are arranged in a radial slice, around a central axis of neutral colors which ranges from black at the bottom to white at the top.\\n\\n![](./images/hsl.png)\\n\\nThe HSL representation models the way different paints mix together to create colour in the real world, with the lightness dimension resembling the varying amounts of black or white paint in the mixture (e.g. to create \\"light red\\", a red pigment can be mixed with white paint; this white paint corresponds to a high \\"lightness\\" value in the HSL representation). Fully saturated colors are placed around a circle at a lightness value of ½, with a lightness value of 0 or 1 corresponding to fully black or white, respectively.\\n\\nMeanwhile, the HSV representation models how colors appear under light. The difference between HSL and HSV is that a color with maximum lightness in HSL is pure white, but a color with maximum value/brightness in HSV is analogous to shining a white light on a colored object (e.g. shining a bright white light on a red object causes the object to still appear red, just brighter and more intense, while shining a dim light on a red object causes the object to appear darker and less bright).\\n\\n![](./images/HSV_color_solid_cylinder_saturation_gray.png)\\n\\nThe issue with both HSV and HSL is that these approaches do not effectively separate colour into their three value components according to human perception of color. This can be seen when the saturation settings are altered — it is quite easy to notice the difference in perceptual lightness despite the \\"V\\" or \\"L\\" setting being fixed.\\n\\nHWB is a cylindrical-coordinate representation of points in an RGB color model, similar to HSL and HSV. It was developed by HSV’s creator Alvy Ray Smith in 1996 to address some of the issues with HSV. HWB was designed to be more intuitive for humans to use and slightly faster to compute. The first coordinate, H (Hue), is the same as the Hue coordinate in HSL and HSV. W and B stand for Whiteness and Blackness respectively and range from 0–100% (or 0–1). The mental model is that the user can pick a main hue and then “mix” it with white and/or black to produce the desired color.\\n\\n## HCL (Lch) color space\\n\\nHCL (Hue-Chroma-Luminance) or Lch refers to any of the many cylindrical color space models that are designed to accord with human perception of color with the three parameters. Lch has been adopted by information visualization practitioners to present data without the bias implicit in using varying saturation. They are, in general, designed to have characteristics of both cylindrical translations of the RGB color space, such as HSL and HSV, and the L*a*b\\\\* color space.\\n\\nCIE-based Lch color spaces are transformations of the two chroma values (ab or uv) into the polar coordinates. The source color spaces are still very well-regarded for their uniformity, and the transformation does not cause degradation in this aspect. See the respective articles for how the underlying coordinates are derived.\\n\\n## Interactive HSL, LCH and HWB color mixer\\n\\nChoose any of the models by clicking on it's name. You can define a hue for the color by clicking on it's sector and then change two other parameters either by dragging the bars on the side or just swiping across the circle. Top-down motion is for the L (W) component and right-left is for the other one.\\n\\n<color-hsl />\\n\\n## CIE 1931 XYZ\\n\\nThe CIE 1931 RGB color space and CIE 1931 XYZ color space were created by the International Commission on Illumination (CIE) in 1931. They resulted from a series of experiments done in the late 1920s by William David Wright using ten observers and John Guild using seven observers. The experimental results were combined into the specification of the CIE RGB color space, from which the CIE XYZ color space was derived.\\n\\nDue to the distribution of cones in the eye, the tristimulus values depend on the observer's field of view. To eliminate this variable, the CIE defined a color-mapping function called the standard (colorimetric) observer, to represent an average human's chromatic response within a 2° arc inside the fovea. This angle was chosen owing to the belief that the color-sensitive cones resided within a 2° arc of the fovea. Thus the CIE 1931 Standard Observer function is also known as the CIE 1931 2° Standard Observer.\\n\\nThe CIE XYZ color space encompasses all color sensations that are visible to a person with average eyesight. That is why CIE XYZ (Tristimulus values) is a device-invariant representation of color. It serves as a standard reference against which many other color spaces are defined. A set of color-matching functions, like the spectral sensitivity curves of the LMS color space, but not restricted to non-negative sensitivities, associates physically produced light spectra with specific tristimulus values.\\n\\nA color space maps a range of physically produced colors from mixed light, pigments, etc. to an objective description of color sensations registered in the human eye, typically in terms of tristimulus values, but not usually in the LMS color space defined by the spectral sensitivities of the cone cells. The tristimulus values associated with a color space can be conceptualized as amounts of three primary colors in a tri-chromatic, additive color model. In some color spaces, including the LMS and XYZ spaces, the primary colors used are not real colors in the sense that they cannot be generated in any light spectrum.\\n\\nIn the CIE 1931 model, Y is the luminance, Z is quasi-equal to blue (of CIE RGB), and X is a mix of the three CIE RGB curves chosen to be nonnegative (see § Definition of the CIE XYZ color space). Setting Y as luminance has the useful result that for any given Y value, the XZ plane will contain all possible chromaticities at that luminance.\\n\\nThe unit of the tristimulus values X, Y, and Z is often arbitrarily chosen so that Y = 1 or Y = 100 is the brightest white that a color display supports. In this case, the Y value is known as the relative luminance. The corresponding whitepoint values for X and Z can then be inferred using the standard illuminants.\\n\\nn other words, the Z value is solely made up of the S cone response, the Y value a mix of L and M responses, and X value a mix of all three. This fact makes XYZ values analogous to, but different from, the LMS cone responses of the human eye.\\n\\n## CIELUV and CIELAB\\n\\nCIELUV, is a color space adopted by the International Commission on Illumination (CIE) in 1976, as a simple-to-compute transformation of the 1931 CIE XYZ color space, but which attempted perceptual uniformity.\\n\\nDue to the distribution of cones in the eye, the tristimulus values depend on the observer's field of view. To eliminate this variable, the CIE defined a color-mapping function called the standard (colorimetric) observer, to represent an average human's chromatic response within a 2° arc inside the fovea.\\n\\n![](./CIE_1976_UCS.png)\\n\\nThe CIELAB color space also referred to as L*a*b* is a color space defined by the International Commission on Illumination (abbreviated CIE) in 1976. It expresses color as three values: L* for perceptual lightness, and a* and b* for the four unique colors of human vision: red, green, blue, and yellow. CIELAB was intended as a perceptually uniform space, where a given numerical change corresponds to similar perceived change in color. While the LAB space is not truly perceptually uniform, it nevertheless is useful in industry for detecting small differences in color.\\n\\nLike the CIEXYZ space it derives from, CIELAB colorspace is a device-independent, \\"standard observer\\" model. The colors it defines are not relative to any particular device such as a computer monitor or a printer, but instead relate to the CIE standard observer which is an averaging of the results of color matching experiments under laboratory conditions.\\n\\n![](./images/Lab_color_at_luminance_75.png)\\n\\nThe CIELAB space is three-dimensional, and covers the entire range of human color perception, or gamut. It is based on the opponent color model of human vision, where red/green forms an opponent pair, and blue/yellow forms an opponent pair. The lightness value, L*, also referred to as \\"Lstar,\\" defines black at 0 and white at 100. The a* axis is relative to the green–red opponent colors, with negative values toward green and positive values toward red. The b\\\\* axis represents the blue–yellow opponents, with negative numbers toward blue and positive toward yellow.\\n\\n## Interactive LAB color mixer\\n\\nMix any possible color out of three color components by dragging the bars on the sides or simply by swiping the central color panel. You can also change the grid resolution and the range of A and B components with the sliders below the grid.\\n\\n<color-lab />\\n\\nWhile the intention behind CIELAB was to create a space that was more perceptually uniform than CIEXYZ using only a simple formula, CIELAB is known to lack perceptually uniformity, particularly in the area of blue hues.\\n\\nThe lightness value, L\\\\* in CIELAB is calculated using the cube root of the relative luminance with an offset near black. This results in an effective power curve with an exponent of approximately 0.43 which represents the human eye's response to light under daylight (photopic) conditions.\\n\\n## HSL and LCH 12 colors cycle comparison\\n\\n<color-table />\\n","frontmatter":{"title":"Perceptual color models","description":"Color spaces based on the \\"standard observer\\" perception of colors","date":"2021-08-08T00:00:00.000Z","cover":"/media_files/cover/theory-color-models-perceptual-CIE_1976_UCS.png"},"url":"/theory/color/models/perceptual/"},{"src":"---\\ntitle: MIDI Recorder\\ndescription: Record MIDI as you play – visualize and save your music\\ndate: 2021-08-04\\nlayout: app\\nsources:\\n  - https://github.com/1j01/midi-recorder/\\n  - https://github.com/Tonejs/Midi\\n  - https://github.com/Tonejs/Tone.js/wiki/TransportTime\\n  - https://webmidijs.org/docs/v3.0.0-alpha.10/index.html\\nstatus: alpha\\nversion: 0.1\\ncover: cover.png\\n---\\n\\n<client-only>\\n  <midi-recorder />\\n</client-only>\\n\\n## Work in progress\\n\\nThis app is a draft to be iterated on. The idea is to make a tool to record some kind of visual midi sketches and store them as mid files and also directly in the browser.\\n","frontmatter":{"title":"MIDI Recorder","description":"Record MIDI as you play – visualize and save your music","date":"2021-08-04T00:00:00.000Z","layout":"app","sources":["https://github.com/1j01/midi-recorder/","https://github.com/Tonejs/Midi","https://github.com/Tonejs/Tone.js/wiki/TransportTime","https://webmidijs.org/docs/v3.0.0-alpha.10/index.html"],"status":"alpha","version":0.1,"cover":"/media_files/cover/practice-midi-recorder-cover.png"},"url":"/practice/midi/recorder/"},{"src":"---\\ntitle: Tabs\\ndescription: Guitar and ukulele tabs for any chord in existence\\ndate: 2021-08-03\\ncover: tabs.png\\nlayout: app\\n---\\n\\n<chord-tabs />\\n","frontmatter":{"title":"Tabs","description":"Guitar and ukulele tabs for any chord in existence","date":"2021-08-03T00:00:00.000Z","cover":"/media_files/cover/practice-chord-tabs-tabs.png","layout":"app"},"url":"/practice/chord/tabs/"},{"src":"---\\ntitle: Color names\\ndescription: Know how to name any color of 12 equally spaced hues\\n\\ndate: 2021-08-01\\ncover: color-names.svg\\n\\n---\\n\\n<script setup>\\nimport col from '#/db/colors/colors.yaml'\\n<\/script>\\n\\n<ColorCards :list=\\"col.colors\\" :langs=\\"col.langs\\" />\\n\\n<ColorNames :list=\\"col.colors\\" :langs=\\"col.langs\\" />\\n\\n<img src=\\"./color-names.svg\\">\\n\\nhttps://en.wikipedia.org/wiki/Tertiary_color\\n\\n<img src=\\"../models/palette.svg\\" width=\\"400\\" height=\\"400\\" />\\n","frontmatter":{"title":"Color names","description":"Know how to name any color of 12 equally spaced hues","date":"2021-08-01T00:00:00.000Z","cover":"/media_files/cover/theory-color-names-color-names.svg"},"url":"/theory/color/names/"},{"src":"---\\ntitle: Practice\\ndescription: Web apps for music education and independent research\\ndate: 2021-07-07\\ncover: soundtrap.jpg\\n---\\n\\nHere's a growing collection of free and open source interactive web experiences for everyone to explore. You can have a direct experience of natural patterns in [human sound perception](./sound/index.md) with just your laptop or a smartphone.\\n\\nWe are building tools for everyone to use in many ways. Some may consider them as toys, but there's much depth for diving yourself or with other musicians. There's huge value for visuals and non-musicians also. Chromatone enables us to see and understand multiple layers of music theory without advanced ear-training. And vice versa! Here we can learn and explore more about our [color perception](./color/index.md) and the multitude of models engineered to navigate the color space.\\n\\nMusic has many faces and it grows through a number of different modes of perception and comprehension. It's a multi-axis space that is build on the sensory and cognitive phenomena. One of the main is time. It gets quite emphasized with note durations and evolving [rhythmic structures](./rhythm/index.md) of organized [noise](./synth/noise/index.md). It demonstrates and utilizes our ability to recognize patterns in repetitions of sounds at frequency range between tens and thousands of events per minute. With higher oscillation speeds we get to a distinct mode of [pitch perception](./pitch/index.md).\\n\\nAll 12 pitch classes form the so called [Chroma](./chroma/index.md) space, where numerous combinations of notes combine to become intervals, [chords](./chord/index.md) and scales. We can interact with the notes via [MIDI](./midi/index.md) protocol commands, or build our own [experimental](./experiments/index.md) visual music tools. There are also some apps for [Jamming](./jam/index.md) together in harmony and in sync.\\n\\nAnd there's a ever growing collection of [external music web-apps](./external/index.md) found on the internet.\\n","frontmatter":{"title":"Practice","description":"Web apps for music education and independent research","date":"2021-07-07T00:00:00.000Z","cover":"/media_files/cover/practice-soundtrap.jpg"},"url":"/practice/"},{"src":"---\\ntitle: Academy\\ndescription: Research and study platform to provide collaborative online education experience for global community of Academy members\\nlayout: iframe\\ndate: 2021-07-05\\ncover: wes-hicks.jpg\\ntopContent: true\\niframe: https://academy.chromatone.center\\nbuttons:\\n  - url: \\"https://academy.chromatone.center/\\"\\n    text: \\"academy.chromatone.center\\"\\n---\\n\\n","frontmatter":{"title":"Academy","description":"Research and study platform to provide collaborative online education experience for global community of Academy members","layout":"iframe","date":"2021-07-05T00:00:00.000Z","cover":"/media_files/cover/academy-wes-hicks.jpg","topContent":true,"iframe":"https://academy.chromatone.center","buttons":[{"url":"https://academy.chromatone.center/","text":"academy.chromatone.center"}]},"url":"/academy/"},{"src":"---\\ntitle: Noise lab\\ndescription: As white light is the combination of all colors, the white noise is the combination of all possible notes\\nlayout: app\\ndate: 2021-06-22\\ncover: noise.jpg\\n---\\n\\n<client-only>\\n  <synth-noise />\\n</client-only >\\n\\n## Noise generation tool\\n\\nA simple tool to generate some noise. Let's look at the possibilities.\\n\\n1. The **noise generator** section\\n   1. You can start the noise by tapping the **NOISE** button at the top left. There's a latch in the bottom of this button to fix the noise playing. Click it again to unlatch the sound playing. The other way is to press **A** – the sound will play as long as you hold it.\\n   2. The **DRY** slider determines the volume of the initial noise source.\\n   3. Choose the type of the noise (it's 'color') between Brown, Pink and White.\\n      1. [White noise](https://en.wikipedia.org/wiki/White_noise) is a random signal having equal intensity at different frequencies, giving it a constant power spectral density.\\n      2. [Pink noise](https://en.wikipedia.org/wiki/Pink_noise) or 1⁄f noise is a signal or process with a frequency spectrum such that the power spectral density (power per frequency interval) is inversely proportional to the frequency of the signal. In pink noise, each octave interval (halving or doubling in frequency) carries an equal amount of noise energy. Pink noise is one of the most common signals in biological systems.\\n      3. The spectral density of the [Brown noise](https://en.wikipedia.org/wiki/Brownian_noise) is inversely proportional to f^2, meaning it has higher intensity at lower frequencies, even more so than pink noise. It decreases in intensity by 6 dB per octave (20 dB per decade) and, when heard, has a \\"damped\\" or \\"soft\\" quality compared to white and pink noise.\\n   4. Next is the **ADSR** controls group: drag **ATTACK**, **DECAY**, **SUSTAIN** and **RELEASE** sliders to adjust the signal envelope.\\n2. **Auto-filter** section. Press or latch the **FILTER** button to engage the filter. Change the FREQUENCY, OCTAVES and Q-FACTOR of the filter. Choose [LP](https://en.wikipedia.org/wiki/Low-pass_filter) (Low-Pass), [HP](https://en.wikipedia.org/wiki/High-pass_filter) (High-pass) or [BP](https://en.wikipedia.org/wiki/Band-pass_filter) (Band-pass) filter type. Then goes the **PLAY** button to turn on the LFO of the filter. **LFO** and **DEPTH** sliders set the swing of the filter and next you have the choise of the Low Frequency Oscillator.\\n3. A [**Bitcrusher**](https://en.wikipedia.org/wiki/Bitcrusher) is an audio effect that produces distortion by reducing of the resolution or bandwidth of digital audio data. The resulting quantization noise may produce a \\"warmer\\" sound impression, or a harsh one, depending on the amount of reduction. Set the volume of the bus, the **BITS** resolution and the **WET** parameter of how much of the signal should come through.\\n4. **Auto-panner** section makes the sound move from left to right with another LFO. Turn on the PAN to turn on the effect. Latch the PLAY button to make the panning move. **LFO** sets the frequency of the movement, **DEPTH** sets the amplitude of it.\\n","frontmatter":{"title":"Noise lab","description":"As white light is the combination of all colors, the white noise is the combination of all possible notes","layout":"app","date":"2021-06-22T00:00:00.000Z","cover":"/media_files/cover/practice-synth-noise-noise.jpg"},"url":"/practice/synth/noise/"},{"src":"---\\ntitle: Mode degrees\\ndescription: Chords of diatonic mode degrees\\ndate: 2021-06-10\\ncover: modes.png\\nlayout: app\\n---\\n\\n<script setup>\\n  import modes from '#/db/chord/modes.yaml'\\n<\/script>\\n\\n<chord-progressions :list=\\"modes\\" />\\n","frontmatter":{"title":"Mode degrees","description":"Chords of diatonic mode degrees","date":"2021-06-10T00:00:00.000Z","cover":"/media_files/cover/practice-chord-modes-modes.png","layout":"app"},"url":"/practice/chord/modes/"},{"src":"---\\ntitle: MIDI File visualizer\\ndescription: Render a MIDI-file to a colorful picture\\ndate: 2021-05-20\\nlayout: app\\ncover: midi-visual.svg\\n---\\n\\n\\n<client-only>\\n  <midi-visualizer />\\n</client-only>\\n","frontmatter":{"title":"MIDI File visualizer","description":"Render a MIDI-file to a colorful picture","date":"2021-05-20T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-midi-visualizer-midi-visual.svg"},"url":"/practice/midi/visualizer/"},{"src":"---\\ntitle: Profile\\ndescription: Get info for any possible chroma combination\\nlayout: app\\ndate: 2021-05-12\\ncover: profile.png\\n---\\n\\n<chroma-profile v-model:chroma=\\"chroma\\"  class=\\"m-2\\" :editable=\\"true\\" />\\n\\n<script setup>\\nimport {ref} from 'vue'\\nconst chroma = ref('100000010000')\\n<\/script>\\n","frontmatter":{"title":"Profile","description":"Get info for any possible chroma combination","layout":"app","date":"2021-05-12T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-profile-profile.png"},"url":"/practice/chroma/profile/"},{"src":"---\\ntitle: GPU shader with feedback\\ndescription: More interesting and chaotic shader setup\\ndate: 2021-04-22\\ncover: feedback.png\\nlayout: app\\n---\\n\\n\\n<client-only>\\n<GpuFeedback class=\\"min-h-70svh h-80svh\\" />\\n</client-only>\\n","frontmatter":{"title":"GPU shader with feedback","description":"More interesting and chaotic shader setup","date":"2021-04-22T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-shader-feedback-feedback.png","layout":"app"},"url":"/practice/chroma/shader/feedback/"},{"src":"---\\ntitle: GPU shader\\ndescription: A MIDI reactive GLSL shader as a direct visual mathematical interpretation of musical notes\\ndate: 2021-04-22\\ncover: shader.png\\nlayout: app\\ntopContent: true\\nlinks:\\n  - https://github.com/kongxiaojian123/vue-glsl#readme\\n  - https://registry.khronos.org/OpenGL-Refpages/gl4/index.php\\n  - https://iquilezles.org/articles/palettes/\\n  - https://thebookofshaders.com/\\n  - https://github.com/jamieowen/glsl-blend\\n  - https://www.shadertoy.com/view/4tSGWV\\n  - https://www.shadertoy.com/view/mtyGWy\\n---\\n\\n\\n<client-only>\\n<GpuShader class=\\"min-h-70svh h-80svh\\" />\\n</client-only>\\n\\nPitch Palette is an immersive digital artwork that leverages Denis Starov's Chromatone system to translate the aural into the visual. Incorporating a microphone to capture live ambient audio, the installation analyzes the sounds and assigns one of twelve unique colors to each of the twelve distinct pitch classes, effectively rendering a visual representation of the sound's frequency content on a screen. This innovative approach not only allows for the visualization of music but also creates a multisensory feedback loop, engaging both sight and hearing in a unified perceptual experience.\\n\\nThe artwork operates within the broader context of the Chromatone music web-apps ecosystem, which is designed to facilitate the study and appreciation of music through visual means. By interacting with Pitch Palette, participants influence the soundscape, thereby altering the visual output in real-time. This participatory element is key, transforming viewers into an integral part of the installation and inviting them to explore the symbiotic relationship between different senses and the environment. Through Pitch Palette, Starov extends an invitation to journey into a synesthetic space where sound and color intersect and are experienced in unison.\\n","frontmatter":{"title":"GPU shader","description":"A MIDI reactive GLSL shader as a direct visual mathematical interpretation of musical notes","date":"2021-04-22T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-shader-shader.png","layout":"app","topContent":true,"links":["https://github.com/kongxiaojian123/vue-glsl#readme","https://registry.khronos.org/OpenGL-Refpages/gl4/index.php","https://iquilezles.org/articles/palettes/","https://thebookofshaders.com/","https://github.com/jamieowen/glsl-blend","https://www.shadertoy.com/view/4tSGWV","https://www.shadertoy.com/view/mtyGWy"]},"url":"/practice/chroma/shader/"},{"src":"---\\ntitle: Compass\\ndescription: Explore any combination of 12 tone equal temperament pitches\\n\\ncover: compass.svg\\ndate: 2021-04-20\\nlayout: app\\n---\\n\\n\\n<client-only>\\n  <chroma-compass />\\n</client-only>\\n","frontmatter":{"title":"Compass","description":"Explore any combination of 12 tone equal temperament pitches","cover":"/media_files/cover/practice-chroma-compass-compass.svg","date":"2021-04-20T00:00:00.000Z","layout":"app"},"url":"/practice/chroma/compass/"},{"src":"---\\ntitle: Shop\\ndescription: Durable vinyl stickers for musical instruments and other printed and printable music theory memos\\ndate: 2021-04-20\\ntopContent: true\\nlayout: iframe\\ncover: shop.jpg\\niframe: https://shop.chromatone.center\\nbuttons:\\n  - url: \\"https://shop.chromatone.center/\\"\\n    text: \\"shop.chromatone.center\\"\\n---\\n","frontmatter":{"title":"Shop","description":"Durable vinyl stickers for musical instruments and other printed and printable music theory memos","date":"2021-04-20T00:00:00.000Z","topContent":true,"layout":"iframe","cover":"/media_files/cover/shop-shop.jpg","iframe":"https://shop.chromatone.center","buttons":[{"url":"https://shop.chromatone.center/","text":"shop.chromatone.center"}]},"url":"/shop/"},{"src":"---\\ntitle: Waveform\\ndescription: Visualization of the sum waveform of any chroma note combination\\nlayout: app\\ndate: 2021-04-12\\ncover: chromaform.png\\n---\\n\\n\\nChoose any of the notes to see the wavefrom of their combination.\\n\\n<client-only >\\n  <chroma-form />\\n</client-only>\\n","frontmatter":{"title":"Waveform","description":"Visualization of the sum waveform of any chroma note combination","layout":"app","date":"2021-04-12T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-waveform-chromaform.png"},"url":"/practice/chroma/waveform/"},{"src":"---\\ntitle: Synthesis\\ndescription: Ways to produce specific sounds\\ncover: adi-goldstein.jpg\\ndate: 2021-04-10\\n---\\n\\n## Resources\\n\\n- https://signalsmith-audio.co.uk/writing/2021/lets-write-a-reverb/\\n- https://ccrma.stanford.edu/~jos/\\n- https://jackschaedler.github.io/circles-sines-signals/\\n- https://www.soundonsound.com/synthesizers/synth-secrets\\n- https://www.theaudioprogrammer.com/\\n- https://www.dsprelated.com/\\n- https://www.earlevel.com/main/\\n- http://www.willpirkle.com/\\n- https://www.hackaudio.com/\\n- https://maxgraf.space/code/2020/04/22/e2e-piano-epiano.html\\n- https://maxgraf.space/code/2020/06/05/pitch-aware-granular-synth.html\\n- https://maxgraf.space/code/2020/06/05/karplus-strong-synth.html\\n- https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html\\n","frontmatter":{"title":"Synthesis","description":"Ways to produce specific sounds","cover":"/media_files/cover/practice-synth-adi-goldstein.jpg","date":"2021-04-10T00:00:00.000Z"},"url":"/practice/synth/"},{"src":"---\\ntitle: Fretboard calculator\\ndescription: A tool to get distances between frets for any scale length of any string instrument\\nlayout: app\\ndate: 2021-04-09\\ncover: fretboard.svg\\ninstruments:\\n  Guitar:\\n    l: 650\\n    frets: 18\\n    tuning: [E2, A2, D3, G3, B3, E4]\\n  Electric guitar:\\n    l: 630\\n    frets: 22\\n    tuning: [E2, A2, D3, G3, B3, E4]\\n  Bass guitar:\\n    l: 860\\n    frets: 24\\n    tuning: [E1, A1, D2, G2]\\n  Mandolin:\\n    l: 360\\n    frets: 14\\n    tuning: [G4, D4, A5, E5]\\n  Mandola:\\n    l: 510\\n    frets: 16\\n    tuning: [C3, G3, D4, A4]\\n  Octave mandolin:\\n    l: 580\\n    frets: 18\\n    tuning: [G3, D3, A4, E4]\\n  Mandocello:\\n    l: 686\\n    frets: 20\\n    tuning: [C2, G2, D3, A3]\\n  Pipa:\\n    l: 900\\n    frets: 17\\n    tuning: [A2, D3, E3, A3]\\n  Balalaika (prima):\\n    l: 660\\n    frets: 20\\n    tuning: [E4, E3, A4]\\n  Ukulele (soprano):\\n    l: 330\\n    frets: 14\\n    tuning: [G4, C4, E4, A4]\\n  Ukulele (concert):\\n    l: 380\\n    frets: 16\\n    tuning: [G4, C4, E4, A4]\\n  Ukulele (tenor):\\n    l: 430\\n    frets: 18\\n    tuning: [G3, C4, E4, A4]\\n  Ukulele (baritone):\\n    l: 480\\n    frets: 20\\n    tuning: [D3, G3, B3, E4]\\n  Ukulele (bass):\\n    l: 510\\n    frets: 17\\n    tuning: [E2, A2, D3, G3]\\n  Banjo:\\n    l: 670\\n    frets: 17\\n    tuning: [G4, D3, G3, B3, D4]\\n  Violin:\\n    l: 330\\n    frets: 1\\n    tuning: [G3, D4, A4, E5]\\n  Cello:\\n    l: 700\\n    frets: 1\\n    tuning: [C2, G2, D3, A3]\\n  Viola:\\n    l: 420\\n    frets: 1\\n    tuning: [C3, G3, D4, A4]\\n  Double bass:\\n    l: 1100\\n    frets: 1\\n    tuning: [E1, A1, D2, G2]\\n---\\n\\n<script setup>\\nimport fretboardTool from './tool.vue'\\n<\/script>\\n\\n<fretboard-tool :instruments=\\"$frontmatter.instruments\\" />\\n<save-svg svg=\\"fretboard\\" />\\n","frontmatter":{"title":"Fretboard calculator","description":"A tool to get distances between frets for any scale length of any string instrument","layout":"app","date":"2021-04-09T00:00:00.000Z","cover":"/media_files/cover/practice-experiments-fretboard-fretboard.svg","instruments":{"Guitar":{"l":650,"frets":18,"tuning":["E2","A2","D3","G3","B3","E4"]},"Electric guitar":{"l":630,"frets":22,"tuning":["E2","A2","D3","G3","B3","E4"]},"Bass guitar":{"l":860,"frets":24,"tuning":["E1","A1","D2","G2"]},"Mandolin":{"l":360,"frets":14,"tuning":["G4","D4","A5","E5"]},"Mandola":{"l":510,"frets":16,"tuning":["C3","G3","D4","A4"]},"Octave mandolin":{"l":580,"frets":18,"tuning":["G3","D3","A4","E4"]},"Mandocello":{"l":686,"frets":20,"tuning":["C2","G2","D3","A3"]},"Pipa":{"l":900,"frets":17,"tuning":["A2","D3","E3","A3"]},"Balalaika (prima)":{"l":660,"frets":20,"tuning":["E4","E3","A4"]},"Ukulele (soprano)":{"l":330,"frets":14,"tuning":["G4","C4","E4","A4"]},"Ukulele (concert)":{"l":380,"frets":16,"tuning":["G4","C4","E4","A4"]},"Ukulele (tenor)":{"l":430,"frets":18,"tuning":["G3","C4","E4","A4"]},"Ukulele (baritone)":{"l":480,"frets":20,"tuning":["D3","G3","B3","E4"]},"Ukulele (bass)":{"l":510,"frets":17,"tuning":["E2","A2","D3","G3"]},"Banjo":{"l":670,"frets":17,"tuning":["G4","D3","G3","B3","D4"]},"Violin":{"l":330,"frets":1,"tuning":["G3","D4","A4","E5"]},"Cello":{"l":700,"frets":1,"tuning":["C2","G2","D3","A3"]},"Viola":{"l":420,"frets":1,"tuning":["C3","G3","D4","A4"]},"Double bass":{"l":1100,"frets":1,"tuning":["E1","A1","D2","G2"]}}},"url":"/practice/experiments/fretboard/"},{"src":"---\\ntitle: Sequencing\\ndescription: Digital music composition\\ndate: 2021-04-09\\nlinks:\\n  - https://blog.native-instruments.com/what-is-a-sequencer-in-music/\\n---\\n\\n## Sequencing\\n\\n**Sequencing** is the stringing together of a precisely-timed sequence of commands to the computer to make sound.\\n\\nThe commands can be things like “play an audio sample” or “send a note-on command on this MIDI channel to this MIDI port” or “select the instrument for a MIDI channel”. In the old days, there was a clear distinction between sequencers, which knew how to record, edit and play back sequences of MIDI commands, but had no ability to record or play back sound on their own, and sound sources, which knew how to respond to MIDI commands by producing actual sound. These days, most applications can do at least something of both. \\n\\n## Sequencers\\n\\nA music sequencer is a tool that allows you to program and playback sequences of notes, rhythms, and effects automatically instead of performing or recording each part in real-time. Sequencers don’t generate their own sounds. Rather, they send MIDI and CV information to trigger other instruments or effect parameters.\\n\\nWhen programming a sequencer, you typically have control over several things: note/pitch, note length, pattern length, velocity, effect parameters and more. In other words, sequencers allow you to program a performance over a specified period of time.\\n\\nSequencers are at the core of modern electronic music production, with arrangements built from loops of sequenced drum beats and synthesizer patterns. They’re also useful as an accompaniment for live musicians.\\n\\nSequencers take many different forms, both in music sequencer hardware and music sequencer software. External instruments like a piano can be synced with a sequencer to keep everything locked to the same tempo, while computer DAWs take non-linear composition to expansive new levels. The most common sequencers music producers use today, however, are the DAW’s piano roll and step sequencers.\\n\\n## Web-apps\\n\\n[Ambient drone box](./ambience/index.md) is an experiment where simplex noise meets generative music.\\n\\n[Pendulums](./pendulums/index.md) are fun. Game like [Matter simulation](./matter/index.md) is even more fun. But orderly [Bouncers](./bounce/index.md) are a bit more pleasant to listen to. For weird vibes go for [Number sequences](./numbers/index.md) and English words sonification.","frontmatter":{"title":"Sequencing","description":"Digital music composition","date":"2021-04-09T00:00:00.000Z","links":["https://blog.native-instruments.com/what-is-a-sequencer-in-music/"]},"url":"/practice/sequencing/"},{"src":"---\\ntitle: Paper\\ndescription: A 8 channel MIDI visualization app, simulating drawing on a fading out virtual paper\\ncover: paper.png\\nlayout: app\\ndate: 2021-04-05\\niframe: https://paper.chromatone.center\\nbuttons:\\n  - url: https://paper.chromatone.center\\n    text: paper.chromatone.center\\n    type: primary\\n  - url: https://github.com/chromatone/midi-paper\\n    text: chromatone/midi-paper\\n    type: github\\n---\\n","frontmatter":{"title":"Paper","description":"A 8 channel MIDI visualization app, simulating drawing on a fading out virtual paper","cover":"/media_files/cover/practice-experiments-paper-paper.png","layout":"app","date":"2021-04-05T00:00:00.000Z","iframe":"https://paper.chromatone.center","buttons":[{"url":"https://paper.chromatone.center","text":"paper.chromatone.center","type":"primary"},{"url":"https://github.com/chromatone/midi-paper","text":"chromatone/midi-paper","type":"github"}]},"url":"/practice/experiments/paper/"},{"src":"---\\ntitle: Jam \\ndescription: A visual guide for collaborative music events\\ndate: 2021-03-30\\ntopContent: true\\ncover: hans-vivek.jpg\\n---\\n\\nApps for improvisational performances and casual jams. You can use our [Jam Session](./session/index.md) to display all the vital parameters of a session. Or put your device with [Jam Table](./table/index.md) app on the screen in front of your synths and players. Or press the Random button in [Random Jam](./random/index.md) app and play to a cleverly generated set of BPM, tonic note and a scale. We can add more for your need - feel free to [contact us](../../contacts/index.md).\\n","frontmatter":{"title":"Jam","description":"A visual guide for collaborative music events","date":"2021-03-30T00:00:00.000Z","topContent":true,"cover":"/media_files/cover/practice-jam-hans-vivek.jpg"},"url":"/practice/jam/"},{"src":"---\\ntitle: Jam session\\ndescription: A visual guide for collaborative music events\\ndate: 2021-03-30\\ntopContent: true\\ncover: cover.png\\nlayout: app\\n---\\n\\n\\n<client-only>\\n  <jam-session />\\n</client-only>\\n","frontmatter":{"title":"Jam session","description":"A visual guide for collaborative music events","date":"2021-03-30T00:00:00.000Z","topContent":true,"cover":"/media_files/cover/practice-jam-session-cover.png","layout":"app"},"url":"/practice/jam/session/"},{"src":"---\\ntitle: Sound laboratory\\ndescription: An modular web app to explore sound synthesis and processing right in the browser\\nlayout: app\\ncover: lab.jpg\\ndate: 2021-03-25\\niframe: https://lab.chromatone.center\\n---\\n\\n","frontmatter":{"title":"Sound laboratory","description":"An modular web app to explore sound synthesis and processing right in the browser","layout":"app","cover":"/media_files/cover/practice-experiments-lab-lab.jpg","date":"2021-03-25T00:00:00.000Z","iframe":"https://lab.chromatone.center"},"url":"/practice/experiments/lab/"},{"src":"---\\ntitle: Experiments\\ndescription: Standalone apps and external music resources\\n\\ndate: 2021-02-30\\ncover: experiments.png\\n---\\n\\nHere's our collection of various web music experiments built by us or other creators.\\n\\nHere's the universal [Fretboard calculator](./fretboard/index.md) that may help you build your own custom fretted string instrument with any given dimestions.\\n\\nWe haven't ported the fabulous [MIDI Paper](./paper/index.md) visualizer yet, but you may play with it standalone. The [Sound Laboratory](./lab/index.md) is another powerful standalone tool to explore basic sound synthesis and effect chains. Some even more old experiments are at [Dev](./dev/index.md).\\n","frontmatter":{"title":"Experiments","description":"Standalone apps and external music resources","date":"2021-03-02T00:00:00.000Z","cover":"/media_files/cover/practice-experiments-experiments.png"},"url":"/practice/experiments/"},{"src":"---\\ntitle: Support\\ndescription: Share links, contribute code or donate money to the open source development\\ndate: 2021-01-05\\ntopContent: true\\ncover: diego-catto.jpg\\nbuttons:\\n  - url: \\"https://instagram.com/chromatone.center\\"\\n    text: \\"@chromatone.center\\"\\n    type: instagram\\n  - url: \\"https://www.reddit.com/r/chromatone\\"\\n    text: r/chromatone\\n    type: reddit\\n  - url: \\"https://github.com/chromatone/\\"\\n    text: \\"GitHub Organisation\\"\\n    type: github\\n---\\n\\n<script setup>\\nimport map from '#/db/map.yml'\\nconst dots = map.cities.map(city=>city.coord)\\n<\/script>\\n\\n<map-globe class=\\"mb-8\\" :dots=\\"dots\\" />\\n\\nChromatone is an open source initiative made not to be a proprietary standard, but to become a wide spread language, used by musicians, visual artists along with music gear companies and app developers all over the world.\\n\\n## Follow and share\\n\\nWe have a subreddit to hang around and an Instagram account to tag in your posts. And it's important to let more people join the growing community of visual musicians. So follow us and spread the word about Chromatone through your social media and beyond.\\n\\n<!-- <a href=\\"https://www.producthunt.com/posts/chromatone?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-chromatone\\" target=\\"_blank\\"><img src=\\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=381642&theme=neutral\\" alt=\\"Chromatone - Visual&#0032;music&#0032;language&#0032;to&#0032;learn&#0044;&#0160;explore&#0032;and&#0032;express&#0032;with | Product Hunt\\" style=\\"width: 250px; height: 54px;\\" width=\\"250\\" height=\\"54\\" /></a> -->\\n\\n- [instagram.com/chromatone.center](https://instagram.com/chromatone.center/)\\n- [reddit.com/r/chromatone](https://reddit.com/r/chromatone)\\n\\nWe are those, who learn, teach, explore and produce music with help of the new clean visual language. And it's getting better with every contribution. Say hi and someone will reply. Everything starts from the first step. More to build together!\\n\\n## Contribute code\\n\\nIf you're a designer, JS developer, audio analysis library or know how else the site may be better - contribute code to our open [GitHub repository](https://github.com/chromatone). Or at least press that star button in the right top corner.\\n\\n## Give us a star\\n\\nIn future the project will grow big enough to become an Open Collective to be transparent about all the funding and expenses. We need to have at least 100 stars at [the repository on GitHub](https://github.com/chromatone/chromatone.center). Let's do it!\\n\\n[![Star History Chart](https://api.star-history.com/svg?repos=chromatone/chromatone.center&type=Date)](https://star-history.com/#chromatone/chromatone.center&Date)\\n","frontmatter":{"title":"Support","description":"Share links, contribute code or donate money to the open source development","date":"2021-01-05T00:00:00.000Z","topContent":true,"cover":"/media_files/cover/support-diego-catto.jpg","buttons":[{"url":"https://instagram.com/chromatone.center","text":"@chromatone.center","type":"instagram"},{"url":"https://www.reddit.com/r/chromatone","text":"r/chromatone","type":"reddit"},{"url":"https://github.com/chromatone/","text":"GitHub Organisation","type":"github"}]},"url":"/support/"},{"src":"---\\ntitle: Contacts\\ndescription: The project and it's author\\ndate: 2021-01-01\\ncover: javier-balseiro.jpg\\norg:\\n  avatar: /media/logo/smooth.svg\\n  name: Chromatone center\\n  pos: HQ\\n  place: Since 2017\\n  about:\\n  social:\\n    instagram: chromatone.center\\n    email: support@chromatone.center\\n    github: chromatone\\n    reddit: r/chromatone\\nauthor:\\n  avatar: /img/starov.jpg\\n  name: Denis Starov\\n  pos: Founder, designer and developer\\n  place: Born in 1987 and dwelling\\n  about: I'm a broad range designer and enthusiastic open source developer. So I explore music with the web browser. And share my experiments and explorations with everyone here.\\n  social:\\n    instagram: starov\\n    telegram: starov\\n    email: davay@chromatone.center\\n    github: davay42\\ntopContent: true\\n---\\n\\n<script setup>\\nimport { useData } from 'vitepress'\\nconst { frontmatter: f } = useData()\\n<\/script>\\n\\n<author-card :author=\\"f?.org\\"  />\\n\\nChromatone is a self sustaining ecosystem of music learners, music teachers and new tools to learn, practice, compose and perform music visually. The source code for them is open and is developed as an internationally funded social initiative.\\n\\nOur mission is to build a complete visual music ecosystem built by international community of learners, teachers and performers. With open music labs as the new form of real time creative collaboration.\\n\\nThe stickers and printable files sales bring fuel to feed the research and development process. Charity funding is very welcome! We are building a whole language here - and the wider we can reach and share the joy of playing Visual Music together. ✨\\n\\n<author-card :author=\\"f?.author\\" />\\n","frontmatter":{"title":"Contacts","description":"The project and it's author","date":"2021-01-01T00:00:00.000Z","cover":"/media_files/cover/contacts-javier-balseiro.jpg","org":{"avatar":"/media/logo/smooth.svg","name":"Chromatone center","pos":"HQ","place":"Since 2017","about":null,"social":{"instagram":"chromatone.center","email":"support@chromatone.center","github":"chromatone","reddit":"r/chromatone"}},"author":{"avatar":"/img/starov.jpg","name":"Denis Starov","pos":"Founder, designer and developer","place":"Born in 1987 and dwelling","about":"I'm a broad range designer and enthusiastic open source developer. So I explore music with the web browser. And share my experiments and explorations with everyone here.","social":{"instagram":"starov","telegram":"starov","email":"davay@chromatone.center","github":"davay42"}},"topContent":true},"url":"/contacts/"},{"src":"---\\ntitle: Chromatic hands\\ndescription: A way to connect musical notes, colors and your own body and consciousness.\\ndate: 2020-10-13\\ncover: hands.png\\nlayout: app\\n---\\n\\n<div class=\\"flex\\">\\n<ChromaHand v-for=\\"right in [false,true]\\" :style=\\"{transform: right?\`translateX(0px) scaleX(-100%) \` : ''}\\" :right=\\"right\\" />\\n</div>\\n","frontmatter":{"title":"Chromatic hands","description":"A way to connect musical notes, colors and your own body and consciousness.","date":"2020-10-13T00:00:00.000Z","cover":"/media_files/cover/practice-chroma-hand-hands.png","layout":"app"},"url":"/practice/chroma/hand/"},{"src":"---\\ntitle: Color palette generator\\ndescription: Poline and other tools by meodai\\ndate: 2020-08-12\\ncover: cover.png\\nlayout: app\\nlinks:\\n  - https://meodai.github.io/poline/\\n  - https://github.com/meodai/poline\\n  - https://codepen.io/meodai/pen/pXNpXe\\n  - https://codepen.io/meodai/pen/xWNNwN\\n  - https://github.com/meodai/color-names\\n---\\n\\n<client-only>\\n\\n  <color-palette id=\\"palette\\" class=\\"max-w-60ch m-2\\" />\\n  <div class=\\"my-4  max-w-90 transform\\">\\n    <save-svg class=\\"\\" svg=\\"palette\\" />\\n  </div>\\n\\n</client-only>\\n\\n- Drag top and bottom rectangles to change Hue, Saturation and Lightness of both start and end colors of your palette.\\n- Drag the list of steps to change the number of steps in your palette\\n","frontmatter":{"title":"Color palette generator","description":"Poline and other tools by meodai","date":"2020-08-12T00:00:00.000Z","cover":"/media_files/cover/practice-color-palette-cover.png","layout":"app","links":["https://meodai.github.io/poline/","https://github.com/meodai/poline","https://codepen.io/meodai/pen/pXNpXe","https://codepen.io/meodai/pen/xWNNwN","https://github.com/meodai/color-names"]},"url":"/practice/color/palette/"},{"src":"---\\ntitle: Printables\\ndescription: Hand crafted PDF files for you to print locally\\ndate: 2020-08-10\\ncover: bank-phrom.jpg\\ntopContent: true\\n---\\n\\nNew way to enjoy Chromatone yourself and share with friends, even offline. Printable PDF cheat-sheets and posters are a growing collection of digital goods, that will be made available in upcoming weeks and months.\\n\\nThe main thing about these files is that they will be evolving with time and we will be able to send updates to previous customers as well as immediately give every new customer to receive the most recent and refined file to print.\\n\\nThe purpose of these pages are to become a guide and helper in a long and sometimes difficult journey into deep understanding and creative exploration of music. With just one sheet of paper you can\\n","frontmatter":{"title":"Printables","description":"Hand crafted PDF files for you to print locally","date":"2020-08-10T00:00:00.000Z","cover":"/media_files/cover/practice-experiments-printables-bank-phrom.jpg","topContent":true},"url":"/practice/experiments/printables/"},{"src":"---\\ntitle: Scale chords\\ndescription: Find all available chords for all degrees of any scale\\ndate: 2020-06-15\\nlayout: app\\n---\\n\\n<control-scale />\\n<chord-scales />\\n\\n## How to use it\\n\\n1. Select a scale from the drop down menu.\\n2. Select a tonic pitch with the top keyboard.\\n3. Get lists of chords fit for each degree of the scale.\\n4. Play a chord by pressing it's block.\\n","frontmatter":{"title":"Scale chords","description":"Find all available chords for all degrees of any scale","date":"2020-06-15T00:00:00.000Z","layout":"app"},"url":"/practice/chord/scales/"},{"src":"---\\ntitle: Dev experiments\\ndescription: The playground for the color music theory education and exploration apps\\ndate: 2020-02-04\\n---\\n\\n## All dev experiments list\\n\\n- Circle of tones\\n  https://circle.chromatone.center/\\n  https://github.com/chromatone/circle-of-tones\\n- Tonal array\\n  https://array.chromatone.center/\\n  https://github.com/chromatone/tonal-array\\n- Dev\\n  https://dev.chromatone.center/\\n  https://github.com/chromatone/apps\\n- Jam\\n  https://jam.chromatone.center/\\n  https://github.com/chromatone/jam-session\\n- Lab\\n  https://lab.chromatone.center/\\n  https://github.com/chromatone/chromatone-lab\\n- MIDI-monitor\\n  https://midi.chromatone.center/\\n  https://github.com/chromatone/midi-monitor\\n- Noise lab\\n  https://noise.chromatone.center/\\n  https://github.com/chromatone/noise-lab\\n- Paper\\n  https://paper.chromatone.center/\\n  https://github.com/chromatone/midi-paper\\n- See Chroma\\n  https://see.chromatone.center/\\n  https://github.com/chromatone/see.chromatone.center\\n- Pitch table\\n  https://table.chromatone.center/\\n  https://github.com/chromatone/pitch-table\\n- TouchMe\\n  https://touchme.chromatone.center/\\n  https://github.com/chromatone/touchme\\n- Trombone\\n  https://trombone.chromatone.center/#/\\n  https://github.com/chromatone/pink-trombone\\n- Tuner\\n  https://tuner.chromatone.center/#/\\n  https://github.com/chromatone/tuner\\n- Tunings\\n  https://tunings.chromatone.center\\n  https://github.com/chromatone/svg-tunings\\n","frontmatter":{"title":"Dev experiments","description":"The playground for the color music theory education and exploration apps","date":"2020-02-04T00:00:00.000Z"},"url":"/practice/experiments/dev/"},{"src":"---\\ntitle: MIDI Rows\\ndescription: Measurewise MIDI recorder\\ndate: 2020-02-02\\nlayout: app\\n---\\n\\n<client-only>\\n<MidiRows/>\\n</client-only>\\n","frontmatter":{"title":"MIDI Rows","description":"Measurewise MIDI recorder","date":"2020-02-02T00:00:00.000Z","layout":"app"},"url":"/practice/experiments/rows/"},{"src":"---\\ntitle: Microphone audio analysis\\ndescription: Use any mic or audio input device and see some valuable data extracted from it\\ndate: 2019-11-03\\ncover: mic-app.png\\nlayout: app\\n---\\n\\n<client-only>\\n<AudioInputMic class=\\"m-2\\" />\\n<AudioAnalysisFFT  class=\\"m-2\\" />\\n</client-only>\\n","frontmatter":{"title":"Microphone audio analysis","description":"Use any mic or audio input device and see some valuable data extracted from it","date":"2019-11-03T00:00:00.000Z","cover":"/media_files/cover/practice-sound-mic-mic-app.png","layout":"app"},"url":"/practice/sound/mic/"},{"src":"---\\ntitle: Drum machine\\ndescription: Simple drum sequencer with synthesized sounds\\ndate: 2019-11-02\\nlayout: app\\n---\\n\\n<client-only>\\n<audio-drums-sequencer class=\\"m-2\\" />\\n</client-only>\\n\\nVery basic drum machine made with Elementary.js. All sounds are synthesized by low level sound engine commands and run in independent Web Audio and WASM threads, ensuring high quality and no glitches in the sound.\\n\\n## TODO\\n\\n- sync with musical transport\\n","frontmatter":{"title":"Drum machine","description":"Simple drum sequencer with synthesized sounds","date":"2019-11-02T00:00:00.000Z","layout":"app"},"url":"/practice/rhythm/drum-machine/"},{"src":"---\\ntitle: Musical transport\\ndescription: How we subdivide time to have a rhythm\\ndate: 2018-10-30\\nlayout: app\\ncover: cover.png\\nlinks: https://discord.com/channels/826071713426178078/834787928688689172/1127958693695205387\\n---\\n\\n\\n<client-only>\\n<AudioTimeMath />\\n</client-only>\\n","frontmatter":{"title":"Musical transport","description":"How we subdivide time to have a rhythm","date":"2018-10-30T00:00:00.000Z","layout":"app","cover":"/media_files/cover/practice-rhythm-time-cover.png","links":"https://discord.com/channels/826071713426178078/834787928688689172/1127958693695205387"},"url":"/practice/rhythm/time/"},{"src":"---\\ntitle: External tools\\ndescription: There's a plenty of opportunities to dive into different aspects of music theory and practice online\\ncover: other.png\\ndate: 2018-09-08\\n---\\n\\n<script setup>\\nimport { data } from '#/data/tools.data'\\n<\/script>\\n\\n<ToolsList :data=\\"data\\" />\\n","frontmatter":{"title":"External tools","description":"There's a plenty of opportunities to dive into different aspects of music theory and practice online","cover":"/media_files/cover/practice-external-other.png","date":"2018-09-08T00:00:00.000Z"},"url":"/practice/external/"},{"src":"---\\ntitle: AMY synth\\ndescription: Wasm synth playground\\ndate: 2013-03-05\\ncover: dx7_algorithms.jpg\\nlayout: app\\n---\\n\\n## AMY Synth\\n\\n### the Additive Music synthesizer librarY\\n\\nHighly experimental. [Issue pending](https://github.com/bwhitman/amy/issues/35)\\n\\n<client-only>\\n<SynthAmy />\\n</client-only>\\n\\n- Press \`A\` on your keyboard to play a note. Or push the PLAY button.\\n- Use <i class=\\"p-3 i-la-arrow-left\\"></i> and <i class=\\"p-3 i-la-arrow-right\\"></i> keys to browse patches\\n\\n[AMY repository](https://github.com/bwhitman/amy)\\n\\nAMY accepts commands in ASCII, like so:\\n\\n# v0w4f440.0l0.9\\n\\nHere's the full list:\\n\\n| Code | Python      | Type-range        | Notes                                                                                                                                                                       |\\n| ---- | ----------- | ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| a    | amp         | float 0-1+        | use after a note on is triggered with velocity to adjust amplitude without re-triggering the note                                                                           |\\n| A    | bp0         | string            | in commas, like 100,0.5,150,0.25,200,0 -- envelope generator with alternating time(ms) and ratio. last pair triggers on note off                                            |\\n| B    | bp1         | string            | set the second breakpoint generator. see breakpoint 0                                                                                                                       |\\n| b    | feedback    | float 0-1         | use for the ALGO synthesis type in FM, or partial synthesis (for bandwidth) or for karplus-strong, or to indicate PCM looping (0 off, >0, on)                               |\\n| C    | bp2         | string            | 3rd breakpoint generator                                                                                                                                                    |\\n| d    | duty        | float 0.001-0.999 | duty cycle for pulse wave, default 0.5                                                                                                                                      |\\n| D    | debug       | uint, 2-4         | 2 shows queue sample, 3 shows oscillator data, 4 shows modified oscillator. will interrupt audio!                                                                           |\\n| f    | freq        | float             | frequency of oscillator                                                                                                                                                     |\\n| F    | filter_freq | float             | center frequency for biquad filter                                                                                                                                          |\\n| g    | mod_target  | uint mask         | Which parameter modulation/LFO controls. 1=amp, 2=duty, 4=freq, 8=filter freq, 16=resonance, 32=feedback. Can handle any combo, add them together                           |\\n| G    | filter_type | 0-3               | 0 = none (default.) 1 = low pass, 2 = band pass, 3 = hi pass.                                                                                                               |\\n| I    | ratio       | float             | for ALGO types, where the base note frequency controls the modulators, or for the ALGO base note and PARTIALS base note, where the ratio controls the speed of the playback |\\n| L    | mod_source  | 0 to OSCS-1       | Which oscillator is used as an modulation/LFO source for this oscillator. Source oscillator will be silent.                                                                 |\\n| l    | vel         | float 0-1+        | velocity - >0 to trigger note on, 0 to trigger note off. sets amplitude                                                                                                     |\\n| N    | latency_ms  | uint              | sets latency in ms. default 0                                                                                                                                               |\\n| n    | note        | uint 0-127        | midi note, sets frequency                                                                                                                                                   |\\n| o    | algorithm   | uint 1-32         | DX7 algorith to use for ALGO type                                                                                                                                           |\\n| O    | algo_source | string            | which oscillators to use for the algorithm. list of six, use -1 for not used, e.g 0,1,2,-1,-1-1                                                                             |\\n| p    | patch       | uint              | choose a preloaded PCM sample, partial patch or FM patch number for ALGO waveforms.                                                                                         |\\n| P    | phase       | float 0-1         | where in the oscillator's cycle to start sampling from (also works on the PCM buffer). default 0                                                                            |\\n| R    | resonance   | float             | q factor of biquad filter. in practice, 0-10.0. default 0.7                                                                                                                 |\\n| S    | reset       | uint              | resets given oscillator. set to > OSCS to reset all oscillators, gain and EQ                                                                                                |\\n| T    | bp0_target  | uint mask         | Which parameter bp0 controls. 1=amp, 2=duty, 4=freq, 8=filter freq, 16=resonance, 32=feedback (can be added together). Can add 64 for linear ramp, otherwise exponential    |\\n| t    | timestamp   | uint              | ms of expected playback since some fixed start point on your host. you should always give this if you can.                                                                  |\\n| v    | osc         | uint 0 to OSCS-1  | which oscillator to control                                                                                                                                                 |\\n| V    | volume      | float 0-10        | volume knob for entire synth, default 1.0                                                                                                                                   |\\n| w    | wave        | uint 0-11         | waveform: [0=SINE, PULSE, SAW_DOWN, SAW_UP, TRIANGLE, NOISE, KS, PCM, ALGO, PARTIAL, PARTIALS, OFF]. default: 0/SINE                                                        |\\n| W    | bp1_target  | uint mask         | see bp0_target                                                                                                                                                              |\\n| x    | eq_l        | float             | in dB, fc=800Hz amount, -15 to 15. 0 is off. default 0.                                                                                                                     |\\n| X    | bp2_target  | uint mask         | see bp0_target                                                                                                                                                              |\\n| y    | eq_m        | float             | in dB, fc=2500Hz amount, -15 to 15. 0 is off. default 0.                                                                                                                    |\\n| z    | eq_h        | float             | in dB, fc=7500Hz amount, -15 to 15. 0 is off. default 0.                                                                                                                    |\\n","frontmatter":{"title":"AMY synth","description":"Wasm synth playground","date":"2013-03-05T00:00:00.000Z","cover":"/media_files/cover/practice-synth-amy-dx7_algorithms.jpg","layout":"app"},"url":"/practice/synth/amy/"},{"src":"---\\ntitle: ChucK\\ndescription: Music programming language\\ndate: 2012-05-23\\ncover: ch.png\\nlayout: app\\n---\\n\\n## Strongly-timed | Concurrent | On-the-fly\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst WebChuck = defineClientComponent(() => {\\n  return import('../../../../components/synth/chuck/SynthChuck.vue')\\n})\\n<\/script>\\n\\n<client-only>\\n<WebChuck/>\\n</client-only>\\n\\nChucK is a programming language for real-time sound synthesis and music creation. ChucK offers a unique **time-based, concurrent programming model** that is precise and expressive (we call this **strongly-timed**), dynamic control rates, and the ability to add and modify code **on-the-fly**. In addition, ChucK supports MIDI, OpenSoundControl, HID device, and multi-channel audio. It is open-source and freely available on macOS, Windows, and Linux. It's fun and easy to learn, and offers composers, researchers, and performers a powerful programming tool for building and experimenting with complex audio synthesis/analysis programs, and real-time interactive music.\\n\\n### Links\\n\\n- <https://chuck.stanford.edu/>\\n- <https://chuck.stanford.edu/ide/#>\\n- <https://chuck.stanford.edu/doc/examples/>\\n- <https://artful.design/stuff/samples/chuck.pdf>\\n- <https://github.com/ccrma/webchuck>\\n- <https://github.com/ccrma/webchuck/blob/main/docs/classes/Chuck.md>\\n\\n<youtube-embed video=\\"2rpk461T6l4\\"/>\\n","frontmatter":{"title":"ChucK","description":"Music programming language","date":"2012-05-23T00:00:00.000Z","cover":"/media_files/cover/practice-synth-chuck-ch.png","layout":"app"},"url":"/practice/synth/chuck/"},{"src":"---\\ntitle: MIDI color mixing\\ndescription: Full screen colors react to midi notes to explore the cross stimulation of the brain\\ndate: 2011-04-05\\ncover: milad-fakurian.jpg\\nlayout: app\\n---\\n\\n\\n<client-only>\\n\\n  <color-mix />\\n\\n</client-only>\\n\\nPress any key on your keyboard to hear a note and to see the corresponding color. Go fullscreen with the button at the top right.\\n","frontmatter":{"title":"MIDI color mixing","description":"Full screen colors react to midi notes to explore the cross stimulation of the brain","date":"2011-04-05T00:00:00.000Z","cover":"/media_files/cover/practice-color-mix-milad-fakurian.jpg","layout":"app"},"url":"/practice/color/mix/"},{"src":"---\\ntitle: Elementary Refs\\ndescription: Implementing the new rendering technique for Elementary 3\\ndate: 2010-11-07\\n---\\n\\n<client-only>\\n<AudioElemRef />\\n</client-only>\\n\\n## Links\\n\\n- https://www.elementary.audio/docs/guides/using_refs\\n","frontmatter":{"title":"Elementary Refs","description":"Implementing the new rendering technique for Elementary 3","date":"2010-11-07T00:00:00.000Z"},"url":"/practice/experiments/ref-synth/"},{"src":"---\\ntitle: Drum rudiments\\ndescription: Interactive database of all 40 stardard drum rudiments\\ndate: 2003-09-07\\ncover: daniel-shapiro.jpg\\nlayout: app\\n---\\n\\n<RhythmDrumRudiments />\\n","frontmatter":{"title":"Drum rudiments","description":"Interactive database of all 40 stardard drum rudiments","date":"2003-09-07T00:00:00.000Z","cover":"/media_files/cover/practice-rhythm-rudiments-daniel-shapiro.jpg","layout":"app"},"url":"/practice/rhythm/rudiments/"},{"src":"---\\ntitle: Wheels\\ndescription: Clockwise motion, but with fixed hands\\ndate: 1987-06-30\\nlayout: app\\n---\\n\\n<client-only>\\n<RhythmWheels />\\n</client-only>\\n","frontmatter":{"title":"Wheels","description":"Clockwise motion, but with fixed hands","date":"1987-06-30T00:00:00.000Z","layout":"app"},"url":"/practice/rhythm/wheel/"},{"src":"---\\ntitle: Words sequencing\\ndesctiption: Decomposing words into riffs and melodies\\ndata: 2024-06-21\\nlayout: app\\nlinks:\\n  - https://github.com/words/similar-english-words?tab=readme-ov-file\\n  - https://github.com/words/an-array-of-english-words?tab=readme-ov-file\\n---\\n\\n\\n<script setup>\\nimport { defineClientComponent } from 'vitepress'\\n\\nconst Words = defineClientComponent(() => {\\n  return import('./Words.vue')\\n})\\n<\/script>\\n\\n<Words/>","frontmatter":{"title":"Words sequencing","desctiption":"Decomposing words into riffs and melodies","data":"2024-06-21T00:00:00.000Z","layout":"app","links":["https://github.com/words/similar-english-words?tab=readme-ov-file","https://github.com/words/an-array-of-english-words?tab=readme-ov-file"]},"url":"/practice/sequencing/words/"},{"src":"---\\ntitle: Visual Music & the Poetics of Synaesthesia\\ndescription: by Michael Filimowicz, PhD\\ndate: 2024-06-20\\ncover: cover.webp\\n---\\n\\nVisual Music and Audiovisual Aesthetics\\n=======================================\\n\\n<youtube-embed video=\\"jQCEXWjitsA\\" />\\n\\nVisual Music & the Poetics of Synaesthesia\\n==========================================\\n\\n**Poetics** in the context of this essay refers broadly to ‘principles of making’ and by extension, general design principles. The origins of poetics was with Aristotle’s _Poetics_ which analyzed literary-theatrical narratives, but today the scope of poetics is much wider and can cover any media- and meaning-making terrain where patterns of making can be formally analyzed.\\n\\n> For most of its long history, the term **poetics** subsumed attempts to reveal the inner [logic](http://csmt.uchicago.edu/glossary2004/logic.htm) of a work of art in an examination of its formal and constituent features while inevitably raising problems of intention, meaning, and interpretation.\\n> \\n> With the advent of new technologies and an increasing differentiation of media, the medium of [print](http://csmt.uchicago.edu/glossary2004/typeprint.htm) has lost some of its status while other technologies vie for acceptance alongside it. Accordingly, in critical [discourse](http://csmt.uchicago.edu/glossary2004/discourse.htm), new media studies have gained ascendancy over poetics. Poetics, broadly understood, takes as its subject matter a hermeneutic process productive of meaning and responsive to [communication](http://csmt.uchicago.edu/glossary2004/communication.htm), even where this process is intentionally made difficult for artistic purposes, a view that has been hotly contested as a result of the emergence of new technologies ([source](https://lucian.uchicago.edu/blogs/mediatheory/keywords/poetics/)).\\n\\nVisual music predates the contemporary concept of the music video by at least half a millennia, depending on how one qualifies it. Most historical commentary on visual music finds an origin point in the Medieval color organ, which is the earliest known technological precursor to today’s iTunes Visualizer. Many commentators, however, do not go so far back, and relate visual music to early 20th Century trends in Modernism. In today’s maker culture, there is often a lack of deep historical sense and context. At the start of the first video embed below, an Arduino-tinkerer claims that the color organ originated in the 1970s (!) when there was a genre of music-light interactive consumer novelties that were also called color organs. Here is what Wikipedia has to say about color organs (all Wikipedia links will be left in place in case you want to explore more):\\n\\n> The term **color organ** refers to a tradition of mechanical devices built to represent sound and accompany music in a visual medium. The earliest created color organs were manual instruments based on the harpsichord design. By the 1900s they were electromechanical. In the early 20th century, a silent color organ tradition (Lumia) developed. In the 1960s and ’70s, the term “color organ” became popularly associated with electronic devices that responded to their music inputs with [light shows](https://en.wikipedia.org/wiki/Liquid_light_show). The term “[light organ](https://en.wikipedia.org/wiki/Light_organ)” is increasingly being used for these devices; allowing “color organ” to reassume its original meaning.\\n> \\n> The dream of creating a visual music comparable to auditory music found its fulfillment in animated abstract films by artists such as [Oskar Fischinger](https://en.wikipedia.org/wiki/Oskar_Fischinger), [Len Lye](https://en.wikipedia.org/wiki/Len_Lye) and [Norman McLaren](https://en.wikipedia.org/wiki/Norman_McLaren); but long before them, many people built instruments, usually called “color organs,” that would display modulated colored light in some kind of fluid fashion comparable to music.\\n> \\n> — [William Moritz](https://en.wikipedia.org/wiki/William_Moritz)\\n> \\n> In 1590, Gregorio Comanini described an invention by the [Mannerist](https://en.wikipedia.org/wiki/Mannerist) painter [Arcimboldo](https://en.wikipedia.org/wiki/Arcimboldo) of a system for creating color-music, based on apparent luminosity (light-dark contrast) instead of hue.\\n> \\n> In 1725, French Jesuit monk [Louis Bertrand Castel](https://en.wikipedia.org/wiki/Louis_Bertrand_Castel) proposed the idea of _Clavecin pour les yeux_ (_Ocular Harpsichord_). In the 1740s, German composer [Telemann](https://en.wikipedia.org/wiki/Georg_Philipp_Telemann) went to [France](https://en.wikipedia.org/wiki/France) to see it, composed some pieces for it and wrote a book about it. It had 60 small colored glass panes, each with a curtain that opened when a key was struck. In about 1742, Castel proposed the _clavecin oculaire_ (a light organ) as an instrument to produce both sound and the ‘proper’ light colors.\\n>\\n\\n![organ](./organ.webp)\\n\\nCastel’s Ocular Organ, [Source](https://en.wikipedia.org/wiki/Color_organ#/media/File:A_caricature_of_Louis-Bertrand_Castel's_%22ocular_organ%22.jpg). A caricature of Louis-Bertrand Castel’s “ocular organ” by [Charles Germain de Saint Aubin](https://en.wikipedia.org/wiki/Charles_Germain_de_Saint_Aubin)\\n\\n> In 1743, Johann Gottlob Krüger, a professor at the University of Hall, proposed his own version of the ocular harpsichord.\\n> \\n> In 1816, [Sir David Brewster](https://en.wikipedia.org/wiki/Sir_David_Brewster) proposed the [Kaleidoscope](https://en.wikipedia.org/wiki/Kaleidoscope) as a form of visual-music that became immediately popular.\\n> \\n> In 1877, US artist, inventor [Bainbridge Bishop](https://en.wikipedia.org/w/index.php?title=Bainbridge_Bishop&action=edit&redlink=1) gets a patent for his first Color Organ.The instruments were lighted attachments designed for pipe organs that could project colored lights onto a screen in synchronization with musical performance. Bishop built three of the instruments; each was destroyed in a fire, including one in the home of [P. T. Barnum](https://en.wikipedia.org/wiki/P._T._Barnum).\\n> \\n> In 1893, British painter [Alexander Wallace Rimington](https://en.wikipedia.org/wiki/Alexander_Wallace_Rimington) invented the [Clavier à lumières](https://en.wikipedia.org/wiki/Clavier_%C3%A0_lumi%C3%A8res). Rimington’s _Colour Organ_ attracted much attention, including that of [Richard Wagner](https://en.wikipedia.org/wiki/Richard_Wagner) and Sir [George Grove](https://en.wikipedia.org/wiki/George_Grove). It has been incorrectly claimed that his device formed the basis of the moving lights that accompanied the [New York City](https://en.wikipedia.org/wiki/New_York_City) premiere of [Alexander Scriabin](https://en.wikipedia.org/wiki/Alexander_Scriabin)’s [synaesthetic](https://en.wikipedia.org/wiki/Synesthesia) symphony [_Prometheus: The Poem of Fire_](https://en.wikipedia.org/wiki/Prometheus:_Poem_of_Fire) in 1915. The instrument that accompanied that premiere was lighting engineer Preston S. Millar’s chromola, which was similar to Rimington’s instrument.\\n> \\n> In a 1916 [art manifesto](https://en.wikipedia.org/wiki/Art_manifesto), the Italian Futurists [Arnaldo Ginna](https://en.wikipedia.org/wiki/Arnaldo_Ginna) and [Bruno Corra](https://en.wikipedia.org/wiki/Bruno_Corra) described their experiments with “color organ” projection in 1909. They also painted nine abstract films, now lost….\\n> \\n> In 1918, American concert pianist [Mary Hallock-Greenewalt](https://en.wikipedia.org/wiki/Mary_Hallock-Greenewalt) created an instrument she called the [_Sarabet_](https://en.wikipedia.org/wiki/Sarabet). Also an inventor, she patented nine inventions related to her instrument, including the [rheostat](https://en.wikipedia.org/wiki/Rheostat).\\n> \\n> In 1921, Arthur C. Vinageras proposed the _Chromopiano,_ an instrument resembling and played like a grand piano, but designed to project “chords” composed from colored lights.\\n> \\n> In the 1920s, Danish-born [Thomas Wilfred](https://en.wikipedia.org/wiki/Thomas_Wilfred) created the _Clavilux,_ a color organ, ultimately patenting seven versions. By 1930, he had produced 16 “Home Clavilux” units. Glass disks bearing art were sold with these “Clavilux Juniors.” Wilfred coined the word [_lumia_](https://en.wikipedia.org/wiki/Lumia_(art)) to describe the art. Significantly, Wilfred’s instruments were designed to project colored imagery, not just fields of colored light as with earlier instruments.\\n> \\n> In 1925, Hungarian composer [Alexander Laszlo](https://en.wikipedia.org/wiki/Alexander_Laszlo_(composer)) wrote a text called _Color-Light-Music_ ; Laszlo toured Europe with a color organ.\\n> \\n> In [Hamburg](https://en.wikipedia.org/wiki/Hamburg), Germany from the late 1920s–early 1930s, several color organs were demonstrated at a series of Colour-Sound Congresses (German:_Kongreß für Farbe-Ton-Forschung_).[Ludwig Hirschfeld Mack](https://en.wikipedia.org/wiki/Ludwig_Hirschfeld_Mack) performed his Farbenlichtspiel colour organ at these congresses and at several other festivals and events in Germany. He had developed this color organ at the [Bauhaus](https://en.wikipedia.org/wiki/Bauhaus) school in Weimar, with Kurt Schwerdtfeger.\\n> \\n> The 1939 London Daily Mail Ideal Home Exhibition featured a “72-way Light Console and Compton Organ for Colour Music”, as well as a 70 feet, 230 kW “Kaleidakon” tower.\\n> \\n> From 1935–77, Charles Dockum built a series of Mobilcolor Projectors, his versions of silent color organs.\\n> \\n> In the late 1940s, [Oskar Fischinger](https://en.wikipedia.org/wiki/Oskar_Fischinger) created the [Lumigraph](https://en.wikipedia.org/w/index.php?title=Lumigraph&action=edit&redlink=1) that produced imagery by pressing objects/hands into a rubberized screen that would protrude into colored light. The imagery of this device was manually generated, and was performed with various accompanying music. It required two people to operate: one to make changes to colors, the other to manipulate the screen. Fischinger performed the Lumigraph in Los Angeles and San Francisco in the late 1940s through early 1950s. The Lumigraph was licensed by the producers of the 1964 sci-fi film, [_The Time Travelers_](https://en.wikipedia.org/wiki/The_Time_Travelers_(1964_film)). The Lumigraph does not have a keyboard, and does not generate music.\\n> \\n> In 2000, [Jack Ox](https://en.wikipedia.org/wiki/Jack_Ox) and David Britton created “The Virtual Color Organ.” The 21st Century Virtual Reality Color Organ is a computational system for translating musical compositions into visual performance. It uses supercomputing power to produce 3D visual images and sound from Musical Instrument Digital Interface (MIDI) files and can play a variety of compositions. Performances take place in interactive, immersive, virtual reality environments such as the Cave Automatic Virtual Environment (CAVE), VisionDome, or Immersadesk. Because it’s a 3D immersive world, the Color Organ is also a place — that is, a performance space._(_[_source_](https://en.wikipedia.org/wiki/Color_organ#:~:text=In%20the%20late%201940s%2C%20Oskar,performed%20with%20various%20accompanying%20music.)_)_\\n\\n\\n![12v LED](./12v.webp)\\n\\nContrary to the Young Maker at the start of the video below, the Color Organ did NOT originate in the 1970s. Image [Source](https://www.richardmudhar.com/blog/2015/12/12v-led-sound-to-light-or-color-organ/)\\n\\n<youtube-embed video=\\"HUw1-Kxq9_U\\" />\\n\\nThere aren’t any videos on YouTube of the Medieval color organ, but in the 20th Century many artists were inspired by the concept, and with new electronic and audiovisual technologies, what is sometimes called sound-image or music-visual ‘synaesthesia’ was often pursued in a range of creative works in different media and performance contexts. Below is an excerpt from a performance of Scriabin’s _Prometheus: Poem of Fire_ painstakingly recreated at Yale University in 2010.\\n\\n<youtube-embed video=\\"V3B7uQ5K0IU\\" />\\n\\nPrometheus: Poem of Fire (Scriabin)\\n\\n> Scriabin suffered from the natural condition of synesthesia, which made him associate musical notes and keys with colors. For example, the pitch “D” represented bright yellow, while “A” looked like dark green, and “D flat” felt like deep purple. In addition, in his late works traditional tonality is replaced by a set of unique harmonic spaces that inhabit a world of polyrhythmic uncertainty. In his quest to transfigure the word, Scriabin thought it necessary to confront the forces of evil. His Ninth Sonata is aptly nicknamed “The Black Mass,” and Scriabin tellingly regarded the performance of this work as “practicing sorcery.” Whatever the case may be, it is certainly a work of great musical concentration and extreme emotional intensity. ([source](https://interlude.hk/taste-color-musicalexander-scriabin/))\\n\\nMany experimental filmmakers made use of optical representations of sound to manipulate the audio track that is played by analog projectors, reversing the usual process of transcribing optical audio by drawing sounds directly onto film to create the soundtrack.\\n\\n<youtube-embed video=\\"Q0vgZv_JWfM\\" />\\nOptical Sound\\n\\n<youtube-embed video=\\"E3-vsKwQ0Cg\\" />\\n\\nMcLaren’s Dots\\n\\nVisual music approaches are particularly popular in creative practices where electroacoustic composition and animation intersect, and the synaesthetic explorations that we saw above in the realm of analog film continue today in the use of integrating the output 3D modeling and animation software with sound synthesis.\\n\\n<iframe title=\\"vimeo-player\\" src=\\"https://player.vimeo.com/video/14112798?h=62e7053ce4\\" width=\\"640\\" height=\\"360\\" frameborder=\\"0\\"    allowfullscreen></iframe>\\n\\nHere is a very recent example of some new trends emerging in computational visual music (to use that term in a very broad sense, since ‘visual music’ can encompass quite a range of creative practices) related to an increasing interest in data and algorithms. Michele Zaccagnini is developing a process he calls Deep Mapping, which is\\n\\n> an approach that allows the composer to store and render musical data into visuals by “catching” the data at its source, at a compositional stage. The advantages of this approach are: accuracy and discreteness in the representation of musical features; computational efficiency; and, more abstractly, the stimulation of a practice of audiovisual composition that encourages composers to envision their multimedia output from the early stages of their work.The drawbacks are: prerecorded sounds cannot be deep-mapped and deep mapping presupposes an algorithmic compositional approach.\\n\\n\\n<youtube-embed video=\\"yGXZBfgmVBo\\" />\\n\\nDeep Map #1\\n\\nVisual Music in Film\\n--------------------\\n\\nVisual Music is a concept also sometimes employed in the purely visual arts, where some painters have found inspiration in the concept of music to describe their abstractions.\\n\\n![New Harmony](./sq.webp)\\n\\nPaul Klee, New Harmony, 1936\\n\\n![New Harmony](./kand.webp)\\n\\nWassily Kandinsky, Improvisation (Dreamy), 1913\\n\\nIn Visual Music of the moving image variety (e.g. film and video, rather than music as the “referent” or metaphor for abstractions in painting, such as those of Kandinsky or Klee), the image track is often in a fantasia mode vis-à-vis the soundtrack. While as is usually the case with sound design, the script, footage and first edits usually precede the production of sound (though there are exceptions, as with Ben Burtt’s collection of sounds for Star Wars where he often recorded interesting sounds before knowing what to do with them), with visual music there is typically a pre-existent work of music, which the moving image takes as an inspiration or motivation for free form and abstract play. Visual Music as a form can range from abstraction (e.g. a play on geometric shapes, light or color), to specific references to technologies of mediation (e.g. bright flashes of overexposed film, video footage modulated by rhythms in a techno beat, or even the generative imagery produced by iTunes Visualizer), to highly stylized and very abstract characterizations of personae with degrees of recognizable action and even plot (for instance, the struggle of an orange triangle to escape from thick lines and grids of black, which metaphorically morph into the bars of a prison or cage, as below with Synchromy No 4 Escape).\\n\\n<youtube-embed video=\\"YRmu-GcClls\\" />\\n\\nMary Ellen Bute’s Synchromy №4 Escape\\n\\n<youtube-embed video=\\"pzErTRNVj3Y\\" />\\n\\nFan video, Black Eyed Peas “I Gotta Feeling” as motion-visual geometry.\\n\\n<youtube-embed video=\\"T96K2inyQok\\" />\\n\\nPowercord vs Philter Phreak\\n\\nPhoto-collage and montage editing have also been a feature of Visual Music, and highly stylized music video production (especially for electronica genres) can often blur the usual stylistic boundaries between what one might typically refer to as a ‘music video’ versus a work of Visual Music.\\n\\n<youtube-embed video=\\"JY_gQ9TNIUw\\" />\\n\\nOne Dot Zero\\n\\n> The ident is based around the idea of the roots of computer technology in the pre digital world — a world of music boxes, jacquard looms, punch cards and relay switches. Music box mechanisms were the precursors to punch cards as ways of communicating binary information, the Jacquard loom used punch-cards to essentially program the loom to create complex textile patterns (looked at now they resemble 8-bit computer drawings). The first real computer circuit was created using telephone relay switches. Our contemporary digital world is linked to pre-electric era of automated crafts and musical automata. This has a resonance with the tenth anniversary of onedotzero — both in the way that it references history but also it is mirrored in a lot of the work that’s being produced now. Computers have become almost invisible, powerful tools which are being used to facilitate craft. ([source](https://www.youtube.com/watch?v=JY_gQ9TNIUw))\\n\\nIn its ‘classic’ mode,’ visual music is often linked to the tradition of seeking an experience of synaesthesia as a spiritually heightened fusion of the senses. Its antecedents are in Wagner’s Gesamtkunstwerk (indeed, Richard Wagner’s “Evening Star” is the music of Mary Ellen Bute’s Synchrony №2) or total artwork (a fusion of the all the arts and consequently, of the senses), but it also has roots in the Symbolist and Spiritualist movements of the 19th century — all of this has its origins in Schopenhauer’s philosophy of music, in which music was framed as the highest art due to its ability to directly represent the Will (for Schopenhauer, the Will as a category included magnetism, love, rage, and electricity — in other words, forces in general, whether internal to one’s self and unconscious, or external in the workings of the world).\\n\\n> As an outgrowth of the Romantic and Symbolist movements, music was elevated to a status of supremacy over all the other forms of creative expression. The other arts, notably poetry and painting, were said to aspire to the “condition of music.” Artists came to believe that painting should be analogous to music.\\n> \\n> Proponents of musical analogy based their aesthetic theories on an abstraction of the idea of music, rather than on a clear understanding of musicology. For them music represented a non-narrative, non-discursive mode of expression. They reasoned that music, in its direct appeal to emotions and senses, transcended language. Just as music was a universal form of expression, so should the visual arts attain universality by evoking sensual pleasure or an emotional response in the viewer.\\n> \\n> Advocates of musical analogy and color music also depended upon the related notion of synaesthesia; that is, they believed in the subjective interaction of all sensory perceptions. This common acceptance of synaesthesia resulted from two divergent philosophical positions. According to the more romantically inclined artists and writers, the interchangeability of the senses was evidence of mystical correspondence to a higher reality. On the other hand, some artists joined forces with scientific researchers to study synaesthesia as a phenomenon of human perception. ([Source](https://www.jstor.org/stable/1483303?seq=1))\\n\\nMany works in the filmic synaesthetic tradition can be read as an a counter-modernist inclination, a vestige of romantic impulse in the development of 20th century mediation.\\n\\n**Sound Design**\\n----------------\\n\\nThe term Sound Design came into vogue in the 1970s to describe a new role in the creation of the sound film, analogous to a “director” or “cinematographer” of the soundtrack. In the early ’70s Dolby noise reduction, which had already established itself widely in music production and distribution during the ’60s, expanded its application to the area of film sound. The specific properties of Dolby — increased dynamic range, improved spatialization, better frequency response, and reduction of the noise floor — combined with Dolby’s strategy of providing relatively affordable licensing to theater owners so that it’s noise reduction technology could be widely adapted, provided for the first time a universal standard in cinematic sound reproduction, allowing the sound mix heard in the theaters to be closer to that heard on the mix stage than at any time previously. ([source](https://www.amazon.com/Dolby-era-contemporary-Hollywood-Popular/dp/0719070678))\\n\\nThe aesthetic possibilities opened up by this technological change were exploited by filmmakers, particularly those based in San Francisco’s “Hollywood North.” For instance, the two artist-technicians usually credited with being the first “sound designers” (the first to receive this designation), Ben Burtt and Walter Murch, were each given unprecedented periods of time to explore sound as a dimension of film. Burtt was given more than a year to build a sound effects library for George Lucas’s _Star Wars_ film soundtrack, famously (in widely circulated images) “wandering the desert” with field recording gear, tapping on phone wires and recording sounds that would eventually support such futuristic technologies as X-Wing Fighters and light sabers. Murch spent a year mixing and remixing Francis Ford Coppola’s _Apocalypse Now_, trying out multiple edits and approaches to what is likewise (as in the case of Star Wars) regarded as a paradigm shift in film mixing.\\n\\nIn entertainment industry contexts, sound‘s role is often described in the relevant literature as a form of “[subordination](https://www.amazon.com/Music-Imagination-Culture-Clarendon-Paperbacks/dp/0198163037/ref=sr_1_1?keywords=Music%2C+Imagination+and+Culture+by+Nicholas+Cook&qid=1579364384&s=books&sr=1-1)” to the film’s imagery. In other words, the work of the soundtrack is to reinforce, through its specific effects (heightened emotion, spatial depth, representing sound sources, clarity of speech, rhythmic pacing and the like) the narratological and often “realist” motivations of the image track (and reciprocally, reserving “weird sound.” often simply taken from the realm of avant-garde music — for dream sequences, aliens, monsters and the like ([source](https://www.jstor.org/stable/j.ctt2005s0z)). Such an approach is typical of more narrative, mainstream or commercial projects.\\n\\nIn contrast, experimental approaches to sound design tend to assert a relative autonomy for the soundtrack in relation to the moving image. But at the same time there is often an “associational intent” at work, in that there is an attempt to create poetic or connotational relationships between sound and image.\\n\\n**Experimental Music**\\n----------------------\\n\\nIn her paper “Experimental Music Semiotics,” Morag Josephine Grant elaborates an intriguing [Peircean semiotic approach](https://vanseodesign.com/web-design/icon-index-symbol/) to understanding the distinction between experimental music and other forms of avant-garde, classical or “new” music. In her analysis, experimental music has a heightened interest in the indexical relationship to sound, whereas other forms may be better described as having a stronger affinity for the symbolic.\\n\\n> Definitive for the icon in similarity with the object referred to, definitive for the index is contiguity with the object referred to, definitive for the symbol is its dependence on a standard rule of interpretation. ([source](https://www.jstor.org/stable/i30032123))\\n\\nIt is in this notion of “a standard rule of interpretation” that one can find a slew of correspondences to non-experimental (including avant-garde) music practices. For instance, an interval can be read as also referring to a moment in the score, a minor third, and all the rules of harmony with its allowances and strictures of what one is to do with a minor third (or not do with it). In the recapitulation of a theme, the work itself can be understood as the interpretant which contextualizes its significance. One can expand this to other fields of music as well. Jazz, for instance, can be understood as a metaphor or symbol for communication (call and response, dialogue). To draw her distinction sharply, she offers the striking example of the sound of a telephone:\\n\\n> So why don’t telephones ring in music? They ring all over the place in literature. They appear in pictures more often than they do in music. They are the hinge of countless film plots.\\n> \\n> The case of experimental music is immediately different because it can deal with the telephone as a telephone.\\n\\nGrant cites [Winfried Nöth](https://www.springer.com/de/book/9783476012265), noting that “the index makes no assertions regarding its object, but merely shows us the object or draws our attention to it,” the index is “of fact, of reality, and of experience in time and space.”\\n\\nExperimental music does not draw a distinction between the realms of “music” and that of “sound and noise.” It forces our attention to the causal dimensions of sonic experience, the productions of sonorous bodies, rather than to the systemic embeddedness of a sound in a formal logic or system (such as score, or the rules of harmony). Indeed, to further bolster her argument that non-experimental (but still scored) music has more of a symbolic character, we need only note the aspects of rhetoric that accompany such compositions: themes, argument, development, recapitulation, verse, refrain, and the like.\\n\\nGrant does not assert, however, that non-experimental music is only symbolic, or that experimental music is only indexical. Indeed, her essay devotes much time to exploring devil’s advocate, borderline, and seemingly contradictory examples to her schema. She notes that “signification generally involves complex hybrids of these categories (icon, index, symbol).” But as a general description of what may make some music “experimental” and others not, it does have a subtle cogency. For instance, John Cage’s silent work _4’33”_ can be understood in relation to Peirce’s example of the indexical weather vane signifying even the absence of wind.\\n\\n> Even if there is no wind at a particular moment, the weather vane still fulfills its purpose, confirming that there is no wind… It is specifically created to draw our attention to something by contiguous relationship with it. Even if there is never wind again, a weather vane will not stop being a weather vane…\\n\\nThe silence evoked by Cage in this work is analogous to the absence of wind — it is still significant (hence a work of experimental music) even though it does not sound.\\n\\nWhat is interesting to note about visualized sound in a Peircean semiotic context is that the sound which results from such processes has its “origin” in an indexical (directly causal) relationship. The nature of the index-causality is different in these cases: pen or scratches on film emulsion in McLaren’s work, or digital drawing tablet in the case of Xenakis‘ [UPIC system](https://en.wikipedia.org/wiki/UPIC). However, once we as listener-viewers are experiencing the work, the synaesthetic play of visual-sonic percepts takes on an iconic dimension as well, as we start to see that the sounds high up in the visual frame also sound high-pitched, or thick bands may produce clusters, while thin bands produce purer tones, or as we notice the way in which rhythmic syncretism in sound and image reinforce each other. At times one feels that one is really ‘seeing the sound’ but simultaneously sounds and images have their own autonomy — in fact, in an iconic sense one is only seeing certain aspects of the sound — both the visual and sonic imagination have their own resonances which can’t be entirely merged.\\n\\nNew Visualizations in Music\\n---------------------------\\n\\nIn the context of visual music, we would be amiss if we didn’t touch on new practices of visualizing musical form that have gone far beyond traditional music notation using bass and treble clefs, note and rest values, bars, measures, time signatures, and all of the other inscription apparatus of classical music common practice. As musical form exploded in its sheer variety of approaches in the 20th Century, so too did ways of representing the new kinds of sounds and their composition. The images below are visualization of musical compositions, and are taken from Sylvia Smith’s article [Visual Music](https://www.jstor.org/stable/i238916).\\n\\n![bl](./bl.webp)\\n![kk](./kk.webp)\\n![12](./12.webp)\\n![qq](./qq.webp)\\n![ww](./ww.webp)\\n![yy](./yy.webp)\\n\\nNote: some text above has been excerpted from [a previous article](http://piim.newschool.edu/journal/issues/2010/02/index.php) in the _Parsons Journal for Information Mapping_.\\n\\nWritten by Michael Filimowicz, PhD\\n----------------------------------\\n\\n[Original article at oundand.design](https://soundand.design/audiovisual-aesthetics-5-b29c9471020)","frontmatter":{"title":"Visual Music & the Poetics of Synaesthesia","description":"by Michael Filimowicz, PhD","date":"2024-06-20T00:00:00.000Z","cover":"/media_files/cover/theory-interplay-visual-music-cover.webp"},"url":"/theory/interplay/visual-music/"},{"src":"---\\ntitle: Sound painting\\ndescription: Sign language for live music composition\\ndate: 2023-07-11\\ncover: stage.jpg\\n---\\n\\n<youtube-embed video=\\"YJQf0MDsNaA\\" />\\n\\n## Introduction\\n\\n[Soundpainting](http://www.soundpainting.com) is the universal multidisciplinary live composing sign language for musicians, actors, dancers, and visual Artists. Presently (2023) the language comprises more than 1500 gestures that are signed by the Soundpainter (composer) to indicate the type of material desired of the performers. The creation of the composition is realized, by the Soundpainter, through the parameters of each set of signed gestures. The Soundpainting language was created by Walter Thompson in Woodstock, New York in 1974.\\n\\n## Developing the creative mind\\n\\nSoundpainting is an essential method for engaging students of all ages, ability levels, and art forms in the creative process. Unlike learning to create within a single style, Soundpainting develops the creative voices of students through an array of structural parameters allowing individual choice and stylistic parameters. Using the composer, or “Soundpainter,” as teacher, the innate creativity of students is drawn out and developed constructively by way of the gestural choices of the Soundpainter, enabling each individual, each group, to express their own character in an experiential learning format.\\n\\n<youtube-embed video=\\"hp_AxCgtD1M\\" />\\n\\n## Analysis\\n\\nThe Soundpainter (the composer) standing in front (usually) of the group communicates a series of signs using hand and body gestures indicating specific and/or aleatoric material to be performed by the group. The Soundpainter develops the responses of the performers, molding and shaping them into the composition then signs another series of gestures, a phrase, and continues in this process of composing the piece.\\n\\nThe Soundpainter composes in real time utilizing the gestures to create the composition in any way they desire. The Soundpainter sometimes knows what he/she will receive from the performers and sometimes does not know what he/she will receive – the elements of specificity and chance. The Soundpainter composes with what happens in the moment, whether expected or not. The ability to compose with what happens in the moment, in real time, is what is required in order to attain a high level of fluency with the Soundpainting language.\\n\\nThe gestures of the Soundpainting language are signed using the syntax of Who, What, How and When. There are many types of gestures, some indicating specific material to be performed as well as others indicating specific styles, genres, aleatoric concepts, improvisation, disciplines, stage positions, costumes, props, and many others.\\n\\n![on stage](./12.jpg)\\n\\n## The Structure of Soundpainting\\n\\nThe Soundpainting gestures are grouped in two basic categories: Sculpting gestures and Function signals.\\n\\nSculpting gestures indicate What type of material and How it is to be performed and Function signals indicate Who performs and When to begin performing. Who, What, How, and When comprise the Soundpainting syntax. Note: The How gestures are not always employed. The Soundpainter often signs a phrase leaving out a How gesture. For example: Whole Group, Long Tone, Play. If you sign your phrase without a How gesture, then it is the performers choice in deciding the dynamics and quality of the material.\\n\\nThe Soundpainting syntax Who, What, How, When and the two basic categories Sculpting Gestures and Function Signals are further broken down into six subcategories: Identifiers, Content, Modifiers, Go gestures, Modes, and Palettes.\\n\\n1. **Identifiers** are in the Function category and are Who gestures such as Whole Group, Woodwinds, Brass, Group 1, Rest of the Group, etc.\\n\\n2. **Content gestures** are in the Sculpting category and identify What type of material is to be performed such as Pointillism, Minimalism, Long Tone, Play Can’t Play etc.\\n\\n3. **Modifiers** are in the Sculpting category and are How gestures such as Volume Fader and Tempo Fader.\\n\\n4. **Go gestures** are in the Function category and indicate When to enter or exit the composition and in some cases when to exit Content such as Snapshot or Launch Mode.\\n\\n5. **Modes** are in the Sculpting category and are Content gestures embodying specific performance parameters. Scanning, Point to Point, and Launch Mode are several examples of Modes.\\n\\n6. **Palettes** are in the Sculpting category and are primarily Content gestures identifying composed and/or rehearsed material\\n\\n![use of sound painting](./use.jpg)\\n\\n## Three Rates of Development\\n\\nCertain gestures such as Point to Point, Scanning, Play Can’t Play, Relate To and Improvise are a few of the Content gestures that include parameters requiring specific rates of material development.\\n\\n**Rate 1:** The performer develops their material in such a way that one minute later there would still be a relationship to their original idea.\\n\\n**Rate 2:** The rate of development of material is about twice as fast as that of Rate 1. A minute later there would only be a vague relationship to the original idea.\\n\\n**Rate 3:** Open rate of development. The performer may develop their material at any rate of their choosing.\\n\\n![drawing of sound painting](./draw.jpg)\\n\\n## Imaginary Regions\\n\\nThere are four Imaginary Regions the Soundpainter utilizes when signing gestures.\\n\\n1. **The Neutral position:** The Neutral position is the place on stage where the Soundpainter’s body indicates silence and/or stillness. It is where the Soundpainter prepares the phrase for initiation.\\n\\n2. **The Box:** An imaginary space just in front of the Soundpainters Neutral position where phrases are initiated – the place of action. The Box is approximately 2 meters (6 feet) long and one meter wide. Important: Who, What, and How (sometimes) gestures are prepared out of the Box and then the Soundpainter steps into the Box initiating the phrase with a Go gesture. For example: Whole Group (out of the Box), Long Tone (out of the Box), Volume Fader (medium) (out of the Box), Play (in the Box). Important Note: Modifying Gestures such as Volume Fader and Tempo Fader can either be prepared out of the Box, then initiated with a Go gesture or, may be used in real time by stepping into the Box and signing the gesture for an immediate response from the performers.\\n\\n3. **The Imaginary Staff:** An imaginary vertical field 1 and ½ meters (3 ½ feet) just in front of the Soundpainter that indicates low to high pitch range with sound and slow to fast movement with certain gestures such as a Long Tone. Note: The name Imaginary Staff is derived from music language. It is related to the music staff, which is a set of five parallel lines with spaces between them, on which notes are written to indicate their pitch.\\n\\n4. **The Imaginary Stage:** A horizontal field (like a small square table top) approximately ¾ of a meter for each side (3/4 of a yard squared) at waist height positioned just in front of the Soundpainter. The Imaginary Stage is the region in which the Soundpainter indicates movement directions on the stage – where the movement will travel to and from. Such gestures as Directions and Space Fader are both signed on the Imaginary Stage.\\n\\n<youtube-embed video=\\"tKFjZEUbYdU\\" />\\n\\n![Walter Thompson](./walter.jpg)\\n\\n## Walter Thompson\\n\\n### Soundpainter, Composer, Woodwinds, Piano, Percussion, Educator\\n\\nWalter Thompson has achieved international recognition as a composer and for the creation of Soundpainting, the universal multidisciplinary live composing sign language. Thompson has composed Soundpaintings with contemporary orchestras, dance companies, theatre ensembles and multidisciplinary groups in United States, Europe and South America.\\n\\nIn 1974, after attending Berklee School of Music, Walter Thompson moved to Woodstock and began an association with the Creative Music Studio. While there, he studied composition and woodwinds with Anthony Braxton and began to develop his interest in using hand and body gestures as a way to create real-time compositions. Beginning as a tool to help shape the direction of a performance, it has evolved to become a universal composing language for composers and artists off all disciplines and abilities.\\n\\nThe language continues to be developed through Thompson’s performances, international think tanks, and the contributions of a wide range of artists and educators. Soundpainting is now being used both professionally and in education in more than 35 countries around the world including; the United States, France, Canada, Australia, Czech Republic, China, Germany, Spain, Norway, Denmark, Sweden, Finland, Italy, Japan, South Africa, Brazil, Uruguay, Montenegro, Guadeloupe, Argentina, Kazakhstan, Mexico, Nigeria, Switzerland, Turkey, and the Netherlands.\\n\\n![WT on stage](./perf.jpg)\\n\\nThompson has composed Soundpaintings with contemporary orchestras, dance companies, theatre ensembles and multidisciplinary groups in many cities, including Barcelona, Paris, New York, Chicago, Los Angeles, Boston, Oslo, Berlin, Bergen, Lucerne, Copenhagen, and Reykjavik, among others, and has taught Soundpainting at the Paris Conservatoire; Grieg Academy, Bergen, Norway; Iceland Academy of the Arts; Eastman School of Music; University of California San Diego; University of Michigan; University of Iowa; Oberlin College-Conservatory of Music; and New York University, among many others. Thompson is founder of and Soundpainter for The Walter Thompson Orchestra founded in 1984 and based in New York City.\\n\\nIn 2002, Premis FAD Sebastià Gasch d’Arts Parateatrals awarded Thompson the prestigious “Aplaudiment” for his work with Soundpainting in Barcelona, Spain. He has also received awards from the National Endowment for the Arts, Meet the Composer, the Mary Flagler Cary Charitable Trust, ASCAP, Rockefeller Foundation, Mid Atlantic Arts Foundation, New York State Council on the Arts, and the Jerome Foundation.\\n\\n## A New Approach In Music Education Improving Creativity: Soundpainting\\n\\nCommon characteristics of Orff, Kodaly and Dalcrose music education approaches are not only that they are the education methods improving the creativity but it is also that they gain aimed behaviours in dramatization, improve musical skills and ensure adaption into social environment thanks to music, acquire mental skills such as motivation, attention and self-confidence. Soundpainting is the universal live composing language created for musicians, dancers, actors, poets and visual artists working in their improvised environment. Soundpainting, a performance art based on improvisation, has started to be used in education in recent years. Just like other music education methods, education of Soundpainting is quite an important music education approach in terms of development in the creativity of individuals, their musical and mental skills. With this study, it has been tried to emphasize the Soundpainting's common points with other music education approaches by providing information about Soundpainting. Within this study, it is aimed at contributing to music education and teaching as a new approach. This research is one of the very few studies, which carried out in the fields of Soundpainting. Therefore, it is important in terms of its contribution to the both education and Soundpainting fields. This research is descriptive research and data were obtained by literature review. At the end of the research, it was emerged that Soundpainting has common ground with the other music education approaches and it could be used in music education.\\n[Read more](https://www.academia.edu/30315900/A_New_Approach_In_Music_Education_Improving_Creativity_Soundpainting)\\n\\n- A New Approach In Music Education Improving Creativity: Soundpainting [Download PDF](/books/A_New_Approach_In_Music_Education_Improv-1.pdf)\\n","frontmatter":{"title":"Sound painting","description":"Sign language for live music composition","date":"2023-07-11T00:00:00.000Z","cover":"/media_files/cover/theory-composition-sound-painting-stage.jpg"},"url":"/theory/composition/sound-painting/"},{"src":"---\\ntitle: Modality\\ndescription: Modal harmony study\\ndate: 01-10-2023\\n---\\n\\n\\n## Introduction\\n\\nThe vast majority of music written in the last few centuries has been ‘tonal’. This is the type of music we are all used to hearing day to day. However, in the 1950’s Jazz musicians began feeling restricted by ‘tonality’ and started experimenting with other ways of structuring harmony (i.e. chords).\\n\\nFrom Tonality (which encompasses your more traditional Jazz all the way through to Bebop, Hard-bop and Cool Jazz) Jazz musicians moved to Modality ([Modal Jazz](https://www.thejazzpianosite.com/jazz-piano-lessons/modern-jazz-theory/modal-jazz/)) and Atonality ([Free Jazz](https://www.thejazzpianosite.com/jazz-piano-lessons/modern-jazz-theory/free-jazz/) – though Free Jazz is NOT necessarily atonal).\\n\\nIn this lesson we’re going to start with the difference between Tonal Harmony vs Modal Harmony.\\n\\nJust as a semantic aside, when I say ‘modal harmony’ I am referring to the modern meaning of the term – that is Miles Davis/Kind of Blue/Modal Jazz Modal Harmony – and **NOT** Medieval music or Gregorian Modes.\\n\\n## Modality\\n\\nModality has the following features:\\n\\n* It uses all [modes](https://www.thejazzpianosite.com/jazz-piano-lessons/the-basics/modes/) (Ionian, Dorian, Phrygian, etc.)\\n* It does NOT use a Functional Harmony\\n* It has a Tonal Centre (i.e. root note)\\n\\nModal songs can be written in any mode (not just major and minor), so for example it can be in the key of D Dorian.\\n\\nIn Modal Harmony, chords DO NOT have a function, so in a sense: all chords are equal. A chord DOES NOT need to resolve to any other chord. But there is still a Tonal Centre – for example the note D in the key of D Dorian (i.e. the root note).\\n\\nBut because there is no ‘functional harmony’ the chords DO NOT feel like they need to resolve to the tonic or Dm7 chord. Each chord just floats there by itself as a standalone entity.\\n\\nIn order to achieve this you have to avoid playing the diatonic tritone – because this tritone interval creates a dissonance which sounds like a Dominant Chord and feels like it wants to resolve to the Tonic Chord, thus turning the music tonal.\\n\\nSo it’s a delicate balance. You have to make D sound like the ‘tonal centre’ but you can’t do it by using the function of the diatonic chords. So you:\\n\\n* CAN’T use a dominant chord to establish the tonic (i.e. A7 to Dm)\\n* CAN use Pedal point (Repeat Root Note)\\n* CAN use Ostinato (Repetitive pattern)\\n\\nBecause the majority of music we hear (pop, rock, etc) is tonal and chords are usually built out of stacked 3rds, we’ve learned to associate chords built in thirds with tonal harmony. The way to get around this problem is to build chord with 4ths – that is, use [**Quartal Chords**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-voicings/quartal-voicings/). By building chords in 4ths, you break that tonal anticipation of the Dominant chord wanting to move to the tonic and you create a more ambiguous, vague and modal sound.\\n\\nBecause modal chords don’t have ‘functions’, they don’t have to go anywhere (i.e. they don’t have to resolve to the tonic). They just float around. So modal songs usually don’t have chord progressions. They just state the key/scale/mode the song is in and it’s your job to play any diatonic chords (i.e. Dm7, Em7, FMaj7, G7, Am7, Bø7, & CMaj7 in the key of D Dorian) and make your own ‘chord progression’.\\n\\nSo then when playing a Modal Song you have to:\\n\\n* Emphasis the root note in the bass (to reinforce the tonal centre); and\\n* Avoid playing the diatonic tritone (to avoid tonal sound)\\n  * DO NOT play Bø7\\n  * Play G Triad (instead of G7) to avoid the tritone interval\\n* Move around the diatonic chords at random but smoothly (generally stepwise)\\n* Keep the chord movements sparse and simple – not too busy, not too many chords, nice and boring. The chords are there just to create a harmonic underlay.\\n* Use Quartal Chords (to avoid tonal sound)\\n\\nModal harmony creates a more ambiguous and vague sound and is now considered much more ‘modern’ than traditional tonal harmony. Modal Harmony completely changed the way people think about Jazz and improvisation. It gave the soloist greater freedom and choice in his or her solo (I’ll have much more to say about this in the next lesson).\\n\\n## Tonal Harmony vs Modal Harmony Summary\\n\\nAnd that, in a nutshell, is the difference between Tonal Harmony vs Modal Harmony. So, in summary:\\n\\n<table id=\\"tablepress-183\\" class=\\"tablepress tablepress-id-183\\">\\n\\n<thead>\\n\\n<tr class=\\"row-1 odd\\">\\n\\n<th class=\\"column-1\\">Tonality</th>\\n\\n<th class=\\"column-2\\">Modality</th>\\n\\n</tr>\\n\\n</thead>\\n\\n<tbody class=\\"row-hover\\">\\n\\n<tr class=\\"row-2 even\\">\\n\\n<td class=\\"column-1\\">Uses Major & minor keys</td>\\n\\n<td class=\\"column-2\\">Uses all modes</td>\\n\\n</tr>\\n\\n<tr class=\\"row-3 odd\\">\\n\\n<td class=\\"column-1\\">Functional Harmony</td>\\n\\n<td class=\\"column-2\\">No Functional Harmony</td>\\n\\n</tr>\\n\\n<tr class=\\"row-4 even\\">\\n\\n<td class=\\"column-1\\">Tonal Centre (root note)</td>\\n\\n<td class=\\"column-2\\">Tonal Centre</td>\\n\\n</tr>\\n\\n</tbody>\\n\\n</table>\\n\\n![Tonal Harmony vs Modal Harmony](https://www.thejazzpianosite.com/wp-content/uploads/2016/12/Tonal-Harmony-vs-Modal-Harmony.png)\\n\\n## Have a Listen to\\n\\n* So What ~ Miles Davis\\n* Milestones ~ Miles Davis\\n* My Favorite Things ~ John Coltrane\\n* Impressions ~ John Coltrane\\n* Little Sunflower ~ Freddie Hubbard\\n* Footprints ~ Wayne Shorter\\n\\n<youtube-embed video=\\"OCkCn0dEgpw\\" />\\n","frontmatter":{"title":"Modality","description":"Modal harmony study","date":"01-10-2023"},"url":"/theory/harmony/modal/"},{"src":"---\\ntitle: Melody study\\ndescription: What is melody and how can we understand it\\ndate: 2021-12-01\\ncover: chandler-cruttenden.jpg\\n---\\n\\nA [melody](https://en.wikipedia.org/wiki/Melody) (from Greek μελῳδία, melōidía, \\"singing, chanting\\"), also tune, voice or line, is a linear succession of musical tones that the listener perceives as a single entity. In its most literal sense, a melody is a combination of pitch and rhythm, while more figuratively, the term can include successions of other musical elements such as tonal color. It is the foreground to the background accompaniment. A line or part need not be a foreground melody.\\n\\nMelodies often consist of one or more musical phrases or motifs, and are usually repeated throughout a composition in various forms. Melodies may also be described by their melodic motion or the pitches or the intervals between pitches (predominantly conjunct or disjunct or with further restrictions), pitch range, tension and release, continuity and coherence, cadence, and shape.\\n\\n<youtube-embed video=\\"QpxN2VXPMLc\\" />\\n\\n## Function and elements\\n\\nJohann Philipp Kirnberger argued:\\n\\n> The true goal of music—its proper enterprise—is melody. All the parts of harmony have as their ultimate purpose only beautiful melody. Therefore, the question of which is the more significant, melody or harmony, is futile. Beyond doubt, the means is subordinate to the end.  \\n> —  Johann Philipp Kirnberger (1771)\\n\\nThe Norwegian composer Marcus Paus has argued:\\n\\n> Melody is to music what a scent is to the senses: it jogs our memory. It gives face to form, and identity and character to the process and proceedings. It is not only a musical subject, but a manifestation of the musically subjective. It carries and radiates personality with as much clarity and poignancy as harmony and rhythm combined. As such a powerful tool of communication, melody serves not only as protagonist in its own drama, but as messenger from the author to the audience.  \\n> — Marcus Paus (2017)\\n\\nGiven the many and varied elements and styles of melody \\"many extant explanations [of melody] confine us to specific stylistic models, and they are too exclusive. Paul Narveson claimed in 1984 that more than three-quarters of melodic topics had not been explored thoroughly.\\n\\nThe melodies existing in most European music written before the 20th century, and popular music throughout the 20th century, featured \\"fixed and easily discernible frequency patterns\\", recurring \\"events, often periodic, at all structural levels\\" and \\"recurrence of durations and patterns of durations\\".\\n\\nMelodies in the 20th century \\"utilized a greater variety of pitch resources than ha[d] been the custom in any other historical period of Western music.\\" While the diatonic scale was still used, the chromatic scale became \\"widely employed.\\" Composers also allotted a structural role to \\"the qualitative dimensions\\" that previously had been \\"almost exclusively reserved for pitch and rhythm\\". Kliewer states, \\"The essential elements of any melody are duration, pitch, and quality (timbre), texture, and loudness. Though the same melody may be recognizable when played with a wide variety of timbres and dynamics, the latter may still be an \\"element of linear ordering.\\"\\n\\n<youtube-embed video=\\"WEnUuYKL3c8\\" />\\n\\n## Examples\\n\\nDifferent musical styles use melody in different ways. For example:\\n\\n- Jazz musicians use the term \\"lead\\" or \\"head\\" to refer to the main melody, which is used as a starting point for improvisation.\\n- Rock music, and other forms of popular music and folk music tend to pick one or two melodies (verse and chorus, sometimes with a third, contrasting melody known as a bridge or middle eight) and stick with them; much variety may occur in the phrasing and lyrics.\\n- Indian classical music relies heavily on melody and rhythm, and not so much on harmony, as the music contains no chord changes.\\n- Balinese gamelan music often uses complicated variations and alterations of a single melody played simultaneously, called heterophony.\\n- In western classical music, composers often introduce an initial melody, or theme, and then create variations. Classical music often has several melodic layers, called polyphony, such as those in a fugue, a type of counterpoint. Often, melodies are constructed from motifs or short melodic fragments, such as the opening of Beethoven's Fifth Symphony. Richard Wagner popularized the concept of a leitmotif: a motif or melody associated with a certain idea, person or place.\\n- While in both most popular music and classical music of the common practice period pitch and duration are of primary importance in melodies, the contemporary music of the 20th and 21st centuries pitch and duration have lessened in importance and quality has gained importance, often primary. Examples include musique concrète, klangfarbenmelodie, Elliott Carter's Eight Etudes and a Fantasy (which contains a movement with only one note), the third movement of Ruth Crawford-Seeger's String Quartet 1931 (later re-orchestrated as Andante for string orchestra), which creates the melody from an unchanging set of pitches through \\"dissonant dynamics\\" alone, and György Ligeti's Aventures, in which recurring phonetics create the linear form.\\n\\n<youtube-embed video=\\"XLIrjjklq_s\\" />\\n\\n### Counterpoint\\n\\n<youtube-embed video=\\"b5PoTBOj7Xc\\" />\\n\\n## Voice leading\\n\\nVoice leading (or part writing) is the linear progression of individual melodic lines (voices or parts) and their interaction with one another to create harmonies, typically in accordance with the principles of common-practice harmony and counterpoint.\\n\\nRigorous concern for voice leading is of greatest importance in common-practice music, although jazz and pop music also demonstrate attention to voice leading to varying degrees. In Jazz Theory, Gabriel Sakuma writes that \\"[a]t the surface level, jazz voice-leading conventions seem more relaxed than they are in common-practice music.\\" Marc Schonbrun also states that while it is untrue that \\"popular music has no voice leading in it, [...] the largest amount of popular music is simply conceived with chords as blocks of information, and melodies are layered on top of the chords.\\"\\n\\n### History\\n\\nVoice leading developed as an independent concept when Heinrich Schenker stressed its importance in \\"free counterpoint\\", as opposed to strict counterpoint. He wrote:\\n\\n> All musical technique is derived from two basic ingredients: voice leading and the progression of scale degrees [i.e. of harmonic roots]. Of the two, voice leading is the earlier and the more original element.\\n> The theory of voice leading is to be presented here as a discipline unified in itself; that is, I shall show how […] it everywhere maintains its inner unity.\\n\\nSchenker indeed did not present the rules of voice leading merely as contrapuntal rules, but showed how they are inseparable from the rules of harmony and how they form one of the most essential aspects of musical composition. (See Schenkerian analysis: voice leading.)\\n\\n### Common-practice conventions and pedagogy\\n\\nWestern musicians have tended to teach voice leading by focusing on connecting adjacent harmonies because that skill is foundational to meeting larger, structural objectives. Common-practice conventions dictate that melodic lines should be smooth and independent. To be smooth, they should be primarily conjunct (stepwise), avoid leaps that are difficult to sing, approach and follow leaps with movement in the opposite direction, and correctly handle tendency tones (primarily, the leading-tone, but also the scale degree 4, which often moves down to scale degree 3) To be independent, they should avoid parallel fifths and octaves.\\n\\nContrapuntal conventions likewise consider permitted or forbidden melodic intervals in individual parts, intervals between parts, the direction of the movement of the voices with respect to each other, etc. Whether dealing with counterpoint or harmony, these conventions emerge not only from a desire to create easy-to-sing parts but also from the constraints of tonal materials and from the objectives behind writing certain textures.\\n\\n### These conventions are discussed in more detail below.\\n\\n1. Move each voice the shortest distance possible. One of the main conventions of common-practice part-writing is that, between successive harmonies, voices should avoid leaps and retain common tones as much as possible. This principle was commonly discussed among 17th- and 18th-century musicians as a rule of thumb. For example, Rameau taught \\"one cannot pass from one note to another but by that which is closest.\\" In the 19th century, as music pedagogy became a more theoretical discipline in some parts of Europe, the 18th-century rule of thumb became codified into a more strict definition. Organist Johann August Dürrnberger coined the term \\"rule of the shortest way\\" for it and delineated that:\\n\\n- When a chord contains one or more notes that will be reused in the chords immediately following, then these notes should remain, that is retained in the respective parts.\\n- The parts which do not remain, follow the law of the shortest way (Gesetze des nächsten Weges), that is that each such part names the note of the following chord closest to itself if no forbidden succession arises from this.\\n- If no note at all is present in a chord which can be reused in the chord immediately following, one must apply contrary motion according to the law of the shortest way, that is, if the root progresses upwards, the accompanying parts must move downwards, or inversely, if the root progresses downwards, the other parts move upwards and, in both cases, to the note of the following chord closest to them.\\n  This rule was taught by Bruckner to Schoenberg and Schenker, who both had followed his classes in Vienna. Schenker re-conceived the principle as the \\"rule of melodic fluency\\":\\n\\n> If one wants to avoid the dangers produced by larger intervals [...], the best remedy is simply to interrupt the series of leaps – that is, to prevent a second leap from occurring by continuing with a second or an only slightly larger interval after the first leap; or one may change the direction of the second interval altogether; finally both means can be used in combination. Such procedures yield a kind of wave-like melodic line which as a whole represents an animated entity, and which, with its ascending and descending curves, appears balanced in all its individual component parts. This kind of line manifests what is called melodic fluency [Fließender Gesang].\\n\\nSchenker attributed the rule to Cherubini, but this is the result of a somewhat inexact German translation. Cherubini only said that conjunct movement should be preferred. Franz Stoepel, the German translator, used the expression Fließender Gesang to translate mouvement conjoint. The concept of Fließender Gesang is a common concept of German counterpoint theory. Modern Schenkerians made the concept of \\"melodic fluency\\" an important one in their teaching of voice leading.\\n\\n2. Voice crossing should be avoided except to create melodic interest.\\n\\n3. Avoid parallel fifths and octaves. To promote voice independence, melodic lines should avoid parallel unisons, parallel fifths, and parallel octaves between any two voices. They should also avoid hidden consecutives, perfect intervals reached by any two voices moving in the same direction, even if not by the same interval, particularly if the higher of the two voices makes a disjunct motion. In organ registers, certain interval combinations and chords are activated by a single key so that playing a melody results in parallel voice leading. These voices, losing independence, are fused into one and the parallel chords are perceived as single tones with a new timbre. This effect is also used in orchestral arrangements; for instance, in Ravel's Boléro #5[clarification needed] the parallel parts of flutes, horn and celesta resemble the sound of an electric organ. In counterpoint, parallel voices are prohibited because they violate the homogeneity of musical texture when independent voices occasionally disappear turning into a new timbre quality and vice versa.\\n\\n### Harmonic roles\\n\\nAs the Renaissance gave way to the Baroque era in the 1600s, part writing reflected the increasing stratification of harmonic roles. This differentiation between outer and inner voices was an outgrowth of both tonality and homophony. In this new Baroque style, the outer voices took a commanding role in determining the flow of the music and tended to move more often by leaps. Inner voices tended to move stepwise or repeat common tones.\\n\\nA Schenkerian analysis perspective on these roles shifts the discussion somewhat from \\"outer and inner voices\\" to \\"upper and bass voices.\\" Although the outer voices still play the dominant, form-defining role in this view, the leading soprano voice is often seen as a composite line that draws on the voice leadings in each of the upper voices of the imaginary continuo. Approaching harmony from a non-Schenkerian perspective, Dmitri Tymoczko nonetheless also demonstrates such \\"3+1\\" voice leading, where \\"three voices articulate a strongly crossing-free voice leading between complete triads [...], while a fourth voice adds doublings,\\" as a feature of tonal writing.\\n\\nNeo-Riemannian theory examines another facet of this principle. That theory decomposes movements from one chord to another into one or several \\"parsimonious movements\\" between pitch classes instead of actual pitches (i.e., neglecting octave shifts). Such analysis shows the deeper continuity underneath surface disjunctions, as in the Bach example from BWV 941 hereby.\\n","frontmatter":{"title":"Melody study","description":"What is melody and how can we understand it","date":"2021-12-01T00:00:00.000Z","cover":"/media_files/cover/theory-melody-study-chandler-cruttenden.jpg"},"url":"/theory/melody/study/"},{"src":"---\\ntitle: Motif\\ndescription: Constructing music piece per repetition and change of ideas\\ndate: 2021-11-27\\n---\\n\\nIn music, a motif is a short musical idea, a salient recurring figure, musical fragment or succession of notes that has some special importance in or is characteristic of a composition. The motif is the smallest structural unit possessing thematic identity.\\n\\n<iframe title=\\"vimeo-player\\" src=\\"https://player.vimeo.com/video/112208320?h=c4e78c0fa8\\" width=\\"640\\" height=\\"360\\" frameborder=\\"0\\"    allowfullscreen></iframe>\\n\\n## History\\n\\nThe Encyclopédie de la Pléiade regards it as a \\"melodic, rhythmic, or harmonic cell\\", whereas the 1958 Encyclopédie Fasquelle maintains that it may contain one or more cells, though it remains the smallest analyzable element or phrase within a subject. It is commonly regarded as the shortest subdivision of a theme or phrase that still maintains its identity as a musical idea. \\"The smallest structural unit possessing thematic identity\\". Grove and Larousse also agree that the motif may have harmonic, melodic and/or rhythmic aspects, Grove adding that it \\"is most often thought of in melodic terms, and it is this aspect of the motif that is connoted by the term 'figure'.\\"\\n\\nA harmonic motif is a series of chords defined in the abstract, that is, without reference to melody or rhythm. A melodic motif is a melodic formula, established without reference to intervals. A rhythmic motif is the term designating a characteristic rhythmic formula, an abstraction drawn from the rhythmic values of a melody.\\n\\nA motif thematically associated with a person, place, or idea is called a leitmotif. Occasionally such a motif is a musical cryptogram of the name involved. A head-motif (German: Kopfmotiv) is a musical idea at the opening of a set of movements which serves to unite those movements.\\n\\nScruton, however, suggests that a motif is distinguished from a figure in that a motif is foreground while a figure is background: \\"A figure resembles a moulding in architecture: it is 'open at both ends', so as to be endlessly repeatable. In hearing a phrase as a figure, rather than a motif, we are at the same time placing it in the background, even if it is...strong and melodious\\".\\n\\nAny motif may be used to construct complete melodies, themes and pieces. Musical development uses a distinct musical figure that is subsequently altered, repeated, or sequenced throughout a piece or section of a piece of music, guaranteeing its unity.\\n\\n<youtube-embed video=\\"J0ib2EKHofc\\" />\\n\\n## Examples\\n\\nSuch motivic development has its roots in the keyboard sonatas of Domenico Scarlatti and the sonata form of Haydn and Mozart's age. Arguably Beethoven achieved the highest elaboration of this technique; the famous \\"fate motif\\" —the pattern of three short notes followed by one long one—that opens his Fifth Symphony and reappears throughout the work in surprising and refreshing permutations is a classic example.\\n\\nMotivic saturation is the \\"immersion of a musical motif in a composition\\", i.e., keeping motifs and themes below the surface or playing with their identity, and has been used by composers including Miriam Gideon, as in \\"Night is my Sister\\" (1952) and \\"Fantasy on a Javanese Motif\\" (1958), and Donald Erb. The use of motifs is discussed in Adolph Weiss' \\"The Lyceum of Schönberg\\".\\n\\n## Definitions\\n\\nHugo Riemann defines a motif as, \\"the concrete content of a rhythmically basic time-unit.\\"\\n\\nAnton Webern defines a motif as, \\"the smallest independent particle in a musical idea\\", which are recognizable through their repetition.\\n\\nArnold Schoenberg defines a motif as, \\"a unit which contains one or more features of interval and rhythm [whose] presence is maintained in constant use throughout a piece\\".\\n\\n## Head-motif\\n\\nHead-motif (German: Kopfmotiv) refers to an opening musical idea of a set of movements which serves to unite those movements. It may also be called a motto, and is a frequent device in cyclic masses.\\n\\n<youtube-embed video=\\"s5SkqX8vo2s\\" />\\n","frontmatter":{"title":"Motif","description":"Constructing music piece per repetition and change of ideas","date":"2021-11-27T00:00:00.000Z"},"url":"/theory/melody/motif/"},{"src":"---\\ntitle: Motion\\ndescription: Melodic motion of the voice\\n\\ndate: 2021-11-24\\n---\\n\\n<youtube-embed video=\\"DU0ZuBccJ2o\\" />\\n\\n<youtube-embed video=\\"Vuk7WQ4xvQs\\" />\\n\\n[Melodic motion](https://en.wikipedia.org/wiki/Melodic_motion) is the quality of movement of a melody, including nearness or farness of successive pitches or notes in a melody. This may be described as conjunct or disjunct, stepwise, skipwise or no movement, respectively. See also contrapuntal motion. In a conjunct melodic motion, the melodic phrase moves in a stepwise fashion; that is the subsequent notes move up or down a semitone or tone, but no greater. In a disjunct melodic motion, the melodic phrase leaps upwards or downwards; this movement is greater than a whole tone. In popular Western music, a melodic leap of disjunct motion is often present in the chorus of a song, to distinguish it from the verses and captivate the audience.\\n\\nBruno Nettl describes various types of melodic movement or contour (Nettl 1956, 51–53):\\n\\n- Ascending: Upwards melodic movement\\n- Descending: Downwards melodic movement (prevalent in the New World and Australian music)\\n- Undulating: Equal movement in both directions, using approximately the same intervals for ascent and descent (prevalent in Old World culture music)\\n- Pendulum: Extreme undulation that covers a large range and uses large intervals is called pendulum-type melodic movement\\n- Tile, terrace, or cascading: a number of descending phrases in which each phrase begins on a higher pitch than the last ended (prevalent in the North American Plain Indians music)\\n- Arc: The melody rises and falls in roughly equal amounts, the curve ascending gradually to a climax and then dropping off (prevalent among Navaho Indians and North American Indian music)\\n- Rise: may be considered a musical form, a contrasting section of higher pitch, a \\"musical plateau\\".\\n\\nOther examples include:\\n\\n- Double tonic: smaller pendular motion in one direction\\n\\nThese all may be modal frames or parts of modal frames.\\n\\n## Modal frame\\n\\nA [modal frame](https://en.wikipedia.org/wiki/Modal_frame) in music is \\"a number of types permeating and unifying African, European, and American song\\" and melody. It may also be called a melodic mode. \\"Mode\\" and \\"frame\\" are used interchangeably in this context without reference to scalar or rhythmic modes. Melodic modes define and generate melodies that are not determined by harmony, but purely by melody. A note frame, is a melodic mode that is atonic (without a tonic), or has an unstable tonic.\\n\\nModal frames may be defined by their:\\n\\n- floor note: the bottom of the frame, felt to be the lowest note, though isolated notes may go lower,\\n- ceiling note: the top of the frame,\\n- central note: the center around which other notes cluster or gravitate,\\n- upper or lower focus: portion of the mode on which the melody temporarily dwells, and can also defined by melody types, such as:\\n  - chant tunes: (Bob Dylan's \\"Subterranean Homesick Blues\\")\\n  - axial tunes: (\\"A Hard Day's Night\\", \\"Peggy Sue\\", Marvin Gaye's \\"Can I Get A Witness\\", and Roy Milton's \\"Do the Hucklebuck\\")\\n  - oscillating: (Rolling Stones' \\"Jumpin' Jack Flash\\")\\n  - open/closed: (Bo Diddley's \\"Hey Bo Diddley\\")\\n  - terrace\\n  - shout-and-fall\\n  - ladder of thirds\\n\\nFurther defined features include:\\n\\n- melodic dissonance: the quality of a note that is modally unstable and attracted to other more important tones in a non-harmonic way\\n- melodic triad: arpeggiated triads in a melody. A non-harmonic arpeggio is most commonly a melodic triad, it is an arpeggio the notes of which do not appear in the harmony of the accompaniment.\\n- level: a temporary modal frame contrasted with another built on a different foundation note. A change in levels is called a shift.\\n- co-tonic: a melodic tonic different from and as important as the harmonic tonic\\n- secondary tonic: a melodic tonic different from but subordinate to the harmonic tonic\\n- pendular third: alternating notes a third apart, most often a neutral, see double tonic\\n\\n### Shout-and-fall\\n\\nShout-and-fall or tumbling strain is a modal frame, \\"very common in Afro-American-derived styles\\" and featured in songs such as \\"Shake, Rattle and Roll\\" and \\"My Generation\\".\\n\\n\\"Gesturally, it suggests 'affective outpouring', 'self-offering of the body', 'emptying and relaxation'.\\" The frame may be thought of as a deep structure common to the varied surface structures of songs in which it occurs.\\n\\n### Ladder of thirds\\n\\nA ladder of thirds (coined by van der Merwe 1989, adapted from Curt Sachs) is similar to the circle of fifths, though a ladder of thirds differs in being composed of thirds, major or minor, and may or may not circle back to its starting note and thus may or may not be an interval cycle.\\n\\nTriadic chords may be considered as part of a ladder of thirds.\\n\\nIt is a modal frame found in Blues and British folk music. Though a pentatonic scale is often analyzed as a portion of the circle of fifths, the blues scale and melodies in that scale come, \\"into being through piling up thirds below and/or above a tonic or central note.\\"\\n\\nThey are \\"commonplace in post-rock 'n' roll popular music – and also appear in earlier tunes\\". Examples include The Beatles' \\"A Hard Day's Night\\", Buddy Holly's \\"Peggy Sue\\" and The Who's \\"My Generation\\", Ben Harney's \\"You've Been A Good Old Wagon\\" (1895) and Ben Bernie et al.'s \\"Sweet Georgia Brown\\" (1925).\\n\\n## Melodic expectation\\n\\nIn music cognition and musical analysis, the study of melodic expectation considers the engagement of the brain's predictive mechanisms in response to music. For example, if the ascending musical partial octave \\"do-re-mi-fa-sol-la-ti-...\\" is heard, listeners familiar with Western music will have a strong expectation to hear or provide one more note, \\"do\\", to complete the octave.\\n\\nThe notion of melodic expectation has prompted the existence of a corpus of studies in which authors often choose to provide their own terminology in place of using the literature's. This results in an important number of different terms that all point towards the phenomenon of musical expectation:\\n\\n- Anticipation\\n- Arousal\\n- Deduction\\n- Directionality\\n- Expectancy, expectation, expectedness, and in French attente\\n- Facilitation\\n- Implication / realization\\n- Implication (independent from realization)\\n- Induction\\n- Inertia\\n- Musical force(s)\\n- Previsibility, predictability and prediction\\n- Resolution\\n- Tension / release, tension / relaxation\\n- Closure, which may be used as the ending of the expectation process, as a group boundary, or as both simultaneously\\n\\nLeonard Meyer's **Emotion and Meaning in Music** is the classic text in music expectation. Meyer's starting point is the belief that the experience of music (as a listener) is derived from one's emotions and feelings about the music, which themselves are a function of relationships within the music itself. Meyer writes that listeners bring with them a vast body of musical experiences that, as one listens to a piece, conditions one's response to that piece as it unfolds. Meyer argued that music's evocative power derives from its capacity to generate, suspend, prolongate, or violate these expectations.\\n","frontmatter":{"title":"Motion","description":"Melodic motion of the voice","date":"2021-11-24T00:00:00.000Z"},"url":"/theory/melody/motion/"},{"src":"---\\ntitle: Singing\\ndescription: Connecting melody and text through a human voice\\n\\ndate: 2021-11-20\\n---\\n\\n## Gregorian chant\\n\\n<youtube-embed video=\\"H3v9unphfi0\\" />\\n\\n## Melismatic singing\\n\\n<youtube-embed video=\\"PRS2grauL4I\\" />\\n\\n<youtube-embed video=\\"U8iJ6SCH6rU\\" />\\n\\n## Riffs and runs\\n\\n<youtube-embed video=\\"EpLdMIA9QzQ\\" />\\n\\n<youtube-embed video=\\"1V25bEVuulk\\" />\\n\\n<youtube-embed video=\\"kkKuecXa5RQ\\" />\\n\\n### Vocal techniques\\n\\n<youtube-embed video=\\"GC-tQl9HWp4\\" />\\n\\n<youtube-embed video=\\"3-UgkKoOcAI\\" />\\n","frontmatter":{"title":"Singing","description":"Connecting melody and text through a human voice","date":"2021-11-20T00:00:00.000Z"},"url":"/theory/melody/singing/"},{"src":"---\\ntitle: Generative theory of tonal music\\ndescription: Formal description of the musical intuitions of a listener who is experienced in a musical idiom\\ndate: 2021-11-13\\ncover: Analysis-of-the-beginning-of-Bachs-chorale-Ermuntre-Dich-mein-schwacher-Geist_Q320.jpg\\n---\\n\\nA [generative theory of tonal music](https://en.wikipedia.org/wiki/Generative_theory_of_tonal_music) (GTTM) is a theory of music conceived by American composer and music theorist Fred Lerdahl and American linguist Ray Jackendoff and presented in the 1983 book of the same title. It constitutes a \\"formal description of the musical intuitions of a listener who is experienced in a musical idiom\\" with the aim of illuminating the unique human capacity for musical understanding.\\n\\nThe musical collaboration between Lerdahl and Jackendoff was inspired by Leonard Bernstein's 1973 Charles Eliot Norton Lectures at Harvard University, wherein he called for researchers to uncover a musical grammar that could explain the human musical mind in a scientific manner comparable to Noam Chomsky's revolutionary transformational or generative grammar.\\n\\nUnlike the major methodologies of music analysis that preceded it, GTTM construes the mental procedures under which the listener constructs an unconscious understanding of music, and uses these tools to illuminate the structure of individual compositions. The theory has been influential, spurring further work by its authors and other researchers in the fields of music theory, music cognition and cognitive musicology.\\nContents\\n\\n<youtube-embed video=\\"ra8TGtzZYo8\\" />\\n\\n## Theory\\n\\nGTTM focuses on four hierarchical systems that shape our musical intuitions. Each of these systems is expressed in a strict hierarchical structure where dominant regions contain smaller subordinate elements and equal elements exist contiguously within a particular and explicit hierarchical level. In GTTM any level can be small-scale or large-scale depending on the size of its elements.\\n\\n### Structures\\n\\n#### I. Grouping structure\\n\\nGTTM considers grouping analysis to be the most basic component of musical understanding. It expresses a hierarchical segmentation of a piece into motives, phrases, periods, and still larger sections.\\n\\n#### II. Metrical structure\\n\\nMetrical structure expresses the intuition that the events of a piece are related to a regular alternation of strong and weak beats at a number of hierarchical levels. It is a crucial basis for all the structures and reductions of GTTM.\\n\\n### III. Time-span reduction\\n\\nTime-span reductions (TSRs) are based on information gleaned from metrical and grouping structures. They establish tree structure-style hierarchical organizations uniting time-spans at all temporal levels of a work. The TSR analysis begins at the smallest levels, where metrical structure marks off the music into beats of equal length (or more precisely into attack points separated by uniform time-spans) and moves through all larger levels where grouping structure divides the music into motives, phrases, periods, theme groups, and still greater divisions. It further specifies a “head” (or most structurally important event) for each time-span at all hierarchical levels of the analysis. A completed TSR analysis is often called a time-span tree.\\n\\n### IV. Prolongational reduction\\n\\nProlongational reduction (PR) provides our \\"psychological\\" awareness of tensing and relaxing patterns in a given piece with precise structural terms. In time-span reduction, the hierarchy of less and more important events is established according to rhythmic stability. In prolongational reduction, hierarchy is concerned with relative stability expressed in terms of continuity and progression, the movement toward tension or relaxation, and the degree of closure or non-closure. A PR analysis also produces a tree-structure style hierarchical analysis, but this information is often conveyed in a visually condensed modified \\"slur\\" notation.\\n\\nThe need for prolongational reduction mainly arises from two limitations of time-span reductions. The first is that time-span reduction fails to express the sense of continuity produced by harmonic rhythm. The second is that time-span reduction—even though it establishes that particular pitch-events are heard in relation to a particular beat, within a particular group—fails to say anything about how music flows across these segments.\\n\\n### More on TSR vs PR\\n\\nIt is helpful to note some basic differences between a time-span tree produced by TSR and a prolongational tree produced by PR. First, though the basic branching divisions produced by the two trees are often the same or similar at high structural levels, branching variations between the two trees often occur as one travels further down towards the musical surface.\\n\\nA second and equally important differentiation is that a prolongational tree carries three types of branching: strong prolongation (represented by an open node at the branching point), weak prolongation (a filled node at the branching point) and progression (simple branching, with no node). Time-span trees do not make this distinction. All time-span tree branches are simple branches without nodes (though time-span tree branches are often annotated with other helpful comments).\\n\\n<youtube-embed video=\\"qWreUHbws9g\\" />\\n\\n## Rules\\n\\nEach of the four major hierarchical organizations (grouping structure, metrical structure, time-span reduction and prolongational reduction) is established through rules, which are in three categories:\\n\\n1. The well-formedness rules, which specify possible structural descriptions.\\n2. The preference rules, which draw on possible structural descriptions eliciting those descriptions that correspond to experienced listeners’ hearings of any particular piece.\\n3. The transformational rules, which provide a means of associating distorted structures with well-formed descriptions.\\n\\n### I. Grouping structure rules\\n\\n#### Grouping well-formedness rules (G~WFRs)\\n\\n1. \\"Any contiguous sequence of pitch-events, drum beats, or the like can constitute a group, and only contiguous sequences can constitute a group.\\"\\n2. \\"A piece constitutes a group.\\"\\n3. \\"A group may contain smaller groups.\\"\\n4. \\"If a group G1 contains part of a group G2, it must contain all of G2.\\"\\n5. 'If a group G1 contains a smaller group G2, then G1 must be exhaustively partitioned into smaller groups.\\"\\n\\n#### Grouping preference rules (G~PRs)\\n\\n1. \\"Avoid analyses with very small groups – the smaller, the less preferable.\\"\\n2. **Proximity:** Consider a sequence of four notes, n1–n4, the transition n2–n3 may be heard as a group boundary if: a.(slur/rest) the interval of time from the end of n2 is greater than that from the end of n1 to the beginning of n2 and that from the end of n3 to the beginning of n4 or if b.(attack/point) the interval of time between the attack points of n2 and n3 is greater than between those of n1 and n2 and between those of n3 and n4.\\n3. **Change:** Consider a sequence of four notes, n1–n4. The transition n2–n3 may be heard as a group boundary if marked by a. register, b. dynamics, c. articulation, or d. length.\\n4. **Intensification:** A larger-level group may be placed where the effects picked out by GPRs 2 and 3 are more pronounced.\\n5. **Symmetry:** \\"Prefer grouping analyses that most closely approach the ideal subdivision of groups into two parts of equal length.\\"\\n6. **Parallelism:** \\"Where two or more segments of music can be construed as parallel, they preferably form parallel parts of groups.\\"\\n7. **Time-span and prolongational stability:** \\"Prefer a grouping structure that results in more stable time-span and/or prolongational reductions.\\"\\n\\n#### Transformational grouping rules\\n\\n1. Grouping overlap (p. 60).\\n2. Grouping elision (p. 61).\\n\\n### II. Metrical structure rules\\n\\n#### Metrical well-formedness rules (M~WFRs)\\n\\n1. \\"Every attack point must be associated with a beat at the smallest metrical level present at that point in the piece.\\"\\n2. \\"Every beat at a given level must also be a beat at all smaller levels present at that point in that piece.\\"\\n3. \\"At each metrical level, strong beats are spaced either two or three beats apart.\\"\\n4. \\"The tactus and immediately larger metrical levels must consist of beats equally spaced throughout the piece. At subtactus metrical levels, weak beats must be equally spaced between the surrounding strong beats.\\"\\n\\n#### Metrical preference rules (M~PRs)\\n\\n1. **Parallelism:** \\"Where two or more groups or parts of groups can be construed as parallel, they preferably receive parallel metrical structure.\\"\\n2. **Strong beat early:** \\"Weakly prefer a metrical structure in which the strongest beat in a group appears relatively early in the group.\\"\\n3. **Event:** \\"Prefer a metrical structure in which beats of level Li that coincide with the inception of pitch-events are strong beats of Li.\\"\\n4. **Stress:** \\"Prefer a metrical structure in which beats of level Li that are stressed are strong beats of Li.\\"\\n5. **Length:** Prefer a metrical structure in which a relatively strong beat occurs at the inception of either relatively long: a. pitch-event; b. duration of a dynamic; c. slur; d. pattern of articulation; e. duration of a pitch in the relevant levels of the time-span reduction; f. duration of a harmony in the relevant levels of the time-span reduction (harmonic rhythm).\\n6. **Bass:** \\"Prefer a metrically stable bass.\\"\\n7. **Cadence:** \\"Strongly prefer a metrical structure in which cadences are metrically stable; that is, strongly avoid violations of local preference rules within cadences.\\"\\n8. **Suspension:** \\"Strongly prefer a metrical structure in which a suspension is on a stronger beat than its resolution.\\"\\n9. **Time-span interaction:** \\"Prefer a metrical analysis that minimizes conflict in the time-span reduction.\\"\\n10. **Binary regularity:** \\"Prefer metrical structures in which at each level every other beat is strong.\\"\\n\\n### Transformational metrical rule\\n\\n1. Metrical deletion (p. 101).\\n\\n### III. Time-span reduction rules\\n\\nTime-span reduction rules begin with two segmentation rules and proceed to the standard WFRs, PRs and TRs.\\n\\n#### Time-span segmentation rules\\n\\n1. \\"Every group in a piece is a time-span in the time-span segmentation of the piece.\\"\\n2. \\"In underlying grouping structure: a. each beat B of the smallest metrical level determines a time-span TB extending from B up to but not including the next beat of the smallest level; b. each beat B of metrical level Li determines a regular time-span of all beats of level Li-1 from B up to but not including (i) the next beat B’ of level Li or (ii) a group boundary, whichever comes sooner; and c. if a group boundary G intervenes between B and the preceding beat of the same level, B determines an augmented time-span T’B, which is the interval from G to the end of the regular time-span TB.\\"\\n\\n#### Time-span reduction well-formedness rules (TSR~WFRs)\\n\\n1. \\"For every time-span T there is an event e (or a sequence of events e1 – e2) that is the head of T.\\"\\n2. \\"If T does not contain any other time-span (that is, if T is the smallest level of time-spans), there e is whatever event occurs in T.\\"\\n3. If T contains other time-spans, let T1,...,Tn be the (regular or augmented) time-spans immediately contained in T and let e1,...,en be their respective heads. Then the head is defined depending on: a. ordinary reduction; b. fusion; c. transformation; d. cadential retention (p. 159).\\n4. \\"If a two-element cadence is directly subordinate to the head e of a time-span T, the final is directly subordinate to e and the penult is directly subordinate to the final.\\"\\n\\n#### Time-span reduction preference rules (TSR~PRs)\\n\\n1. (Metrical position) \\"Of the possible choices for head of time-span T, prefer that is in a relatively strong metrical position.\\"\\n2. (Local harmony) \\"Of the possible choices for head of time-span T, prefer that is: a. relatively intrinsically consonant, b. relatively closely related to the local tonic.\\"\\n3. (Registral extremes) \\"Of the possible choices for head of time-span T, weakly prefer a choice that has: a. a higher melodic pitch; b. a lower bass pitch.\\"\\n4. (Parallelism) \\"If two or more time-spans can be construed as motivically and/or rhythmically parallel, preferably assign them parallel heads.\\"\\n5. (Metrical stability) \\"In choosing the head of a time-span T, prefer a choice that results in more stable choice of metrical structure.\\"\\n6. (Prolongational stability) \\"In choosing the head of a time-span T, prefer a choice that results in more stable choice of prolongational structure.\\"\\n7. (Cadential retention) (p. 170).\\n8. (Structural beginning) \\"If for a time-span T there is a larger group G containing T for which the head of T can function as the structural beginning, then prefer as head of T an event relatively close to the beginning of T (and hence to the beginning of G as well).\\"\\n9. \\"In choosing the head of a piece, prefer the structural ending to the structural beginning.\\"\\n\\n### IV. Prolongational reduction rules\\n\\n#### Prolongational reduction well-formedness rules (PR~WFRs)\\n\\n1. \\"There is a single event in the underlying grouping structure of every piece that functions as prolongational head.\\"\\n2. \\"An event ei can be a direct elaboration of another pitch ej in any of the following ways: a. ei is a strong prolongation of ej if the roots, bass notes, and melodic notes of the two events are identical; b. ei is a weak prolongation of ej if the roots of the two events are identical but the bass and/or melodic notes differ; c. ei is a progression to or from ej if the harmonic roots of the two events are different.\\"\\n3. \\"Every event in the underlying grouping structure is either the prolongational head or a recursive elaboration of the prolongational head.\\"\\n4. (No crossing branches) \\"If an event ei is a direct elaboration of an event ej, every event between ei and ej must be a direct elaboration of either ei, ej, or some event between them.\\"\\n\\n#### Prolongational reduction preference rules (PR~PRs)\\n\\n1. (Time-span importance) \\"In choosing the prolongational most important event ek of a prolongational region (ei – ej), strongly prefer a choice in which ek is relatively time-span important.\\"\\n2. (Time-span segmentation) \\"Let ek be the prolongationally most important region (ei – ej). If there is a time-span that contains ei and ek but not ej, prefer a prolongational reduction in which ek is an elaboration of ei; similarly with the roles of ei and ej reversed.\\"\\n3. (Prolongational connection) \\"In choosing the prolongationally most important region (ei – ej), prefer an ek that attaches to as to form a maximally stable prolongational connections with one of the endpoints of the region.\\"\\n4. (Prolongational importance) \\"Let ek be the prolongationally most important region (ei – ej). Prefer a prolongational reduction in which ek is an elaboration of the prolongationally more important of the endpoints.\\"\\n5. (Parallelism) \\"Prefer a prolongational reduction in which parallel passages receive parallel analyses.\\"\\n6. (Normative prolongational structure) \\"A cadenced group preferably contains four (five) elements in its prolongational structure: a. a prolongational beginning; b. a prolongational ending consisting of one element of the cadences; (c. a right-branching prolongational as the most important direct elaboration direct of the prolongational beginning); d. a right-branching progression as the (next) most important direct elaboration of the prolongational beginning; e. a left-branching ‘subdominant’ progression as the most important elaboration of the first element of the cadence.\\"\\n\\n#### Prolongational reduction transformational rules\\n\\n1. Stability conditions for prolongational connection (p. 224): a. Branching condition; b. Pitch-collection condition; c. Melodic condition; d. Harmonic condition.\\n2. Interaction principle: \\"to make a sufficiently stable prolongational connection ek must be chosen from the events in the two most important levels of time-span reduction represented in (ei – ej).\\"\\n","frontmatter":{"title":"Generative theory of tonal music","description":"Formal description of the musical intuitions of a listener who is experienced in a musical idiom","date":"2021-11-13T00:00:00.000Z","cover":"/media_files/cover/theory-composition-generative-Analysis-of-the-beginning-of-Bachs-chorale-Ermuntre-Dich-mein-schwacher-Geist_Q320.jpg"},"url":"/theory/composition/generative/"},{"src":"---\\ntitle: Atonality and serialism\\ndescription: Arnold Schoenberg and his explorations of 12 tone composition techniques\\ncover: Richard-Paul-Lohse.jpg\\ndate: 2021-11-12\\n---\\n\\n<youtube-embed video=\\"2ucLa-xLElo\\" />\\n\\n## Atonality\\n\\nAtonality in its broadest sense is music that lacks a tonal center, or key. Atonality, in this sense, usually describes compositions written from about the early 20th-century to the present day, where a hierarchy of harmonies focusing on a single, central triad is not used, and the notes of the chromatic scale function independently of one another. More narrowly, the term atonality describes music that does not conform to the system of tonal hierarchies that characterized European classical music between the seventeenth and nineteenth centuries. \\"The repertory of atonal music is characterized by the occurrence of pitches in novel combinations, as well as by the occurrence of familiar pitch combinations in unfamiliar environments\\".\\n\\n<youtube-embed video=\\"DhdrKpw_VFc\\" />\\n\\nThe term is also occasionally used to describe music that is neither tonal nor serial, especially the pre-twelve-tone music of the Second Viennese School, principally Alban Berg, Arnold Schoenberg, and Anton Webern. However, \\"as a categorical label, 'atonal' generally means only that the piece is in the Western tradition and is not 'tonal'\\", although there are longer periods, e.g., medieval, renaissance, and modern modal music to which this definition does not apply. \\"Serialism arose partly as a means of organizing more coherently the relations used in the pre-serial 'free atonal' music. ... Thus, many useful and crucial insights about even strictly serial music depend only on such basic atonal theory\\".\\n\\nLate 19th- and early 20th-century composers such as Alexander Scriabin, Claude Debussy, Béla Bartók, Paul Hindemith, Sergei Prokofiev, Igor Stravinsky, and Edgard Varèse have written music that has been described, in full or in part, as atonal.\\n\\n<youtube-embed video=\\"1k3yb0o2uU0\\" />\\n\\n<youtube-embed video=\\"VCODCJ3dERs\\" />\\n\\n### Free atonality\\n\\nThe twelve-tone technique was preceded by Schoenberg's freely atonal pieces of 1908 to 1923, which, though free, often have as an \\"integrative element...a minute intervallic cell\\" that in addition to expansion may be transformed as with a tone row, and in which individual notes may \\"function as pivotal elements, to permit overlapping statements of a basic cell or the linking of two or more basic cells\\".\\n\\nThe twelve-tone technique was also preceded by nondodecaphonic serial composition used independently in the works of Alexander Scriabin, Igor Stravinsky, Béla Bartók, Carl Ruggles, and others. \\"Essentially, Schoenberg and Hauer systematized and defined for their own dodecaphonic purposes a pervasive technical feature of 'modern' musical practice, the ostinato.\\"\\n\\n### Composing atonal music\\n\\nSetting out to compose atonal music may seem complicated because of both the vagueness and generality of the term. Additionally George Perle explains that, \\"the 'free' atonality that preceded dodecaphony precludes by definition the possibility of self-consistent, generally applicable compositional procedures\\". However, he provides one example as a way to compose atonal pieces, a pre-twelve-tone technique piece by Anton Webern, which rigorously avoids anything that suggests tonality, to choose pitches that do not imply tonality. In other words, reverse the rules of the common practice period so that what was not allowed is required and what was required is not allowed. This is what was done by Charles Seeger in his explanation of dissonant counterpoint, which is a way to write atonal counterpoint.\\n\\nKostka and Payne list four procedures as operational in the atonal music of Schoenberg, all of which may be taken as negative rules. Avoidance of melodic or harmonic octaves, avoidance of traditional pitch collections such as major or minor triads, avoidance of more than three successive pitches from the same diatonic scale, and use of disjunct melodies (avoidance of conjunct melodies).\\n\\nFurther, Perle agrees with Oster and Katz that, \\"the abandonment of the concept of a root-generator of the individual chord is a radical development that renders futile any attempt at a systematic formulation of chord structure and progression in atonal music along the lines of traditional harmonic theory\\". Atonal compositional techniques and results \\"are not reducible to a set of foundational assumptions in terms of which the compositions that are collectively designated by the expression 'atonal music' can be said to represent 'a system' of composition\\". Equal-interval chords are often of indeterminate root, mixed-interval chords are often best characterized by their interval content, while both lend themselves to atonal contexts.\\n\\nPerle also points out that structural coherence is most often achieved through operations on intervallic cells. A cell \\"may operate as a kind of microcosmic set of fixed intervallic content, statable either as a chord or as a melodic figure or as a combination of both. Its components may be fixed with regard to order, in which event it may be employed, like the twelve-tone set, in its literal transformations. … Individual tones may function as pivotal elements, to permit overlapping statements of a basic cell or the linking of two or more basic cells\\".\\n\\nRegarding the post-tonal music of Perle, one theorist wrote: \\"While ... montages of discrete-seeming elements tend to accumulate global rhythms other than those of tonal progressions and their rhythms, there is a similarity between the two sorts of accumulates spatial and temporal relationships: a similarity consisting of generalized arching tone-centers linked together by shared background referential materials\\".\\n\\nAnother approach of composition techniques for atonal music is given by Allen Forte who developed the theory behind atonal music. Forte describes two main operations: transposition and inversion. Transposition can be seen as a rotation of t either clockwise or anti-clockwise on a circle, where each note of the chord is rotated equally. For example, if t = 2 and the chord is [0 3 6], transposition (clockwise) will be [2 5 8]. Inversion can be seen as a symmetry with respect to the axis formed by 0 and 6. If we carry on with our example [0 3 6] becomes [0 9 6].\\n\\nAn important characteristic are the invariants, which are the notes which stay identical after a transformation. No difference is made between the octave in which the note is played so that, for example, all C♯s are equivalent, no matter the octave in which they actually occur. This is why the 12-note scale is represented by a circle. This leads us to the definition of the similarity between two chords which considers the subsets and the interval content of each chord.\\n\\n## Serialism\\n\\nIn music, [serialism](https://en.wikipedia.org/wiki/Serialism) is a method of composition using series of pitches, rhythms, dynamics, timbres or other musical elements. Serialism began primarily with Arnold Schoenberg's twelve-tone technique, though some of his contemporaries were also working to establish serialism as a form of post-tonal thinking. Twelve-tone technique orders the twelve notes of the chromatic scale, forming a row or series and providing a unifying basis for a composition's melody, harmony, structural progressions, and variations. Other types of serialism also work with sets, collections of objects, but not necessarily with fixed-order series, and extend the technique to other musical dimensions (often called \\"parameters\\"), such as duration, dynamics, and timbre.\\n\\n<youtube-embed video=\\"9jqyU5oCZuQ\\" />\\n\\nThe idea of serialism is also applied in various ways in the visual arts, design, and architecture,and the musical concept has also been adapted in literature.\\n\\nIntegral serialism or total serialism is the use of series for aspects such as duration, dynamics, and register as well as pitch. Other terms, used especially in Europe to distinguish post–World War II serial music from twelve-tone music and its American extensions, are general serialism and multiple serialism.\\n\\nComposers such as Arnold Schoenberg, Anton Webern, Alban Berg, Karlheinz Stockhausen, Pierre Boulez, Luigi Nono, Milton Babbitt, Elisabeth Lutyens, Henri Pousseur, Charles Wuorinen and Jean Barraqué used serial techniques of one sort or another in most of their music. Other composers such as Béla Bartók, Luciano Berio, Benjamin Britten, John Cage, Aaron Copland, Ernst Krenek, Gyorgy Ligeti, Olivier Messiaen, Arvo Pärt, Walter Piston, Ned Rorem, Alfred Schnittke, Ruth Crawford Seeger, Dmitri Shostakovich, and Igor Stravinsky used serialism only in some of their compositions or only in some sections of pieces, as did some jazz composers, such as Bill Evans, Yusef Lateef, and Bill Smith.\\n\\n<youtube-embed video=\\"Rr9zUyoBHBY\\" />\\n\\n## Basic definitions\\n\\nSerialism is a method, \\"highly specialized technique\\", or \\"way\\" of composition. It may also be considered \\"a philosophy of life (Weltanschauung), a way of relating the human mind to the world and creating a completeness when dealing with a subject\\".\\n\\nSerialism is not by itself a system of composition or a style. Neither is pitch serialism necessarily incompatible with tonality, though it is most often used as a means of composing atonal music.\\n\\n\\"Serial music\\" is a problematic term because it is used differently in different languages and especially because, shortly after its coinage in French, it underwent essential alterations during its transmission to German. The term's use in connection with music was first introduced in French by René Leibowitz in 1947, and immediately afterward by Humphrey Searle in English, as an alternative translation of the German Zwölftontechnik (twelve-tone technique) or Reihenmusik (row music); it was independently introduced by Stockhausen and Herbert Eimert into German in 1955 as serielle Musik, with a different meaning, but also translated as \\"serial music\\".\\nTwelve-tone serialism\\n\\nSerialism of the first type is most specifically defined as a structural principle according to which a recurring series of ordered elements (normally a set—or row—of pitches or pitch classes) is used in order or manipulated in particular ways to give a piece unity. \\"Serial\\" is often broadly used to describe all music written in what Schoenberg called \\"The Method of Composing with Twelve Notes related only to one another\\", or dodecaphony, and methods that evolved from his methods. It is sometimes used more specifically to apply only to music in which at least one element other than pitch is treated as a row or series. Such methods are often called post-Webernian serialism. Other terms used to make the distinction are twelve-note serialism for the former and integral serialism for the latter.\\n\\nA row may be assembled pre-compositionally (perhaps to embody particular intervallic or symmetrical properties), or derived from a spontaneously invented thematic or motivic idea. The row's structure does not in itself define the structure of a composition, which requires development of a comprehensive strategy. The choice of strategy often depends on the relationships contained in a row class, and rows may be constructed with an eye to producing the relationships needed to form desired strategies.\\n\\nThe basic set may have additional restrictions, such as the requirement that it use each interval only once.\\n\\n### Non-twelve-tone serialism\\n\\n\\"The series is not an order of succession, but indeed a hierarchy—which may be independent of this order of succession\\".\\n\\nRules of analysis derived from twelve-tone theory do not apply to serialism of the second type: \\"in particular the ideas, one, that the series is an intervallic sequence, and two, that the rules are consistent\\". For example, Stockhausen's early serial works, such as Kreuzspiel and Formel, \\"advance in unit sections within which a preordained set of pitches is repeatedly reconfigured ... The composer's model for the distributive serial process corresponds to a development of the Zwölftonspiel of Josef Matthias Hauer\\". Goeyvaerts's Nummer 4\\n\\n> provides a classic illustration of the distributive function of seriality: 4 times an equal number of elements of equal duration within an equal global time is distributed in the most equable way, unequally with regard to one another, over the temporal space: from the greatest possible coïncidence to the greatest possible dispersion. This provides an exemplary demonstration of that logical principle of seriality: every situation must occur once and only once.\\n\\nHenri Pousseur, after initially working with twelve-tone technique in works like Sept Versets (1950) and Trois Chants sacrés (1951),\\n\\n> evolved away from this bond in Symphonies pour quinze Solistes [1954–55] and in the Quintette [à la mémoire d’Anton Webern, 1955], and from around the time of Impromptu [1955] encounters whole new dimensions of application and new functions.\\n\\n> The twelve-tone series loses its imperative function as a prohibiting, regulating, and patterning authority; its working-out is abandoned through its own constant-frequent presence: all 66 intervallic relations among the 12 pitches being virtually present. Prohibited intervals, like the octave, and prohibited successional relations, such as premature note repetitions, frequently occur, although obscured in the dense contexture. The number twelve no longer plays any governing, defining rôle; the pitch constellations no longer hold to the limitation determined by their formation. The dodecaphonic series loses its significance as a concrete model of shape (or a well-defined collection of concrete shapes) is played out. And the chromatic total remains active only, and provisionally, as a general reference.\\n\\nIn the 1960s Pousseur took this a step further, applying a consistent set of predefined transformations to preexisting music. One example is the large orchestral work Couleurs croisées (Crossed Colours, 1967), which performs these transformations on the protest song \\"We Shall Overcome\\", creating a succession of different situations that are sometimes chromatic and dissonant and sometimes diatonic and consonant. In his opera Votre Faust (Your Faust, 1960–68) Pousseur used many quotations, themselves arranged into a \\"scale\\" for serial treatment. This \\"generalised\\" serialism (in the strongest possible sense) aims not to exclude any musical phenomena, no matter how heterogeneous, in order \\"to control the effects of tonal determinism, dialectize its causal functions, and overcome any academic prohibitions, especially the fixing of an anti-grammar meant to replace some previous one\\".\\n\\nAt about the same time, Stockhausen began using serial methods to integrate a variety of musical sources from recorded examples of folk and traditional music from around the world in his electronic composition Telemusik (1966), and from national anthems in Hymnen (1966–67). He extended this serial \\"polyphony of styles\\" in a series of \\"process-plan\\" works in the late 1960s, as well as later in portions of Licht, the cycle of seven operas he composed between 1977 and 2003.\\n\\n## History of serial music\\n\\n### Before World War II\\n\\nIn the late 19th and early 20th century, composers began to struggle against the ordered system of chords and intervals known as \\"functional tonality\\". Composers such as Debussy and Strauss found ways to stretch the limits of the tonal system to accommodate their ideas. After a brief period of free atonality, Schoenberg and others began exploring tone rows, in which an ordering of the 12 pitches of the equal-tempered chromatic scale is used as the source material of a composition. This ordered set, often called a row, allowed for new forms of expression and (unlike free atonality) the expansion of underlying structural organizing principles without recourse to common practice harmony.\\n\\nTwelve-tone serialism first appeared in the 1920s, with antecedents predating that decade (instances of 12-note passages occur in Liszt's Faust Symphony and in Bach. Schoenberg was the composer most decisively involved in devising and demonstrating the fundamentals of twelve-tone serialism, though it is clear it is not the work of just one musician. In Schoenberg’s own words, his goal of l'invention contrariée was to show constraint in composition. Consequently, some reviewers have jumped to the conclusion that serialism acted as a predetermined method of composing to avoid the subjectivity and ego of a composer in favour of calculated measure and proportion.\\n\\n### After World War II\\n\\nAlong with John Cage's indeterminate music (music composed with the use of chance operations) and Werner Meyer-Eppler's aleatoricism, serialism was enormously influential in postwar music. Theorists such as Milton Babbitt and George Perle codified serial systems, leading to a mode of composition called \\"total serialism\\", in which every aspect of a piece, not just pitch, is serially constructed. Perle's 1962 text Serial Composition and Atonality became a standard work on the origins of serial composition in the music of Schoenberg, Berg, and Webern.[citation needed]\\n\\nThe serialization of rhythm, dynamics, and other elements of music was partly fostered by the work of Olivier Messiaen and his analysis students, including Karel Goeyvaerts and Boulez, in postwar Paris. Messiaen first used a chromatic rhythm scale in his Vingt Regards sur l'enfant-Jésus (1944), but he did not employ a rhythmic series until 1946–48, in the seventh movement, \\"Turangalîla II\\", of his Turangalîla-Symphonie. The first examples of such integral serialism are Babbitt's Three Compositions for Piano (1947), Composition for Four Instruments (1948), and Composition for Twelve Instruments (1948). He worked independently of the Europeans.[citation needed]\\nOlivier Messiaen's unordered series for pitch, duration, dynamics, and articulation from the pre-serial Mode de valeurs et d'intensités, upper division only—which Pierre Boulez adapted as an ordered row for his Structures I.\\n\\nSeveral of the composers associated with Darmstadt, notably Stockhausen, Goeyvaerts, and Pousseur, developed a form of serialism that initially rejected the recurring rows characteristic of twelve-tone technique in order to eradicate any lingering traces of thematicism. Instead of a recurring, referential row, \\"each musical component is subjected to control by a series of numerical proportions\\". In Europe, some serial and non-serial music of the early 1950s emphasized the determination of all parameters for each note independently, often resulting in widely spaced, isolated \\"points\\" of sound, an effect called first in German \\"punktuelle Musik\\" (\\"pointist\\" or \\"punctual music\\"), then in French \\"musique ponctuelle\\", but quickly confused with \\"pointillistic\\" (German \\"pointillistische\\", French \\"pointilliste\\"), the term associated with the densely packed dots in Seurat's paintings, even though the concept was unrelated.\\n\\nPieces were structured by closed sets of proportions, a method closely related to certain works from the de Stijl and Bauhaus movements in design and architecture some writers called \\"serial art\\", specifically the paintings of Piet Mondrian, Theo van Doesburg, Bart van Leck, Georg van Tongerloo, Richard Paul Lohse, and Burgoyne Diller, who had sought to \\"avoid repetition and symmetry on all structural levels and working with a limited number of elements\\".\\n\\nStockhausen described the final synthesis in this manner:\\n\\n> So serial thinking is something that's come into our consciousness and will be there forever: it's relativity and nothing else. It just says: Use all the components of any given number of elements, don't leave out individual elements, use them all with equal importance and try to find an equidistant scale so that certain steps are no larger than others. It's a spiritual and democratic attitude toward the world. The stars are organized in a serial way. Whenever you look at a certain star sign you find a limited number of elements with different intervals. If we more thoroughly studied the distances and proportions of the stars we'd probably find certain relationships of multiples based on some logarithmic scale or whatever the scale may be.\\n\\nStravinsky's adoption of twelve-tone serial techniques shows the level of influence serialism had after the Second World War. Previously Stravinsky had used series of notes without rhythmic or harmonic implications. Because many of the basic techniques of serial composition have analogs in traditional counterpoint, uses of inversion, retrograde, and retrograde inversion from before the war do not necessarily indicate Stravinsky was adopting Schoenbergian techniques. But after meeting Robert Craft and other younger composers, Stravinsky began to study Schoenberg's music, as well as that of Webern and later composers, and to adapt their techniques in his work, using, for example, serial techniques applied to fewer than twelve notes. During the 1950s he used procedures related to Messiaen, Webern and Berg. While it is inaccurate to call them all \\"serial\\" in the strict sense, all his major works of the period have clear serialist elements.[citation needed]\\n\\nDuring this period, the concept of serialism influenced not only new compositions but also scholarly analysis of the classical masters. Adding to their professional tools of sonata form and tonality, scholars began to analyze previous works in the light of serial techniques; for example, they found the use of row technique in previous composers going back to Mozart and Beethoven. In particular, the orchestral outburst that introduces the development section halfway through the last movement of Mozart's Symphony No. 40 is a tone row that Mozart punctuates in a very modern and violent way that Michael Steinberg called \\"rude octaves and frozen silences\\".\\n\\nRuth Crawford Seeger extended serial control to parameters other than pitch and to formal planning as early as 1930–33 in a fashion that goes beyond Webern but was less thoroughgoing than the later practices of Babbitt and European postwar composers.[citation needed] Charles Ives's 1906 song \\"The Cage\\" begins with piano chords presented in incrementally decreasing durations, an early example of an overtly arithmetic duration series independent of meter (like Nono's six-element row shown above), and in that sense a precursor to Messiaen’s style of integral serialism. The idea of organizing pitch and rhythm according to similar or related principles is also suggested by both Henry Cowell's New Musical Resources (1930) and the work of Joseph Schillinger.[citation needed]\\n\\n## Reactions to serialism\\n\\n> the first time I ever heard Webern in a concert performance …[t]he impression it made on me was the same as I was to experience a few years later when … I first laid eyes on a Mondriaan canvas...: those things, of which I had acquired an extremely intimate knowledge, came across as crude and unfinished when seen in reality.\\n\\nKarel Goeyvaerts on Anton Webern's music.\\n\\nSome music theorists have criticized serialism on the basis that its compositional strategies are often incompatible with the way the human mind processes a piece of music. Nicolas Ruwet (1959) was one of the first to criticise serialism by a comparison with linguistic structures, citing theoretical claims by Boulez and Pousseur, taking as specific examples bars from Stockhausen's Klavierstücke I & II, and calling for a general reexamination of Webern's music. Ruwet specifically names three works as exempt from his criticism: Stockhausen's Zeitmaße and Gruppen, and Boulez's Le marteau sans maître.\\n\\nIn response, Pousseur questioned Ruwet's equivalence between phonemes and notes. He also suggested that, if analysis of Le marteau sans maître and Zeitmaße, \\"performed with sufficient insight\\", were to be made from the point of view of wave theory—taking into account the dynamic interaction of the different component phenomena, which creates \\"waves\\" that interact in a sort of frequency modulation—the analysis \\"would accurately reflect the realities of perception\\". This was because these composers had long since acknowledged the lack of differentiation found in punctual music and, becoming increasingly aware of the laws of perception and complying better with them, \\"paved the way to a more effective kind of musical communication, without in the least abandoning the emancipation that they had been allowed to achieve by this 'zero state' that was punctual music\\". One way this was achieved was by developing the concept of \\"groups\\", which allows structural relationships to be defined not only between individual notes but also at higher levels, up to the overall form of a piece. This is \\"a structural method par excellence\\", and a sufficiently simple conception that it remains easily perceptible. Pousseur also points out that serial composers were the first to recognize and attempt to move beyond the lack of differentiation within certain pointillist works. Pousseur later followed up on his own suggestion by developing his idea of \\"wave\\" analysis and applying it to Stockhausen's Zeitmaße in two essays.\\n\\nLater writers have continued both lines of reasoning. Fred Lerdahl, for example, in his essay \\"Cognitive Constraints on Compositional Systems\\", argues that serialism's perceptual opacity ensures its aesthetic inferiority. Lerdahl has in turn been criticized for excluding \\"the possibility of other, non-hierarchical methods of achieving musical coherence,\\" and for concentrating on the audibility of tone rows, and the portion of his essay focusing on Boulez's \\"multiplication\\" technique (exemplified in three movements of Le Marteau sans maître) has been challenged on perceptual grounds by Stephen Heinemann and Ulrich Mosch. Ruwet's critique has also been criticised for making \\"the fatal mistake of equating visual presentation (a score) with auditive presentation (the music as heard)\\".\\n\\nIn all these reactions discussed above, the \\"information extracted\\", \\"perceptual opacity\\", \\"auditive presentation\\" (and constraints thereof) pertain to what defines serialism, namely use of a series. And since Schoenberg remarked, \\"in the later part of a work, when the set [series] had already become familiar to the ear\\", it has been assumed that serial composers expect their series to be aurally perceived. This principle even became the premise of empirical investigation in the guise of \\"probe-tone\\" experiments testing listeners' familiarity with a row after exposure to its various forms (as would occur in a 12-tone work). In other words the supposition in critiques of serialism has been that, if a composition is so intricately structured by and around a series, that series should ultimately be clearly perceived or that a listener ought to become aware of its presence or importance. Babbitt denied this:\\n\\n> That's not the way I conceive of a set [series]. This is not a matter of finding the lost [series]. This is not a matter of cryptoanalysis (where's the hidden [series]?). What I'm interested in is the effect it might have, the way it might assert itself not necessarily explicitly.\\n\\nSeemingly in accord with Babbitt's statement, but ranging over such issues as perception, aesthetic value, and the \\"poietic fallacy\\", Walter Horn offers a more extensive explanation of the serialism (and atonality) controversy.\\n\\nWithin the community of modern music, exactly what constituted serialism was also a matter of debate. The conventional English usage is that the word \\"serial\\" applies to all twelve-tone music, which is a subset of serial music, and it is this usage that is generally intended in reference works. Nevertheless, a large body of music exists that is called \\"serial\\" but does not employ note-rows at all, let alone twelve-tone technique, e.g., Stockhausen's Klavierstücke I–IV (which use permuted sets), his Stimmung (with pitches from the overtone series, which is also used as the model for the rhythms), and Pousseur's Scambi (where the permuted sounds are made exclusively from filtered white noise).[citation needed]\\n\\nWhen serialism is not limited to twelve-tone techniques, a contributing problem is that the word \\"serial\\" is seldom if ever defined. In many published analyses of individual pieces the term is used while actual meaning is skated around.\\n\\n## Theory of twelve-tone serial music\\n\\nDue to Babbitt's work, in the mid-20th century serialist thought became rooted in set theory and began to use a quasi-mathematical vocabulary for the manipulation of the basic sets. Musical set theory is often used to analyze and compose serial music, and is also sometimes used in tonal and nonserial atonal analysis.[citation needed]\\n\\nThe basis for serial composition is Schoenberg's twelve-tone technique, where the 12 notes of the chromatic scale are organized into a row. This \\"basic\\" row is then used to create permutations, that is, rows derived from the basic set by reordering its elements. The row may be used to produce a set of intervals, or a composer may derive the row from a particular succession of intervals. A row that uses all of the intervals in their ascending form once is an all-interval row. In addition to permutations, the basic row may have some set of notes derived from it, which is used to create a new row. These are derived sets.[citation needed]\\n\\nBecause there are tonal chord progressions that use all twelve notes, it is possible to create pitch rows with very strong tonal implications, and even to write tonal music using twelve-tone technique. Most tone rows contain subsets that can imply a pitch center; a composer can create music centered on one or more of the row's constituent pitches by emphasizing or avoiding these subsets, respectively, as well as through other, more complex compositional devices.\\n\\nTo serialize other elements of music, a system quantifying an identifiable element must be created or defined (this is called \\"parametrization\\", after the term in mathematics). For example, if duration is serialized, a set of durations must be specified; if tone colour (timbre) is serialized, a set of separate tone colours must be identified; and so on.[citation needed]\\n\\nThe selected set or sets, their permutations and derived sets form the composer's basic material.[citation needed]\\n\\nComposition using twelve-tone serial methods focuses on each appearance of the collection of twelve chromatic notes, called an aggregate. (Sets of more or fewer pitches, or of elements other than pitch, may be treated analogously.) One principle operative in some serial compositions is that no element of the aggregate should be reused in the same contrapuntal strand (statement of a series) until all the other members have been used, and each member must appear only in its place in the series. Yet, since most serial compositions have multiple (at least two, sometimes as many as a few dozen) series statements occurring concurrently, interwoven with each other in time, and feature repetitions of some of their pitches, this principle as stated is more a referential abstraction than a description of the concrete reality of a musical work that is termed \\"serial\\".[citation needed]\\n\\nA series may be divided into subsets, and the members of the aggregate not part of a subset are said to be its complement. A subset is self-complementing if it contains half of the set and its complement is also a permutation of the original subset. This is most commonly seen with hexachords, six-note segments of a tone row. A hexachord that is self-complementing for a particular permutation is called prime combinatorial. A hexachord that is self-complementing for all the canonic operations—inversion, retrograde, and retrograde inversion—is called all-combinatorial.\\n\\n### Twelve-tone technique\\n\\n[The twelve-tone technique](https://en.wikipedia.org/wiki/Twelve-tone_technique) — also known as dodecaphony, twelve-tone serialism, and (in British usage) twelve-note composition — is a method of musical composition first devised by Austrian composer Josef Matthias Hauer, who published his \\"law of the twelve tones\\" in 1919. In 1923, Arnold Schoenberg (1874–1951) developed his own, better-known version of 12-tone technique, which became associated with the \\"Second Viennese School\\" composers, who were the primary users of the technique in the first decades of its existence. The technique is a means of ensuring that all 12 notes of the chromatic scale are sounded as often as one another in a piece of music while preventing the emphasis of any one note through the use of tone rows, orderings of the 12 pitch classes. All 12 notes are thus given more or less equal importance, and the music avoids being in a key. Over time, the technique increased greatly in popularity and eventually became widely influential on 20th-century composers. Many important composers who had originally not subscribed to or actively opposed the technique, such as Aaron Copland and Igor Stravinsky,[clarification needed] eventually adopted it in their music.\\n\\nSchoenberg himself described the system as a \\"Method of composing with twelve tones which are related only with one another\\". It is commonly considered a form of serialism.\\n\\nSchoenberg's fellow countryman and contemporary Hauer also developed a similar system using unordered hexachords or tropes—but with no connection to Schoenberg's twelve-tone technique. Other composers have created systematic use of the chromatic scale, but Schoenberg's method is considered to be historically and aesthetically most significant.\\n\\nhttps://www.musictheory.net/calculators/matrix\\n\\n### Tone row\\n\\nThe basis of the twelve-tone technique is the [tone row](https://en.wikipedia.org/wiki/Tone_row), an ordered arrangement of the twelve notes of the chromatic scale (the twelve equal tempered pitch classes). There are four postulates or preconditions to the technique which apply to the row (also called a set or series), on which a work or section is based:\\n\\n1. The row is a specific ordering of all twelve notes of the chromatic scale (without regard to octave placement).\\n2. No note is repeated within the row.\\n3. The row may be subjected to interval-preserving transformations—that is, it may appear in inversion (denoted I), retrograde (R), or retrograde-inversion (RI), in addition to its \\"original\\" or prime form (P).\\n4. The row in any of its four transformations may begin on any degree of the chromatic scale; in other words it may be freely transposed. (Transposition being an interval-preserving transformation, this is technically covered already by 3.) Transpositions are indicated by an integer between 0 and 11 denoting the number of semitones: thus, if the original form of the row is denoted P0, then P1 denotes its transposition upward by one semitone (similarly I1 is an upward transposition of the inverted form, R1 of the retrograde form, and RI1 of the retrograde-inverted form).\\n\\n(In Hauer's system postulate 3 does not apply.)\\n\\nA particular transformation (prime, inversion, retrograde, retrograde-inversion) together with a choice of transpositional level is referred to as a set form or row form. Every row thus has up to 48 different row forms. (Some rows have fewer due to symmetry; see the sections on derived rows and invariance below.)\\n\\nhttps://en.wikipedia.org/wiki/List_of_tone_rows_and_series\\n\\n### Schoenberg's mature practice\\n\\nTen features of Schoenberg's mature twelve-tone practice are characteristic, interdependent, and interactive:\\n\\n1. Hexachordal inversional combinatoriality\\n2. Aggregates\\n3. Linear set presentation\\n4. Partitioning\\n5. Isomorphic partitioning\\n6. Invariants\\n7. Hexachordal levels\\n8. Harmony, \\"consistent with and derived from the properties of the referential set\\"\\n9. Metre, established through \\"pitch-relational characteristics\\"\\n10. Multidimensional set presentations.\\n\\n### Unified field\\n\\nIn music, [unified field](https://en.wikipedia.org/wiki/Unified_field) is the 'unity of musical space' created by the free use of melodic material as harmonic material and vice versa.\\n\\nThe technique is most associated with the twelve-tone technique, created by its 'total thematicism' where a tone-row (melody) generates all (harmonic) material. It was also used by Alexander Scriabin, though from a diametrically opposed direction, created by his use of extremely slow harmonic rhythm which eventually led to his use of unordered pitch-class sets, usually hexachords (of six pitches) as harmony from which melody may also be created. (Samson 1977)\\n\\nIt may also be observed in Igor Stravinsky's Russian period, such as in Les Noces, derived from his use of folk melodies as generating material and influenced by shorter pieces by Claude Debussy, such as Voiles, and Modest Mussorgsky. In Béla Bartók's Bagatelles, and several of Alfredo Casella's Nine Piano Pieces such as No. 4 'In Modo Burlesco' the close intervallic relationship between motive and chord creates or justifies the great harmonic dissonance.\\n\\n> Webern was the only one...who was conscious of a new sound-dimension, of the abolition of horizontal-vertical opposition, so that he saw in the series only a way of giving structure to the sound-space....That functional redistribution of intervals toward which he tended marks an extremely important moment in the history of language.\\n> — Pierre Boulez, Notes of an Apprenticeship, p.149,\\n\\nhttps://en.wikipedia.org/wiki/Who_Cares_if_You_Listen\\n\\n<a href=\\"/media/pdf/who-cares-if-you-listen.pdf\\" >Who cares if you listen?</a>\\n","frontmatter":{"title":"Atonality and serialism","description":"Arnold Schoenberg and his explorations of 12 tone composition techniques","cover":"/media_files/cover/theory-composition-serialism-Richard-Paul-Lohse.jpg","date":"2021-11-12T00:00:00.000Z"},"url":"/theory/composition/serialism/"},{"src":"---\\ntitle: Harmony study\\ndescription: Different approaches to harmony in music and everything else\\ndate: 2021-11-10\\n---\\n\\n## Ancient Greece\\n\\nIn Greek mythology, Harmonia (/hɑːrˈmoʊniə/; Ancient Greek: Ἁρμονία) is the immortal goddess of harmony and concord. Her Roman counterpart is Concordia. Her Greek opposite is Eris, whose Roman counterpart is Discordia.\\n\\nAccording to one account, she is the daughter of Ares and Aphrodite. By another account, Harmonia was from Samothrace and was the daughter of Zeus and Electra, her brother Iasion being the founder of the mystic rites celebrated on the island.\\n\\nAlmost always, Harmonia is the wife of Cadmus. With Cadmus, she was the mother of Ino, Polydorus, Autonoë, Agave, and Semele. Their youngest son was Illyrius.\\n\\nHe was the first Greek hero and, alongside Perseus and Bellerophon, the greatest hero and slayer of monsters before the days of Heracles.\\n\\nCadmus was credited by the ancient Greeks (such as Herodotus c. 484 – c. 425 BC, one of the first Greek historians, but one who also wove standard myths and legends through his work) with introducing the original Phoenician alphabet to the Greeks, who adapted it to form their Greek alphabet. Herodotus estimates that Cadmus lived sixteen hundred years before his time, which would be around 2000 BC.\\n\\n### Pythagoreans\\n\\nPythagoras pioneered the mathematical and experimental study of music. He objectively measured physical quantities, such as the length of a string, and discovered quantitative mathematical relationships of music through arithmetic ratios. Pythagoras attempted to explain subjective psychological and aesthetic feelings, such as the enjoyment of musical harmony. Pythagoras and his students experimented systematically with strings of varying length and tension, with wind instruments, with brass discs of the same diameter but different thickness, and with identical vases filled with different levels of water. Early Pythagoreans established quantitative ratios between the length of a string or pipe and the pitch of notes and the frequency of string vibration.\\n\\nPythagoras is credited with discovering that the most harmonious musical intervals are created by the simple numerical ratio of the first four natural numbers which derive respectively from the relations of string length: the octave (1/2), the fifth (2/3) and the fourth (3/4). The sum of those numbers 1 + 2 + 3 + 4 = 10 was for Pythagoreans the perfect number, because it contained in itself \\"the whole essential nature of numbers\\". Werner Heisenberg has called this formulation of musical arithmetic as \\"among the most powerful advances of human science\\" because it enables the measurement of sound in space.\\n\\nPythagorean tuning is a system of musical tuning in which the frequency ratios of all intervals are based on the ratio 3:2. This ratio, also known as the \\"pure\\" perfect fifth, is chosen because it is one of the most consonant and easiest to tune by ear and because of importance attributed to the integer 3. As Novalis put it, \\"The musical proportions seem to me to be particularly correct natural proportions.\\"\\n\\nThe fact that mathematics could explain the human sentimental world had a profound impact on the Pythagorean philosophy. Pythagoreanism became the quest for establishing the fundamental essences of reality. Pythagorean philosophers advanced the unshakable belief that the essence of all thing are numbers and that the universe was sustained by harmony. According to ancient sources music was central to the lives of those practicing Pythagoreanism. They used medicines for the purification (katharsis) of the body and, according to Aristoxenus, music for the purification of the soul. Pythagoreans used different types of music to arouse or calm their souls.\\n\\n> ![](./Pythagoras_and_Philolaus.png)\\n>\\n> Medieval woodcut by Franchino Gaffurio, depicting Pythagoras and Philolaus conducting musical investigations.\\n\\nFor Pythagoreans, harmony signified the \\"unification of a multifarious composition and the agreement of unlike spirits\\". In Pythagoreanism, numeric harmony was applied in mathematical, medical, psychological, aesthetic, metaphysical and cosmological problems. For Pythagorean philosophers, the basic property of numbers was expressed in the harmonious interplay of opposite pairs. Harmony assured the balance of opposite forces. Pythagoras had in his teachings named numbers and the symmetries of them as the first principle, and called these numeric symmetries harmony. This numeric harmony could be discovered in rules throughout nature. Numbers governed the properties and conditions of all beings and were regarded the causes of being in everything else. Pythagorean philosophers believed that numbers were the elements of all beings and the universe as a whole was composed of harmony and numbers.\\n\\n## Ancient Rome\\n\\n### Concordia discors\\n\\n> Cum tu inter scabiem tantam et contagia lucri\\n> Nil parvum sapias et adhuc sublimia cures:\\n> Quae mare conpescant causae, quid temperet annum,\\n> Stellae sponte sua iussaene vagentur et errent,\\n> Quid premat obscurum lunae, quid proferat orbem,\\n> Quid velit et possit rerum concordia discors,\\n> Empedocles an Stertinium deliret acumen.\\n> — Horat. Epist. I,12 (23-20 BCE)\\n\\n> Temporis angusti mansit concordia discors\\n> Paxque fuit non sponte ducum  …\\n> — Lucan. Bell. civ. I, vers.98-99 (48-65 AD)\\n\\n## Discordia concors\\n\\n> …faciuntque deum per quattuor artus\\n> Et mundi struxere globum prohibentque requiri\\n> Ultra se quicquam, cum per se cuncta crearint:\\n> Frigida nec calidis desint aut umida siccis,\\n> Spiritus aut solidis, sitque haec discordia concors\\n> Quae nexus habilis et opus generabile fingit\\n> Atque omnis partus elementa capacia reddit:\\n> Semper erit pugna ingeniis, dubiumque manebit\\n> Quod latet et tantum supra est hominemque deumque.\\n> — Manilius. Astronomica, I.137-146\\n\\n## Renaissance\\n\\n> ![](./Banchieri1.jpg)\\n> Adriano Banchieri (1628)\\n\\n<youtube-embed video=\\"eRkgK4jfi6M\\" />\\n","frontmatter":{"title":"Harmony study","description":"Different approaches to harmony in music and everything else","date":"2021-11-10T00:00:00.000Z"},"url":"/theory/harmony/study/"},{"src":"---\\ntitle: Musical form\\ndescription: The structure of a musical composition or performance\\ncover: 100122828-0232_Lohse_Zwei_Themen_web.jpg\\ndate: 2021-11-02\\nlinks:\\n  - https://en.wikipedia.org/wiki/List_of_classical_music_genres\\n---\\n\\nIn music, [form](https://en.wikipedia.org/wiki/Musical_form) refers to the structure of a musical composition or performance. In his book, Worlds of Music, Jeff Todd Titon suggests that a number of organizational elements may determine the formal structure of a piece of music, such as \\"the arrangement of musical units of rhythm, melody, and/or harmony that show repetition or variation, the arrangement of the instruments (as in the order of solos in a jazz or bluegrass performance), or the way a symphonic piece is orchestrated\\", among other factors.\\n\\nThese organizational elements may be broken into smaller units called phrases, which express a musical idea but lack sufficient weight to stand alone. Musical form unfolds over time through the expansion and development of these ideas.\\n\\nCompositions that do not follow a fixed structure and rely more on improvisation are considered free-form. A fantasia is an example of this.\\n\\n## Labeling procedures\\n\\nTo aid in the process of describing form, musicians have developed a simple system of labeling musical units with letters. In his textbook \\"Listening to Music\\", professor Craig Wright writes,\\n\\n> The first statement of a musical idea is designated A. Subsequent contrasting sections are labeled B, C, D, and so on. If the first or any other musical unit returns in varied form, then that variation is indicated by a superscript number-- A1 and B2, for example. Subdivisions of each large musical unit are shown by lowercase letters (a, b, and so on).\\n\\nSome writers also use a prime label (such as B', pronounced \\"B prime\\", or B'', pronounced \\"B double prime\\") to denote sections that are closely related, but vary slightly.\\n\\n## Levels of organization\\n\\nThe founding level of musical form can be divided into two parts:\\n\\n- The arrangement of the pulse into unaccented and accented beats, the cells of a measure that, when harmonized, may give rise to a motif or figure.\\n- The further organization of such a measure, by repetition and variation, into a true musical phrase having a definite rhythm and duration that may be implied in melody and harmony, defined, for example, by a long final note and a breathing space. This \\"phrase\\" may be regarded as the fundamental unit of musical form: it may be broken down into measures of two or three beats, but its distinctive nature will then be lost. Even at this level, the importance of the principles of repetition and contrast, weak and strong, climax and repose, can be seen. Thus, form may be understood on three levels of organization. For the purpose of this exposition, these levels can be roughly designated as passage, piece, and cycle.\\n\\n### Passage\\n\\nThe smallest level of construction concerns the way musical phrases are organized into musical sentences and \\"paragraphs\\" such as the verse of a song. This may be compared to, and is often decided by, the verse form or meter of the words or the steps of a dance.\\n\\nFor example, the twelve bar blues is a specific verse form, while common meter is found in many hymns and ballads and, again, the Elizabethan galliard, like many dances, requires a certain rhythm, pace and length of melody to fit its repeating pattern of steps. Simpler styles of music may be more or less wholly defined at this level of form, which therefore does not differ greatly from the loose sense first mentioned and which may carry with it rhythmic, harmonic, timbral, occasional and melodic conventions.\\n\\n### Piece (or movement)\\n\\nThe next level concerns the entire structure of any single self-contained musical piece or movement. If the hymn, ballad, blues or dance alluded to above simply repeats the same musical material indefinitely then the piece is said to be in strophic form overall. If it repeats with distinct, sustained changes each time, for instance in setting, ornamentation or instrumentation, then the piece is a theme and variations. If two distinctly different themes are alternated indefinitely, as in a song alternating verse and chorus or in the alternating slow and fast sections of the Hungarian czardas, then this gives rise to a simple binary form. If the theme is played (perhaps twice), then a new theme is introduced, the piece then closing with a return to the first theme, we have a simple ternary form.\\n\\nGreat arguments and misunderstanding can be generated by such terms as 'ternary' and 'binary', as a complex piece may have elements of both at different organizational levels.[citation needed] A minuet, like any Baroque dance, generally had simple binary structure (AABB), however, this was frequently extended by the introduction of another minuet arranged for solo instruments (called the trio), after which the first was repeated again and the piece ended—this is a ternary form—ABA: the piece is binary on the lower compositional level but ternary on the higher. Organisational levels are not clearly and universally defined in western musicology, while words like \\"section\\" and \\"passage\\" are used at different levels by different scholars whose definitions, as Schlanker[full citation needed] points out, cannot keep pace with the myriad innovations and variations devised by musicians.\\n\\n### Cycle\\n\\nThe grandest level of organization may be referred to as \\"cyclical form\\".[citation needed] It concerns the arrangement of several self-contained pieces into a large-scale composition. For example, a set of songs with a related theme may be presented as a song-cycle, whereas a set of Baroque dances were presented as a suite. The opera and ballet may organize song and dance into even larger forms. The symphony, generally considered to be one piece, nevertheless divides into multiple movements (which can usually work as a self-contained piece if played alone). This level of musical form, though it again applies and gives rise to different genres, takes more account of the methods of musical organisation used. For example: a symphony, a concerto and a sonata differ in scale and aim, yet generally resemble one another in the manner of their organization. The individual pieces which make up the larger form may be called movements.\\n\\n## Common forms in Western music\\n\\nScholes suggested that European classical music had only six stand-alone forms: simple binary, simple ternary, compound binary, rondo, air with variations, and fugue (although musicologist Alfred Mann emphasized that the fugue is primarily a method of composition that has sometimes taken on certain structural conventions).\\n\\nCharles Keil classified forms and formal detail as \\"sectional, developmental, or variational.\\"\\n\\n### Sectional form\\n\\nThis form is built from a sequence of clear-cut units that may be referred to by letters but also often have generic names such as introduction and coda, exposition, development and recapitulation, verse, chorus or refrain, and bridge. Sectional forms include:\\n\\n#### Strophic form\\n\\n[Strophic form](https://en.wikipedia.org/wiki/Strophic_form) – also called verse-repeating form, chorus form, AAA song form, or one-part song form – is a song structure in which all verses or stanzas of the text are sung to the same music. Contrasting song forms include through-composed, with new music written for every stanza, and ternary form, with a contrasting central section.\\n\\nThe term is derived from the Greek word στροφή, strophē, meaning \\"turn\\". It is the simplest and most durable of musical forms, extending a piece of music by repetition of a single formal section. This may be analyzed as \\"A A A...\\". This additive method is the musical analogue of repeated stanzas in poetry or lyrics and, in fact, where the text repeats the same rhyme scheme from one stanza to the next, the song's structure also often uses either the same or very similar material from one stanza to the next.\\n\\nA modified strophic form varies the pattern in some stanzas (A A' A\\"...) somewhat like a rudimentary theme and variations. Contrasting verse-chorus form is a binary form that alternates between two sections of music (ABAB), although this may also be interpreted as constituting a larger strophic verse-refrain form. While the terms 'refrain' and 'chorus' are often used interchangeably, 'refrain' may indicate a recurring line of identical melody and lyrics as a part of the verse (as in \\"Blowin' in the Wind\\": \\"...the answer my friend...\\"), while 'chorus' means an independent form section (as in \\"Yellow Submarine\\": \\"We all live in...\\").\\n\\nMany folk and popular songs are strophic in form, including the twelve-bar blues, ballads, hymns and chants. Examples include \\"Barbara Allen\\", \\"Erie Canal\\", and \\"Michael, Row the Boat Ashore\\". Also \\"Oh! Susanna\\" (A = verse & chorus).\\n\\nMany classical art songs are also composed in strophic form, from the 17th century French air de cour to 19th century German lieder and beyond. Haydn used the strophic variation form in many of his string quartets and a few of his symphonies, employed almost always in the slow second movement. Franz Schubert composed many important strophic lieder, including settings of both narrative poems and simpler, folk-like texts, such as his \\"Heidenröslein\\" and \\"Der Fischer\\". Several of the songs in his song cycle Die schöne Müllerin use strophic form.\\n\\n#### Medley or \\"chain\\" form\\n\\nMedley, potpourri or chain form is the extreme opposite, that of \\"unrelieved variation\\": it is simply an indefinite sequence of self-contained sections (ABCD...), sometimes with repeats (AABBCCDD...).\\n\\n[Potpourri or Pot-Pourri](<https://en.wikipedia.org/wiki/Potpourri_(music)>) (/ˌpoʊpʊˈriː/; French, literally \\"putrid pot\\") is a kind of musical form structured as ABCDEF..., the same as medley or, sometimes, fantasia. It is often used in light, easy-going and popular types of music.\\n\\nThis is a form of arrangement where the individual sections are simply juxtaposed with no strong connection or relationship. This type of form is organized by the principle of non-repetition. This is usually to be applied to a composition that consists of a string of favourite tunes, like a potpourri based on either some popular opera, operetta, or a collection of songs, dances, etc.\\n\\nThe term has been in use since the beginning of the 18th century, or to be more specific, since it was used by the French music publisher Christophe Ballard (1641–1715) for the edition of a collection of pieces in 1711. In the 18th century the term was used in France for collections of songs which, with a thematic link, were sometimes given stage presentation. Later the term was used also for instrumental collections, like the \\"Potpourry français\\", a collection of originally unconnected dance pieces issued by the publisher Bouïn.\\n\\nPotpourris became especially popular in the 19th century. The opera overtures of French composers, such as François-Adrien Boïeldieu (1775–1834), Daniel Auber (1782–1871) and Ferdinand Hérold (1791–1833), or the Englishman Arthur Sullivan (1842–1900) belong to this type. Richard Strauss called the overture to his Die schweigsame Frau a \\"pot-pourri\\".\\n\\nThe \\"overtures\\" to light modern stage works (e.g. operettas or musicals) are almost always written in potpourri form, using airs from the work in question. There is usually some structure to the order presented though. The opening is usually a fanfare or majestic theme (presumably the supposed hoped-for most popular song number), followed by a romantic number, then a comical number; and finally a return to the opening theme or a variation thereof.\\n\\n#### Binary form\\n\\nThe term [\\"Binary Form\\"](https://en.wikipedia.org/wiki/Binary_form) is used to describe a musical piece with two sections that are about equal in length. Binary Form can be written as AB or AABB. Using the example of Greensleeves provided, the first system is almost identical to the second system. We call the first system A and the second system A' (A prime) because of the slight difference in the last measure and a half. The next two systems (3rd and 4th) are almost identical as well, but a new musical idea entirely than the first two systems. We call the third system B and the fourth system B' (B prime) because of the slight difference in the last measure and a half. As a whole, this piece of music is in Binary Form: AA'BB'.\\n\\nBinary form is a musical form in 2 related sections, both of which are usually repeated. Binary is also a structure used to choreograph dance. In music this is usually performed as A-A-B-B.\\n\\nBinary form was popular during the Baroque period, often used to structure movements of keyboard sonatas. It was also used for short, one-movement works. Around the middle of the 18th century, the form largely fell from use as the principal design of entire movements as sonata form and organic development gained prominence. When it is found in later works, it usually takes the form of the theme in a set of variations, or the Minuet, Scherzo, or Trio sections of a \\"minuet and trio\\" or \\"scherzo and trio\\" movement in a sonata, symphony, etc. Many larger forms incorporate binary structures, and many more complicated forms (such as the 18th-century sonata form) share certain characteristics with binary form.\\n\\n##### Structure\\n\\nA typical example of a piece in binary form has two large sections of roughly equal duration. The first will begin in a certain key, which will often, (but not always), modulate to a closely related key. Pieces in a major key will usually modulate to the dominant, (the fifth scale degree above the tonic). Pieces in a minor key will generally modulate to the relative major key, (the key of the third scale degree above the minor tonic), or to the dominant minor. A piece in minor may also stay in the original key at the end of the first section, closing with an imperfect cadence.\\n\\nThe second section of the piece begins in the newly established key, where it remains for an indefinite period of time. After some harmonic activity, the piece will eventually modulate back to its original key before ending.\\n\\nMore often than not, especially in 18th-century compositions, the A and B sections are separated by double bars with repeat signs, meaning both sections were to be repeated.\\n\\nBinary form is usually characterized as having the form AB, though since both sections repeat, a more accurate description would be AABB. Others, however, prefer to use the label AA′. This second designation points to the fact that there is no great change in character between the two sections. The rhythms and melodic material used will generally be closely related in each section, and if the piece is written for a musical ensemble, the instrumentation will generally be the same. This is in contrast to the use of verse-chorus form in popular music—the contrast between the two sections is primarily one of the keys used.\\n\\n#### Further distinctions\\n\\nA piece in binary form can be further classified according to a number of characteristics:\\n\\n##### Simple vs. rounded\\n\\nOccasionally, the B section will end with a \\"return\\" of the opening material from the A section. This is referred to as rounded binary, and is labeled as ABA′. In rounded binary, the beginning of the B section is sometimes referred to as the \\"bridge\\", and will usually conclude with a half cadence in the original key. Rounded binary is not to be confused with ternary form, also labeled ABA—the difference being that, in ternary form, the B section contrasts completely with the A material as in, for example, a minuet and trio. Another important difference between the rounded and ternary form is that in rounded binary, when the \\"A\\" section returns, it will typically contain only half of the full \\"A\\" section, whereas ternary form will end with the full \\"A\\" section.\\n\\nSometimes, as in the keyboard sonatas of Domenico Scarlatti, the return of the A theme may include much of the original A section in the tonic key, so much so that some of his sonatas can be regarded as precursors of sonata form.\\n\\nRounded binary form is sometimes referred to as small ternary form.\\n\\nRounded binary or minuet form:\\n\\n> A :||: B A or A'  \\n> I(->V) :||: V(or other closely related) I\\n\\nIf the B section lacks such a return of the opening A material, the piece is said to be in simple binary.\\n\\nSimple:\\n\\n> A->B :||: A->B  \\n> I->V :||: V->I\\n\\nSlow-movement form:\\n\\n> A' A\\"  \\n> I->V I->I\\n\\nMany examples of rounded binary are found among the church sonatas of Vivaldi including his Sonata No. 1 for Cello and Continuo, First Movement, while certain Baroque composers such as Bach and Handel used the form rarely.\\n\\n##### Sectional vs. continuous\\n\\nIf the A section ends with an Authentic (or Perfect) cadence in the original tonic key of the piece, the design is referred to as a sectional binary. This refers to the fact that the piece is in different tonal sections, each beginning in their own respective keys.\\n\\nIf the A section ends with any other kind of cadence, the design is referred to as a continuous binary. This refers to the fact that the B section will \\"continue on\\" with the new key established by the cadence at the end of A.\\n\\n##### Symmetrical vs. asymmetrical\\n\\nIf the A and B sections are roughly equal in length, the design is referred to as symmetrical.\\n\\nIf the A and B sections are of unequal length, the design is referred to as asymmetrical. In such cases, the B section is usually substantially longer than the A section.\\n\\nThe asymmetrical binary form becomes more common than the symmetrical type from about the time of Beethoven, and is almost routine in the main sections of Minuet and Trio or Scherzo and Trio movements in works from this period. In such cases, occasionally only the first section of the binary structure is marked to be repeated.\\n\\nAlthough most of Chopin's nocturnes are in an overall ternary form, quite often the individual sections (either the A, the B, or both) are in binary form, most often of the asymmetrical variety. If a section of this binary structure is repeated, in this case it is written out again in full, usually considerably varied, rather than enclosed between repeat signs.\\n\\n##### Balanced binary\\n\\nBalanced binary is when the end of the first section and the end of the second section have analogous material and are organized in a parallel way.\\n\\n#### Ternary form\\n\\n[Ternary form](https://en.wikipedia.org/wiki/Ternary_form) is a three-part musical form in which the third part repeats or at least contains the principal idea of the first part, represented as A B A. There are both simple and compound ternary forms. Da capo arias are usually in simple ternary form (i.e. \\"from the head\\"). A compound ternary form (or trio form) similarly involves an ABA pattern, but each section is itself either in binary (two sub-sections which may be repeated) or (simple) ternary form.\\n\\nTernary form, sometimes called song form, is a three-part musical form consisting of an opening section (A), a following section (B) and then a repetition of the first section (A). It is usually schematized as A–B–A. Prominent examples include the da capo aria \\"The trumpet shall sound\\" from Handel's Messiah, Chopin's Prelude in D-Flat Major \\"Raindrop\\", (Op. 28) and the opening chorus of Bach's St John Passion.\\n\\n##### Simple ternary form\\n\\nIn ternary form each section is self-contained both thematically as well as tonally (that is, each section contains distinct and complete themes), and ends with an authentic cadence. The B section is generally in a contrasting but closely related key, usually a perfect fifth above or the parallel minor of the home key of the A section (V or i); however, in many works of the Classical period, the B section stays in tonic but has contrasting thematic material. It usually also has a contrasting character; for example section A might be stiff and formal while the contrasting B section would be melodious and flowing.\\nDa capo aria\\n\\nBaroque opera arias and a considerable number of baroque sacred music arias was dominated by the Da capo aria which were in the ABA form. A frequent model of the form began with a long A section in a major key, a short B section in a relative minor key mildly developing the thematic material of the A section and then a repetition of the A section. By convention in the third section (the repeat of section A after section B) soloists may add some ornamentation or short improvised variations. In later classical music such changes may have been written into the score. In these cases the last section is sometimes labeled A’ or A1 to indicate that it is slightly different from the first A section.\\n\\n##### Compound ternary or trio form\\n\\nIn a trio form each section is a dance movement in binary form (two sub-sections which are each repeated) and a contrasting trio movement also in binary form with repeats. An example is the minuet and trio from Haydn's Surprise Symphony. The minuet consists of one section (1A) which is repeated and a second section (1B) which is also repeated. The trio section follows the same format (2A repeated and 2B repeated). The complete minuet is then played again at the end of the trio represented as: [(1A–1A–1B–1B) (2A–2A–2B–2B) (1A–1A–1B–1B)]. By convention in the second rendition of the minuet, the sections are not repeated with the scheme [(1A–1A–1B–1B) (2A–2A–2B–2B) (1A–1B)]. The trio may also be referred to as a double or as I/II, such as in Bach's polonaise and double (or Polonaise I/II) from his second orchestral suite and his bouree and double (or Bouree I/II) from his second English Suite for harpsichord.\\n\\nThe scherzo and trio, which is identical in structure to other trio forms, developed in the late Classical and early Romantic periods. Examples include the scherzo and trio (second movement) from Beethoven's Symphony No. 9 and the scherzo and trio in Schubert's String Quintet. Another name for the latter is \\"composite ternary form\\".[citation needed]\\n\\nTrio form movements (especially scherzos) written from the early romantic era sometimes include a short coda (a unique ending to complete the entire movement) and possibly a short introduction. The second movement of Beethoven's Symphony No. 9 is written in this style which can be diagrammed as [(INTRO) (1A–1A–1B–1B) (2A–2A–2B–2B) (1A–1B) (CODA)]\\n\\nMarches by John Philip Sousa and others follow this form, and the middle section is called the \\"trio\\". Polkas are also often in compound-ternary form.\\n\\n##### Quasi compound form\\n\\nOccasionally the A section or B section of a dance like movement is not divided into two repeating parts. For example, in the Minuet in Haydn's String Quartet op. 76 no. 6, the Minuet is in standard binary form (section A and B) while the trio is in free form and not in two repeated sections. Haydn labeled the B section \\"Alternative\\", a label used in some Baroque pieces (though most such pieces were in proper compound ternary form).\\n\\n#### Ternary form within a ternary form\\n\\nIn a complex ternary form each section is itself in ternary form in the scheme of [(A–B–A)(C–D–C)(A–B–A)] By convention each part is repeated and only on its first rendition: [(A–A–B–B–A)(C–C–D–D–C)(A–B–A)]. An example are the Impromptus (Op. 7) by Jan Voříšek.[9]\\n\\nExpanded ternary forms are especially common among Romantic-era composers; for example, Chopin's \\"Military\\" Polonaise (Op. 40, No. 1) is in the form [(A–A–B–A-B–A)(C–C–D–C-D–C)(A–B–A)], where the A and B sections and C and D sections are repeated as a group, and the original theme returning at the end without repeats.\\n\\n#### Rondo form\\n\\n[Rondo form](https://en.wikipedia.org/wiki/Rondo) has a recurring theme alternating with different (usually contrasting) sections called \\"episodes\\". It may be asymmetrical (ABACADAEA) or symmetrical (ABACABA). A recurring section, especially the main theme, is sometimes more thoroughly varied, or else one episode may be a \\"development\\" of it. A similar arrangement is the ritornello form of the Baroque concerto grosso. Arch form (ABCBA) resembles a symmetrical rondo without intermediate repetitions of the main theme.\\n\\n#### Variational form\\n\\n[Variational](<https://en.wikipedia.org/wiki/Variation_(music)>) forms are those in which variation is an important formative element.\\n\\n[Theme and Variations](https://en.wikipedia.org/wiki/Theme_and_Variations): a theme, which in itself can be of any shorter form (binary, ternary, etc.), forms the only \\"section\\" and is repeated indefinitely (as in strophic form) but is varied each time (A,B,A,F,Z,A), so as to make a sort of sectional chain form. An important variant of this, much used in 17th-century British music and in the Passacaglia and Chaconne, was that of the ground bass—a repeating bass theme or basso ostinato over and around which the rest of the structure unfolds, often, but not always, spinning polyphonic or contrapuntal threads, or improvising divisions and descants. This is said by Scholes (1977) to be the form par excellence of unaccompanied or accompanied solo instrumental music. The Rondo is often found with sections varied (AA1BA2CA3BA4) or (ABA1CA2B1A).\\n\\n#### Sonata-allegro form\\n\\nSonata-allegro form (also [sonata form](https://en.wikipedia.org/wiki/Sonata_form) or first movement form) is typically cast in a greater ternary form, having the nominal subdivisions of Exposition, Development and Recapitulation. Usually, but not always, the \\"A\\" parts (Exposition and Recapitulation, respectively) may be subdivided into two or three themes or theme groups which are taken asunder and recombined to form the \\"B\\" part (the development) —thus, e.g. (AabB[dev. of a and/or b]A1ab1+coda).\\n\\n<youtube-embed video=\\"14dwegqniNg\\" />\\n\\nThe sonata form is \\"the most important principle of musical form, or formal type from the classical period well into the twentieth century.\\" It is usually used as the form of the first movement in multi-movement works. So, it is also called \\"first-movement form\\" or \\"sonata-allegro form\\"(Because usually the most common first movements are in allegro tempo).\\n\\nEach section of Sonata Form movement has its own function:\\n\\n- It may have an introduction at the beginning.\\n- Following the introduction, the exposition is the first required section. It lays out the thematic material in its basic version. There are usually two themes or theme groups in the exposition, and they are often in contrast styles and keys and connected by a transition. In the end of the exposition, there is a closing theme which concludes the section.\\n- The exposition is followed by the development section in which the material in the exposition is developed.\\n- After the development section, there is a returning section called recapitulation where the thematic material returns in the tonic key.\\n- At the end of the movement, there may be a coda, after the recapitulation.\\n\\n<youtube-embed video=\\"HzHS7QL-B-c\\" />\\n\\n## Forms used in Western popular music\\n\\nSome forms are used predominantly within popular music, including genre-specific forms. Popular music forms are often derived from strophic form (AAA song form), 32-bar form (AABA song form), verse-chorus form (AB song form) and 12-bar blues form (AAB song form).\\n\\n### Sectional forms\\n\\n- AABA a.k.a. American Popular\\n- AB a.k.a. Verse/Chorus\\n  - ABC a.k.a. Verse/Chorus/Bridge\\n- ABAB\\n- ABAC a.k.a. Verse/Chorus/Verse/Bridge\\n- ABCD a.k.a. Through-composed\\n- Blues Song forms\\n  - AAB a.k.a. Twelve-bar blues\\n  - 8-Bar Blues\\n  - 16-Bar Blues\\n\\n### Extended forms\\n\\nExtended form are forms that have their root in one of the forms above, however, they have been extended with additional sections. For example:\\n\\n- AAAAA\\n- AABABA\\n\\n### Compound forms\\n\\nAlso called Hybrid song forms. Compound song forms blend together two or more song forms.\\n\\n### Section names in popular music\\n\\n- Introduction a.k.a. Intro\\n- Verse\\n- Refrain\\n- Pre-chorus / Rise / Climb\\n- Chorus\\n- Post-chorus\\n- Bridge\\n- Middle-Eight\\n- Solo / Instrumental Break\\n- Collision\\n- CODA / Outro\\n- Ad Lib (Often in CODA / Outro)\\n\\n### Cyclical forms\\n\\nIn the 13th century the song cycle emerged, which is a set of related songs (as the suite is a set of related dances). The oratorio took shape in the second half of the 16th century as a narrative recounted—rather than acted—by the singers.\\n\\n### Matrix\\n\\nIn music, especially folk and popular music, a matrix is an element of variations which does not change. The term was derived from use in musical writings and from Arthur Koestler's The Act of Creation, who defines creativity as the bisociation of two sets of ideas or matrices. Musical matrices may be combined in any number, usually more than two, and may be — and must be for analysis — broken down into smaller ones. They may be intended by the composer and perceived by the listener, or they may not, and they may be purposefully ambiguous.\\n\\nThe simplest examples given by van der Merwe are fixed notes, definite intervals, and regular beats, while the most complex given are the Baroque fugue, Classical tonality, and Romantic chromaticism. The following examples are some matrices which are part of \\"Pop Goes the Weasel\\":\\n\\n- major mode\\n- 6/8 time\\n- four-bar phrasing\\n- regular beat\\n- rhyming tune structure\\n- ending both halves of the tune with the same figure\\n- melodic climax\\n- perfect cadence\\n- three primary triads implied\\n\\nCo-ordinated matrices may possess \\"bound-upness\\" or \\"at-oddness\\", depending on the degree to which they are connected to each other or go their separate ways, respectively, and are more or less easy to reconcile. The matrices of the larger matrix known as sonata rondo form are more bound up than the matrices of rondo form, while African and Indian music feature more rhythmic at-oddness than European music's coinciding beats, and European harmony features more at-oddness (between the melody and bass) than the preceding organum. At-oddness is a matter of degree, and almost all at odd matrices are partially bound up.[3]\\n","frontmatter":{"title":"Musical form","description":"The structure of a musical composition or performance","cover":"/media_files/cover/theory-composition-form-100122828-0232_Lohse_Zwei_Themen_web.jpg","date":"2021-11-02T00:00:00.000Z","links":["https://en.wikipedia.org/wiki/List_of_classical_music_genres"]},"url":"/theory/composition/form/"},{"src":"---\\ntitle: Theory\\ndescription: All the knowledge of music becoming visible with the simple color coding system\\ncover: manuel-nageli.jpg\\ndate: 2021-10-30\\ntopContent: true\\n---\\n\\n> **Chroma** - from Greek **khrōma** - \\"surface of the body, skin, color of the skin,\\" also used generically for \\"color\\"\\n\\n&nbsp;+\\n\\n> **Tone** - from Greek **tonos** \\"vocal pitch, raising of voice, accent, key in music,\\" originally \\"a stretching, tightening, taut string\\".\\n\\nWelcome to the main research hub for establishing the Chromatone interpretation of basic and profound music theory concepts.\\n\\nWe start from the very beginning - the physical world around us and the ways we can perceive and interpret it. What is [Light and Color](./color/index.md) and how do we see it? What is [Sound](./sound/index.md) and how do we hear it? This gives us the firm foundation for building more and more intricate structures on top of it.\\n\\nSome sounds are more musical than others and we soon find the importance of their frequency profile. [Notes](./notes/index.md) are born from distinguishing particular sound pitches. And then all the combinations arise.\\n\\nTwo notes form [Intervals](./intervals/index.md) and three or more of them from [Chords](./chords/index.md). If there's too many sounds to be played simultaneously, but still they have pleasant relations to one another, we talk about [Scales](./scales/index.md).\\n\\nThen we start organizing all these sound structures in time based on [Rhythm](./rhythm/index.md) and dive deep into [Harmony](./harmony/index.md) and [Melody](./melody/index.md) that evolve naturally to the whole [Composition](./composition/index.md) level.\\n\\nThere's quite a deep research here, and there's more [External resources](./resources/index.md) to explore for those, who needs to learn even more about music theory themselves.\\n","frontmatter":{"title":"Theory","description":"All the knowledge of music becoming visible with the simple color coding system","cover":"/media_files/cover/theory-manuel-nageli.jpg","date":"2021-10-30T00:00:00.000Z","topContent":true},"url":"/theory/"},{"src":"---\\ntitle: Modal interplay\\ndescription: Exploring the physical, physiological, neurological and psychological links between sight and hearing – the two main modalities of human perception.\\ndate: 2021-10-19\\ncover: logo.svg\\n---\\n\\nChromatone is a term composed of two parts. \\"Chroma\\" is an Ancient Greek word χρῶμα (khrôma) and stands for \\"color\\". \\"Tone\\" comes from Latin word tonus (\\"sound\\") derived from Ancient Greek τόνος (tónos, “strain, tension, pitch”). Together they form Chromatone – the colorful notation system. It's based on combining the two circular models – the octave equivalence in music and the color circle of visual arts. This gives not only the colors for each of 12 chromatic notes of modern music, but can be extended to derive a certain color for any acoustic frequency.\\n\\n# Circle of colors and notes\\n\\n<img src=\\"./logo.svg\\">\\n\\nA is the lowest frequency note and red is the lowest frequency color. It’s the starting point. Then we divide the [Light spectrum](./spectrum/index.md) into 12 parts and get scientifically correspondent colors for every note in an octave. Now we can see the circle of musical intervals with our eyes and use it to remember all the musical semitones. It may be like an artificial [Synesthesia](./synesthesia/index.md) to be developed to improve music learning and performing skills. Learn more about history of [Visual Music with Michael Filimowicz](./visual-music/index.md).\\n\\n- https://en.wikipedia.org/wiki/Colored_music_notation\\n- https://en.wikipedia.org/wiki/Visual_music\\n- https://www.researchgate.net/publication/334643020_Interactive_Visual_Music\\n- https://github.com/GeWu-Lab/awesome-audiovisual-learning\\n","frontmatter":{"title":"Modal interplay","description":"Exploring the physical, physiological, neurological and psychological links between sight and hearing – the two main modalities of human perception.","date":"2021-10-19T00:00:00.000Z","cover":"/media_files/cover/theory-interplay-logo.svg"},"url":"/theory/interplay/"},{"src":"---\\ntitle: Drone\\ndescription: A harmonic or monophonic effect or accompaniment where a note or chord is continuously sounded throughout most or all of a piece\\ncover: s-l1600.jpg\\ndate: 2021-10-14\\n---\\n\\nA drone is a harmonic or monophonic effect or accompaniment where a note or chord is continuously sounded throughout most or all of a piece. A drone may also be any part of a musical instrument used to produce this effect; an archaic term for this is burden (bourdon or burdon) such as a \\"drone [pipe] of a bagpipe\\", the pedal point in an organ, or the lowest course of a lute. Α burden is also part of a song that is repeated at the end of each stanza, such as the chorus or refrain.\\n\\n## Musical effect\\n\\n> \\"Of all harmonic devices, it [a drone] is not only the simplest, but probably also the most fertile.\\"\\n\\nA drone effect can be achieved through a sustained sound or through repetition of a note. It most often establishes a tonality upon which the rest of the piece is built. A drone can be instrumental, vocal or both. Drone (both instrumental and vocal) can be placed in different ranges of the polyphonic texture: in the lowest part, in the highest part, or in the middle. The drone is most often placed upon the tonic or dominant. A drone on the same pitch as a melodic note tends to both hide that note and to bring attention to it by increasing its importance.\\n\\nA drone differs from a pedal tone or point in degree or quality. A pedal point may be a form of nonchord tone and thus required to resolve unlike a drone, or a pedal point may simply be considered a shorter drone, a drone being a longer pedal point.\\n\\n## History and distribution\\n\\n> ![](./images/A_Lady_Playing_the_Tanpura,_ca._1735.jpg)\\n> A Lady Playing the Tanpura, ca. 1735.\\n\\nThe systematic use of drones originated in instrumental music of ancient Southwest Asia, and spread north and west to Europe, east to India, and south to Africa. It is used in Indian music and is played with the tanpura (or tambura) and other Indian drone instruments like the ottu, the ektar, the dotara (or dotar; dutar in Persian Central Asia), the surpeti, the surmandal (or swarmandal) and the shankh (conch shell). Most of the types of bagpipes that exist worldwide have up to three drones, making this one of the first instruments that comes to mind when speaking of drone music. In America, most forms of the African-influenced banjo contain a drone string. Since the 1960s, the drone has become a prominent feature in drone music and other forms of avant-garde music.\\n\\nIn vocal music drone is particularly widespread in traditional musical cultures, particularly in Europe, Polynesia and Melanesia. It is also present in some isolated regions of Asia (like among Pearl-divers in the Persian Gulf, some national minorities of South-West China, Taiwan, Vietnam, and Afghanistan).\\n\\n## Part(s) of a musical instrument\\n\\n> ![](./images/Golowan_Festival_Penzance_June_2005_Mid-Argyl_band2.jpg)\\n> Highland bagpipes, with drone pipes over the pipers' left shoulders\\n\\nDrone is also the term for the part of a musical instrument intended to produce the drone effect's sustained pitch, generally without the ongoing attention of the player. Different melodic Indian instruments (e.g. the sitar, the sarod, the sarangi and the rudra veena) contain a drone. For example, the sitar features three or four resonating drone strings, and Indian notes (sargam) are practiced to a drone. Bagpipes (like the Great Highland Bagpipe and the Zampogna) feature a number of drone pipes, giving the instruments their characteristic sounds. A hurdy-gurdy has one or more drone strings. The fifth string on a five-string banjo is a drone string with a separate tuning peg that places the end of the string five frets down the neck of the instrument; this string is usually tuned to the same note as that which the first string produces when played at the fifth fret, and the drone string is seldom fretted. The bass strings of the Slovenian drone zither also freely resonate as a drone. The Welsh Crwth also features two drone strings.\\n\\n## Use in musical compositions\\n\\nComposers of Western classical music occasionally used a drone (especially one on open fifths) to evoke a rustic or archaic atmosphere, perhaps echoing that of Scottish or other early or folk music. Examples include the following:\\n\\n- Haydn, Symphony No. 104, \\"London\\", opening of finale, accompanying a folk melody\\n- Beethoven, Symphony No. 6, \\"Pastoral\\", opening and trio section of scherzo\\n- Mendelssohn, Symphony No. 3 in A minor, opus 56, 'Scottish', especially the finale.\\n- Chopin, Mazurkas, Op. 7: all five contain a drone.\\n- Berlioz, Harold in Italy, accompanying oboes as they imitate the piffero of Italian peasants\\n- Richard Strauss, Also sprach Zarathustra, Introduction: the opening grows out of a drone effect in the orchestra.\\n- Mahler, Symphony No. 1, introduction; a seven-octave drone on A evokes \\"the awakening of nature at the earliest dawn\\"\\n- Bartók, in his adaptations for piano of Hungarian and other folk music\\n\\nThe best-known drone piece in the concert repertory is the Prelude to Wagner's Das Rheingold (1854) wherein low horns and bass instruments sustain an E♭ throughout the entire movement. The atmospheric ostinato effect that opens Beethoven's Ninth Symphony, which inspired similar gestures in the opening of all the symphonies of Anton Bruckner, represents a gesture derivative of drones.\\n\\nOne consideration for composers of common practice keyboard music was equal temperament. The adjustments lead to slight mistunings as heard against a sustained drone. Even so, drones have often been used to spotlight dissonance purposefully.\\n\\nModern concert musicians make frequent use of drones, often with just or other non-equal tempered tunings. Drones are a regular feature in the music of composers indebted to the chant tradition, such as Arvo Pärt, Sofia Gubaidulina, and John Tavener. The single-tones that provided the impetus for minimalism through the music of La Monte Young and many of his students qualify as drones. David First, the band Coil, the early experimental compilations of John Cale (Sun Blindness Music, Dream Interpretation, and Stainless Gamelan), Pauline Oliveros and Stuart Dempster, Alvin Lucier (Music On A Long Thin Wire), Ellen Fullman, Lawrence Chandler and Arnold Dreyblatt all make notable use of drones. The music of Italian composer Giacinto Scelsi is essentially drone-based. Shorter drones or the general concept of a continuous element are often used by many other composers. Other composers whose music is entirely based on drones include Charlemagne Palestine and Phill Niblock. The Immovable Do by Percy Grainger contains a sustained high C (heard in the upper woodwinds) that lasts for the entirety of the piece. Drone pieces also include Loren Rush's Hard Music (1970) and Folke Rabe's Was?? (1968), as well as Robert Erickson's Down at Piraeus. The avant-garde guitarist Glenn Branca also used drones extensively. French singer Camille uses a continuous B throughout her album Le_Fil.\\n\\nDrones continue to be characteristic of folk music. Early songs by Bob Dylan employ the effect with a retuned guitar in \\"Masters of War\\" and \\"Mr. Tambourine Man\\". The song \\"You Will Be My Ain True Love\\", written by Sting for the 2003 movie Cold Mountain and performed by Alison Krauss and Sting, uses drone bass.\\n\\nDrones are used widely in the blues and blues-derived genres. Jerry Lee Lewis featured drones in solos and fills. Drones were virtually absent in original rock and roll music, but gained popularity after the Beatles used drones in a few popular compositions (for example, \\"Blackbird\\" has a drone in the middle of a texture throughout the whole song, \\"Tomorrow Never Knows\\" makes use of tambura). They also used high drone for the dramatic effect in some sections of several of their compositions (like the last verses of \\"Yesterday\\" and \\"Eleanor Rigby\\"). The rock band U2 uses drones in their compositions particularly widely. In the Led Zeppelin song \\"In The Light\\", a keyboard drone is used throughout the song, mostly in the intro.\\n\\n## Use for musical training\\n\\nDrones are used by a number of music education programs for ear training and pitch awareness, as well as a way to improvise ensemble music. A shruti box is often used by vocalists in this style of musical training. Drones, owing to their acoustic properties and following their longstanding use in ritual and chant, can be useful in constructing aural structures outside common practice expectations of harmony and melody.\\n\\n## Shruti box\\n\\nA shruti box (sruti box or surpeti) is an instrument, originating from the Indian subcontinent, that traditionally works on a system of bellows. It is similar to a harmonium and is used to provide a drone in a practice session or concert of Indian classical music. It is used as an accompaniment to other instruments and notably the flute. The shruti box is also used in classical singing. In classical singing, the shruti box is used to help tune the voice. The use of the shruti box has widened with the cross-cultural influences of world music and new-age music to provide a drone for many other instruments as well as vocalists.\\n\\n![](./s-l1600.jpg)\\n\\nAdjustable buttons allow tuning. Nowadays, electronic shruti boxes are commonly used, which are called shruthi pettige in Kannada, shruti petti in Tamil and Telugu and sur peti in Hindi. Recent versions also allow for changes to be made in the tempo, and the notes such as Madhyamam, Nishadam to be played in place of the usual three notes (i.e., Lower shadjam, panchamam, and the upper shadjam)\\n\\n### History\\n\\nBefore the arrival of the harmonium in the Indian subcontinent, musicians used either a tambura or a specific pitch reference instrument, such as the nadaswaram, to produce the drone. Some forms of music such as Yakshagana used the pungi reedpipe as drone. After the Western small pump harmonium became popular, musicians would modify the harmonium to automatically produce the reference pitch. Typically, one would open up the cover and adjust the stop of the harmonium to produce a drone.\\n\\nLater, a keyless version of the harmonium was invented for the specific purpose of producing the drone sound. It was given the name shruti box or sruti box. These types of instruments had controls on the top or on the side of the box for controlling the pitch.\\n\\n![](./images/kyw-professionalconcert-shruti-box-teak-wood.jpg)\\n\\nThe shruti box is enjoying a renaissance in the West amongst traditional and contemporary musicians, who are using it for a range of different styles. In the early nineties, traditional Irish singer Nóirín Ní Riain brought the shruti box to Ireland, giving it a minor place in traditional Irish music. More recently Scottish folk artist Karine Polwart and Julie Fowlis use the instrument, using it on some of their songs. Singers find it very useful as an accompaniment and instrumentalists enjoy the drone reference it gives to play along with.\\n\\n### Jivari\\n\\n> ![](./images/Sitar_jawari.jpg)\\n> The Javari of a sitar, made from ebony, showing graphite marks from the first two strings\\n\\nJavārī, (also: 'joārī', 'juvārī', 'jvārī' (alternately transcribed 'jawārī', 'jowārī', 'joyārī', 'juwārī', and 'jwārī')) in Indian classical music refers to the overtone-rich \\"buzzing\\" sound characteristic of classical Indian string instruments such as the tanpura, sitar, surbahar, rudra veena and Sarasvati veena. Javari can refer to the acoustic phenomenon itself and to the meticulously carved bone, ivory or wooden bridges that support the strings on the sounding board and produce this particular effect. A similar sort of bridge is used on traditional Ethiopian lyres, as well as on the ancient Greek kithara, and the \\"bray pins\\" of some early European harps operated on the same principle. A similar sound effect, called in Japanese sawari, is used on some traditional Japanese instruments as well.\\n\\nUnder the strings of tanpuras, which are unfretted (unstopped), and occasionally under those bass drone strings of sitars and surbahars which are seldom fretted, cotton threads are placed on the javari bridge to control the exact position of the node and its height above the curved surface, in order to more precisely refine the sound of javari. These cotton threads are known in Hindi as 'jīvā', meaning \\"life\\" and referring to the brighter tone heard from the plucked string once the thread has been slid into the correct position. This process is called \\"adjusting the javari\\". After a substantial time of playing, the surface directly under the string will wear out through the erosive impact of the strings. The sound will become thin and sharp and tuning also becomes a problem. Then a skilled, experienced craftsman needs to redress and polish the surface, which is called \\"doing the javari\\" (\\"'Javārī Sāf Karnā' or \\"Cleaning the Javārī'\\").\\n\\n> ![](./images/Topvieuw_of_a_tambura_bridge.jpg)\\n> Top view of a rosewood tambura bridge. Notice the marks left by the strings as the javari-maker assures that the contact-lines on the surface of the bridge are continuous and even. As a further test strings are pulled sideways and lengthwise in order to rub the bridge with the string, to better judge the quality of the surface, as unevenness in the surface shows clearly as a gap.\\n\\nThe rich and very much 'alive' resonant sound requires great sensitivity and experience in the tuning process. In the actual tuning, the fundamentals are of lesser interest as attention is drawn to the sustained harmonics that should be clearly audible, particularly the octaves, fifths, major thirds and minor sevenths of the (fundamental) tone of the string. The actual tuning is done on three levels: firstly by means of the large pegs, secondly, by carefully shifting tuning-beads for micro-tuning and thirdly, on a tanpura, by even more careful shifting of the cotton threads that pass between the strings and the bridge, somewhat before the zenith of its curve.\\n\\n#### Effect\\n\\nTypical of javari on an instrument with preferably long strings, is that on the soundboard the strings run over a wide bridge with a very flat parabolic curve. The curvature of the bridge has been made in a precise relation to the optimum level of playing, or more exact, a precise amplitude of each string. Any string, given length, density, pitch and tension, wants to be plucked within the limits of its elasticity, and so vibrate harmoniously with a steady pitch. When a string of a tanpura is plucked properly, it produces a tone with a certain amplitude that will slowly decrease as the tone fades out. In this gradual process, the string, moving up and down according to its frequency, will make a periodic grazing contact with the curved surface of the bridge. The exact grazing-spot will gradually shift up the sloping surface, as a function of the decreasing amplitude, finally dissolving into the rest-position of the open string. In this complex dynamic sonation process, the shifting grazing will touch upon micro-nodes on the string, exciting a wide range of harmonics in a sweeping mode. The desired effect is that of a cascading row of harmonics in a rainbow of sound. As an analogy, a properly shaped and adjusted javari is similar to the refraction of white light through a prism. When the prism is of good proportions and quality and used properly, the phenomenon should produce itself. \\"The voice of an artist which is marked by a rich sound resembling that produced by two consonants played together, is often loosely known to have Javārī in it, although such use is arbitrary.\\"\\n\\n#### Construction\\n\\nThe javari of a tanpura is in a way fine-tuned with a cotton thread under the string. Both the thread itself and its function is called 'jiva'. The jiva lifts the string by its diameter off the bridge and gives the necessary clearance and adjustability. By carefully shifting the jiva the sequence of the shifting grazing on the parabolic surface of the bridge becomes 'tuneable' within limits. For each string there should be a spot relative to the curve of the bridge where optimum sound quality is found. Within the area of optimum resonance and sustain, a little play should be available for further fine-tuning, in which the jiva can hardly be seen to move. Staying with optics, shifting the jiva would be similar to using the manual fine focus on a camera. Experienced 'javari-makers' will agree that the 'javari' has to be made specific to certain string lengths, gauges and pitches and certain amplitudes.\\n\\n> ![](./images/Side_view_of_Tanjore-style_rosewood_tanpura_bridge_with_cotton_threads_adjusted_for_full_resonance.jpg)\\n> Side view of a Tanjore-style rosewood tanpura bridge with cotton threads adjusted for full resonance.\\n\\nThe curvature of the bridge of the main strings of a sitar will be different from that of the smaller and lower bridge in front of the main bridge, which carries the sympathetic resonance-strings (tarafs). As this choir of thinner and shorter strings is excited solely by the sympathetic resonance with the tones played on the main strings, the general amplitude is smaller, so accordingly the curvature will be flatter. The making of a perfectly sounding javari for any instrument requires a very high degree of skill and expertise. Tanpuras are the only instruments that are always used with jiva-threads, except the octave-tamburis. Sitar, Rudra Veena, Sarasvati Veena, all have parabolic wide javari bridges for the main playing strings. Sarod and Sarangi have some of their sympathetic resonance strings (tarafs) on small, flat javari-bridges similar to that of the sitar. The javari of a sitar will be made according to the wishes of the player, either 'open',('khula') with a bright sounding javari-effect, or 'closed' ('band') with a relatively more plain tone, or something in between ('ghol'). The choice depends on the preference of the sitar-player and on the adapted playing style.\\n","frontmatter":{"title":"Drone","description":"A harmonic or monophonic effect or accompaniment where a note or chord is continuously sounded throughout most or all of a piece","cover":"/media_files/cover/theory-melody-drone-s-l1600.jpg","date":"2021-10-14T00:00:00.000Z"},"url":"/theory/melody/drone/"},{"src":"---\\ntitle: Song structure\\ndescription: The form variations of a songwriting process\\ndate: 2021-10-12\\ncover: structure.jpg\\n---\\n\\n[Song structure](https://en.wikipedia.org/wiki/Song_structure) is the arrangement of a song, and is a part of the songwriting process. It is typically sectional, which uses repeating forms in songs. Common forms include bar form, 32-bar form, verse–chorus form, ternary form, strophic form, and the 12-bar blues. Popular music songs traditionally use the same music for each verse or stanza of lyrics (as opposed to songs that are \\"through-composed\\"—an approach used in classical music art songs). Pop and traditional forms can be used even with songs that have structural differences in melodies.[clarification needed] The most common format in modern popular music is introduction (intro), verse, pre-chorus, chorus (or refrain), verse, pre-chorus, chorus, bridge (\\"middle eight\\"), verse, chorus and outro. In rock music styles, notably heavy metal music, there is usually one or more guitar solos in the song, often found after the middle chorus part. In pop music, there may be a guitar solo, or a solo may be performed by a synthesizer player or sax player.\\n\\nThe foundation of popular music is the \\"verse\\" and \\"chorus\\" structure. Some writers use a simple \\"verse, hook, verse, hook, bridge, hook\\" method. \\"Pop and rock songs nearly always have both a verse and a chorus. The primary difference between the two is that when the music of the verse returns, it is almost always given a new set of lyrics, whereas the chorus usually retains the same set of lyrics every time its music appears.\\" Both are essential elements, with the verse usually played first (exceptions abound, of course, with \\"She Loves You\\" by The Beatles being an early example in the rock music genre). Each verse usually employs the same melody (possibly with some slight modifications), while the lyrics usually change for each verse. The chorus (or \\"refrain\\") usually consists of a melodic and lyrical phrase that repeats. Pop songs may have an introduction and coda (\\"tag\\"), but these elements are not essential to the identity of most songs. Pop songs often connect the verse and chorus via a pre-chorus, with a bridge section usually appearing after the second chorus.\\n\\nThe verse and chorus are usually repeated throughout a song, while the intro, bridge, and coda (also called an \\"outro\\") are usually only used once. Some pop songs may have a solo section, particularly in rock or blues-influenced pop. During the solo section, one or more instruments play a melodic line which may be the melody used by the singer, or, in blues or jazz improvised.\\n\\n![Anatomy of songs](./structure.jpg)\\n\\n## Elements\\n\\n### Introduction\\n\\nThe [introduction](<https://en.wikipedia.org/wiki/Introduction_(music)>) is a unique section that comes at the beginning of the piece. Generally speaking, an introduction contains just music and no words. It usually builds up suspense for the listener so when the downbeat drops in, it creates a pleasing sense of release. The intro also creates the atmosphere of the song. As such, the rhythm section typically plays in the \\"feel\\" of the song that follows. For example, for a blues shuffle, a band starts playing a shuffle rhythm. In some songs, the intro is one or more bars of the tonic chord (the \\"home\\" key of the song). With songs, another role of the intro is to give the singer the key of the song. For this reason, even if an intro includes chords other than the tonic, it generally ends with a cadence, either on the tonic or dominant chord.\\n\\nThe introduction may also be based around the chords used in the verse, chorus, or bridge, or a stock \\"turnaround\\" progression may be played, such as the I–vi–ii–V progression (particularly in jazz influenced pop songs). More rarely, the introduction may begin by suggesting or implying another key. For example, a song in C Major might begin with an introduction in G Major, which makes the listener think that the song will eventually be in G Major. A cliche used to indicate to the listener that this G Major section is in fact the dominant chord of another key area is to add the dominant seventh, which in this case would shift the harmony to a G7 chord. In some cases, an introduction contains only drums or percussion parts that set the rhythm and \\"groove\\" for the song. Alternately the introduction may consist of a solo section sung by the lead singer (or a group of backup singers), or a riff played by an instrumentalist.\\n\\nThe most straightforward, and least risky way to write an introduction is to use a section from the song. This contains melodic themes from the song, chords from one of the song's sections, and the beat and style of the song. However, not all songs have an intro of this type. Some songs have an intro that does not use any of the material from the song that is to follow. With this type of intro, the goal is to create interest in the listener and make them unsure of what will happen. This type of intro could consist of a series of loud, accented chords, punctuated by cymbal, with a bassline beginning near the end, to act as a pitch reference point for the singer.\\n\\n### Verse\\n\\nIn popular music, a [verse](https://en.wikipedia.org/wiki/Verse%E2%80%93chorus_form) roughly corresponds to a poetic stanza because it consists of rhyming lyrics most often with an AABB or ABAB rhyme scheme. When two or more sections of the song have almost identical music but different lyrics, each section is considered one verse.\\n\\nMusically, \\"the verse is to be understood as a unit that prolongs the tonic... The musical structure of the verse nearly always recurs at least once with a different set of lyrics.\\" The tonic or \\"home key\\" chord of a song can be prolonged in a number of ways. Pop and rock songs often use chords closely related to the tonic, such as iii or vi, to prolong the tonic. In the key of C Major, the iii chord would be E Minor and the vi chord would be A Minor. These chords are considered closely related to the tonic because they share chord tones. For example, the chord E Minor includes the notes E and G, both of which are part of the C Major triad. Similarly, the chord A Minor includes the notes C and E, both part of the C Major triad.\\n\\nLyrically, \\"the verse contains the details of the song: the story, the events, images and emotions that the writer wishes to express....Each verse will have different lyrics from the others.\\" \\"A verse exists primarily to support the chorus or refrain...both musically and lyrically.\\" A verse of a song, is a repeated sung melody where the words change from use to use (though not necessarily a great deal).\\n\\n### Pre-chorus\\n\\nAn optional section that may occur after the verse is the pre-chorus. Also known as a \\"build\\", \\"channel\\", or \\"transitional bridge\\", the pre-chorus functions to connect the verse to the chorus with intermediary material, typically using subdominant (usually built on the IV chord or ii chord, which in the key of C Major would be an F Major or D minor chord) or similar transitional harmonies. \\"Often, a two-phrase verse containing basic chords is followed by a passage, often harmonically probing, that leads to the full chorus.\\" Often, when verse and chorus use the same harmonic structure, the pre-chorus introduces a new harmonic pattern or harmony that prepares the verse chords to transition into the chorus.\\n\\nFor example, if a song is set in C Major, and the songwriter aims to get to a chorus that focuses on the dominant chord (G Major) being tonicized (treated like a \\"home key\\" for a short period), a chord progression could be used for the pre-chorus that gets the listener ready to hear the chorus' chord (G Major) as an arrival key. One widely used way to accomplish this is to precede the G Major chord with its own ii–V7 chords. In the key given, ii of G Major would be an A minor chord. V7 of G Major would be D7. As such, with the example song, this could be done by having a pre-chorus that consists of one bar of A minor and one bar of D7. This would allow the listener to expect a resolution from ii–V to I, which in this case is the temporary tonic of G Major. The chord A minor would not be unusual to the listener, as it is a shared chord that exists in both G Major and C Major. A minor is the ii chord in G Major, and it is the vi chord in C Major. The chord that would alert the listener that a change was taking place is the D7 chord. There is no D7 chord in C Major. A listener experienced with popular and traditional music would hear this as a secondary dominant. Harmonic theorists and arrangers would call it V7/V or five of five, as the D7 chord is the dominant (or fifth) chord of G Major.\\n\\n### Chorus or refrain\\n\\nThe terms [chorus and refrain](https://en.wikipedia.org/wiki/Refrain) are often used interchangeably, both referring to a recurring part of a song. When a distinction is made, the chorus is the part that contains the hook or the \\"main idea\\" of a song's lyrics and music, and there is rarely variation from one repetition of the chorus to the next. A refrain is a repetitive phrase or phrases that serve the function of a chorus lyrically, but are not in a separate section or long enough to be a chorus. For example, refrains are found in the Beatles' \\"She Loves You\\" (\\"yeah, yeah, yeah\\"), AC/DC's \\"You Shook Me All Night Long\\", Paul Simon's \\"The Sound of Silence\\", and \\"Deck the Halls\\" (\\"fa la la la la\\").\\n\\nThe chorus or refrain is the element of the song that repeats at least once both musically and lyrically. It is always of greater musical and emotional intensity than the verse. \\"The chorus, which gets its name from a usual thickening of texture from the addition of backing vocals, is always a discrete section that nearly always prolongs the tonic and carries an unvaried poetic text.\\" In terms of narrative, the chorus conveys the main message or theme of the song. Normally the most memorable element of the song for listeners, the chorus usually contains the hook.\\n\\n### Post-chorus\\n\\nAn optional section that may occur after the chorus is the [post-chorus](https://en.wikipedia.org/wiki/Post-chorus) (or postchorus). The term can be used generically for any section that comes after a chorus, but more often refers to a section that has similar character to the chorus, but is distinguishable in close analysis. The concept of a post-chorus has been particularly popularized and analyzed by music theorist Asaf Peres, who is followed in this section.\\n\\nCharacterizations of post-chorus vary, but are broadly classed into simply a second chorus (in Peres's terms, a detached postchorus) or an extension of the chorus (in Peres's terms, an attached postchorus). Some restrict \\"post-chorus\\" to only cases where it is an extension of a chorus (attached postchorus), and do not consider the second part of two-part choruses (detached postchorus) as being a \\"post\\"-chorus.\\n\\nAs with distinguishing the pre-chorus from a verse, it can be difficult to distinguish the post-chorus from the chorus. In some cases they appear separately – for example, the post-chorus only appears after the second and third chorus, but not the first – and thus are clearly distinguishable. In other cases they always appear together, and thus a \\"chorus + post-chorus\\" can be considered a subdivision of the overall chorus, rather than an independent section.\\n\\nCharacterization of a post-chorus varies, beyond \\"comes immediately after the chorus\\"; Peres characterizes it by two conditions: it maintains or increases sonic energy, otherwise it's a bridge or verse; and contains a melodic hook (vocal or instrumental), otherwise it's a transition.\\n\\nDetached post-choruses typically have distinct melody and lyrics from the chorus:\\n\\n- Chandelier (Sia, 2014): the chorus begins and ends with \\"I'm gonna swing from the chandelier / From the chandelier\\", while the post-chorus repeats instead \\"holding on\\", in \\"I'm holding on for dear life\\" and \\"I'm just holding on for tonight\\", and has a new melody, but the same chord progression as the chorus.\\n\\nLyrics of attached post-choruses typically repeat the hook/refrain from the chorus, with little additional content, often using vocables like \\"ah\\" or \\"oh\\". Examples include:\\n\\n- \\"Umbrella\\" (Rihanna, 2007): the chorus begins \\"When the sun shine, we shine together\\" and run through \\"You can stand under my umbrella / You can stand under my umbrella, ella, ella, eh, eh, eh\\", which is followed by three more repetitions of \\"Under my umbrella, ella, ella, eh, eh, eh\\", the last one adding another \\"eh, eh-eh\\". Here the division between chorus and post-chorus is blurred, as the \\"ella, ella\\" begins in the chorus, and was a play on the reverb effect.\\n- \\"Shape of You\\" (Ed Sheeran, 2017): the chorus runs \\"I'm in love with the shape of you ... Every day discovering something brand new / I'm in love with your body\\", and the post-chorus repeats vocables and the hook \\"Oh—I—oh—I—oh—I—oh—I / I'm in love with your body\\", then repeats the end of the chorus, switching \\"your body\\" to \\"the shape of you\\": \\"Every day discovering something brand new / I'm in love with the shape of you\\"\\n- \\"Girls Like You\\" (Maroon 5, 2018): the chorus runs \\"'Cause girls like you ... I need a girl like you, yeah, yeah ... I need a girl like you, yeah, yeah\\", and the post-chorus repeats the hook with added \\"yeah\\"s: \\"Yeah, yeah, yeah, yeah, yeah, yeah / I need a girl like you, yeah, yeah / Yeah yeah yeah, yeah, yeah, yeah / I need a girl like you\\".\\n\\nHybrids are also common (Peres: hybrid postchorus), where the post-chorus keeps the hook from the chorus (like an attached postchorus), but introduces some additional content (hook or melody, like a detached postchorus.\\n\\n### Bridge\\n\\nA [bridge](<https://en.wikipedia.org/wiki/Bridge_(music)>) may be a transition, but in popular music, it more often is \\"...a section that contrasts with the verse...[,] usually ends on the dominant...[,] [and] often culminates in a strong re-transitional.\\" \\"The bridge is a device that is used to break up the repetitive pattern of the song and keep the listener's attention....In a bridge, the pattern of the words and music change.\\" For example, John Denver's \\"Country Roads\\" is a song with a bridge while Stevie Wonder's \\"You Are the Sunshine of My Life\\" is a song without one.\\n\\nIn music theory, \\"middle eight\\" (a common type of bridge) refers to a section of a song with a significantly different melody and lyrics, which helps the song develop itself in a natural way by creating a contrast to the previously played, usually placed after the second chorus in a song.\\n\\nA song employing a middle eight might look like:\\n\\n          ....  ....    ....  ....    ........  ....     ....\\n    Intro-{Verse-Chorus}{Verse-Chorus}-Middle 8-{Chorus}-{Chorus}-(Outro)\\n\\nBy adding a powerful upbeat middle eight, musicians can then end the song with a hook in the end chorus and finale.\\n\\n### Conclusion or outro\\n\\nThe conclusion or (in popular-music terminology) [outro](<https://en.wikipedia.org/wiki/Conclusion_(music)#Outro>) of a song is a way of finishing or completing the song. It signals to the listeners that the song is nearing its close. The reason for having an outro is that if a song just ended at the last bar of a section, such as on the last verse or the last chorus, this might feel too abrupt for listeners. By using an outro, the songwriter signals that the song is, in fact, nearing its end. This gives the listeners a good sense of closure. For DJs, the outro is a signal that they need to be ready to mix in their next song.\\n\\nIn general, songwriters and arrangers do not introduce any new melodies or riffs in the outro. However, a melody or riff used throughout the song may be re-used as part of an outro. Generally, the outro is a section where the energy of the song, broadly defined, dissipates. For example, many songs end with a fade-out, in which the song gets quieter and quieter. In many songs, the band does a ritardando during the outro, a process of gradually slowing down the tempo. Both the fade-out and the ritardando are ways of decreasing the intensity of a song and signalling that it is nearing its conclusion.\\n\\nFor an outro that fades out, the arranger or songwriter typically repeats a short section of the music over and over. This can be the chorus, for example. An audio engineer then uses the fader on the mixing board to gradually decrease the volume of the recording. When a tribute band plays a cover song that, in the recorded version ends with a fade-out, the live band may imitate that by playing progressively quieter.\\n\\nAnother way many pop and rock songs end is with a tag. There are two types of tags: the instrumental tag and the instrumental/vocal tag. With an instrumental tag, the vocalist no longer sings, and the band's rhythm section takes over the music to finish off the song. A tag is often a vamp of a few chords that the band repeats. In a jazz song, this could be a standard turnaround, such as I–vi–ii–V7 or a stock progression, such as ii–V7. If the tag includes the tonic chord, such as a vamp on I–IV, the bandleader typically cues the last time that the penultimate chord (a IV chord in this case) is played, leading to an ending on the I chord. If the tag does not include the tonic chord, such as with a ii–V7 tag, the bandleader cues the band to do a cadence that resolves onto the tonic (I) chord. With an instrumental and vocal tag, the band and vocalist typically repeat a section of the song, such as the chorus, to give emphasis to its message. In some cases, the vocalist may use only a few words from the chorus or even one word. Some bands have the guitar player do a guitar solo during the outro, but it is not the focus of the section; instead, it is more to add interesting improvisation. A guitar solo during an outro is typically mixed lower than a mid-song guitar solo.\\n\\n### Elision\\n\\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (February 2020) (Learn how and when to remove this template message)\\n\\nAn elision is a section of music where different sections overlap one another, usually for a short period. It is mostly used in fast-paced music, and it is designed to create tension and drama. Songwriters use elision to keep the song from losing its energy during cadences, the points at which the music comes to rest on, typically on a tonic or dominant chord. If a song has a section that ends with a cadence on the tonic, if the songwriter gives this cadence a full bar, with the chord held as a whole note, this makes the listener feel like the music is stopping. However, if songwriters use an elided cadence, they can bring the section to a cadence on the tonic, and then, immediately after this cadence, begin a new section of music which overlaps with the cadence. Another form of elision would, in a chorus later in the song, to interject musical elements from the bridge.\\n\\n### Instrumental solo\\n\\nA [solo](<https://en.wikipedia.org/wiki/Solo_(music)>) is a section designed to showcase an instrumentalist (e.g. a guitarist or a harmonica player) or less commonly, more than one instrumentalist (e.g., a trumpeter and a sax player). Guitar solos are common in rock music, particularly heavy metal and in the blues. The solo section may take place over the chords from the verse, chorus, or bridge, or over a standard solo backing progression, such as the 12-bar blues progression. In some pop songs, the solo performer plays the same melodies that were performed by the lead singer, often with flourishes and embellishments, such as riffs, scale runs, and arpeggios. In blues- or jazz-influenced pop songs, the solo performers may improvise a solo.\\n\\n### Ad lib\\n\\nAn [ad lib](https://en.wikipedia.org/wiki/Ad_libitum) section of a song (usually in the coda or outro) occurs when the main lead vocal or a second lead vocal breaks away from the already established lyric and/or melody to add melodic interest and intensity to the end of the song. Often, the ad lib repeats the previously sung line using variations on phrasing, melodic shape, and/or lyric, but the vocalist may also use entirely new lyrics or a lyric from an earlier section of the song. During an ad lib section, the rhythm may become freer (with the rhythm section following the vocalist), or the rhythm section may stop entirely, giving the vocalist the freedom to use whichever tempo sounds right. During live performances, singers sometimes include ad libs not originally in the song, such as making a reference to the town of the audience or customizing the lyrics to the current events of the era.\\n\\nThere is a distinction between ad lib as a song section and ad lib as a general term. Ad lib as a general term can be applied to any free interpretation of the musical material.\\n\\n## AABA form\\n\\n[Thirty-two-bar form](https://en.wikipedia.org/wiki/Thirty-two-bar_form) uses four sections, most often eight measures long each (4×8=32), two verses or A sections, a contrasting B section (the bridge or \\"middle-eight\\") and a return of the verse in one last A section (AABA). The B section is often intended as a contrast to the A sections that precede and follow it. The B section may be made to contrast by putting it in a new harmony. For example, with the jazz standard \\"I've Got Rhythm\\", the A sections are all tonic prolongations based around the I–vi–ii–V chord progression (B♭ in the standard key); however, the B section changes key and moves to V/vi, or D7 in the standard key, which then does a circle of fifths movement to G7, C7 and finally F7, setting the listener up for a return to the tonic Bb in the final A section.\\n\\nThe \\"I've Got Rhythm\\" example also provides contrast because the harmonic rhythm changes in the B section. Whereas the A sections contain a vibrant, exciting feel of two chord changes per bar (e.g., the first two bars are often B♭–g minor/c minor–F7), the B section consists of two bars of D7, two bars of G7, two bars of C7 and two bars of F7. In some songs, the \\"feel\\" also changes in the B section. For example, the A sections may be in swing feel, and the B section may be in Latin or Afro-Cuban feel.\\n\\nWhile the form is often described as AABA, this does not mean that the A sections are all exactly the same. The first A section ends by going back to the next A section, and the second A section ends and transitions into the B section. As such, at the minimum, the composer or arranger often modifies the harmony of the end of the different A sections to guide the listener through the key changes. As well, the composer or arranger may re-harmonize the melody on one or more of the A sections, to provide variety. Note that with a reharmonization, the melody does not usually change; only the chords played by the accompaniment musicians change.\\n\\nExamples include \\"Deck the Halls\\":\\n\\n> A: Deck the hall with boughs of holly,\\n> A: 'Tis the season to be jolly.\\n> B: Don we now our gay apparel,\\n> A: Troll the ancient Yuletide carol.\\n\\n## Variation on the basic structure\\n\\nVerse-chorus form or ABA form may be combined with AABA form, in compound AABA forms. That means that every A section or B section can consist of more then one section (for example Verse-Chorus). In that way the modern popular song structure can be viewed as a AABA form, where the B is the bridge.\\n\\nAAA format may be found in Bob Dylan's \\"The Times They Are a-Changin'\\", and songs like \\"The House of the Rising Sun\\", and \\"Clementine\\". Also \\"Old MacDonald\\", \\"Amazing Grace\\", \\"The Thrill Is Gone\\", and Gordon Lightfoot's \\"The Wreck of the Edmund Fitzgerald\\".\\n\\nAABA may be found in Crystal Gayle's \\"Don't It Make My Brown Eyes Blue\\", Billy Joel's \\"Just the Way You Are\\", and The Beatles' \\"Yesterday\\".\\n\\nABA (verse/chorus or chorus/verse) format may be found in Pete Seeger's \\"Turn! Turn! Turn!\\" (chorus first) and The Rolling Stones's \\"Honky Tonk Woman\\" (verse first).\\n\\nABAB may be found in AC/DC's \\"Back in Black\\", Jimmy Buffett's \\"Margaritaville\\", The Archies's \\"Sugar, Sugar\\", and The Eagles's \\"Hotel California\\".\\n\\nABABCB format may be found in John Cougar Mellencamp's \\"Hurts So Good\\", Tina Turner's \\"What's Love Got to Do with It?\\", and ZZ Top's \\"Sharp Dressed Man\\". Variations include Smokey Robinson's \\"My Guy\\", The Beatles's \\"Ticket to Ride\\",[18] The Pretenders' \\"Back on the Chain Gang\\" (ABABCAB), Poison's \\"Every Rose Has Its Thorn\\" (ABABCBAB), and Billy Joel's \\"It's Still Rock and Roll to Me\\" (ABABCABCAB).\\n","frontmatter":{"title":"Song structure","description":"The form variations of a songwriting process","date":"2021-10-12T00:00:00.000Z","cover":"/media_files/cover/theory-composition-song-structure.jpg"},"url":"/theory/composition/song/"},{"src":"---\\ntitle: Composers\\ndescription: Interviews and retrospectives\\ndate: 2021-10-02\\ncover: brian-eno-A-Year-with-Swollen-Appendices-faber-book.jpg\\n---\\n\\n## Steve Reich\\n\\n<youtube-embed video=\\"4guApFvA3nk\\" />\\n\\n<youtube-embed video=\\"_2EZ4ZBK4pQ\\" />\\n\\n<youtube-embed video=\\"muH9JZZ3tG8\\" />\\n\\n## Naithan Bosse\\n\\n[Network compositions](https://www.naithan.com/networked-music-performance/)\\n\\n- [Paresthesia - for distributed woodwinds and percussion (2016). PDF score](/public/media/pdf/Paresthesia_Score_July25_2019.pdf)\\n","frontmatter":{"title":"Composers","description":"Interviews and retrospectives","date":"2021-10-02T00:00:00.000Z","cover":"/media_files/cover/theory-composition-composers-brian-eno-A-Year-with-Swollen-Appendices-faber-book.jpg"},"url":"/theory/composition/composers/"},{"src":"---\\ntitle: Articulation and ornamentation\\ndescription: String techniques and way to play\\ndate: 2021-09-30\\n---\\n\\n## Articulation elements\\n\\n<youtube-embed video=\\"sFBz_VDpTVY\\" />\\n\\n<youtube-embed video=\\"b_mAdJfcEZg\\" />\\n\\n## String technique instructions\\n\\n<youtube-embed video=\\"ux3Z3yAK-UE\\" />\\n\\n## Ornamentation\\n\\nhttps://en.wikipedia.org/wiki/Ornament_(music)\\n\\n<youtube-embed video=\\"64lyO-tlSZI\\" />\\n\\n<youtube-embed video=\\"Hx_-ZWk0sy0\\" />\\n","frontmatter":{"title":"Articulation and ornamentation","description":"String techniques and way to play","date":"2021-09-30T00:00:00.000Z"},"url":"/theory/melody/articulation/"},{"src":"---\\ntitle: Numbered notation\\ndescription: A simplified notation using numbers to show scale degrees\\n\\ndate: 2021-09-29\\n---\\n\\n### Jian pu - 'simplified notation'\\n\\nA similar invention was presented by Jean-Jacques Rousseau in his work presented to the French Academy of Sciences in 1742. Due to its straightforward correspondence to the standard notation, it is possible that many other claims of independent invention are also true. Grove's credits Emile J.M. Chevé.\\n\\nAlthough the system is used to some extent in Germany, France, and the Netherlands, and more by the Mennonites in Russia, it has never become popular in the Western world. Number notation was used extensively in the 1920s and 30s by Columbia University, Teachers College music educator Satis Coleman, who felt it \\"proved to be very effective for speed with adults, and also as a means simple enough for young children to use in writing and reading tunes which they sing, and which they play on simple instruments.\\"\\n\\nThe system is very popular among some Asian people, making conventions to encode and decode music more accessible than in the West, as more Chinese can sight read jianpu than standard notation. Most Chinese traditional music scores and popular song books are published in jianpu, and jianpu notation is often included in vocal music with staff notation.\\n\\n![](./china.jpg)\\n\\n![](./jianpu.jpg)\\n\\n<youtube-embed video=\\"TyB1efr8nGY\\" />\\n\\n![](./AmazingGraceNumberedMusicalNotation.png)\\n","frontmatter":{"title":"Numbered notation","description":"A simplified notation using numbers to show scale degrees","date":"2021-09-29T00:00:00.000Z"},"url":"/theory/notes/alternative/numbered/"},{"src":"---\\ntitle: Bilinear notation\\ndescription: Upgraded staff notation by Jose A. Sotorrio\\ndate: 2021-09-25\\n---\\n\\nBilinear is quite similar to [Reed’s Twinline](http://musicnotation.org/system/twinline-notation-by-thomas-reed/). Sotorrio maintains he had no prior knowledge of Twinline when designing Bilinear, since he relied primarily on Gardner Read’s Source Book of Proposed Music Notation Reforms which does not include Twinline. (It was published in 1987, just after Twinline was introduced in 1986.) Since Twinline is the earlier system (Bilinear was introduced in 1997), Sotorrio now offers Bilinear as a variant of Twinline.\\n\\n![](./bilinear-jose-sotorrio.png)\\n\\nThe two systems share the same line pattern and the same alternating oval and triangle shaped noteheads, but there are differences in their details. Twinline’s triangles are right triangles with the 90 degree angle at their tip, while Bilinear’s triangles have a sharper angle at their tip. Also, the shape, color, and size of noteheads in Bilinear may be different depending on a note’s duration, as illustrated in the following image (courtesy of the Bilinear website):\\n\\n![](./blinearcomparison2.jpg)\\n","frontmatter":{"title":"Bilinear notation","description":"Upgraded staff notation by Jose A. Sotorrio","date":"2021-09-25T00:00:00.000Z"},"url":"/theory/notes/alternative/bilinear/"},{"src":"---\\ntitle: Chromatic staff\\ndescription: Extension of the regular staff to have room for all the 12 notes\\n\\ndate: 2021-09-22\\n---\\n\\n> “The need for a new notation, or a radical improvement of the old, is greater than it seems, and the number of ingenious minds that have tackled the problem is greater than one might think.” — Arnold Schoenberg\\n\\nHere is a chromatic scale on a traditional diatonic staff (above) and the same chromatic scale on a chromatic staff with five lines (below). This is just one of many versions of chromatic staff.\\n\\n![](./chromatic-staff.png)\\n\\nOn a chromatic staff each note has its own line or space on the staff. On the traditional staff only seven notes have their own line or space, the notes from just one key (C major/A minor, the white keys on the piano). The remaining notes (the black keys) have to be represented by altering these seven notes with sharp signs (#) or flat signs (b), either in the key signature or as an accidental.\\n\\n![](./octaves-chromatic-5-line.png)\\n\\nAll of these features of traditional music notation combine to make reading music much more difficult than it might be with a better notation system. For an analogy, imagine trying to do arithmetic with Roman numerals. It can be done, but the notation system makes a big difference. Of course it is important to view traditional notation in its broader historical context and to keep in mind the innovations and reforms that it has undergone over time.\\n\\n[Music notation project](http://musicnotation.org/)\\n","frontmatter":{"title":"Chromatic staff","description":"Extension of the regular staff to have room for all the 12 notes","date":"2021-09-22T00:00:00.000Z"},"url":"/theory/notes/alternative/chromatic-staff/"},{"src":"---\\ntitle: Polytonality\\ndescription: The musical use of more than one key simultaneously.\\ndate: 2021-09-20\\n---\\n\\nPolytonality (also polyharmony) is the musical use of more than one key simultaneously. Bitonality is the use of only two different keys at the same time. Polyvalence is the use of more than one harmonic function, from the same key, at the same time.\\n\\n<youtube-embed video=\\"lxPvWRXkEbE\\" />\\n\\n## History\\n\\n### In traditional music\\n\\n<youtube-embed video=\\"iGPO1kcTTIc\\" />\\n\\nLithuanian traditional singing style sutartines is based on polytonality. A typical sutartines song is based on a six-bar melody, where the first three bars contains melody based on the notes of the triad of a major key (for example, in G major), and the next three bars is based on another key, always a major second higher or lower (for example, in A major). This six-bar melody is performed as a canon, and repetition starts from the fourth bar. As a result, parts are constantly singing in different tonality (key) simultaneously (in G and in A). As a traditional style, sutartines disappeared in Lithuanian villages by the first decades of the 20th century, but later became a national musical symbol of Lithuanian music.\\n\\n<youtube-embed video=\\"Wij_cgVGOxw\\" />\\n\\n<youtube-embed video=\\"zeEnhlRteiA\\" />\\n\\n---\\n\\nTribes throughout India—including the Kuravan of Kerala, the Jaunsari of Uttar Pradesh, the Gond, the Santal, and the Munda—also use bitonality, in responsorial song.\\n\\n### In classical music\\n\\nIn J. S. Bach's Clavier-Übung III, there is a two-part passage where, according to Scholes: \\"It will be seen that this is a canon at the fourth below; as it is a strict canon, all the intervals of the leading 'voice' are exactly imitated by the following 'voice', and since the key of the leading part is D minor modulating to G minor, that of the following part is necessarily A minor modulating to D minor. Here, then, we have a case of polytonality, but Bach has so adjusted his progressions (by the choice at the critical moment of notes common to two keys) that while the right hand is doubtless quite under the impression that the piece is in D minor, etc., and the left hand that it is in A minor, etc., the listener feels that the whole thing is homogeneous in key, though rather fluctuating from moment to moment. In other words, Bach is trying to make the best of both worlds—the homotonal one of his own day and (prophetically) the polytonal one of a couple of centuries ater.\\"\\n\\n<youtube-embed video=\\"zJAcqI2HE8c\\" />\\n\\nAnother early use of polytonality occurs in the classical period in the finale of Wolfgang Amadeus Mozart's composition A Musical Joke, which he deliberately ends with the violins, violas and horns playing in four discordant keys simultaneously. However, it was not featured prominently in non-programmatic contexts until the twentieth century, particularly in the work of Charles Ives (Psalm 67, c. 1898–1902), Béla Bartók (Fourteen Bagatelles, Op. 6, 1908), and Stravinsky (Petrushka, 1911). Ives claimed that he learned the technique of polytonality from his father, who taught him to sing popular songs in one key while harmonizing them in another.\\n\\nAlthough it is only used in one section and intended to represent drunken soldiers, there is an early example of polytonality in Heinrich Ignaz Franz Biber's short composition Battalia, written in 1673.\\n\\n<youtube-embed video=\\"EkwqPJZe8ms\\" />\\n\\nStravinsky's The Rite of Spring is widely credited with popularizing bitonality, and contemporary writers such as Casella (1924) describe him as progenitor of the technique: \\"the first work presenting polytonality in typical completeness—not merely in the guise of a more or less happy 'experiment', but responding throughout to the demands of expression—is beyond all question the grandiose Le Sacre du Printemps of Stravinsky (1913)\\".\\n\\n<youtube-embed video=\\"ISdxPv2u-ns\\" />\\n\\nBartók's \\"Playsong\\" demonstrates easily perceivable bitonality through \\"the harmonic motion of each key ... [being] relatively uncomplicated and very diatonic\\". Here, the \\"duality of key\\" featured is A minor and C♯ minor.\\n\\n> <youtube-embed video=\\"zZanU1ZaN6k\\" />\\n> Example of polytonality or extended tonality from Milhaud's Saudades do Brasil (1920), right hand in B major and left hand in G major, or both hands in extended G major.\\n\\nOther polytonal composers influenced by Stravinsky include those in the French group, Les Six, particularly Darius Milhaud, as well as Americans such as Aaron Copland.\\n\\n<youtube-embed video=\\"vC3qQpyp4rI\\" />\\n\\nBenjamin Britten used bi- and polytonality in his operas, as well as enharmonic relationships, for example to signify the conflict between Claggart (F minor) and Billy (E major) in Billy Budd (note the shared enharmonically equivalent G♯/A♭) or to express the main character's \\"maladjustment\\" in Peter Grimes.\\n\\n### Polytonality and polychords\\n\\nPolytonality requires the presentation of simultaneous key-centers. The term \\"polychord\\" describes chords that can be constructed by superimposing multiple familiar tonal sonorities. For example, familiar ninth, eleventh, and thirteenth chords can be built from or decomposed into separate chords:\\n\\nThus polychords do not necessarily suggest polytonality, but they may not be explained as a single tertian chord. The Petrushka chord is an example of a polychord. This is the norm in jazz, for example, which makes frequent use of \\"extended\\" and polychordal harmonies without any intended suggestion of \\"multiple keys.\\"\\n\\n## Polyvalency\\n\\nThe following passage, taken from Beethoven's Piano Sonata in E♭, Op. 81a (Les Adieux), suggests clashes between tonic and dominant harmonies in the same key.\\n\\nLeeuw points to Beethoven's use of the clash between tonic and dominant, such as in his Third Symphony, as polyvalency rather than bitonality, with polyvalency being, \\"the telescoping of diverse functions that should really occur in succession to one another\\".\\n\\n## Polymodality\\n\\nPassages of music, such as Poulenc's Trois mouvements perpétuels, I., may be misinterpreted as polytonal rather than polymodal. In this case, two scales[clarification needed] are recognizable but are assimilated through the common tonic (B♭).\\n\\n## Polyscalarity\\n\\nPolyscalarity is defined as \\"the simultaneous use of musical objects which clearly suggest different source-collections. Specifically in reference to Stravinsky's music, Tymoczko uses the term polyscalarity out of deference to terminological sensibilities. In other words, the term is meant to avoid any implication that the listener can perceive two keys at once. Though Tymoczko believes that polytonality is perceivable, he believes polyscalarity is better suited to describe Stravinsky's music. This term is also used as a response to Van den Toorn's analysis against polytonality. Van den Toorn, in an attempt to dismiss polytonal analysis used a monoscalar approach to analyze the music with the octatonic scale. However, Tymoczko states that this was problematic in that it does not resolve all instances of multiple interactions between scales and chords. Moreover, Tymoczko quotes Stravinsky's claim that the music of Petrouchka's second tableau was conceived \\"in two keys\\". Polyscalarity is then a term encompassing multiscalar superimpositions and cases which give a different explanation than the octatonic scale.\\n\\n## Challenges\\n\\nSome music theorists, including Milton Babbitt and Paul Hindemith have questioned whether polytonality is a useful or meaningful notion or \\"viable auditory possibility\\". Babbitt called polytonality a \\"self-contradictory expression which, if it is to possess any meaning at all, can only be used as a label to designate a certain degree of expansion of the individual elements of a well-defined harmonic or voice-leading unit\\". Other theorists to question or reject polytonality include Allen Forte and Benjamin Boretz, who hold that the notion involves logical incoherence.\\n\\nOther theorists, such as Dmitri Tymoczko, respond that the notion of \\"tonality\\" is a psychological, not a logical notion. Furthermore, Tymoczko argues that two separate key-areas can, at least at a rudimentary level, be heard at one and the same time: for example, when listening to two different pieces played by two different instruments in two areas of a room.\\n\\n## Octatonicism\\n\\n<youtube-embed video=\\"esD90diWZds\\" />\\n\\nSome critics of the notion of polytonality, such as Pieter van den Toorn, argue that the octatonic scale accounts in concrete pitch-relational terms for the qualities of \\"clashing\\", \\"opposition\\", \\"stasis\\", \\"polarity\\", and \\"superimposition\\" found in Stravinsky's music and, far from negating them, explains these qualities on a deeper level. For example, the passage from Petrushka, cited above, uses only notes drawn from the C octatonic collection C–C♯–D♯–E–F♯–G–A–A♯.\\n\\n## Polymodal chromaticism\\n\\nIn music, polymodal chromaticism is the use of any and all musical modes sharing the same tonic simultaneously or in succession and thus creating a texture involving all twelve notes of the chromatic scale (total chromatic). Alternately it is the free alteration of the other notes in a mode once its tonic has been established.\\n\\nThe term was coined by composer, ethnomusicologist, and pianist Béla Bartók. The technique became a means in Bartók's composition to avoid, expand, or develop major-minor tonality (i.e. common practice harmony). This approach differed from that used by Arnold Schoenberg and his followers in the Second Viennese School and later serialists.\\n\\nThe concept was indicated by Bartók's folk-music-derived view of each note of the chromatic scale as being \\"of equal value\\" and thus to be used \\"freely and independently\\" (autobiography) and supported by references to the conception below in his Harvard Lectures (1943). The concept may be extended to the construction of non-diatonic modes from the pitches of more than one diatonic mode such as distance models including 1:3, the alternation of semitones and minor thirds, for example C–E♭–E–G–A♭–B–C which includes both the tonic and dominant as well as \\"'two of the most typical degrees from both major and minor' (E and B, E♭ and A♭, respectively) Kárpáti 1975 p. 132)\\".\\n\\nBartók had realised that both melodic minor scales gave rise to four chromatic steps between the two scales' fifths and the rising melodic minor scale's seventh degrees when superimposed. Consequently, he started investigating if the same pattern could be established in some way in the beginning of any scales and came to realise that superimposing a Phrygian and a Lydian scale with the same tonic resulted in what looked like a chromatic scale. Bartók's twelve-tone Phrygian/Lydian polymode, however, differed from the chromatic scale as used by, for example, late-Romantic composers like Richard Strauss and Richard Wagner. During the late 19th century the chromatic altering of a chord or melody was a change in strict relation to its functional non-altered version. Alterations in the twelve-tone Phrygian/Lydian polymode, the other hand, were \\"diatonic ingredients of a diatonic modal scale.\\"\\n\\n> Phrygian mode (C) C–D♭–E♭–F–G–A♭–B♭–C\\n> Lydian mode (C) C–D–E–F♯–G–A–B–C\\n> Twelve-tone Phrygian/Lydian polymode (C) C–D♭–D–E♭–E–F–F♯–G–A♭–A–B♭–B–C\\n>\\n> Twelve-tone Phrygian-Lydian polymode\\n\\nMelodies could be developed and transformed in novel ways through diatonic extension and chromatic compression, while still having coherent links to their original forms. Bartók described this as a new means to develop a melody.\\n\\nBartók started to superimpose all possible diatonic modes on each other in order to extend and compress melodies in ways that suited him, unrestricted by Baroque-Romantic tonality as well as strict serial methods such as the twelve-tone technique.\\n\\nIn 1941, Bartók's ethnomusicological studies brought him into contact with the music of Dalmatia and he realised that the Dalmatian folk-music used techniques that resembled polymodal chromaticism. Bartók had defined and used polymodal chromaticism in his own music before this. The discovery inspired him to continue to develop the technique.\\n\\nExamples of Bartók's use of the technique include No. 80 (\\"Hommage à R. Sch.\\") from Mikrokosmos featuring C Phrygian/Lydian (C–D♭–E♭–F–G–A♭–B♭–C/C–D–E–F♯–G–A–B–C). Lendvai identifies the technique in the late works of Modest Mussorgsky, Richard Wagner, Franz Liszt, and Giuseppe Verdi.\\n","frontmatter":{"title":"Polytonality","description":"The musical use of more than one key simultaneously.","date":"2021-09-20T00:00:00.000Z"},"url":"/theory/harmony/polytonality/"},{"src":"---\\ntitle: Klavarskribo\\ndescription: Vertical chromatic staff notation by Cornelis Pot\\n\\ndate: 2021-09-20\\n---\\n\\nKlavarskribo (sometimes shortened to klavar) is a music notation system that was introduced in 1931 by the Dutchman Cornelis Pot (1885–1977). The name means \\"keyboard writing\\" in Esperanto. It differs from conventional music notation in a number of ways and is intended to be easily readable.\\n\\n![](./Klavar.png)\\n\\nThe stave on which the notes are written is vertical so the music is read from top to bottom. Each note has its own individual position, low notes on the left and high notes on the right as on the piano. This stave consists of groups of two and three vertical lines corresponding to the black keys (notes) of the piano. White notes are written in the seven white spaces between the lines. Therefore sharps and flats are no longer needed, as each note has its own place in the octave. The evident correspondence between the stave and a piano induced Pot to use the name Klavarskribo.\\n\\n![](./KlavarExplain_3-E.png)\\n\\nAll notes are provided with stems—stems to the right: play with the right hand, stems to the left: left hand.\\n\\n<youtube-embed video=\\"efTv05nWNhk\\" />\\n\\n<youtube-embed video=\\"5mTRUF6q5-I\\" />\\n\\n![](./Klavar-debussy.png)\\n\\n[](https://www.klavarskribo.eu/en/)\\n","frontmatter":{"title":"Klavarskribo","description":"Vertical chromatic staff notation by Cornelis Pot","date":"2021-09-20T00:00:00.000Z"},"url":"/theory/notes/alternative/klavar/"},{"src":"---\\ntitle: Dodeka\\ndescription: Keyboard and notation redesigned for consistence and ease of use\\n\\ndate: 2021-09-18\\ncover: dodeka-keys.jpg\\n---\\n\\nThe Dodeka Keyboard Design is an isomorphic keyboard invented and designed by Jacques-Daniel Rochat. It is similar to a piano keyboard but with only a single row of keys containing each chromatic note.The keys corresponding to C, E and A flat are highlighted to provide visual landmarks. The creators aimed to create a rational and chromatic approach to music and performance. As an isomorphic keyboard, any musical sequence or interval has the same shape in each of the 12 keys.\\n\\n![](./DODEKA_Keyboard-comparison.png)\\n\\nThe Dodeka Music Notation is an alternative music notation or musical notation system invented and designed in 1980s by inventor and musician Jacques-Daniel Rochat in an attempt to improve upon traditional music notation.\\n\\n![](./Dodeka-music-notation-staff-pitch-web.jpg)\\n\\nUnlike conventional musical notation, the Dodeka music notation system uses a chromatic scale of 12 pitches and follows an equal pitch intervals configuration, with 4 lines per octave. In this configuration, the 12 notes of an octave appear in four positions vis-à-vis the staff lines, that is, either on, between, above and below the lines.\\n\\nEach pitch has its own unique place on the staff. And while conventional music notation may alter notes using accidental signs or key signatures, notes in the Dodeka notation appear as they are. There are no more key signatures or accidental signs in this musical system.\\n\\n> ![](./dodeka-alternative-music-notation-moonlight-D.jpg)\\n> (Excerpt of Beethoven Für Elise written in Dodeka Notation)\\n\\nThe Dodeka notation system represents note duration in a visual manner. Note lengths are represented through the notes graphical shapes, similar to what can be found in sequencer programmes. The reference time unit or time value being the quarter note (or crotchet), all durations are expressed as visual ratios from this reference point. For example, a whole note is the representation of four quarter note lengths. At the opposite, an eighth note (or quaver) is twice as short as a quarter note. All the other symbols and articulation marks are also [reimagined in Dodeka](https://www.dodekamusic.com/learn/alternative-music-notation/dodeka-musical-symbols-list-meaning/).\\n\\n[![](./dodeka-app.png)](https://apps.apple.com/us/app/dodeka-music/id1260932281?ls=1)\\n\\n### Dodeka note names\\n\\nThe objective was to create 2-letter names that convey a relationship between the names of the notes and their position on the staff. We did that using letters that are not present in the English (anglo-saxon) designation. For example, the note Do# (C#) is called Ka (K) because it shares the same position as La (A) (ie. both notes are above a line).\\n\\nFollowing this logic, the 12 notes can be written as:\\nDo / Ka / Ré / To(l) / Mi / Fa / Hu / So(l) / Pi / La / Vé / Si.\\n\\nIn English, we only use the first letters, which gives us the following sequence:\\nC / K / D / T / E / F / H / G / P / A / V / B.\\n\\n[Dodeka music](https://www.dodekamusic.com)\\n\\n![](./dodeka-keys.jpg)\\n","frontmatter":{"title":"Dodeka","description":"Keyboard and notation redesigned for consistence and ease of use","date":"2021-09-18T00:00:00.000Z","cover":"/media_files/cover/theory-notes-alternative-dodeka-dodeka-keys.jpg"},"url":"/theory/notes/alternative/dodeka/"},{"src":"---\\ntitle: Parsons code\\ndescription: A simple notation used to identify a piece of music through melodic motion\\n\\ndate: 2021-09-17\\n---\\n\\nThe Parsons code, formally named the Parsons code for melodic contours, is a simple notation used to identify a piece of music through melodic motion — movements of the pitch up and down. Denys Parsons (father of Alan Parsons) developed this system for his 1975 book The Directory of Tunes and Musical Themes. Representing a melody in this manner makes it easier to index or search for pieces, particularly when the notes' values are unknown. Parsons covered around 15,000 classical, popular and folk pieces in his dictionary. In the process he found out that \\\\*UU is the most popular opening contour, used in 23% of all the themes, something that applies to all the genres.\\n\\n\`\`\`\\nParsons Code of Ode to Joy\\n\\n    Parsons$ ./contour *RUURDDDDRUURDR\\n            *-*\\n           /   \\\\\\n          *     *\\n         /       \\\\\\n      *-*         *         *-*\\n                   \\\\       /   \\\\\\n                    *     *     *-*\\n                     \\\\   /\\n                      *-*\\n\\n\`\`\`\\n\\nThe first note of a melody is denoted with an asterisk (\\\\*), although some Parsons code users omit the first note. All succeeding notes are denoted with one of three letters to indicate the relationship of its pitch to the previous note:\\n\\n- - = first tone as reference,\\n- u = \\"up\\", for when the note is higher than the previous note,\\n- d = \\"down\\", for when the note is lower than the previous note,\\n- r = \\"repeat\\", for when the note has the same pitch as the previous note.\\n\\n[Search a melody by it's Parsons code at Musipedia](https://www.musipedia.org/melodic_contour.html)\\n\\n### Some examples\\n\\n- Ode to Joy: \\\\*RUURDDDDRUURDR\\n- \\"Twinkle Twinkle Little Star\\": \\\\*rururddrdrdrdurdrdrdurdrdrddrururddrdrdrd\\n- \\"Silent Night\\": \\\\*udduuddurdurdurudddudduruddduddurudduuddduddd\\n- \\"Aura Lea\\" (\\"Love Me Tender\\"): \\\\*uduududdduu\\n- \\"White Christmas\\": \\\\*udduuuu\\n- First verse in Madonna's \\"Like a Virgin\\": \\\\*rrurddrdrrurdudurrrrddrduuddrdu\\n\\nThere are [studies](http://ismir2003.ismir.net/papers/Uitdenbogerd.pdf) showing that despite it's simplicity, Parsons code is still too hard for non-musicians to formulate and interpret the code for melody search. Yet it may be useful for more skilled musicians, but the audio-based search becomes more widely spread and adopted.\\n","frontmatter":{"title":"Parsons code","description":"A simple notation used to identify a piece of music through melodic motion","date":"2021-09-17T00:00:00.000Z"},"url":"/theory/notes/alternative/parsons/"},{"src":"---\\ntitle: Intervals\\ndescription: Different kinds of relations between two notes\\n\\ncover: guang-yang.jpg\\ndate: 2021-09-15\\n---\\n\\n![svg](./chromatic.svg)\\n\\nTwo notes sounding simultaneously or sequentially form the basic building block for all the emotional expressiveness of music. They form some kind of relationships that bring up some distinct feeling.\\n\\nThe most basic is the 1:2 ratio of an [Unison and octave](./unison-octave/index.md), that are foundational for cyclic nature of pitch class space. [Perfect Fifth and Fourth](./fifth-fourth/index.md) are the foundational consonances that bring joy of the simple 2:3 and 3:4 ratios. This is the root of the 12 note system as a whole.\\n\\n[Thirds and Sixth](./third-sixth/index.md) are the imperfect consonances to evoke deeper feelings while the [Seconds and Sevenths](./second-seventh/index.md) are the sharper dissonances to spice everything up. We'll explore the process of the [Emancipation of dissonance](./emancipation/index.md) to find out how did we get at this point in our pitch pairs interpretation. And how science finally got [a measure for sound consonance](./dissonance/index.md). And take a brief look at some mathematical implications of building [interval chains](./cycles/index.md).\\n\\n<YoutubeEmbed video=\\"3sUpoSTy8zw\\" />\\n","frontmatter":{"title":"Intervals","description":"Different kinds of relations between two notes","cover":"/media_files/cover/theory-intervals-guang-yang.jpg","date":"2021-09-15T00:00:00.000Z"},"url":"/theory/intervals/"},{"src":"---\\ntitle: ABC notation\\ndescription: A shorthand form of musical notation for computers\\n\\ndate: 2021-09-15\\n---\\n\\n[ABC notation](https://abcnotation.com/wiki/abc:standard:v2.1) is a shorthand form of musical notation for computers. In basic form it uses the letter notation with a–g, A–G, and z, to represent the corresponding notes and rests, with other elements used to place added value on these – sharp, flat, raised or lowered octave, the note length, key, and ornamentation. This form of notation began from a combination of Helmholtz pitch notation and using ASCII characters to imitate standard musical notation (bar lines, tempo marks, etc.) that could facilitate the sharing of music online, and also added a new and simple language for software developers, not unlike other notations designed for ease, such as tablature and solfège.\\n\\n<client-only >\\n  <abc-editor />\\n</client-only>\\n\\n[Browse tunes](https://abcnotation.com/browseTunes)\\n\\nThe earlier ABC notation was built on, standardized, and changed by Chris Walshaw to better fit the keyboard and an ASCII character set, with the help and input of others. Originally designed to encode folk and traditional Western European tunes (e.g., from England, Ireland, and Scotland) which are typically single-voice melodies that can be written in standard notation on a single staff line, the extensions by Walshaw and others has opened this up with an increased list of characters and headers in a syntax that can also support metadata for each tune:\\n\\n- The index, when there are more than one tune in a file (X:)- the title (T:),\\n- the time signature (M:),\\n- the default note length (L:),\\n- the type of tune (R:),\\n- the key (K:)\\n  - with the clef (K: clef=[treble|alto|tenor|bass|perc])\\n\\nLines following the key designation represent the tune.\\n\\nAfter a surge of renewed interest in clarifying some ambiguities in the 2.0 draft and suggestions for new features, serious discussion of a new (and official) standard resumed in 2011, culminating in the release of ABC 2.1 as a new standard in late December 2011. Chris Walshaw has become involved again and is coordinating the effort to further improve and clarify the language, with plans for topics to be addressed in future versions to be known as ABC 2.2 and ABC 2.3 .\\n\\n<youtube-embed video=\\"H8hWKP5cEXE\\" />\\n\\n## More links\\n\\n- https://abcnotation.com/learn\\n- https://www.abcjs.net/\\n","frontmatter":{"title":"ABC notation","description":"A shorthand form of musical notation for computers","date":"2021-09-15T00:00:00.000Z"},"url":"/theory/notes/computer/abc/"},{"src":"---\\ntitle: Integer notation\\ndescription: System that uses numbers to show notes\\n\\ndate: 2021-09-14\\n---\\n\\nIn music, integer notation is the translation of pitch classes and/or interval classes into whole numbers. Thus if C = 0, then C♯ = 1 ... A♯ = 10, B = 11, with \\"10\\" and \\"11\\" substituted by \\"t\\" and \\"e\\" in some sources, A and B in others (like the duodecimal numeral system, which also uses \\"t\\" and \\"e\\", or A and B, for \\"10\\" and \\"11\\"). This allows the most economical presentation of information regarding post-tonal materials.\\n\\nTo avoid the problem of enharmonic spellings, theorists typically represent pitch classes using numbers beginning from zero, with each successively larger integer representing a pitch class that would be one semitone higher than the preceding one, if they were all realised as actual pitches in the same octave. Because octave-related pitches belong to the same class, when an octave is reached, the numbers begin again at zero. This cyclical system is referred to as modular arithmetic and, in the usual case of chromatic twelve-tone scales, pitch-class numbering is regarded as \\"modulo 12\\" (customarily abbreviated \\"mod 12\\" in the music-theory literature) — that is, every twelfth member is identical.\\n\\nOne can map a pitch's fundamental frequency f (measured in hertz) to a real number p using the equation\\n\\n    p = 9 + 12 log 2 (⁡ f / 440  Hz ).\\n\\nThis creates a linear pitch space in which octaves have size 12, semitones (the distance between adjacent keys on the piano keyboard) have size 1, and middle C (C4) is assigned the number 0 (thus, the pitches on piano are −39 to +48). Indeed, the mapping from pitch to real numbers defined in this manner forms the basis of the MIDI Tuning Standard, which uses the real numbers from 0 to 127 to represent the pitches C−1 to G9 (thus, middle C is 60).\\n\\nTo represent pitch classes, we need to identify or \\"glue together\\" all pitches belonging to the same pitch class. The result is a cyclical quotient group that musicians call pitch class space and mathematicians call R/12Z. Points in this space can be labelled using real numbers in the range 0 ≤ x < 12. These numbers provide numerical alternatives to the letter names of elementary music theory:\\n\\n- 0 = C,\\n- 1 = C♯/D♭,\\n- 2 = D,\\n- 2.5 = Dhalf sharp (quarter tone sharp),\\n- 3 = D♯/E♭,\\n\\nand so on. In this system, pitch classes represented by integers are classes of twelve-tone equal temperament (assuming standard concert A).\\n","frontmatter":{"title":"Integer notation","description":"System that uses numbers to show notes","date":"2021-09-14T00:00:00.000Z"},"url":"/theory/notes/alternative/integer/"},{"src":"---\\ntitle: Standard pitch notation\\ndescription: American SPN\\n\\ndate: 2021-09-14\\n---\\n\\n![](./Scientific_pitch_notation_octaves_of_C.png)\\n\\nScientific pitch notation (SPN), also known as American standard pitch notation (ASPN) and international pitch notation (IPN),[1] is a method of specifying musical pitch by combining a musical note name (with accidental if needed) and a number identifying the pitch's octave.\\n\\nAlthough scientific pitch notation was originally designed as a companion to scientific pitch (see below), the two are not synonymous. Scientific pitch is a pitch standard—a system that defines the specific frequencies of particular pitches (see below). Scientific pitch notation concerns only how pitch names are notated, that is, how they are designated in printed and written text, and does not inherently specify actual frequencies. Thus, the use of scientific pitch notation to distinguish octaves does not depend on the pitch standard used.\\n\\nThe notation makes use of the traditional tone names (A to G) which are followed by numbers showing which octave they are part of.\\n\\nFor standard A440 pitch equal temperament, the system begins at a frequency of 16.35160 Hz, which is assigned the value C0.\\n\\nThe octave 0 of the scientific pitch notation is traditionally called the sub-contra octave, and the tone marked C0 in SPN is written as ,,C or C,, or CCC in traditional systems, such as Helmholtz notation. Octave 0 of SPN marks the low end of what humans can actually perceive, with the average person being able to hear frequencies no lower than 20 Hz as pitches.\\n\\n### Use\\n\\nScientific pitch notation is often used to specify the range of an instrument. It provides an unambiguous means of identifying a note in terms of textual notation rather than frequency, while at the same time avoiding the transposition conventions that are used in writing the music for instruments such as the clarinet and guitar. It is also easily translated into staff notation, as needed. In describing musical pitches, nominally enharmonic spellings can give rise to anomalies where, for example in meantone temperaments C♭\\n4 is a lower frequency than B3; but such paradoxes usually do not arise in a scientific context.\\n\\nScientific pitch notation avoids possible confusion between various derivatives of Helmholtz notation which use similar symbols to refer to different notes. For example, \\"c\\" in Helmholtz's original notation refers to the C below middle C, whereas \\"C\\" in ABC Notation refers to middle C itself. With scientific pitch notation, middle C is always C4, and C4 is never any note but middle C. This notation system also avoids the \\"fussiness\\" of having to visually distinguish between four and five primes, as well as the typographic issues involved in producing acceptable subscripts or substitutes for them. C7 is much easier to quickly distinguish visually from C8, than is, for example, c′′′′ from c′′′′′, and the use of simple integers (e.g. C7 and C8) makes subscripts unnecessary altogether.\\n\\nAlthough pitch notation is intended to describe sounds audibly perceptible as pitches, it can also be used to specify the frequency of non-pitch phenomena. Notes below E0 or higher than E♭\\n10 are outside most humans' hearing range, although notes slightly outside the hearing range on the low end may still be indirectly perceptible as pitches due to their overtones falling within the hearing range.\\n\\n## Helmholtz pitch notation\\n\\nHelmholtz pitch notation is a system for naming musical notes of the Western chromatic scale. Fully described and normalized by the German scientist Hermann von Helmholtz, it uses a combination of upper and lower case letters (A to G), and the sub- and super-prime symbols ( ͵  ′  or ⸜ ⸝) to denote each individual note of the scale. It is one of two formal systems for naming notes in a particular octave, the other being scientific pitch notation.\\n\\n### Use\\n\\nThe accenting of the scale in Helmholtz notation always starts on the note C and ends at B (e.g. C D E F G A B). The note C is shown in different octaves by using upper-case letters for low notes, and lower-case letters for high notes, and adding sub-primes and primes in the following sequence: C͵͵ C͵ C c c′ c″ c‴ (or ,,C ,C C c c′ c″ c‴ or C⸜⸜ C⸜ C c c⸝ c⸝⸝ c⸝⸝⸝) and so on.\\n\\nMiddle C is designated c′, therefore the octave from middle C upwards is c′–b′.\\n\\nWhole octaves may also be given a name based on \\"English strokes notation\\". For example, the octave from c′–b′ is called the one-line octave or (less common) once-accented octave. Correspondingly, the notes in the octave may be called one-lined C (for c′), etc.\\n\\nThis diagram gives examples of the lowest and highest note in each octave, giving their name in the Helmholtz system, and the \\"German method\\" of octave nomenclature. (The octave below the contra octave is known as the sub-contra octave).\\n\\n<img src=\\"./Helmholtz-pitch-notation.svg\\">\\n","frontmatter":{"title":"Standard pitch notation","description":"American SPN","date":"2021-09-14T00:00:00.000Z"},"url":"/theory/notes/alternative/scientific/"},{"src":"---\\ntitle: Piano roll\\ndescription: A common form of music in modern DAWs\\n\\ndate: 2021-09-13\\nlinks: \\n  - https://blog.landr.com/piano-roll/\\n---\\n\\nThe Buffalo Convention of December 10, 1908 established two future roll formats for the US-producers of piano rolls for self-playing pianos. The two formats had different punchings of 65 and 88 notes, but the same width (11+1⁄4 inches or 286 millimetres); thus 65-note rolls would be perforated at 6 holes to the inch, and 88-note rolls at 9 holes to the inch, leaving margins at both ends for future developments. This made it possible to play the piano rolls on any self-playing instrument built according to the convention, albeit sometimes with a loss of special functionality. This format became a loose world standard.\\n\\n![](./PlayerPianoRoll.jpg)\\n\\n![](./FL.png)\\n","frontmatter":{"title":"Piano roll","description":"A common form of music in modern DAWs","date":"2021-09-13T00:00:00.000Z","links":["https://blog.landr.com/piano-roll/"]},"url":"/theory/notes/computer/piano-roll/"},{"src":"---\\ntitle: Modulation\\ndescription: Changing keys during the composition\\ndate: 2021-09-12\\n---\\n\\n## Tonicization\\n\\nIn music, [tonicization](https://en.wikipedia.org/wiki/Tonicization) is the treatment of a pitch other than the overall tonic (the \\"home note\\" of a piece) as a temporary tonic in a composition. In Western music that is tonal, the piece is heard by the listener as being in a certain key. A tonic chord has a dominant chord; in the key of C major, the tonic chord is C major and the dominant chord is G major or G dominant seventh. The dominant chord, especially if it is a dominant seventh, is heard by Western composers and listeners familiar with music as resolving (or \\"leading\\") to the tonic, due to the use of the leading note in the dominant chord. A tonicized chord is a chord other than the tonic chord to which a dominant or dominant seventh chord progresses. When a dominant chord or dominant seventh chord is used before a chord other than the tonic, this dominant or dominant seventh chord is called a secondary dominant. When a chord is tonicized, this makes this non-tonic chord sound temporarily like a tonic chord.\\n\\n### Examples\\n\\nUsing Roman numeral chord analysis, a chord labeled \\"V/ii\\" (colloquially referred to as \\"five of two\\") would refer to the V chord of a different key; specifically, a key named after the ii chord of the original tonic. This would usually resolve to the ii chord (of the original key). In this situation, the ii has been tonicized.\\n\\nFor example, in a piece in the key of C major, the ii chord is D minor, because D is the second scale degree in a C major scale. The D is minor because to construct a triad over D using only the pitches available in the key of C major—i.e. no sharps, no flats—the triad must be minor—the individual notes D, F and A. The V/ii chord is composed of the pitches in a V chord in the key of ii (key of D minor). The pitches used in a V/ii in this example include the notes A, C# and E (creating an A major chord). In the key of D minor, an A major chord is the dominant chord. In the key of C major, C sharp is an accidental. One can often find examples of tonicization by looking for accidentals, as there are always accidentals involved in tonicization. However, it is important to note that the opposite is not true—just because there is an accidental does not mean that it is definitely a case of tonicization.\\n\\nOnly major and minor chords may be tonicized. Diminished chords and augmented chords cannot be tonicized because they do not represent stable key areas in Western music. For example, a B minor chord (B, D, F#) occurring in any of its closely related keys may be tonicized with an F# major chord (V/V) because B minor also represents a key area—the key of B minor. However, a B diminished chord (B, D, F) may not be tonicized because \\"B diminished\\" could not be a stable key area; there is no key area in Western classical music that has B, D, & F—the pitches that make up the B diminished chord—as the first, third and fifth scale degrees, respectively. This holds true of all diminished and augmented chords.\\n\\nTonicizations may last for multiple chords. Taking the example given above with the chord progression V/ii → ii, it is possible to extend this sequence backwards. Instead of just V/ii → ii, there could be iv/ii → V/ii → ii (additionally, thinking about the last chord in the sequence: ii, as i/ii, it becomes clear why the phrase \\"temporary tonic\\"—see above—is often used in relation to tonicization). Though perceptions vary as a general rule if a chord is treated as the tonic for longer than a phrase before returning to the previous key area, then the treatment is considered a modulation to a new key.\\n\\n## Modulation\\n\\nIn a song in C major, if a composer treats another key as the tonic (for example, the ii chord, D minor) for a short period by alternating between A7 (the notes A, C#, E and G) and D minor, and then returns to the tonic (C Major), this is a tonicization of the key of D minor. However, if a song in C major shifts to the key of D minor and stays in this second, new key for a significant period, then this is usually considered to be a modulation to the new key (in this case, from C major to D minor). In effect, D minor has become the new key of the song.\\n\\n\\"A secondary dominant is like a miniature modulation; for just an instant, the harmony moves out of the diatonic chords of the key.\\"\\n\\nIn music, [modulation](<https://en.wikipedia.org/wiki/Modulation_(music)>) is the change from one tonality (tonic, or tonal center) to another. This may or may not be accompanied by a change in key signature. Modulations articulate or create the structure or form of many pieces, as well as add interest. Treatment of a chord as the tonic for less than a phrase is considered tonicization.\\n\\n> Modulation is the essential part of the art. Without it there is little music, for a piece derives its true beauty not from the large number of fixed modes which it embraces but rather from the subtle fabric of its modulation.  \\n> — Charles-Henri Blainville (1767)\\n\\n## Requirements\\n\\n- Harmonic: quasi-tonic, modulating dominant, pivot chord\\n- Melodic: recognizable segment of the scale of the quasi-tonic or strategically placed leading-tone\\n- Metric & rhythmic: quasi-tonic and modulating dominant on metrically accented beats, prominent pivot chord\\n\\nThe **quasi-tonic** is the tonic of the new key established by the modulation. The modulating dominant is the dominant of the quasi-tonic. The pivot chord is a predominant to the modulating dominant and a chord common to both the keys of the tonic and the quasi-tonic. For example, in a modulation to the dominant, ii/V–V/V–V could be a pivot chord, modulating dominant, and quasi-tonic.\\n\\n## Types\\n\\n### Common-chord modulation\\n\\nCommon-chord modulation (also known as diatonic-pivot-chord modulation) moves from the original key to the destination key (usually a closely related key) by way of a chord both keys share: \\"Most modulations are made smoother by using one or more chords that are common to both keys.\\" For example, G major and D major have four triad chords in common: G major, B minor, D major and E minor.\\n\\nAny chord with the same root note and chord quality (major, minor, diminished) can be used as the pivot chord. Therefore, chords that are not generally found in the style of the piece (for example, major VII chords in a J. S. Bach-style chorale) are also not likely to be chosen as the pivot chord. The most common pivot chords are the predominant chords (ii and IV) in the new key. In analysis of a piece that uses this style of modulation, the common chord is labeled with its function in both the original and the destination keys, as it can be heard either way.\\n\\nWhere an altered chord is used as a pivot chord in either the old or new key (or both), this would be referred to as altered common chord modulation, in order to distinguish the chromaticism that would be introduced from the otherwise, diatonic method.\\n\\n### Enharmonic modulation\\n\\nModulation from D major to D♭ major in Schubert's Op. 9, No. 14, D. 365, mm. 17–24, using the German sixth, in the new key, that is enharmonic to the dominant seventh in the old key.\\n\\nAn enharmonic modulation takes place when one treats a chord as if it were spelled enharmonically as a functional chord in the destination key, and then proceeds in the destination key. There are two main types of enharmonic modulations: dominant seventh/augmented sixth, and (fully) diminished seventh. Any dominant seventh or German sixth can be reinterpreted as the other by respelling the m7 or A6 chord tone (respectively) in order to modulate to a key a half-step away (descending or ascending); if the fifth-from-root chord tone of a German sixth is omitted, the result is an Italian sixth. A diminished seventh chord meanwhile, can be respelled in multiple other ways to form a diminished seventh chord in a key a minor third (m3 as root), tritone (d5 as root) or major sixth (d7 as root) away. Where the dominant seventh is found in all diatonic scales, the diminished seventh is found only in the harmonic scale naturally; an augmented sixth is itself an altered chord, relying on the raised fourth scale degree.\\n\\nBy combining the diminished seventh with a dominant seventh and/or augmented sixth, altering only one pivot note (by a half tone), it is possible to modulate quite smoothly from any key to any other in at most three chords, no matter how distant the starting and ending keys (be aware that, only when modulating between key signatures featuring double-sharps/flats, may the need to respell natural notes enharmonically arise); however, this may or may not require the use of altered chords (operating in the harmonic minor without augmented sixth would not) where the effect can be less subtle than other modulations. The following are examples used to describe this in chord progressions starting from the key of D minor (these chords may instead be used in other keys as borrowed chords, such as the parallel major, or other forms of the minor):\\n\\n- C♯–E–G–B♭ (dim. 7th), C–E–G–B♭ (lowering the root a semitone to a modulating dom. 7th), F–A–C (quasi-tonic) takes us to F major—a relative major modulation (though not enharmonic); but exactly the same progression enharmonically C♯–E–G–B♭, C–E–G–A♯ (Ger. aug. 6th), E–G–B–E (quasi-tonic) takes us somewhat unexpectedly to E natural/harmonic minor—a half-step modulation (ascending).\\n- C♯–E–G–B♭ (dim. 7th), A–C♯–E–G (lowering the 7th a semitone and respelling as a modulating dom. 7th), D–F♯–A (quasi-tonic) takes us to the key of D major—a parallel modulation (though not enharmonic). Enharmonically: C♯–E–G–B♭, A–C♯–E–Fdouble sharp (Ger. aug. 6th), C♯–E–G♯ (quasi-tonic) modulates to C♯ minor—a major seventh modulation/half-step descending.\\n- C♯–E–G–B♭ (dim. 7th), C♯–E♭–G–B♭ ≡ E♭–G–B♭–D♭ (lowering the major third a half tone and respelling as a modulating dom. 7th), A♭–C–E♭ (quasi-tonic) leads to A♭ major—a minor third and relative modulation (or tritone modulation if starting in D Major).\\n\\nNote that in standard voice leading practice, any type of augmented sixth chord favors a resolution to the dominant chord (see: augmented sixth chord), with the exception of the German sixth, where it is difficult to avoid incurring parallel fifths; to prevent this, a cadential six four is commonly introduced before the dominant chord (which would then typically resolve to the tonic to establish tonality in the new key), or an Italian/French sixth is used instead.\\n\\nIn short, lowering any note of a diminished seventh chord a half tone leads to a dominant seventh chord (or German sixth enharmonically), the lowered note being the root of the new chord. Raising any note of a diminished seventh chord a half tone leads to a half-diminished seventh chord, the root of which is a whole step above the raised note. This means that any diminished chord can be modulated to eight different chords by simply lowering or raising any of its notes. If also employing enharmonic respelling of the diminished seventh chord, such as that beginning the modulation in the above examples (allowing for three other possible diminished seventh chords in other keys), it quickly becomes apparent the versatility of this combination technique and the wide range of available options in key modulation.\\n\\nThis type of modulation is particularly common in Romantic music, in which chromaticism rose to prominence.\\n\\nOther types of enharmonic modulation include the augmented triad (III+) and French sixth (Fr+6). Augmented triad modulation occurs in the same fashion as the diminished seventh, that is, to modulate to another augmented triad in a key: a major third (M3 as root) or minor sixth (A5 as root) away. French augmented sixth (Fr+6) modulation is achieved similarly but by respelling both notes of either the top or bottom major third (i.e. root and major third or diminished fifth and augmented sixth) enharmonically and inverting with the other major third (i.e. diminished fifth and augmented sixth becomes root and major third of the new Fr+6); either choice results in the same chord and key modulation (a tritone away), as the diminished fifth always becomes the new root.\\n\\n### Common-tone modulation\\n\\nCommon-tone modulation uses a sustained or repeated pitch from the old key as a bridge between it and the new key (common tone). Usually, this pitch will be held alone before the music continues in the new key. For example, a held F from a section in B♭ major could be used to transition to F major. This is used, for example, in Schubert's Unfinished Symphony. \\"If all of the notes in the chord are common to both scales (major or minor), then we call it a common chord modulation. If only one or two of the notes are common, then we call it common tone modulation.\\"\\n\\nStarting from a major chord, for example G major (G–B–D), there are twelve potential goals using a common-tone modulation: G minor, G♯ minor, B♭ major, B major, B minor, C major, C minor, D minor, D major, E♭ major, E major, E minor. Thus common-tone modulations are convenient for modulation by diatonic or chromatic third.\\n\\n### Chromatic modulation\\n\\nA chromatic modulation is so named because it occurs at the point of a chromatic progression, one which involves the chromatic inflection of one or more notes whose letter name, thus, remains the same though altered through an accidental. Chromatic modulations are often between keys which are not closely related. A secondary dominant or other chromatically altered chord may be used to lead one voice chromatically up or down on the way to the new key. (In standard four-part chorale-style writing, this chromatic line will most often be in one voice.) For example, a chromatic modulation from C major to D minor.\\n\\nIn this case, the IV chord in C major (F major) would be spelled F–A–C, the V/ii chord in C major (A major) spelled A–C♯–E, and the ii chord in C major (D minor), D–F–A. Thus the chromaticism, C–C♯–D, along the three chords; this could easily be part-written so those notes all occurred in one voice. Despite the common chord (ii in C major or i in D minor), this modulation is chromatic due to this inflection.\\n\\nThe consonant triads for chromatic modulation are ♭III, ♭VI, ♭II, ♯iv, vii, and ♭VII in major, and ♮iii, ♮vi, ♭II, ♯iv, ii, and ♮vii in minor.\\n\\nIn the example pictured, a chromatic modulation from F major to D minor.\\n\\nIn this case, the V chord in F major (C major) would be spelled C–E–G, the V in D minor (A major) would be spelled A–C♯–E. Thus the chromaticism, C–C♯–D, which is here split between voices but may often easily be part-written so that all three notes occur in one voice.\\n\\nThe combination of chromatic modulation with enharmonic modulation in late Romantic music led to extremely complex progressions in the music of such composers as César Franck, in which two or three key shifts may occur in the space of a single bar, each phrase ends in a key harmonically remote from its beginning, and great dramatic tension is built while all sense of underlying tonality is temporarily in abeyance. Good examples are to be found in the opening of his Symphony in D minor, of which he himself said (see Wikiquote) \\"I dared much, but the next time, you will see, I will dare even more...\\"; and his Trois Chorals for organ, especially the first and third of these, indeed fulfill that promise.\\n\\n### Phrase modulation\\n\\nPhrase (also called direct, static, or abrupt) modulation is a modulation in which one phrase ends with a cadence in the original key, and the next phrase begins in the destination key without any transition material linking the two keys. This type of modulation is frequently done to a closely related key—particularly the dominant or the relative major/minor key.\\n\\nAn unprepared modulation is a modulation \\"without any harmonic bridge\\", characteristic of impressionism.\\n\\nFor example:\\n\\n              A   E   A   F   B♭   F\\n    A major   I   V   I\\n    F major               I   IV    I\\n\\n### Sequential modulation\\n\\n\\"A passage in a given key ending in a cadence might be followed by the same passage transposed (up or down) to another key,\\" this being known as sequential modulation. Although a sequence does not have to modulate, it is also possible to modulate by way of a sequence. A sequential modulation is also called rosalia. The sequential passage will begin in the home key, and may move either diatonically or chromatically. Harmonic function is generally disregarded in a sequence, or, at least, it is far less important than the sequential motion. For this reason, a sequence may end at a point that suggests a different tonality than the home key, and the composition may continue naturally in that key.\\n\\n### Chain modulation\\n\\nDistant keys may be reached sequentially through closely related keys by chain modulation, for example C to G to D or C to C minor to E♭ major. A common technique is the addition of the minor seventh after each tonic is reached, thus turning it into a dominant seventh chord:\\n\\n    D \\t→ \\tD7 \\tG \\t→ \\tG7 \\tC \\t→ \\tC7 \\tF\\n    I \\t→ \\tV7 \\tI \\t→ \\tV7 \\tI \\t→ \\tV7 \\tI\\n\\n### Changes between parallel keys\\n\\nSince modulation is defined as a change of tonic (tonality or tonal center), the change between minor and its parallel major or the reverse is technically not a modulation but a change in mode. Major tonic harmony that concludes music in minor contains what is known as a Picardy third. Any harmony associated with the minor mode in the context of major musical passages is often referred to as a borrowed chord, which creates mode mixture.\\n\\n### Common modulations\\n\\nThe most common modulations are to closely related keys (I, V, IV, vi, iii, ii). V (dominant) is the most frequent goal and, in minor, III (relative key) is also a common goal. Modulation to the dominant or the subdominant is relatively simple as they are adjacent steps on the circle of fifths. Modulations to the relative major or minor are also simple, as these keys share all pitches in common. Modulation to distantly related keys is often done smoothly through using chords in successive related keys, such as through the circle of fifths, the entirety of which may be used in either direction:\\n\\n    D – A – E – B/C♭ – F♯/G♭ – C♯/D♭ – G♯/A♭ – D♯/E♭ – A♯/B♭ – F – C – G – D\\n\\nIf a given key were G major, the following chart could be used:\\n\\n    C \\t— \\tG \\t— \\tD\\n\\nFrom G (which is the given key), a musician would go P5 (a perfect fifth) above G (which is D) and also P5 below G (which is C).\\n\\nFrom this, the musician would go to G major's relative minor which is E minor, and potentially to C major and D major's related minor as well (a musician who does not know the related minor for C and D major may also go P5 below or above E minor).\\n\\n    C \\t— \\tG \\t— \\tD\\n    | \\t\\t| \\t\\t|\\n    Am \\t\\tEm \\t\\tBm\\n\\nBy using the relative minor keys one can find the specific key that the key can modulate into.\\n\\nMany musicians use the circle of fifths to find these keys and make similar charts to help with the modulation.\\n\\n<youtube-embed video=\\"epqYft12nV4\\" />\\n\\n## Significance\\n\\nIn certain classical music forms, a modulation can have structural significance. In sonata form, for example, a modulation separates the first subject from the second subject. Frequent changes of key characterize the development section of sonatas. Moving to the subdominant is a standard practice in the trio section of a march in a major key, while a minor march will typically move to the relative major.\\n\\nChanges of key may also represent changes in mood. In many genres of music, moving from a lower key to a higher often indicates an increase in energy.\\n\\nChange of key is not possible in the full chromatic or the twelve tone technique, as the modulatory space is completely filled; i.e., if every pitch is equal and ubiquitous there is nowhere else to go. Thus other differentiating methods are used, most importantly ordering and permutation. However, certain pitch formations may be used as a \\"tonic\\" or home area.\\n\\n## Other types\\n\\nThough modulation generally refers to changes of key, any parameter may be modulated, particularly in music of the 20th and 21st century. Metric modulation (known also as tempo modulation) is the most common, while timbral modulation (gradual changes in tone color), and spatial modulation (changing the location from which sound occurs) are also used.\\n\\nModulation may also occur from a single tonality to a polytonality, often by beginning with a duplicated tonic chord and modulating the chords in contrary motion until the desired polytonality is reached.\\n\\n## Chromatic mediant changes\\n\\nhttps://youtu.be/mjFACmJ5ON8\\n","frontmatter":{"title":"Modulation","description":"Changing keys during the composition","date":"2021-09-12T00:00:00.000Z"},"url":"/theory/harmony/modulation/"},{"src":"---\\ntitle: MIDI\\ndescription: Standard for digital music communication\\n\\ndate: 2021-09-12\\ncover: GM_Standard_Drum_Map_on_the_keyboard.svg\\nlinks:\\n  - https://www.scoringnotes.com/opinion/a-brief-history-of-music-notation-on-computers/\\n---\\n\\nAt the 1983 Winter NAMM Show, Smith demonstrated a MIDI connection between Prophet 600 and Roland JP-6 synthesizers. The MIDI specification was published in August 1983. The MIDI standard was unveiled by Kakehashi and Smith, who received Technical Grammy Awards in 2013 for their work. In 1982, the first instruments were released with MIDI, the Roland Jupiter-6 and the Prophet 600. In 1983, the first MIDI drum machine, the Roland TR-909, and the first MIDI sequencer, the Roland MSQ-700 were released. The first computer to support MIDI, the NEC PC-88 and PC-98, was released in 1982. The MIDI standard connected ground-breaking hardware like Yamaha’s DX7 synthesiser and Roland’s TR-909 drum machine.\\n\\n![](./midi-notes.jpg)\\n\\nA MIDI message is an instruction that controls some aspect of the receiving device. A MIDI message consists of a status byte, which indicates the type of the message, followed by up to two data bytes that contain the parameters. MIDI messages can be channel messages sent on only one of the 16 channels and monitored only by devices on that channel, or system messages that all devices receive. Each receiving device ignores data not relevant to its function.There are five types of message: Channel Voice, Channel Mode, System Common, System Real-Time, and System Exclusive.\\n\\n![](./midi_data.gif)\\n\\nChannel Voice messages transmit real-time performance data over a single channel. Examples include \\"note-on\\" messages which contain a MIDI note number that specifies the note's pitch, a velocity value that indicates how forcefully the note was played, and the channel number; \\"note-off\\" messages that end a note; program change messages that change a device's patch; and control changes that allow adjustment of an instrument's parameters. MIDI notes are numbered from 0 to 127 assigned to C−1 to G9. This corresponds to a range of 8.175799 to 12543.85 Hz (assuming equal temperament and 440 Hz A4) and extends beyond the 88 note piano range from A0 to C8. Middle C has the number 60. A4 (A440) – 69.\\n\\n![svg](./GM_Standard_Drum_Map_on_the_keyboard.svg)\\n\\n## MIDI clock\\n\\nMIDI beat clock, or simply MIDI clock, is a clock signal that is broadcast via MIDI to ensure that several MIDI-enabled devices such as a synthesizer or music sequencer stay in synchronization. Clock events are sent at a rate of 24 pulses per quarter note. Those pulses are used to maintain a synchronized tempo for synthesizers that have BPM-dependent voices and also for arpeggiator synchronization.\\n\\nMIDI beat clock differs from MIDI timecode in that MIDI beat clock is tempo-dependent.\\n\\nLocation information can be specified using MIDI Song Position Pointer (SPP, see below), although many simple MIDI devices ignore this message.\\nMessages\\n\\nMIDI beat clock defines the following real-time messages:\\n\\n- clock (decimal 248, hex 0xF8)\\n- start (decimal 250, hex 0xFA)\\n- continue (decimal 251, hex 0xFB)\\n- stop (decimal 252, hex 0xFC)\\n\\nMIDI also specifies a System Common message called Song Position Pointer (SPP). SPP can be used in conjunction with the above realtime messages for complete sync. This message consists of 3 bytes; a status byte (decimal 242, hex 0xF2), followed by two 7-bit data bytes (least significant byte first) forming a 14-bit value which specifies the number of \\"MIDI beats\\" (1 MIDI beat = a 16th note = 6 clock pulses) since the start of the song. This message only needs to be sent once if a jump to a different position in the song is needed. Thereafter only realtime clock messages need to be sent to advance the song position one tick at a time.\\n","frontmatter":{"title":"MIDI","description":"Standard for digital music communication","date":"2021-09-12T00:00:00.000Z","cover":"/media_files/cover/theory-notes-computer-midi-GM_Standard_Drum_Map_on_the_keyboard.svg","links":["https://www.scoringnotes.com/opinion/a-brief-history-of-music-notation-on-computers/"]},"url":"/theory/notes/computer/midi/"},{"src":"---\\ntitle: Unison and octave\\ndescription: Intervals inside the same pitch class\\n\\ndate: 2021-09-10\\n---\\n\\n## Unison P1\\n\\n<abc-render abc=\\"[A4A4] AA\\" />\\n\\n<chroma-profile chroma=\\"100000000000\\" />\\n\\nUnison is two or more musical parts that sound either the same pitch or pitches separated by intervals of one or more octaves, usually at the same time.\\n\\nUnison or perfect unison (also called a prime, or perfect prime) may refer to the (pseudo-)interval formed by a tone and its duplication (in German, Unisono, Einklang, or Prime), for example C–C, as differentiated from the second, C–D, etc. In the unison the two pitches have the ratio of 1:1 or 0 half steps and zero cents. Although two tones in unison are considered to be the same pitch, they are still perceivable as coming from separate sources, whether played on instruments of a different type or of the same type. This is because a pair of tones in unison come from different locations or can have different \\"colors\\" (timbres), i.e. come from different musical instruments or human voices. Voices with different colors have, as sound waves, different waveforms. These waveforms have the same fundamental frequency but differ in the amplitudes of their higher harmonics. The unison is considered the most consonant interval while the near unison is considered the most dissonant. The unison is also the easiest interval to tune. The unison is abbreviated as \\"P1\\".\\n\\n## Octave P8\\n\\n<abc-render abc=\\"[A4a] Aa\\" />\\n\\nAn octave (Latin: octavus: eighth) or perfect octave (sometimes called the diapason) is the interval between one musical pitch and another with double its frequency. The octave relationship is a natural phenomenon that has been referred to as the \\"basic miracle of music,\\" the use of which is \\"common in most musical systems.\\" The interval between the first and second harmonics of the harmonic series is an octave.\\n\\nAny two musical notes with fundamental frequencies in a ratio equal to 2n (n is any integer) are perceived as very similar and represent the simplest interval in music – an octave. Human pitch perception is periodic so that “color” or chroma of all the notes that are an octave apart seem circularly equivalent and brings them together into one pitch class.\\n\\n<img src=\\"./key-intervals.svg\\">\\n\\nTo emphasize that it is one of the perfect intervals (including unison, perfect fourth, and perfect fifth), the octave is designated P8.\\n\\n## Notation\\n\\nOctaves are identified with various naming systems. Among the most common are the scientific, Helmholtz, organ pipe, and MIDI note systems. In scientific pitch notation, a specific octave is indicated by a numerical subscript number after note name. In this notation, middle C is C4, because of the note's position as the fourth C key on a standard 88-key piano keyboard, while the C an octave higher is C5.\\n\\n### Octave equivalence\\n\\nAfter the unison, the octave is the simplest interval in music. The human ear tends to hear both notes as being essentially \\"the same\\", due to closely related harmonics. Notes separated by an octave \\"ring\\" together, adding a pleasing sound to music. The interval is so natural to humans that when men and women are asked to sing in unison, they typically sing in octave.\\n\\n<img src=\\"./octaves.svg\\">\\n\\nFor this reason, notes an octave apart are given the same note name in the Western system of music notation—the name of a note an octave above A is also A. This is called octave equivalence, the assumption that pitches one or more octaves apart are musically equivalent in many ways, leading to the convention \\"that scales are uniquely defined by specifying the intervals within an octave\\". The conceptualization of pitch as having two dimensions, pitch height (absolute frequency) and pitch class (relative position within the octave), inherently include octave circularity. Thus all C♯s, or all 1s (if C = 0), in any octave are part of the same pitch class.\\n\\nA [pitch class](https://en.wikipedia.org/wiki/Pitch_class) (p.c. or pc) is a set of all pitches that are a whole number of octaves apart, e.g., the pitch class A consists of the As in all octaves. \\"The pitch class A stands for all possible As, in whatever octave position.\\"\\n\\n> Although there is no formal upper or lower limit to this sequence, only a few of these pitches are audible to the human ear. Yet we can imagine seeing the 40th octave as the frequency gets to the visual spectrum.\\n\\nPitch class is important because human pitch-perception is periodic: pitches belonging to the same pitch class are perceived as having a similar quality or color, a property called **\\"octave equivalence\\"**.\\n\\nPsychologists refer to the quality of a pitch as its **\\"chroma\\"**. A chroma is an attribute of pitches (as opposed to tone height), just like hue is an attribute of color. A pitch class is a set of all pitches that share the same chroma, just like \\"the set of all yellow things\\" is the collection of all yellow objects.\\n\\n## Pitch class space\\n\\nIn music theory, pitch-class space is the circular space representing all the notes (pitch classes) in a musical octave. In this space, there is no distinction between tones that are separated by an integral number of octaves. For example, C4, C5, and C6, though different pitches, are represented by the same point in pitch class space.\\n\\nSince pitch-class space is a circle, we return to our starting point by taking a series of steps in the same direction: beginning with C, we can move \\"upward\\" in pitch-class space, through the pitch classes C♯, D, D♯, E, F, F♯, G, G♯, A, A♯, and B, returning finally to C. By contrast, pitch space is a linear space: the more steps we take in a single direction, the further we get from our starting point.\\n\\nDeutsch and Feroe (1981), and Lerdahl and Jackendoff (1983) use a \\"reductional format\\" to represent the perception of pitch-class relations in tonal contexts. These two-dimensional models resemble bar graphs, using height to represent a pitch class's degree of importance or centricity. Lerdahl's version uses five levels: the first (highest) contains only the tonic, the second contains tonic and dominant, the third contains tonic, mediant, and dominant, the fourth contains all the notes of the diatonic scale, and the fifth contains the chromatic scale. In addition to representing centricity or importance, the individual levels are also supposed to represent \\"alphabets\\" that describe the melodic possibilities in tonal music (Lerdahl 2001, 44–46). The model asserts that tonal melodies will be cognized in terms of one of the five levels a-e:\\n\\n> Level a: C C\\n> Level b: C G C\\n> Level c: C E G C\\n> Level d: C D E F G A B C\\n> Level e: C D♭ D E♭ E F F♯ G A♭ A B♭ B C\\n>\\n> (Lerdahl 1992, 113)\\n\\nNote that Lerdahl's model is meant to be cyclical, with its right edge identical to its left. One could therefore display Lerdahl's graph as a series of five concentric circles representing the five melodic \\"alphabets.\\" In this way one could unite the circular representation depicted at the beginning of this article with Lerdahl's flat two-dimensional representation depicted above.\\n\\nAccording to David Kopp (2002, 1), \\"Harmonic space, or tonal space as defined by Fred Lerdahl, is the abstract nexus of possible normative harmonic connections in a system, as opposed to the actual series of temporal connections in a realized work, linear or otherwise.\\"\\n","frontmatter":{"title":"Unison and octave","description":"Intervals inside the same pitch class","date":"2021-09-10T00:00:00.000Z"},"url":"/theory/intervals/unison-octave/"},{"src":"---\\ntitle: Fifth and fourth\\ndescription: Perfect, but not equivalent intervals\\ndate: 2021-09-08\\n---\\n\\n## Fifth P5\\n\\n<abc-render abc=\\"[A4e] Ae\\" />\\n\\n<chroma-profile :chroma=\\"'100000010000'\\" />\\n\\nThe second most harmonic interval is the fifth – a 3/2 of any given frequency. Pythagoras is claimed to be the first to use this law to construct pleasant musical notes combinations. This principle is foundational for the modern 12-TET equal temperament. Take the lowest starting frequency and go up in two ways:\\n\\n- multiplying it by two – stepping an octave above,\\n- and also multiplying by 1.5 – stepping a fifth in a time.\\n\\n<img src=\\"./images/circle-of-fifths-exp.svg\\">\\n\\nAfter 7 octaves and 12 fifths you’ll end up on the same starting tone. And you’ll find that you’ve pressed all the other tones on the way. So any other step of fifth gives us a new note. Get the note frequencies, then divide them by two until they’re in the same octave with the starting frequency. And there you got it – 12 notes in any given octave.\\n\\n<img src=\\"./images/oct-equation.svg\\">\\n\\nThis equation shows the approximate equality of the values of 12 perfect fifth intervals and 7 octaves. If we use the just interval of 3/2 we get the small difference, that represents the Pythagorean comma.\\n\\nIn musical tuning, the Pythagorean comma (or ditonic comma), named after the ancient mathematician and philosopher Pythagoras, is the small interval (or comma) existing in Pythagorean tuning between two enharmonically equivalent notes such as C and B♯ (Play), or D♭ and C♯. It is equal to the frequency ratio. (1.5)12⁄27 =. 531441⁄524288 ≈ 1.01364, or about 23.46 cents, roughly a quarter of a semitone (in between 75:74 and 74:73).\\n\\n<img src=\\"./images/key-intervals.svg\\">\\n\\n### 12-Tone Equal Temperament\\n\\nTwelve-tone equal temperament is the musical system that divides the octave into 12 parts, all of which are equally tempered (equally spaced) on a logarithmic scale, with a ratio equal to the 12th root of 2 (12√2 ≈ 1.05946). That resulting smallest interval, 1⁄12 the width of an octave, is called a semitone or half step.\\n\\n<img src=\\"./images/tet-fifth-equation.svg\\" />\\n\\n## Perfect fourth P4\\n\\n<abc-render abc=\\"[A4d] Ad\\" />\\n\\n<chroma-profile :chroma=\\"'100001000000'\\" />\\n\\nPerfect fourth is the inverse of the perfect fifth.\\n\\nThe perfect fourth may be derived from the harmonic series as the interval between the third and fourth harmonics. The term perfect identifies this interval as belonging to the group of perfect intervals, so called because they are neither major nor minor.\\n\\nA perfect fourth in just intonation corresponds to a pitch ratio of 4:3, or about 498 cents, while in equal temperament a perfect fourth is equal to five semitones, or 500 cents.\\n\\nThe perfect fourth is a perfect interval like the unison, octave, and perfect fifth, and it is a sensory consonance. In common practice harmony, however, it is considered a stylistic dissonance in certain contexts, namely in two-voice textures and whenever it occurs \\"above the bass in chords with three or more notes\\". If the bass note also happens to be the chord's root, the interval's upper note almost always temporarily displaces the third of any chord, and, in the terminology used in popular music, is then called a suspended fourth.\\n\\n## Quartal and quintal harmony\\n\\nIn music, quartal harmony is the building of harmonic structures built from the intervals of the perfect fourth, the augmented fourth and the diminished fourth. For instance, a three-note quartal chord on C can be built by stacking perfect fourths, C–F–B♭.\\n\\nQuintal harmony is harmonic structure preferring the perfect fifth, the augmented fifth and the diminished fifth. For instance, a three-note quintal chord on C can be built by stacking perfect fifths, C–G–D.\\n\\nRegarding chords built from perfect fourths alone, composer Vincent Persichetti writes that:\\n\\n> Chords by perfect fourth are ambiguous in that, like all chords built by equidistant intervals (diminished seventh chords or augmented triads), any member can function as the root. The indifference of this rootless harmony to tonality places the burden of key verification upon the voice with the most active melodic line.\\n","frontmatter":{"title":"Fifth and fourth","description":"Perfect, but not equivalent intervals","date":"2021-09-08T00:00:00.000Z"},"url":"/theory/intervals/fifth-fourth/"},{"src":"---\\ntitle: Third and sixth\\ndescription: The imperfect consonant intervals\\ndate: 2021-09-06\\n---\\n\\n## Major third M3\\n\\n<abc-render abc=\\"[A^c] A^c\\" />\\n\\n<chroma-profile :chroma=\\"'100010000000'\\" />\\n\\nThe major third may be derived from the harmonic series as the interval between the fourth and fifth harmonics. The major third is classed as an imperfect consonance and is considered one of the most consonant intervals after the unison, octave, perfect fifth, and perfect fourth.\\n\\nA major third is slightly different in different musical tunings:\\n\\n- in just intonation corresponds to a pitch ratio of 5:4 (fifth harmonic in relation to the fourth) or 386.31 cents;\\n- in equal temperament, a major third is equal to four semitones, a ratio of 21/3:1 (about 1.2599) or 400 cents, 13.69 cents wider than the 5:4 ratio.\\n- The older concept of a ditone (two 9:8 major seconds) made a dissonantly wide major third with the ratio 81:64 (408 cents).\\n- The septimal major third is 9:7 (435 cents), the undecimal major third is 14:11 (418 cents), and the tridecimal major third is 13:10 (452 cents).\\n\\nIn equal temperament three major thirds in a row are equal to an octave (for example, A♭ to C, C to E, and E to G♯; G♯ and A♭ represent the same note). This is sometimes called the \\"circle of thirds\\". In just intonation, however, three 5:4 major third, the 125th subharmonic, is less than an octave. For example, three 5:4 major thirds from C is B♯ (C to E to G♯ to B♯) (B♯ = 5^3 / 2^6 = 125 / 64 ). The difference between this just-tuned B♯ and C, like that between G♯ and A♭, is called the \\"enharmonic diesis\\", about 41 cents (the inversion of the 125/64 interval: 128 / 125 = 2^7 / 3^3 ).\\n\\n![](./Comparison_of_major_thirds.png)\\n\\n## Minor third m3\\n\\n<abc-render abc=\\"[A4c] Ac\\" />\\n\\n<chroma-profile :chroma=\\"'100100000000'\\" />\\n\\nA minor third is a musical interval that encompasses three half steps, or semitones. It is called minor because it is the smaller of the two: the major third spans an additional semitone.\\n\\nThe minor third may be derived from the harmonic series as the interval between the fifth and sixth harmonics, or from the 19th harmonic. The minor third is also obtainable in reference to a fundamental note from the undertone series, while the major third is obtainable as such from the overtone series. The 12-TET minor third (300 cents) more closely approximates the nineteenth harmonic with only 2.49 cents error.\\n\\n- A minor third, in just intonation, corresponds to a pitch ratio of 6:5 or 315.64 cents.\\n- In an equal tempered tuning, a minor third is equal to three semitones, a ratio of 2^1/4:1 (about 1.189), or 300 cents, 15.64 cents narrower than the 6:5 ratio.\\n\\nThe minor third is commonly used to express sadness in music, and research shows that this mirrors its use in speech, as a tone similar to a minor third is produced during sad speech.\\n\\n![](./Comparison_of_minor_thirds.png)\\n\\n## Minor sixth m6\\n\\n<abc-render abc=\\"[A4f] Af\\" />\\n\\n<chroma-profile :chroma=\\"'100000001000'\\" />\\n\\nMinor sixth is the inverse the major third.\\n\\nIn the common practice period, sixths were considered interesting and dynamic consonances along with their inverses the thirds.\\n\\nIn just intonation multiple definitions of a minor sixth can exist:\\n\\n- In 3-limit tuning, i.e. Pythagorean tuning, the minor sixth is the ratio 128:81, or 792.18 cents, i.e. 7.82 cents flatter than the 12-ET-minor sixth. This is denoted with a \\"-\\" (minus) sign (see figure).\\n\\n- In 5-limit tuning, a minor sixth most often corresponds to a pitch ratio of 8:5 or 814 cents; i.e. 13.7 cents sharper than the 12-ET-minor sixth.\\n\\n- In 11-limit tuning, the 11:7 undecimal minor sixth is 782.49 cents.\\n\\nIn the common practice period, sixths were considered interesting and dynamic consonances along with their inverses the thirds, but in medieval times they were considered dissonances unusable in a stable final sonority. In that period they were tuned to the flatter Pythagorean minor sixth of 128:81. In 5-limit just intonation, the minor sixth of 8:5 is classed as a consonance.\\n\\n## Major sixth M6\\n\\n<abc-render abc=\\"[A4^f] A^f\\" />\\n\\n<chroma-profile :chroma=\\"'100000000100'\\" />\\n\\nMajor sixth is the inverse the minor third.\\n\\nThe major sixth spans nine semitones. It is a sixth because it encompasses six note letter names (C, D, E, F, G, A) and six staff positions.\\n\\nThe major sixth is one of the consonances of common practice music, along with the unison, octave, perfect fifth, major and minor thirds, minor sixth, and (sometimes) the perfect fourth. In the common practice period, sixths were considered interesting and dynamic consonances along with their inverses the thirds. In medieval times theorists always described them as Pythagorean major sixths of 27/16 and therefore considered them dissonances unusable in a stable final sonority. We cannot know how major sixths actually were sung in the Middle Ages. In just intonation, the (5/3) major sixth is classed as a consonance of the 5-limit.\\n\\nThe nineteenth subharmonic is a major sixth, 32/19 = 902.49 cents.\\n\\n- In just intonation, the most common major sixth is the pitch ratio of 5:3 , approximately 884 cents.\\n- In 12-tone equal temperament, a major sixth is equal to nine semitones, exactly 900 cents, with a frequency ratio of the (9/12) root of 2 over 1.\\n- Another major sixth is the Pythagorean major sixth with a ratio of 27:16, approximately 906 cents,[4] called \\"Pythagorean\\" because it can be constructed from three just perfect fifths (C-A = C-G-D-A = 702+702+702-1200=906). It corresponds to the interval between the 27th and the 16th harmonics.\\n","frontmatter":{"title":"Third and sixth","description":"The imperfect consonant intervals","date":"2021-09-06T00:00:00.000Z"},"url":"/theory/intervals/third-sixth/"},{"src":"---\\ntitle: Seconds and sevenths\\ndescription: The rather dissonant shortest intervals\\ndate: 2021-09-04\\ncover: Epogdoon.jpg\\n---\\n\\n## Second\\n\\n### Major second M2\\n\\n<abc-render abc=\\"[A4B] AB\\" />\\n\\n<chroma-profile :chroma=\\"'101000000000'\\" />\\n\\nA major second (sometimes also called **whole tone** or a **whole step**) is a second spanning two semitones. The major second is the interval that occurs between the first and second degrees of a major scale, the tonic and the supertonic.\\n\\nOn a musical keyboard, a major second is the interval between two keys separated by one key, counting white and black keys alike. On a guitar string, it is the interval separated by two frets. In moveable-do solfège, it is the interval between do and re. It is considered a melodic step, as opposed to larger intervals called skips.\\n\\nIn just intonation, major seconds can occur in at least two different frequency ratios: 9:8 (about 203.9 cents) major tone and 10:9 minor tone (about 182.4 cents). The largest (9:8) ones are called major tones or greater tones, the smallest (10:9) are called minor tones or lesser tones. Their size differs by exactly one syntonic comma (81:80, or about 21.5 cents). Some equal temperaments, such as 15-ET and 22-ET, also distinguish between a greater and a lesser tone.\\n\\n![](./images/Comparison_of_major_seconds.png)\\n\\nThe major tone may be derived from the harmonic series as the interval between the eighth and ninth harmonics. The minor tone may be derived from the harmonic series as the interval between the ninth and tenth harmonics.\\n\\nIn Pythagorean music theory, the epogdoon (Ancient Greek: ἐπόγδοον) is the interval with the ratio 9 to 8. The word is composed of the prefix epi- meaning \\"on top of\\" and ogdoon meaning \\"one eighth\\"; so it means \\"one eighth in addition\\".\\n\\n> ![](./Epogdoon.jpg)\\n>\\n> Diagram showing relations between epogdoon, diatessaron, diapente, and diapason\\n\\n### Minor second m2\\n\\n<abc-render abc=\\"[A4_B] A_B\\" />\\n\\n<chroma-profile :chroma=\\"'110000000000'\\" />\\n\\nA semitone, also called a half step or a half tone, is the smallest musical interval commonly used in Western tonal music, and it is considered the most dissonant when sounded harmonically. It is defined as the interval between two adjacent notes in a 12-tone scale.\\n\\nIn twelve-tone equal temperament all semitones are equal in size (100 cents). In other tuning systems, \\"semitone\\" refers to a family of intervals that may vary both in size and name. In Pythagorean tuning, seven semitones out of twelve are diatonic, with ratio 256:243 or 90.2 cents (Pythagorean limma), and the other five are chromatic, with ratio 2187:2048 or 113.7 cents (Pythagorean apotome); they differ by the Pythagorean comma of ratio 531441:524288 or 23.5 cents. In quarter-comma meantone, seven of them are diatonic, and 117.1 cents wide, while the other five are chromatic, and 76.0 cents wide; they differ by the lesser diesis of ratio 128:125 or 41.1 cents. 12-tone scales tuned in just intonation typically define three or four kinds of semitones. For instance, Asymmetric five-limit tuning yields chromatic semitones with ratios 25:24 (70.7 cents) and 135:128 (92.2 cents), and diatonic semitones with ratios 16:15 (111.7 cents) and 27:25 (133.2 cents).\\n\\n![](./images/Comparison_of_minor_seconds.png)\\n\\nMelodically, this interval is very frequently used, and is of particular importance in cadences. In the perfect and deceptive cadences it appears as a resolution of the leading-tone to the tonic. In the plagal cadence, it appears as the falling of the subdominant to the mediant. It also occurs in many forms of the imperfect cadence, wherever the tonic falls to the leading-tone.\\n\\nHarmonically, the interval usually occurs as some form of dissonance or a nonchord tone that is not part of the functional harmony. It may also appear in inversions of a major seventh chord, and in many added tone chords.\\n\\n### Minor seventh m7\\n\\n<abc-render abc=\\"[A4g] Ag\\" />\\n\\n<chroma-profile :chroma=\\"'100000000010'\\" />\\n\\nThe minor seventh spans ten semitones.\\n\\nMinor seventh intervals rarely feature in melodies (and especially in their openings) but occur more often than major sevenths.\\n\\nConsonance and dissonance are relative, depending on context, the minor seventh being defined as a dissonance requiring resolution to a consonance.\\n\\nIn just intonation there is both a 16:9 \\"small just minor seventh\\", also called the \\"Pythagorean small minor seventh\\", equivalent to two perfect fourths stacked on top of each other, and a 9:5 \\"large just minor seventh\\" equivalent to a perfect fifth and a minor third on top of each other.\\n\\n### Major seventh M7\\n\\n<abc-render abc=\\"[A4^g] A^g\\" />\\n\\n<chroma-profile :chroma=\\"'100000000001'\\" />\\n\\nThe major seventh spans eleven semitones.\\n\\nA major seventh in just intonation most often corresponds to a pitch ratio of 15:8 (About this soundplay (help·info)); in 12-tone equal temperament, a major seventh is equal to eleven semitones, or 1100 cents, about 12 cents wider than the 15:8 major seventh.\\n\\nThe major seventh interval is considered one of the most dissonant intervals after its inversion the minor second. For this reason, its melodic use is infrequent in classical music.\\n\\nThe major seventh chord is however very common in jazz, especially 'cool' jazz, and has a characteristically soft and sweet sound.\\n","frontmatter":{"title":"Seconds and sevenths","description":"The rather dissonant shortest intervals","date":"2021-09-04T00:00:00.000Z","cover":"/media_files/cover/theory-intervals-second-seventh-Epogdoon.jpg"},"url":"/theory/intervals/second-seventh/"},{"src":"---\\ntitle: Harmonic movements\\ndescription: Ways to move chords\\ndate: 2021-09-02\\n---\\n\\n## Descending fifths progressions\\n\\n<youtube-embed video=\\"v=fJvxaIfX6V4\\"></youtube-embed>\\n\\nDiscusses chord progressions whose roots move by descending fifth, especially as they appear in Jazz standards.\\n\\n## Chord substitutions\\n\\nIn music theory, [chord substitution](https://en.wikipedia.org/wiki/Chord_substitution) is the technique of using a chord in place of another in a progression of chords, or a chord progression. Much of the European classical repertoire and the vast majority of blues, jazz and rock music songs are based on chord progressions. \\"A chord substitution occurs when a chord is replaced by another that is made to function like the original. Usually substituted chords possess two pitches in common with the triad that they are replacing.\\"\\n\\nA chord progression may be repeated to form a song or tune. Composers, songwriters and arrangers have developed a number of ways to add variety to a repeated chord progression. There are many ways to add variety to music, including changing the dynamics (loudness and softness).\\n\\nThe diminished triad can be used to substitute for the dominant seventh chord. In major scales, a diminished triad occurs only on the seventh scale degree. For instance, in the key of C, this is a B diminished triad (B, D, F). Since the triad is built on the seventh scale degree, it is also called the leading-tone triad. This chord has a dominant function. Unlike the dominant triad or dominant seventh, the leading-tone triad functions as a prolongational chord rather than a structural chord since the strong root motion by fifth is absent.\\n\\n### Use in blues, jazz and rock music\\n\\nJazz musicians often substitute chords in the original progression to create variety and add interest to a piece.\\n\\nThe substitute chord must have some harmonic quality and degree of function in common with the original chord, and often only differs by one or two notes. Scott DeVeaux describes a \\"penchant in modern jazz for harmonic substitution.\\"\\n\\nOne simple type of chord substitution is to replace a given chord with a chord that has the same function. Thus, in the simple chord progression I–ii–V–I, which in the key of C major would be the chords C–DM–G–C, a musician could replace the I chords with \\"tonic substitutes\\". The most widely used substitutes are iii and vi (in a Major key), which in this case would be the chords \\"e minor\\" and \\"a minor\\".\\n\\nThis simple chord progression with tonic substitutes could become iii–ii–V–vi or, with chord names, \\"e minor–d minor–G Major–a minor\\". Given the overlap in notes between the original tonic chords and the chord substitutes (for example, C major is the notes \\"C, E, and G\\", and \\"e minor\\" is the notes \\"E, G and B\\"), the melody is likely to be supported by the new chords. The musician typically uses her/his \\"ear\\" (sense of the musical style and harmonic suitability) to determine if the chord substitution works with the melody.\\n\\nThere are also subdominant substitutes and dominant substitutes. For subdominant chords, in the key of C major, in the chord progression C major/F major/G7/C major (a simple I /IV/V7/I progression), the notes of the subdominant chord, F major, are \\"F, A, and C\\". As such, a performer or arranger who wished to add variety to the song could try using a chord substitution for a repetition of this progression. One simple chord substitute for IV is the \\"ii\\" chord, a minor chord built on the second scale degree. In the key of C major, the \\"ii\\" chord is \\"d minor\\", which is the notes \\"D, F, and A\\". As there are two shared notes between the IV and \\"ii\\" chords, a melody that works well over IV is likely to be supported by the \\"ii\\" chord.\\n\\n### Types\\n\\nThe ii–V substitution is when a chord or each chord in a progression is preceded by its supertonic (ii7) and dominant (V7), or simply its dominant. For example, a C major chord would be preceded by Dm7 and G7. Since secondary dominant chords are often inserted between the chords of a progression rather than replacing one, this may be considered as 'addition' rather than 'substitution'.\\n\\nChord quality alteration is when the quality of a chord is changed, and the new chord of similar root and construction, but with one pitch different, is substituted for the original chord, for example the minor sixth for the major seventh, or the major seventh for the minor.\\n\\nThe diminished seventh chord is often used in place of a dominant 7th chord. In the key of A Major the V chord, E dominant 7th (which is made up the notes E, G♯, B, and D) can be replaced with a G♯ diminished seventh chord (G♯, B, D, F). If the diminished seventh chord (G♯) is followed by the I chord (A), this creates chromatic (stepwise semitonal) root movement, which can add musical interest in a song mainly constructed around the interval of the fourth or fifth. The diminished seventh chord on the sharpened second scale degree, ♯IIo7, may be used as a substitute dominant, for example in C: ♯IIo7 = D♯–F♯–A–C♮ ↔ B–D♯–F♯–A = VII7, which creates the chromatic root movement D – D♭ – C.\\nContrast with the original ii–V–I progression in C, which creates the leading-tone B – C.\\n\\nIn a tritone substitution, the substitute chord only differs slightly from the original chord. If the original chord in a song is G7 (G, B, D, F), the tritone substitution would be D♭7 (D♭, F, A♭, C♭). Note that the 3rd and 7th notes of the G7 chord are found in the D♭7 chord (albeit with a change of role). The tritone substitution is widely used for V7 chords in the popular jazz chord progression \\"ii-V-I\\". In the key of C, this progression is \\"d minor, G7, C Major\\". With tritone substitution, this progression would become \\"d minor, D♭7, C Major,\\" which contains chromatic root movement. When performed by the bass player, this chromatic root movement creates a smooth-sounding progression. \\"Tritone substitutions and altered dominants are nearly identical...Good improvisers will liberally sprinkle their solos with both devices. A simple comparison of the notes generally used with the given chord [notation] and the notes used in tri-tone substitution or altered dominants will reveal a rather stunning contrast, and could cause the unknowledgeable analyzer to suspect errors. ...(the distinction between the two [tri-tone substitution and altered dominant] is usually a moot point).\\"\\n\\nTonic substitution is the use of chords that sound similar to the tonic chord (or I chord) in place of the tonic. In major keys, the chords iii and vi are often substituted for the I chord, to add interest. In the key of C major, the I major 7 chord is \\"C, E, G, B,\\" the iii chord (\\"III–7\\") is E minor 7 (\\"E, G, B, D\\") and the vi minor 7 chord is A minor 7 (\\"A, C, E, G\\"). Both of the tonic substitute chords use notes from the tonic chord, which means that they usually support a melody originally designed for the tonic (I) chord.\\n\\nThe relative major/minor substitution shares two common tones and is so called because it involves the relation between major and minor keys with the same key signatures, such as C major and A minor.\\n\\nThe augmented triad on the fifth scale degree may be used as a substitute dominant, and may also be considered as ♭III+, for example in C: V+ = G–B–D♯, ♭III+ = E♭–G–B♮, and since in every key: D♯ = E♭.\\n\\"Backdoor ii–V\\" in C: IV7–♭VII7–I. Chord symbols for the conventional ii–V progression are above the staff, with the chord symbols for the substitution in parentheses.\\n\\nThe chord a minor third above, ♭VII7, may be substituted for the dominant, and may be preceded by its ii: iv7. Due to common use the two chords of the backdoor progression (IV7-♭VII7) may be substituted for the dominant chord. In C major the dominant would be G7: GBDF, sharing two common tones with B♭7: B♭DFA♭. A♭ and F serve as upper leading-tones back to G and E, respectively, rather than B♮ and F serving as the lower and upper leading-tones to C and E.\\n\\n### Application\\n\\nIn jazz, chord substitutions can be applied by composers, arrangers, or performers. Composers may use chord substitutions when they are basing a new jazz tune on an existing chord progression from an old jazz standard or a song from a musical; arrangers for a big band or jazz orchestra may use chord substitutions in their arrangement of a tune, to add harmonic interest or give a different \\"feel\\" to a song; and instrumentalists may use chord substitutions in their performance of a song. Given that many jazz songs have repetition of internal sections, such as with a 32-bar AABA song form, performers or arrangers may use chord substitution within the A sections to add variety to the song.\\n\\nJazz \\"comping\\" instruments (piano, guitar, organ, vibes) often use chord substitution to add harmonic interest to a jazz tune with slow harmonic change. For example, the jazz standard chord progression of \\"rhythm changes\\" uses a simple eight bar chord progression in the bridge with the chords III7, VI7, II7, V7; in the key of B♭, these chords are D7, G7, C7, and F7 (each for two bars). A jazz guitarist might add a \\"ii–V7\\" aspect to each chord, which would make the progression: \\"a minor, D7, d minor, G7, g minor, C7, c minor, F7. Alternatively, tritone substitutions could be applied to the progression.\\n\\n> Note that both the back door progression and ♯IIo7, when substituted for V7, introduces notes that seem wrong or anachronistic to the V7 chord (such as the fourth and the major seventh). They work only because the given instances of those chords are familiar to the ear; hence when an improviser uses them against the V7, the listener's ear hears the given precedents for the event, instead of the conflict with the V7.\\n> — Coker (1997), p. 82\\n\\nTheoretically, any chord can substitute for any other chord, as long as the new chord supports the melody. In practice, though, only a few options sound musically and stylistically appropriate to a given melody. This technique is used in music such as bebop or fusion to provide more sophisticated harmony, or to create a new-sounding re-harmonization of an old jazz standard.\\n\\nJazz soloists and improvisers also use chord substitutions to help them add interest to their improvised solos. Jazz soloing instruments that can play chords, such as jazz guitar, piano, and organ players may use substitute chords to develop a chord solo over an existing jazz tune with slow-moving harmonies. Also, jazz improvisers may use chord substitution as a mental framework to help them create more interesting-sounding solos. For example, a saxophonist playing an improvised solo over the basic \\"rhythm changes\\" bridge (in B♭, this is \\"D7, G7, C7, and F7\\", each for two bars) might think of a more complex progression that uses substitute chords (e.g., \\"a minor, D7, d minor, G7, g minor, C7, c minor, F7). In doing so, this implies the substitute chords over the original progression, which adds interest for listeners.\\n\\n## Tritone substitution\\n\\nThe [tritone substitution](https://en.wikipedia.org/wiki/Tritone_substitution) is a common chord substitution found in both jazz and classical music. Where jazz is concerned, it was the precursor to more complex substitution patterns like Coltrane changes. Tritone substitutions are sometimes used in improvisation—often to create tension during a solo. Though examples of the tritone substitution, known in the classical world as an augmented sixth chord, can be found extensively in classical music since the Renaissance period, they were not heard until much later in jazz by musicians such as Dizzy Gillespie and Charlie Parker in the 1940s, as well as Duke Ellington, Art Tatum, Coleman Hawkins, Roy Eldridge and Benny Goodman.\\n\\nThe tritone substitution can be performed by exchanging a dominant seventh chord for another dominant seven chord which is a tritone away from it. For example, in the key of C major one can use D♭7 instead of G7. (D♭ is a tritone away from G).\\n\\nIn tonal music, a conventional perfect cadence consists of a dominant seventh chord followed by a tonic chord. For example, in the key of C major, the chord of G7 is followed by a chord of C. In order to execute a tritone substitution, common variant of this progression, one would replace the dominant seventh chord with a dominant chord that has its root a tritone away from the original.\\n\\nFranz Schubert's String Quintet in C major concludes with a dramatic final cadence that uses the third of the above progressions. The conventional G7 chord is replaced in bars 3 and 4 of the following example with a D♭7 chord, with a diminished fifth (G♮ as the enharmonic equivalent of Adouble flat); a chord otherwise known as a 'French sixth'.\\n\\n## Coltrane changes\\n\\n[Coltrane changes](https://en.wikipedia.org/wiki/Coltrane_changes) (Coltrane Matrix or cycle, also known as chromatic third relations and multi-tonic changes) are a harmonic progression variation using substitute chords over common jazz chord progressions. These substitution patterns were first demonstrated by jazz musician John Coltrane on the albums Bags & Trane (on the track \\"Three Little Words\\") and Cannonball Adderley Quintet in Chicago (on \\"Limehouse Blues\\"). Coltrane continued his explorations on the 1959 album Giant Steps and expanded on the substitution cycle in his compositions \\"Giant Steps\\" and \\"Countdown\\", the latter of which is a reharmonized version of Eddie Vinson's \\"Tune Up\\". The Coltrane changes are a standard advanced harmonic substitution used in jazz improvisation.\\n\\n<youtube-embed video=\\"5PVPM-KoILE\\" />\\n\\n### Function\\n\\nThe changes serve as a pattern of chord substitutions for the ii–V–I progression (supertonic–dominant–tonic) and are noted for the tonally unusual root movement by major thirds (either up or down by a major third interval), creating an augmented triad. Root movement by thirds is unusual in jazz, as the norm is circle of fifths root movement, such as ii-V-I, which in the key of C is D dorian, G7 and C major.\\n\\n### Influences\\n\\nDavid Demsey, saxophonist and coordinator of jazz studies at William Paterson University, cites a number of influences leading to Coltrane's development of these changes. After Coltrane's death it was proposed that his \\"preoccupation with... chromatic third-relations\\" was inspired by religion or spirituality, with three equal key areas having numerological significance representing a \\"magic triangle\\", or, \\"the trinity, God, or unity.\\" However, Demsey shows that though this meaning was of some importance, third relationships were much more \\"earthly\\", or rather historical, in origin. Mention should be made of his interests in Indian ragas during the early 1960s, the Trimurti of Vishnu, Brahma and Shiva may well have been an inherent reference in his chromatic third relations, tritone substitutes, and so on. In playing that style, Coltrane found it \\"easy to apply the harmonic ideas I had... I started experimenting because I was striving for more individual development.\\" He developed his sheets of sound style while playing with Miles Davis and with pianist Thelonious Monk during this period. In terms of the origin of this “sheets of sound” technique, saxophonist Odean Pope considers pianist Hasaan Ibn Ali a major influence on Coltrane and his development of this signature style.\\n\\nColtrane studied harmony with Dennis Sandole and at the Granoff School of Music in Philadelphia. He explored contemporary techniques and theory. He also studied the Thesaurus of Scales and Melodic Patterns by Nicolas Slonimsky (1947).\\n\\nThe first appearance of the \\"Coltrane changes\\" appear in the verse to the standard \\"Till the Clouds Roll By\\" by Jerome Kern. The bridge of the Richard Rodgers song and jazz standard \\"Have You Met Miss Jones?\\" (1937) predated Tadd Dameron's \\"Lady Bird\\", after which Coltrane named his \\"Lazy Bird\\", by incorporating modulation by major third(s). (highlighted yellow below) \\"Giant Steps\\" and \\"Countdown\\" may both have taken the inspiration for their augmented tonal cycles from \\"Have You Met Miss Jones?\\".\\n\\n> \\"Have You Met Miss Jones?\\" B section chord progression (bridge):\\n>\\n> │ B♭Maj7 │ A♭m7 D♭7 │ G♭Maj7 │ Em7 A7 |\\n> │ DMaj7 │ A♭m7 D♭7 │ G♭Maj7 │ Gm7 C7 │\\n\\n<youtube-embed video=\\"62tIvfP9A2w\\" />\\n\\n### Major thirds cycle\\n\\nThe harmonic use of the chromatic third relation originated in the Romantic era and may occur on any structural level, for example in chord progressions or through key changes. The standard Western chromatic scale has twelve equidistant semitones. When arranged according to the circle of fifths, it looks like this.\\n\\n> Precisely because of this equidistancy, the roots of these three chords can produce a destabilizing effect; if C, A♭ and E appear as the tonic pitches of three key areas on a larger level, the identity of the composition's tonal center can only be determined by the closure of the composition.\\n> — Demsey (1991)\\n\\nLooking above at the marked chords from \\"Have You Met Miss Jones?\\", B♭, G♭ and D are spaced a major third apart. On the circle of fifths it appears as an equilateral triangle.\\n\\nBy rotating the triangle, all of the thirds cycles can be shown. Note that there are only four unique thirds cycles. This approach can be generalized; different interval cycles will appear as different polygons on the diagram.\\n\\n<youtube-embed video=\\"CdIstkTHqO8\\" />\\n\\n### Standard substitution\\n\\nAlthough \\"Giant Steps\\" and \\"Countdown\\" are perhaps the most famous examples, both of these compositions use slight variants of the standard Coltrane changes (The first eight bars of \\"Giant Steps\\" uses a shortened version that does not return to the I chord, and in \\"Countdown\\" the progression begins on ii7 each time.) The standard substitution can be found in several Coltrane compositions and arrangements recorded around this time. These include: \\"26-2\\" (a reharmonization of Charlie Parker's \\"Confirmation\\"), \\"Satellite\\" (based on the standard \\"How High the Moon\\"), \\"Exotica\\" (loosely based on the harmonic form of \\"I Can't Get Started\\"), Coltrane's arrangement of \\"But Not for Me\\", and on the bridge of his arrangement of \\"Body and Soul\\".\\n\\nIn \\"Fifth House\\" (based on \\"Hot House\\", i.e. \\"What Is This Thing Called Love\\") the standard substitution is implied over an ostinato bass pattern with no chordal instrument instructed to play the chord changes. When Coltrane's improvisation superimposes this progression over the ostinato bass, it is easy to hear how he used this concept for his more free playing in later years.\\n\\n<youtube-embed video=\\"L_XJ_s5IsQc\\" />\\n","frontmatter":{"title":"Harmonic movements","description":"Ways to move chords","date":"2021-09-02T00:00:00.000Z"},"url":"/theory/harmony/movement/"},{"src":"---\\ntitle: Functional tonal harmony\\ndescription: Relating chords by their interval content\\ndate: 2021-09-01\\nsecondary: \\n  - bII7\\n  - iim6\\n  - III7\\n  - ivm6\\n  - V7\\n  - \\"#vm6\\"\\n  - vim6\\n  - bVII7\\n  - VIIo7\\n---\\n\\n**Functional** means based on [functions](https://en.wikipedia.org/wiki/Function_(music)), **tonal** means based on [tonality](https://en.wikipedia.org/wiki/Tonality), harmony means lively movement through all that emotional space.\\n\\n## Tonality\\n\\nSo let’s begin with tonality. 99% of the songs you hear day to day are Tonal. Tonality is a system of harmony created & used in the Common-Practice Period (that is, in the Baroque, Classical and Romantic Eras of classical music), so from about 1700 to 1900. Tonal harmony is the ‘standard’ music theory that you learn through your Classical music studies. And, in fact, most of my previous lessons presuppose or function within ‘tonal harmony’.\\n\\nTonality has the following features:\\n\\n- It uses Major and minor keys\\n- It uses a Functional Harmony\\n- It has a Tonal Centre (i.e. root note)\\n\\nSo point one is self-explanatory. Points two and three are more interesting. Tonality uses a Functional Harmony and has a Tonal Centre (that is, a Tonic). In tonal harmony every chord has a function, it can be categorised as either:\\n\\n- Pre-Dominant;\\n- Dominant; or\\n- Tonic\\n\\nThe function of a Pre-Dominant chord is to get you to the Dominant chord. The function of a Dominant chord is to get you to the Tonic chord, thus the harmony (that is, the chords) are ‘functional’.\\n\\nAnd the Tonic chord is the ‘Tonal Centre’. This can be thought of as a ‘Centre of Gravity’ to which all other chords gravitate and resolved into.\\n\\nThus, a tonal chord progression sounds like it is moving towards the tonic. For example, take the below chord progression:\\n\\nEm7 A7 Dm7 G7 ???\\n\\n## What chord comes next?\\n\\nWe all know instinctively that it should be a CMaj7. It just SOUNDS like it needs to go back home and resolve to the tonic; thus there is a ‘tonal centre’. (Notice also that tonal chord progressions tend to move via the Circle of Fifths).\\n\\nThe G7 gravitates and wants to resolve to CMaj7. This is because all Dominant chords have a tritone interval between their 3rd and 7th (in the case of G7 – B & F). This is known as a ‘diatonic tritone‘. The tritone is a very unstable and dissonant interval that wants to resolve. And it does so either:\\n\\n- Inwards to C & E (1 & 3 of CMaj7 – creating a G7 to CMaj7 progression)\\n- Outwards to B♭ & G♭ (3 & 1 of G♭Maj7 – creating a D♭7 to G♭Maj7 progression)\\n\\nThis ‘diatonic tritone’ is the basis of all tonal music. It is what makes the Dominant chord feel like it wants to resolve to the tonic (thus making the music ‘tonal’).\\n\\n## Functional Tonal Harmony 1\\n\\nPart one of three. Discusses consonance and dissonance, construction of the major scale, tendency tones, and harmonic function.\\n\\n<youtube-embed video=\\"qzzLj1tbVnA\\" />\\n\\n## Functional Tonal Harmony 2: Minor mode\\n\\nDiscusses harmony in the minor mode. The three versions of the scale: Natural minor, harmonic minor and Melodic minor, and why we use them.\\n\\n<youtube-embed video=\\"d5jdbqU-DLw\\" />\\n\\n## Functional tonal harmony 3: Secondary dominants\\n\\nIn music theory, a secondary dominant chord is a type of chord that functions as the dominant (V) of a chord other than the tonic (I) chord. This means that it creates a sense of tension that resolves to a chord other than the tonic.\\n\\nTo create a secondary dominant chord, you use the dominant (V) chord of the chord you want to resolve to. For example, let's say we're in the key of C major, and we want to create a secondary dominant chord that resolves to the IV chord (F major). The V chord of F major is C7 (C dominant 7th), so we would play a C7 chord before the F major chord to create a sense of tension and resolution.\\n\\nThe use of secondary dominant chords is a common technique in many musical styles, including jazz, pop, and classical music. They can add interest and complexity to a chord progression by introducing unexpected harmonic changes and creating new tonal centers.\\n\\nIt's important to note that secondary dominant chords should be used tastefully and in moderation, as using them too frequently can create a sense of harmonic instability and disrupt the overall flow of a musical composition.\\n\\n<youtube-embed video=\\"6a5HvGQfDgg\\" />\\n\\n<youtube-embed video=\\"py4HaueW50Q\\" />\\n\\n## Harmony is in changes\\n\\nWe build harmony out of different chords as steps of the emotional ladder but what really counts is the movement itself. We can go down and up, slow down or speed up, jump and even fly above if we want to. This is the story the composer tells to the listeners and it's vowen with movements.\\n\\nThe functional relations between chords in a scale can be expanded quite drastically with deeper analysis of underlying intevals, that create the desired change in the mood of the music. Many new relations appear to build up into a huge landscape of the tonal space.\\n\\n## Tonal Harmony in 3D\\n\\n<youtube-embed video=\\"RcUXObvRLb4\\" />\\n\\n## Functional chords on scale degrees\\n\\nHere are some common chords that can be constructed for each of the scale degrees in tonal harmony:\\n\\n### Tonic Scale Degrees\\n\\n- First scale degree (I): major triad (I), major seventh chord (IMaj7)\\n- Third scale degree (iii): minor triad (iii), minor seventh chord (iiim7)\\n- Sixth scale degree (vi): minor triad (vi), minor seventh chord (vim7), dominant seventh chord (V7/vi)\\n\\n### Subdominant Scale Degrees\\n\\n- Second scale degree (ii): minor triad (ii), minor seventh chord (iim7), dominant seventh chord (V7/ii)\\n- Fourth scale degree (IV): major triad (IV), major seventh chord (IVMaj7), dominant seventh chord (V7/IV)\\n\\n### Dominant Scale Degrees\\n\\n- Fifth scale degree (V): dominant seventh chord (V7), dominant ninth chord (V9), dominant thirteenth chord (V13), altered dominant chord (V7alt)\\n- Seventh scale degree (vii°): diminished triad (vii°), half-diminished seventh chord (viiø7), dominant seventh flat nine chord (V7b9/vii°), fully diminished seventh chord (vii°7)\\n","frontmatter":{"title":"Functional tonal harmony","description":"Relating chords by their interval content","date":"2021-09-01T00:00:00.000Z","secondary":["bII7","iim6","III7","ivm6","V7","#vm6","vim6","bVII7","VIIo7"]},"url":"/theory/harmony/tonal/"},{"src":"---\\ntitle: Synesthesia\\ndescription: Neurological phenomenon of interlinked sensory signals\\ndate: 2021-08-25\\n\\ncover: Number_Form-synesthesia.jpg\\n---\\n\\nThe term Synesthesia comes from the Ancient Greek σύν syn, 'together', and αἴσθησις aisthēsis, 'sensation'.\\n\\nSynesthesia (American English) or synaesthesia (British English) is a perceptual phenomenon in which stimulation of one sensory or cognitive pathway leads to involuntary experiences in a second sensory or cognitive pathway.People who report a lifelong history of such experiences are known as synesthetes. Awareness of synesthetic perceptions varies from person to person. In one common form of synesthesia, known as grapheme–color synesthesia or color–graphemic synesthesia, letters or numbers are perceived as inherently colored. In spatial-sequence, or number form synesthesia, numbers, months of the year, or days of the week elicit precise locations in space (for example, 1980 may be \\"farther away\\" than 1990), or may appear as a three-dimensional map (clockwise or counterclockwise). Synesthetic associations can occur in any combination and any number of senses or cognitive pathways.\\n\\nLittle is known about how synesthesia develops. It has been suggested that synesthesia develops during childhood when children are intensively engaged with abstract concepts for the first time. This hypothesis – referred to as semantic vacuum hypothesis – explains why the most common forms of synesthesia are grapheme–color, spatial sequence, and number form. These are usually the first abstract concepts that educational systems require children to learn.\\n\\n## Types\\n\\nThere are two overall forms of synesthesia:\\n\\n- projective synesthesia: people who see colors, forms, or shapes when stimulated (the widely understood version of synesthesia).\\n- associative synesthesia: people who feel a very strong and involuntary connection between the stimulus and the sense that it triggers.\\n\\nFor example, in chromesthesia (sound to color), a projector may hear a trumpet, and see an orange triangle in space, while an associator might hear a trumpet, and think very strongly that it sounds \\"orange\\".\\n\\nSynesthesia can occur between nearly any two senses or perceptual modes, and at least one synesthete, Solomon Shereshevsky, experienced synesthesia that linked all five senses.\\n\\nWhile nearly every logically possible combination of experiences can occur, several types are more common than others.\\n\\n## Grapheme–color synesthesia\\n\\n![](./Number_Form-synesthesia.jpg)\\nA picture from the 2009 non-fiction book Wednesday Is Indigo Blue. Note the numbers 1-12 form an upside-down clock face.\\n\\nIn one of the most common forms of synesthesia, individual letters of the alphabet and numbers (collectively referred to as graphemes) are \\"shaded\\" or \\"tinged\\" with a color. While different individuals usually do not report the same colors for all letters and numbers, studies with large numbers of synesthetes find some commonalities across letters (e.g., A is likely to be red).\\n\\n## Chromesthesia\\n\\nAnother common form of synesthesia is the association of sounds with colors. For some, everyday sounds such as doors opening, cars honking, or people talking can trigger seeing colors. For others, colors are triggered when musical notes or keys are being played. People with synesthesia related to music may also have perfect pitch because their ability to see/hear colors aids them in identifying notes or keys.\\n\\nThe colors triggered by certain sounds, and any other synesthetic visual experiences, are referred to as photisms.\\n\\nIndividuals rarely agree on what color a given sound is. B flat might be orange for one person and blue for another. Composers Franz Liszt and Nikolai Rimsky-Korsakov famously disagreed on the colors of musical keys.\\n\\n## Composers with synesthesia\\n\\n**Franz Liszt** is a composer who was known for asking performers to play with color. He was noted telling his orchestra to play the music in a \\"Bluer Fashion,\\" since that is what the tone required. Synesthesia was not a common term in Liszt's time; people thought he was playing a trick on them when he referred to a color instead of a musical term.\\n\\n**Leonard Bernstein** openly discussed his chromesthesia, which he described as a \\"timbre to color.\\" Although he does not reference specific songs as being a certain color, he does explain the way it should sound to the artist performing. There are recordings of him stopping orchestras and singers when they are changing the \\"timbre.\\" If someone changes the “timbre” or tone in a piece, it does not necessarily change the sound to the listener, but the composer with Chromesthesia will automatically know.\\n\\n**Amy Beach** was another composer who had synesthesia. According to her perspective, each key signature was associated with a particular color. If an artist changed the key to suit their voice, then she would become upset because it would change the intended sound, portrayal, and emotion of the piece.\\n\\n**Olivier Messiaen** was influenced by the color of musical keys for his compositions.\\n\\n**Alexander Scriabin** was a Russian composer and pianist. He is famously regarded as a synesthete, but there is a lot of controversy surrounding whether he had chromesthesia or not. Scriabin was a major proponent of Theosophy, which had a system associating colors to feelings and emotions. This influenced the musician, who distinguished \\"spiritual\\" tonalities (like F-sharp major) from \\"earthly, material\\" ones (C major, F major). Furthermore, Alexander Scriabin developed a \\"keyboard with lights\\" or clavier à lumières, which directly matched musical notes with colors.\\n\\n![svg](./Scriabin-Circle.svg)\\n\\nScriabin's sound-to-color associations arranged into a circle of fifths, demonstrating its spectral quality.\\n\\n<youtube-embed video=\\"V3B7uQ5K0IU\\" />\\n\\nScriabin was friends with composer **Nikolai Rimsky-Korsakov**, who was a synesthete, and their sound-to-color associations were not the same. Specifically, Rimsky-Korsakov made a distinction between major and minor scales and his associations had a \\"more neutral, spontaneous character\\".\\n\\n## Other types\\n\\n### Spatial sequence synesthesia\\n\\nThose with spatial sequence synesthesia (SSS) tend to see ordinal sequences as points in space. For example some people see months as a spiral or a column (this also happens with letters, numbers and any other sequence). People with SSS may have superior memories; in one study, they were able to recall past events and memories far better and in far greater detail than those without the condition. They can also see months or dates in the space around them, but most synesthetes \\"see\\" these sequences in their mind's eye. Some people see time like a clock above and around them.\\n\\n### Number form\\n\\nA number form is a mental map of numbers that automatically and involuntarily appear whenever someone who experiences number-forms synesthesia thinks of numbers. These numbers might appear in different locations and the mapping changes and varies between individuals. Number forms were first documented and named in 1881 by Francis Galton in \\"The Visions of Sane Persons\\". It is suggested that this might be caused by \\"cross-activation\\" of the neural pathway that connects the parietal lobes and angular gyrus. Both of these areas are involved in numerical cognition and spatial cognition respectively.\\n\\n### Auditory–tactile synesthesia\\n\\nIn auditory–tactile synesthesia, certain sounds can induce sensations in parts of the body. For example, someone with auditory–tactile synesthesia may experience that hearing a specific word or sound feels like touch in one specific part of the body or may experience that certain sounds can create a sensation in the skin without being touched (not to be confused with the milder general reaction known as frisson, which affects approximately 50% of the population). It is one of the least common forms of synesthesia.\\n\\n### List of people with synesthesia\\n\\nhttps://en.wikipedia.org/wiki/List_of_people_with_synesthesia\\n\\n## Frisson\\n\\nFrisson (UK: /ˈfriːsɒn/ FREE-son, US: /friːˈsoʊn/ free-SOHN French: [fʁisɔ̃]; French for \\"shiver\\"), also known as aesthetic chills or musical chills is a psychophysiological response to rewarding auditory and/or visual stimuli that often induces a pleasurable or otherwise positively-valenced affective state and transient paresthesia (skin tingling or chills), sometimes along with piloerection (goose bumps) and mydriasis (pupil dilation).\\n\\n### Frisson is caused by violations of musical expectancy\\n\\nRhythmic, dynamic, harmonic, and/or melodic violations of a person’s explicit or implicit expectations are associated with musical frisson as a prerequisite. Loud, very high or low frequency, or quickly varying sounds (unexpected harmonies, moments of modulations, melodic appoggiaturas) has been shown to arouse the autonomic nervous system (ANS). Activation of the ANS has a consistent strong correlation with frisson, as one study showed that an opioid antagonist could block frisson from music. Leonard Meyer, a prominent philosopher of music, wrote in his text, “Emotion and Meaning in Music” that music’s ability to evoke emotion in the listener stems from its ability to meet and break expectations.\\n\\n## Ideasthesia\\n\\nIdeasthesia (alternative spelling ideaesthesia) is a neuroscientific phenomenon in which activations of concepts (inducers) evoke perception-like sensory experiences (concurrents). The name comes from the Ancient Greek ἰδέα (idéa) and αἴσθησις (aísthēsis), meaning \\"sensing concepts\\" or \\"sensing ideas\\". The notion was introduced by neuroscientist Danko Nikolić as an alternative explanation for a set of phenomena traditionally covered by synesthesia.\\n\\nWhile \\"synesthesia\\" meaning \\"union of senses\\" implies the association of two sensory elements with little connection to the cognitive level, empirical evidence indicated that most phenomena linked to synesthesia are in fact induced by semantic representations. That is, the linguistic meaning of the stimulus is what is important rather than its sensory properties. In other words, while synesthesia presumes that both the trigger (inducer) and the resulting experience (concurrent) are of sensory nature, ideasthesia presumes that only the resulting experience is of sensory nature while the trigger is semantic.\\n\\n![svg](./Booba-Kiki.svg)\\n\\nOver the past decade, it has been suggested that the Bouba/Kiki phenomenon is a case of ideasthesia. Most people will agree that the star-shaped object on the left is named Kiki and the round one on the right Bouba. It has been assumed that these associations come from direct connections between visual and auditory cortices. However, Gomez et al. have shown that Kiki/Bouba associations are much richer as either word and either image is associated semantically to a number of concepts such as white or black color, feminine vs. masculine, cold vs. hot, and others. These sound-shape associations seem to be related through a large overlap between semantic networks of Kiki and star-shape on the one hand, and Bouba and round-shape on the other hand. For example, both Kiki and star-shape are clever, small, thin and nervous. This indicates that behind Kiki-Bouba effect lies a rich semantic network. In other words, our sensory experience is largely determined by the meaning that we assign to stimuli.\\n\\n## Implications for art theory\\n\\nThe concept of ideasthesia has been often discussed in relation to art, and also used to formulate a psychological theory of art. According to the theory, we consider something to be a piece of art when experiences induced by the piece are accurately balanced with semantics induced by the same piece. Thus, a piece of art makes us both strongly think and strongly experience. Moreover, the two must be perfectly balanced such that the most salient stimulus or event is both the one that evokes strongest experiences (fear, joy, ... ) and strongest cognition (recall, memory, ...) — in other words, idea is well balanced with aesthesia.\\n\\nIdeasthesia theory of art may be used for psychological studies of aesthetics. It may also help explain classificatory disputes about art as its main tenet is that experience of art can only be individual, depending on person's unique knowledge, experiences and history. There could exist no general classification of art satisfactorily applicable to each and all individuals.\\n","frontmatter":{"title":"Synesthesia","description":"Neurological phenomenon of interlinked sensory signals","date":"2021-08-25T00:00:00.000Z","cover":"/media_files/cover/theory-interplay-synesthesia-Number_Form-synesthesia.jpg"},"url":"/theory/interplay/synesthesia/"},{"src":"---\\ntitle: Chromatic spectrum\\ndescription: The model in which musical octave meets color spectrum.\\ncover: spectrum.svg\\ndate: 2021-08-24\\n---\\n\\nSonic and electromagnetic waves have very different mediums as a carrier field. Sound is carried by air molecules, light travels through vacuum just because of ever present electromagnetic field.\\n\\nBut they're stil oscillations, so we an compare their frequencies and wavelenghts. But what to choose? Let's try both!\\n\\n## Frequency\\n\\n![svg](./acoustic-spectrum.svg)\\n\\nLet's start with frequencies. What is **1 Hz**? It's one oscillation per second. For EM it corresponds to radiation far in the **long radio spectrum**. We can't hear such slow air oscillations and 1 Hz is in **infrasonic** range.\\n\\n<img src=\\"./em-acoustic.svg\\" >\\n\\nThis juxtaposition shows that electromagnetic and acoustic oscillations are of entirely different nature and can’t be matched just as they are. Audible frequencies of oscillating air correspond to long radio range of EM spectrum. If compared by the wavelengths our notes are situated somewhere around the FM radio range. In turn the visible light oscillations are so fast, that they can be matched only with hypersonic waves in some rigid bodies.\\n\\nThese oscillations are so short that they are comparable with the size of atoms in a crystal grid. The faster atoms move – the more heat they carry. A heated body starts to emit electromagnetic waves, starting from infrared and coming to the visible light range after about 1000K. So we can say, that sound and light are two main forms of oscillating energy propagation mechanics. And the similarities between them can be better justified not by their physical nature, but by the nature of human perception of them.\\n\\n# 40th octave imaginary sound\\n\\nLet take it mathematically. Acoustic oscillations frequency multiplies by to with every octave. This means we can find an imaginary pitch for any given frequency. This means we can find rythm notes and also it's another way to bring light and sound together.\\n\\nLet's keep multiplying our A = 440 Hz by two until we reach the visible light spectrum – about 0.4–1 PHz. We can calculate all the notes frequencies and place them in the spectrogram. What we get is that A is near orange red, C is green and E is blue. Roughly. But If we consider a little lower base A frequency, we can see pretty nice corellation.\\n\\n<img src=\\"./spectrum.svg\\" />\\n\\nWe can conclude that it's a fundamental property of our perception to close perceived parts of any spectrum into a seamless circle. And these circles are not just illusions as the resonances and periodicities are based on fundamental principles of physics.\\n","frontmatter":{"title":"Chromatic spectrum","description":"The model in which musical octave meets color spectrum.","cover":"/media_files/cover/theory-interplay-spectrum-spectrum.svg","date":"2021-08-24T00:00:00.000Z"},"url":"/theory/interplay/spectrum/"},{"src":"---\\ntitle: Harmony\\ndescription: Chord progressions and accompaniment\\ndate: 2021-08-18\\ncover: omar-flores.jpg\\n---\\n\\nWhat is [Harmony](./study/index.md)?\\n\\nMay two or more scales [Sound nice simultaneously](./polytonality/index.md)? Or how to [Transition from one key to another](./modulation/index.md)? Let's explore all the possible [Harmonic movements](./movement/index.md) in different frames like [Chord-scale system](./chord-scale/index.md) or the [Chord and nonchord tones approach](./non-chord/index.md)\\n\\n## Harmonic rhythm\\n\\nIn music theory, harmonic rhythm, also known as harmonic tempo, is the rate at which the chords change (or progress) in a musical composition, in relation to the rate of notes. Thus a passage in common time with a stream of sixteenth notes and chord changes every measure has a slow harmonic rhythm and a fast surface or \\"musical\\" rhythm (16 notes per chord change), while a piece with a trickle of half notes and chord changes twice a measure has a fast harmonic rhythm and a slow surface rhythm (1 note per chord change). Harmonic rhythm may be described as strong or weak.\\n\\nAccording to William Russo harmonic rhythm is, \\"the duration of each different chord...in a succession of chords.\\" According to Joseph Swain (2002 p. 4) harmonic rhythm, \\"is simply that perception of rhythm that depends on changes in aspects of harmony.\\" According to Walter Piston (1944), \\"the rhythmic life contributed to music by means of the underlying changes of harmony. The pattern of the harmonic rhythm of a given piece of music, derived by noting the root changes as they occur, reveals important and distinctive features affecting the style and texture.\\"\\n\\nStrong harmonic rhythm is characterized by strong root progressions and emphasis of root positions, weak contrapuntal bass motion, strong rhythmic placement in the measure (especially downbeat), and relatively longer duration.\\n\\n\\"The 'fastness' or 'slowness' of harmonic rhythm is not absolute, but relative,\\"[self-published source] and thus analysts compare the overall pace of harmonic rhythm from one piece to another, or the amount of variation of harmonic rhythm within a piece. For example, a key stylistic difference between Baroque music and Classical-period music is that the latter exhibits much more variety of harmonic rhythm, even though the harmony itself is less complex.\\n","frontmatter":{"title":"Harmony","description":"Chord progressions and accompaniment","date":"2021-08-18T00:00:00.000Z","cover":"/media_files/cover/theory-harmony-omar-flores.jpg"},"url":"/theory/harmony/"},{"src":"---\\ntitle: Chord-scale system\\ndescription: Harmony oragnization using different scales for the sounding chord\\ndate: 2021-08-12\\n---\\n\\nThe chord-scale system is a method of matching, from a list of possible chords, a list of possible scales. The system has been widely used since the 1970s and is \\"generally accepted in the jazz world today\\".\\n\\nHowever, the majority of older players used the chord tone/chord arpeggio method. The system is an example of the difference between the treatment of dissonance in jazz and classical harmony: \\"Classical treats all notes that don't belong to the chord...as potential dissonances to be resolved...Non-classical harmony just tells you which note in the scale to [potentially] avoid..., meaning that all the others are okay\\".\\n\\nThe chord-scale system may be compared with other common methods of improvisation, first, the older traditional chord tone/chord arpeggio method, and where one scale on one root note is used throughout all chords in a progression (for example the blues scale on A for all chords of the blues progression: A7 E7 D7). In contrast, in the chord-scale system, a different scale is used for each chord in the progression (for example Mixolydian scales on A, E, and D for chords A7, E7, and D7, respectively). Improvisation approaches may be mixed, such as using \\"the blues approach\\" for a section of a progression and using the chord-scale system for the rest.\\nDominant seventh chord normally paired with mixolydian scale, the fifth mode of the major scale.\\n\\nThe scales commonly used today consist of the seven modes of the diatonic scale, the seven modes of the melodic minor scale, the diminished scales, the whole-tone scale, and pentatonic and bebop scales. Students now typically learn as many as twenty-one scales, which may be compared with the four scales commonly used in jazz in the 1940s (major, minor, mixolydian, and blues) and the two later added by bebop (diminished and whole-tone) to the tonal resources of jazz.\\nThe corresponding scale for the C7♯11 chord, with added ninth and thirteenth tensions, is C lydian dominant, the fourth mode of the ascending melodic minor.\\n\\nOriginating with George Russell's Lydian Chromatic Concept of Tonal Organization (1959), the chord-scale system is now the \\"most widely used method for teaching jazz improvisation in college\\". This approach is found in instructional books including Jerry Bergonzi's Inside Improvisation series and characterized by the highly influential Play-A-Long series by Jamey Aebersold. Aebersold's materials, and their orientation to learning by applying theory over backing tracks, also provided the first known publication of the blues scale in the 1970 revision of Volume 1 There are differences of approach within the system. For example, Russell associated the C major chord with the lydian scale, while teachers including John Mehegan, David Baker, and Mark Levine teach the major scale as the best match for a C major chord.\\n\\nMiles Davis's Lydian Chromatic Concept-influenced first modal jazz album Kind of Blue, is often given as an example of chord-scale relationships in practice.\\n\\nThe chord-scale system provides familiarity with typical chord progressions, technical facility from practicing scales and chord arpeggios, and generally succeeds in reducing \\"clams\\", or notes heard as mistakes (through providing note-choice possibilities for the chords of progressions), and building \\"chops\\", or virtuosity.\\n\\nDisadvantages include the exclusion of non-chord tones characteristic of bop and free styles, the \\"in-between\\" sounds featured in the blues, and consideration of directionality created between the interaction of a solo and a chord progression: \\"The disadvantages of this system may become clear when students begin to question why their own playing does not sound like such outstanding linear-oriented players as Charlie Parker, Sonny Stitt or Johnny Griffin (or, for that matter, the freer jazz stylists)\\":\\n\\n> The chord-scale method's 'vertical' approach...is 'static,' offering little assistance in generating musical direction through the movement of chords. Hence the importance of knowing the older chord tone approach. But...Swing- and bop-era songforms operate teleologically with regard to harmony. Highly regarded soloists in those styles typically imply the movements of chords...either by creating lines that voice-lead smoothly from one chord to another or by confounding the harmony pull through anticipating or delaying harmonic resolution.\\n\\nEssential considerations of a style such as Charlie Parker's, including \\"rhythm, phrase shape and length, dynamics, and tone color,\\" as well as \\"passing tones, appoggiatura, and 'blue notes'\\" are unaddressed. This appears to have led educators to emphasize a specific repertoire of pieces most appropriate to the chord-scale system, such as John Coltrane's \\"Giant Steps\\", while excluding others, such as Coltrane's later styles of composition, and producing generations of \\"pattern\\" players among college-educated musicians.\\n\\nhttps://en.wikipedia.org/wiki/Avoid_note\\n","frontmatter":{"title":"Chord-scale system","description":"Harmony oragnization using different scales for the sounding chord","date":"2021-08-12T00:00:00.000Z"},"url":"/theory/harmony/chord-scale/"},{"src":"---\\ntitle: Nonchord tones\\ndescription: Notes in a piece of music or song that are not part of the chord set out by the harmonic framework\\ndate: 2021-08-10\\n---\\n\\n## Non-chord tones\\n\\nA nonchord tone (NCT), nonharmonic tone, or embellishing tone is a note in a piece of music or song that is not part of the implied or expressed chord set out by the harmonic framework. In contrast, a chord tone is a note that is a part of the functional chord (see: factor (chord)). Non-chord tones are most often discussed in the context of the common practice period of classical music, but they can be used in the analysis of other types of tonal music as well, such as Western popular music.\\n\\nNonchord tones are often categorized as accented non-chord tones and unaccented non-chord tones depending on whether the dissonance occurs on an accented or unaccented beat (or part of a beat).\\n\\nOver time, some musical styles assimilated chord types outside of the common-practice style. In these chords, tones that might normally be considered nonchord tones are viewed as chord tones, such as the seventh of a minor seventh chord. For example, in 1940s-era bebop jazz, an F♯ played with a C 7 chord would be considered a chord tone if the chord were analyzed as C7(♯11). In European classical music, \\"[t]he greater use of dissonance from period to period as a result of the dialectic of linear/vertical forces led to gradual normalization of ninth, eleventh, and thirteenth chords [in analysis and theory]; each additional non-chord tone above the foundational triad became frozen into the chordal mass.\\"\\n\\n## Theory\\n\\nChord and nonchord tones are defined by their membership (or lack of membership) in a chord: \\"The pitches which make up a chord are called chord-tones: any other pitches are called non-chord-tones.\\" They are also defined by the time at which they sound: \\"Nonharmonic tones are pitches that sound along with a chord but are not chord pitches.\\" For example, if an excerpt from a piece of music implies or uses a C-major chord, then the notes C, E and G are members of that chord, while any other note played at that time (e.g., notes such as F♯) is a nonchord tone. Such tones are most obvious in homophonic music but occur at least as frequently in contrapuntal music.\\n\\nAccording to Music in Theory and Practice, \\"Most nonharmonic tones are dissonant and create intervals of a second, fourth or seventh\\", which are required to resolve to a chord tone in conventional ways. If the note fails to resolve until the next change of harmony, it may instead create a seventh chord or extended chord. While theoretically in a three-note chord, there are nine possible nonchord tones in equal temperament, in practice nonchord tones are usually in the prevailing key. Augmented and diminished intervals are also considered dissonant, and all nonharmonic tones are measured from the bass note, or lowest note sounding in the chord except in the case of nonharmonic bass tones.\\n\\nNonharmonic tones generally occur in a pattern of three pitches, of which the nonharmonic tone is the center:\\n\\n> Chord tone – Nonchord tone – Chord tone\\n> Preparation – Dissonance – Resolution\\n\\nNonchord tones are categorized by how they are used. The most important distinction is whether they occur on a strong or weak beat and are thus either accented or unaccented nonchord tones They are also distinguished by their direction of approach and departure and the voice or voices in which they occur and the number of notes they contain.\\n\\n### Unaccented\\n\\n#### Anticipation\\n\\nAn anticipation (ANT) occurs when this note is approached by step and then remains the same. It is basically a note of the second chord played early.\\n\\nA portamento is the late Renaissance precursor to the anticipation, though today it refers to a glissando.\\n\\n#### Neighbor tone\\n\\nA neighbor tone (NT) or auxiliary note (AUX) is a nonchord tone that passes stepwise from a chord tone directly above or below it (which frequently causes the NT to create dissonance with the chord) and resolves to the same chord tone.\\n\\nIn practice and analysis, neighboring tones are sometimes differentiated depending upon whether or not they are lower or higher than the chord tones surrounding them. A neighboring tone that is a step higher than the surrounding chord tones is called an upper neighboring tone or an upper auxiliary note while a neighboring tone that is a step lower than the surrounding chord tones is a lower neighboring tone or lower auxiliary note. However, following Heinrich Schenker's usage in Free Composition, some authors reserve the term \\"neighbor note\\" to the lower neighbor a half step below the main note.\\n\\nThe German term Nebennote is a somewhat broader category, including all nonchord tones approached from the main note by step.\\n\\n#### Escape tone\\n\\nAn escape tone (ET) or echappée is a particular type of unaccented incomplete neighbor tone that is approached stepwise from a chord tone and resolved by a skip in the opposite direction back to the harmony.\\n\\n#### Passing tone\\n\\nA passing tone (PT) or passing note is a nonchord tone prepared by a chord tone a step above or below it and resolved by continuing in the same direction stepwise to the next chord tone (which is either part of the same chord or of the next chord in the harmonic progression).\\n\\nWhere two nonchord tones are before the resolution they are double passing tones or double passing notes.\\n\\n### Accented Non-Chord Tones\\n\\n#### Passing tone\\n\\nA tone that sits between two chord tones and is between them.\\n\\n#### Neighbor tone\\n\\nA neighbour tone is where you skip up or down from a note (or chord tone) and then move back to the original note.\\n\\n#### Suspension and retardation\\n\\n> Endeavor, moreover, to introduce suspensions now in this voice, now in that, for it is incredible how much grace the melody acquires by this means. And every note which has a special function is rendered audible thereby.\\n> — Johann Joseph Fux (1725)\\n\\nA suspension (SUS) (sometimes referred to as a syncope) occurs when the harmony shifts from one chord to another, but one or more notes of the first chord (the preparation) are either temporarily held over into or are played again against the second chord (against which they are nonchord tones called the suspension) before resolving downwards to a chord tone by step (the resolution). The whole process is called a suspension as well as the specific nonchord tone(s).\\n\\nSuspensions may be further described with two numbers: (1) the interval between the suspended note and the bass note and (2) the interval between the resolution and the bass note. The most common suspensions are 4-3 suspension, 7-6 suspension, or 9-8 suspension. Note that except for the 9-8 suspensions, the numbers are typically referred to using the simple intervals, so for instance, if the intervals are actually an 11th and a 10th (the first example below), you would typically call it a 4-3 suspension. If the bass note is suspended, then the interval is calculated between the bass and the part that is most dissonant with it, often resulting in a 2-3 suspension.\\n\\nSuspensions must resolve downwards. If a tied note is prepared like a suspension but resolves upwards, it is called a retardation. Common retardations include 2-3 and 7-8 retardations.\\n\\nDecorated suspensions are common and consist of portamentos or double eighth notes, the second being a lower neighbor tone.\\n\\nA chain of suspensions constitutes the fourth species of counterpoint; an example may be found in the second movement of Arcangelo Corelli's Christmas Concerto.\\n\\n#### Appoggiatura\\n\\nAn appoggiatura (APP) is a type of accented incomplete neighbor tone approached skip-wise from one chord tone and resolved stepwise to another chord tone (\\"overshooting\\" the chord tone).\\n\\n#### Nonharmonic bass\\n\\nNonharmonic bass notes are bass notes that are not a member of the chord below which they are written. Examples include the Elektra chord. An example of a nonharmonic bass from the third movement of Stravinsky's Symphony of Psalms.\\n\\n### Involving more than three notes\\n\\n#### Changing tones\\n\\nChanging tones (CT) are two successive nonharmonic tones. A chord tone steps to a nonchord tone which skips to another nonchord tone which leads by step to a chord tone, often the same chord tone. They may imply neighboring tones with a missing or implied note in the middle. Also called double neighboring tones or neighbor group.\\n\\n#### Pedal point\\n\\nAnother form of nonchord tone is a pedal point or pedal tone (PD) or note, almost always the tonic or dominant, which is held through a series of chord changes. The pedal point is almost always in the lowest voice (the term originates from organ playing), but it may be in an upper voice; then it may be called an inverted pedal. It may also be between the upper and lower voices, in which case it is called an internal pedal.\\n\\n### Chromatic nonharmonic tone\\n\\nA chromatic nonharmonic tone is a nonharmonic tone that is chromatic, or outside of the key and creates half-step motion. The use of which, especially chromatic appoggiaturas and chromatic passing tones, increased in the Romantic Period.\\n\\n## Outside (jazz)\\n\\nIn jazz improvisation, outside playing describes an approach where one plays over a scale, mode or chord that is harmonically distant from the given chord. There are several common techniques to playing outside, that include side-stepping or side-slipping, superimposition of Coltrane changes, and polytonality.\\n\\n### Side-slipping\\n\\nThe term side-slipping or side-stepping has been used to describe several similar yet distinct methods of playing outside. In one version, one plays only the five \\"'wrong'\\" non-scale notes for the given chord and none of the seven scale or three to four chord tones, given that there are twelve notes in the equal tempered scale and heptatonic scales are generally used. Another technique described as sideslipping is the addition of distant ii–V relationships, such as a half-step above the original ii–V. This increases chromatic tension as it first moves away and then towards the tonic. Lastly, side-slipping can be described as playing in a scale a half-step above or below a given chord, before resolving, creating tension and release.\\n","frontmatter":{"title":"Nonchord tones","description":"Notes in a piece of music or song that are not part of the chord set out by the harmonic framework","date":"2021-08-10T00:00:00.000Z"},"url":"/theory/harmony/non-chord/"},{"src":"---\\ntitle: Composition\\ndescription: The act of conceiving a piece of music, the art of creating music, or the finished product\\ndate: 2021-07-10\\ncover: dayne-topkin.jpg\\nlinks:\\n  - https://www.researchgate.net/publication/353829597_Visualizing_music_structure_using_Spotify_data\\n  - https://jobsavelsberg.com/musicstructure/\\n---\\n\\nHere we try to tie up all the learned levels of music to establish systems if creating whole music pieces. [Generative theory of tonal music](./generative/index.md) views music evolution similar to human speach. The innovative rules of [Atonality and serialism](./serialism/index.md) bring music to the edge of complex mathematics.\\n\\n[Musical form](./form/index.md) is the means of expression of the most complex ideas. [Song structure](./song/index.md) is the way to build the bigger frame for the ideas that are sung about. We'll explore the resulting [Texture](./texture/index.md) of music created by many great [Composers](./composers/index.md) of all times,\\n\\n<YoutubeEmbed video=\\"GS24I5tZQNU\\" />\\n","frontmatter":{"title":"Composition","description":"The act of conceiving a piece of music, the art of creating music, or the finished product","date":"2021-07-10T00:00:00.000Z","cover":"/media_files/cover/theory-composition-dayne-topkin.jpg","links":["https://www.researchgate.net/publication/353829597_Visualizing_music_structure_using_Spotify_data","https://jobsavelsberg.com/musicstructure/"]},"url":"/theory/composition/"},{"src":"---\\ntitle: Texture\\nsubtitles: Overall quality of the sound in a musical piece\\ncover: cover.jpg\\ndate: 2021-07-10\\n---\\n\\n## Texture\\n\\nIn music, texture is how the tempo, melodic, and harmonic materials are combined in a musical composition, determining the overall quality of the sound in a piece. The texture is often described in regard to the density, or thickness, and range, or width, between lowest and highest pitches, in relative terms as well as more specifically distinguished according to the number of voices, or parts, and the relationship between these voices. For example, a thick texture contains many 'layers' of instruments. One of these layers could be a string section or another brass. The thickness also is changed by the amount and the richness of the instruments playing the piece. The thickness varies from light to thick. A piece's texture may be changed by the number and character of parts playing at once, the timbre of the instruments or voices playing these parts and the harmony, tempo, and rhythms used. The types categorized by number and relationship of parts are analyzed and determined through the labeling of primary textural elements: primary melody (PM), secondary melody (SM), parallel supporting melody (PSM), static support (SS), harmonic support (HS), rhythmic support (RS), and harmonic and rhythmic support (HRS).\\n\\n<youtube-embed video=\\"teh22szdnRQ\\" />\\n\\n### Common types\\n\\nIn musical terms, particularly in the fields of music history and music analysis, some common terms for different types of texture are:\\n\\n- **Monophonic** - Monophonic texture includes a single melodic line with no accompaniment.PSMs often double or parallel the PM they support.\\n- **Biphonic** - Two distinct lines, the lower sustaining a drone (constant pitch) while the other line creates a more elaborate melody above it. Pedal tones or ostinati would be an example of a SS. It is generally considered to be a type of polyphony. Pedal tone in Bach's Prelude No. 6 in D minor, BWV 851, from The Well-Tempered Clavier, Book I, mm. 1–2. All pedal tone notes are consonant except for the last three of the first measure.\\n- **Polyphonic or Counterpoint or Contrapuntal** - Multiple melodic voices which are to a considerable extent independent from or in imitation with one another. Characteristic texture of the Renaissance music, also prevalent during the Baroque period. Polyphonic textures may contain several PMs.\\n- **Homophonic** - The most common texture in Western music: melody and accompaniment. Multiple voices of which one, the melody, stands out prominently and the others form a background of harmonic accompaniment. If all the parts have much the same rhythm, the homophonic texture can also be described as homorhythmic. Characteristic texture of the Classical period and continued to predominate in Romantic music while in the 20th century, \\"popular music is nearly all homophonic,\\" and, \\"much of jazz is also\\" though, \\"the simultaneous improvisations of some jazz musicians creates a true polyphony\\". Homophonic textures usually contain only one PM. HS and RS are often combined, thus labeled HRS.\\n- **Homorhythmic** - Multiple voices with similar rhythmic material in all parts. Also known as \\"chordal\\". May be considered a condition of homophony or distinguished from it.\\n- **Heterophonic** - Two or more voices simultaneously performing variations of the same melody.\\n- **Silence** - No sound at all or the absence of intended sound\\n\\nMany classical pieces feature different kinds of texture within a short space of time. An example is the Scherzo from Schubert’s piano sonata in B major, D575. The first four bars are monophonic, with both hands performing the same melody an octave apart. Bars 5–10 are homophonic, with all voices coinciding rhythmically.Bars 11–20 are polyphonic. There are three parts, the top two moving in parallel (interval of a tenth). The lowest part imitates the rhythm of the upper two at the distance of three beats. The passage climaxes abruptly with a bar’s silence.\\n\\nAfter the silence, the polyphonic texture expands from three to four independent parts moving simultaneously in bars 21–24. The upper two parts are imitative, the lowest part consists of a repeated note (pedal point) and the remaining part weaves an independent melodic line. The final four bars revert to homophony, bringing the section to a close.\\n\\n<youtube-embed video=\\"xcQcAeiNK2Q\\" />\\n\\n### Additional types\\n\\nAlthough in music instruction certain styles or repertoires of music are often identified with one of these descriptions this is basically added music (for example, Gregorian chant is described as monophonic, Bach Chorales are described as homophonic and fugues as polyphonic), many composers use more than one type of texture in the same piece of music.\\n\\nA simultaneity is more than one complete musical texture occurring at the same time, rather than in succession.\\n\\nA more recent type of texture first used by György Ligeti is **micropolyphony**. Other textures include **polythematic**, **polyrhythmic**, **onomatopoeic**, **compound**, and **mixed** or **composite** textures.\\n","frontmatter":{"title":"Texture","subtitles":"Overall quality of the sound in a musical piece","cover":"/media_files/cover/theory-composition-texture-cover.jpg","date":"2021-07-10T00:00:00.000Z"},"url":"/theory/composition/texture/"},{"src":"---\\ntitle: Electronic minimalism\\ndescription: Ways to produce compelling electronic compositions\\ndate: 2021-07-03\\ncover: underdog.jpg\\n---\\n\\n## The 4 principles of techno minimalism by [Underdog](https://underdog.brussels/)\\n\\n<youtube-embed video=\\"mh8jV6IGI84\\" />\\n\\n## 1. Subtle motifs\\n\\n### Two elements bouncing at each other\\n\\nEnsure something is going on in the lows, in the mids & the highs. Choose a phrase length & design it to create a simple groove.\\n\\n## 2. Movement\\n\\n### Too little is boring, too much is distracting\\n\\nCreate movement in the timbre of your elements. Use modulating effects, tweak filters, change envelope lengths, LFOs or automation to create movement.\\n\\n## 3. Polymeters\\n\\n### Slightly unstable, but exciting in moderation\\n\\nSimple grooves become endlesly listenable when you add 1 or 2 polymeters to them.  During breaks polymeters make it hard to guess where the ‘1’ of the groove is, which is satisfying, when resolved.\\n\\n## 4. Tension and release\\n\\n### Make the audience wait\\n\\nEvolve the global story of the track to build up tension and then release that tension. Make them want it, tease them, drive them crazy! Use contrast (busy vs sparse). Use reversed reverb tails as buildups.\\n\\n<youtube-embed video=\\"B_D3dCSylCg\\" />\\n\\n## Making minimalist music\\n\\n> Only Having What You Need\\n\\nWrite as little as possible.\\n\\n### Rule of three\\n\\nAt maximum three layers of music can have listeners attention.\\n\\n### Avoid habits and answer questions\\n\\n- Why am I doing this?\\n- What is doing this adding to the final result?\\n- Is this really making any difference?\\n- Is it really necessary?\\n\\nMinimalism and why it might be the most effective way to finish more music.\\n\\n<youtube-embed video=\\"8FNmtguAJGE\\" />\\n","frontmatter":{"title":"Electronic minimalism","description":"Ways to produce compelling electronic compositions","date":"2021-07-03T00:00:00.000Z","cover":"/media_files/cover/theory-composition-electronic-underdog.jpg"},"url":"/theory/composition/electronic/"},{"src":"---\\ntitle: Reharmonization\\ndescription: How to reharmonize a song\\nlink: https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-reharmonization/how-to-reharmonize-a-song/\\n---\\n\\n<youtube-embed video=\\"lz3WR-F_pnM\\" />\\n\\n## Reharmonization = Chord substitution but for the whole chord progression\\n\\nReharmonization is used to:\\n\\n* Make a song more ‘jazzy’ – that is, more harmonically and/or structurally complex;\\n* Personalise a song and make it your own (it’s almost like composing a brand new song, or a variation of an existing song).\\n\\nSo, generally, a song consists of a:\\n\\n* Melody; and\\n* Chord progression\\n\\nReharmonization involves **changing the melody or chords** or both – but changing them with regard to certain rules or ideas.\\n\\nTo reharmonize a song you need to take two things into account:\\n\\n* **Harmony**\\n  * This depends on the interaction between the melody and the chords\\n  * It depends on the quality of the chord (Maj, min, V7, etc.)\\n  * **Goal**: To ensure the **melody note is an ‘acceptable harmony’ over the chord**\\n* **Structure**\\n  * This refers to the movement of chords & bass-line\\n  * It is NOT affected by the quality of the chord\\n  * **Goal**: The structure must be logical.\\n  * In practice this means that chords and bass-lines should move:\\n    * by Fixed Intervals;\\n    * by Diatonically;\\n    * be Melody based.\\n\\n**The Overarching Goal of Reharmonization is**:\\n\\n* Change the chords and/or melody to ensure the melody is an ‘acceptable harmony’ over the chord.\\n* Change chords and bass-line so they move in a ‘structured way’.\\n\\n<youtube-embed video=\\"XPFo_LmqnJg\\" />\\n\\n## Key Melody Note\\n\\nThe first thing you have to do when reharmonizing a song is to identify the **Key Melody Note** (KMN) of each bar:\\n\\n* The KMN is harmonically the most important note in a bar – with all the other notes treated as passing notes (so NOT harmonically important)\\n* This is largely subjective, but the KMN tends to be the:\\n  * Longest note in the bar\\n  * First note in the bar\\n  * Most repeated note in the bar\\n  * A note played on-the-beat\\n* There may be more than one KMN in a bar, in which case:\\n  * Account for both; or\\n  * Look for the KMN in each half-bar (and so on)\\n* There may be no obvious KMN – e.g. a fast run of notes, in this case:\\n  * Look at ALL or MOST of the notes in the bar\\n  * Structure > Harmony – more on this later\\n\\n## Harmony\\n\\nFirst let’s deal with the **Harmony**:\\n\\n* Change the chord (tonality and quality) or KMN to ensure the KMN is an ‘acceptable harmony’ over the chord\\n* We have already learned in previous lessons that not all notes are equal. Some notes sound strong when played over a chord ([**Guide Tones**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-improvisation/guide-tones/)), some notes sound pleasant and complement the sound of a chord ([**Available Tensions**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chords/available-tensions/)), while some notes sound weak and dissonant ([**Avoid Notes**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-improvisation/avoid-notes/)). Well, I’ve defined ‘acceptable harmony’ as ‘guide tones’ (3rd & 7th) plus ‘available tensions’. These are the notes that sound good over a particular chord. I have allocated every note into the following categories:\\n  * **Strong Harmony** = Guide Tones\\n  * **Weak Harmony** = Root & 5th\\n  * **Jazzy Harmony** = Available Tensions\\n  * **Unacceptable Harmony** = Unavailable Tensions/Avoid Notes\\n\\nAcceptable Harmony = Guide Tones + Available Tensions\\n\\nBelow are the Acceptable Harmonies for a number of chord types.\\n\\n### Acceptable Harmonies\\n\\n![How to Reharmonize a Song](https://www.thejazzpianosite.com/wp-content/uploads/2016/12/How-to-Reharmonize-a-Song.png)\\n\\nOk, so now let’s do the same exercise but in reverse. Instead of taking a chord and finding all its acceptable harmonies, let’s take a note and find all the chords where that note is an acceptable harmony. Let’s use the note ‘C’.\\n\\n* Below, all chords that create an ‘Acceptable Harmony’ with the Key Melody Note (C) are highlighted <span style=\\"color: #008000;\\">**Green**</span>.\\n* The tonality/root of the chord is given in the row labelled ‘Root’\\n* The quality of the chord is given in the rows labelled ‘Chord Quality’\\n* The row labelled ‘Degree’ will tell you what degree the Key Melody Note is in relation to the chord.\\n\\n![Reharmonization Chords](https://www.thejazzpianosite.com/wp-content/uploads/2016/12/Reharmonization-Chords.png)\\n\\nYou can use any of the chords coloured <span style=\\"color: #008000;\\">**Green**</span> above to substitute for a chord when the key melody note of a bar is ‘C’.\\n\\n## Structure\\n\\nNext let’s deal with the Structure:\\n\\n* ‘Structure’ involves moving the **chord** and the **bass-line** in a ‘structured’ or ‘logical’ way, ignoring the quality of the chord.\\n* In reality this means moving the chords and bass-line in:\\n  * Fixed intervals;\\n  * Diatonically;\\n  * Melody based; or\\n  * Some other logical structure\\n* You can change chord inversions to create a smoother bass-line that doesn’t jump around too much\\n* The bass-line and chords can move in different ways as long as they are both ‘structured’\\n\\n<table id=\\"tablepress-161\\" class=\\"tablepress tablepress-id-161\\">\\n\\n<tbody class=\\"row-hover\\">\\n\\n<tr class=\\"row-1 odd\\">\\n\\n<td class=\\"column-1\\">**Chromatic (Fixed Intervals)**</td>\\n\\n<td class=\\"column-2\\">E♭7</td>\\n\\n<td class=\\"column-3\\">D7</td>\\n\\n<td class=\\"column-4\\">D♭7</td>\\n\\n<td class=\\"column-5\\">CMaj7</td>\\n\\n</tr>\\n\\n<tr class=\\"row-2 even\\">\\n\\n<td class=\\"column-1\\">**Coltrane (Fixed Intervals)**</td>\\n\\n<td class=\\"column-2\\">CMaj7</td>\\n\\n<td class=\\"column-3\\">G#Maj7</td>\\n\\n<td class=\\"column-4\\">EMaj7</td>\\n\\n<td class=\\"column-5\\">CMaj7</td>\\n\\n</tr>\\n\\n<tr class=\\"row-3 odd\\">\\n\\n<td class=\\"column-1\\">**Diatonic**</td>\\n\\n<td class=\\"column-2\\">F7</td>\\n\\n<td class=\\"column-3\\">E7</td>\\n\\n<td class=\\"column-4\\">D7</td>\\n\\n<td class=\\"column-5\\">CMaj7</td>\\n\\n</tr>\\n\\n<tr class=\\"row-4 even\\">\\n\\n<td class=\\"column-1\\">**Melody Based**</td>\\n\\n<td class=\\"column-2\\">**Melody:** C  \\n**Chord:** Am7</td>\\n\\n<td class=\\"column-3\\">**Melody:** E  \\n**Chord:** CMaj7</td>\\n\\n<td class=\\"column-4\\">**Melody:** F  \\n**Chord:** D♭Maj7</td>\\n\\n<td class=\\"column-5\\">**Melody:** F  \\n**Chord:** Dm7</td>\\n\\n</tr>\\n\\n<tr class=\\"row-5 odd\\">\\n\\n<td class=\\"column-1\\">**Bassline (Pedal Point)**</td>\\n\\n<td class=\\"column-2\\">**Chord:** E♭6  \\n**Bass:** C</td>\\n\\n<td class=\\"column-3\\">**Chord:** D7  \\n**Bass:** C</td>\\n\\n<td class=\\"column-4\\">**Chord:** D♭Maj7  \\n**Bass:** C</td>\\n\\n<td class=\\"column-5\\">**Chord:** CMaj7  \\n**Bass:** C</td>\\n\\n</tr>\\n\\n<tr class=\\"row-6 even\\">\\n\\n<td class=\\"column-1\\">**Bassline (Stepwise)**</td>\\n\\n<td class=\\"column-2\\">**Chord:** Em7  \\n**Bass:** E</td>\\n\\n<td class=\\"column-3\\">**Chord:** A7  \\n**Bass:** E</td>\\n\\n<td class=\\"column-4\\">**Chord:** Dm7 - G7  \\n**Bass:** D - D</td>\\n\\n<td class=\\"column-5\\">**Chord:** CMaj7  \\n**Bass:** C</td>\\n\\n</tr>\\n\\n</tbody>\\n\\n</table>\\n\\n_Remember: The chords and bass-line can move independently and the chord quality doesn’t matter_\\n\\n## Some Rules and Tips\\n\\n* Choose chords & melody that increase and then decrease tension\\n  * To increase tension – use higher extensions and alterations (e.g.♭13)\\n  * To decrease tension – use Guide Tones (3rd & 7th) & lower extensions (e.g. 9)\\n* On a long melody note or repeated melody note, move through a number of chords (this makes the melody note a kind of pedal point, which sounds great)\\n* While ideally we should have an acceptable harmony AND a logical structure, it is possible to have one without the other:\\n  * You can have a weak harmony (root or 5th) if you have a strong structure (II-V); OR\\n  * You can have a weak structure (no pattern) if you have a strong harmony (3rd or 7th)\\n* If the melody is a fast run of notes with no obvious ‘key melody note’\\n  * Structure becomes more important than Harmony\\n    * Bebop songs often use fast melody runs with strong II-V structured chord progressions\\n  * Look at and consider all the notes in the bar\\n\\n## Further study\\n\\nTo make your reharmonization sound even more professional and smooth:\\n\\n* Add [**Passing Chords**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-improvisation/passing-notes/)\\n* Add [**Jazz Chord Voicings**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-voicings/)\\n* [**Embellish the Melody**](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-improvisation/embellishing-the-melody/)\\n\\n## Google Doc\\n\\nBelow is an embedded Google Doc which outlines all the possible reharmonization (substitute) chords for all chord types and all 12 note. You’re welcome to export it to Excel. To do this:\\n\\n* Go to the Google Doc by [clicking here](https://docs.google.com/spreadsheets/d/1SuTuEAg8Lk8S09YJnBpy5UIP-MJZiKXycD7kmsaZW48)\\n* Press ‘File’\\n* Select ‘Download as’\\n* Select ‘Microsoft Excel’\\n\\n<iframe src=\\"https://docs.google.com/spreadsheets/d/1SuTuEAg8Lk8S09YJnBpy5UIP-MJZiKXycD7kmsaZW48/pubhtml?widget=true&amp;headers=false\\" width=\\"640\\" height=\\"500\\"></iframe>\\n\\nTo see the above theory in action, please watch the below video.\\n\\n<youtube-embed video=\\"hhMCNhfZ8Iw\\" />\\n\\n* Quoted from the source at https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-reharmonization/how-to-reharmonize-a-song/\\n","frontmatter":{"title":"Reharmonization","description":"How to reharmonize a song","link":"https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-reharmonization/how-to-reharmonize-a-song/"},"url":"/theory/harmony/reharmonization/"},{"src":"---\\ntitle: Karplus–Strong string\\ndescription: A method of physical modelling synthesis\\ndate: 2023-11-14\\ncover: ksa.png\\n---\\n\\nKarplus–Strong string synthesis is a method of physical modelling synthesis that loops a short waveform through a filtered delay line to simulate the sound of a hammered or plucked string or some types of percussion.\\n\\nAt first glance, this technique can be viewed as subtractive synthesis based on a feedback loop similar to that of a comb filter for z-transform analysis. However, it can also be viewed as the simplest class of wavetable-modification algorithms now known as digital waveguide synthesis, because the delay line acts to store one period of the signal.\\n\\nAlexander Strong invented the algorithm, and Kevin Karplus did the first analysis of how it worked. Together they developed software and hardware implementations of the algorithm, including a custom VLSI chip. They named the algorithm \\"Digitar\\" synthesis, as a portmanteau for \\"digital guitar\\".\\n\\n## How it works\\n\\n![schema](./ksa.png)\\n\\n- A short excitation waveform (of length L samples) is generated. In the original algorithm, this was a burst of white noise, but it can also include any wideband signal, such as a rapid sine wave chirp or frequency sweep, or a single cycle of a sawtooth wave or square wave.\\n- This excitation is output and simultaneously fed back into a delay line L samples long.\\n- The output of the delay line is fed through a filter. The gain of the filter must be less than 1 at all frequencies, to maintain a stable positive feedback loop. The filter can be a first-order lowpass filter (as pictured). In the original algorithm, the filter consisted of averaging two adjacent samples, a particularly simple filter that can be implemented without a multiplier, requiring only shift and add operations. The filter characteristics are crucial in determining the harmonic structure of the decaying tone.\\n- The filtered output is simultaneously mixed into the output and fed back into the delay line.\\n\\n## Tuning the string\\n\\nThe fundamental frequency (specifically, the lowest nonzero resonant frequency) of the resulting signal is the lowest frequency at which the unwrapped phase response of the delay and filter in cascade is − 2 π -2\\\\pi . The required phase delay D for a given fundamental frequency F0 is therefore calculated according to D = Fs/F0 where Fs is the sampling frequency.\\n\\nThe length of any digital delay line is a whole-number multiple of the sampling period. In order to obtain a fractional delay often needed for fine tuning the string below JND (Just Noticeable Difference), interpolating filters are used with parameters selected to obtain an appropriate phase delay at the fundamental frequency. Either IIR or FIR filters may be used, but FIR have the advantage that transients are suppressed if the fractional delay is changed over time. The most elementary fractional delay is the linear interpolation between two samples (e.g., s(4.2) = 0.8s(4) + 0.2s(5)). If the phase delay varies with frequency, harmonics may be sharpened or flattened relative to the fundamental frequency. The original algorithm used equal weighting on two adjacent samples, as this can be achieved without multiplication hardware, allowing extremely cheap implementations.\\n\\nZ-transform analysis can be used to get the pitches and decay times of the harmonics more precisely, as explained in the 1983 paper that introduced the algorithm.\\n\\nHolding the period (= length of the delay line) constant produces vibrations similar to those of a string or bell. Increasing the period sharply after the transient input produces drum-like sounds.\\n\\n## Refinements to the algorithm\\n\\nDue to its plucked-string sound in certain modes, Alex Strong and Kevin Karplus conjectured that the Karplus-Strong (KS) algorithm was in some sense a vibrating string simulation, and they worked on showing that it solved the wave equation for the vibrating string, but this was not completed.  Julius O. Smith III  recognized that the transfer-function of the KS, when viewed as a digital filter, coincided with that of a vibrating string, with the filter in the feedback loop representing the total string losses over one period. He later derived the KS algorithm as a special case of digital waveguide synthesis, which was used to model acoustic waves in strings, tubes, and membranes. The first set of extensions and generalizations of the Karplus-Strong Algorithm, typically known as the Extended Karplus-Strong (EKS) Algorithm, was presented in a paper in 1982 at the International Computer Music Conference in Venice, Italy, and published in more detail in 1983 in Computer Music Journal in an article entitled \\"Extensions of the Karplus Strong Plucked String Algorithm,\\" by David A. Jaffe and Julius O. Smith, and in Smith's PhD/EE dissertation.\\n\\nAlex Strong developed a superior wavetable-modification method for plucked-string synthesis, but only published it as a patent.\\n\\n## Musical applications\\n\\nThe first musical use of the algorithm was in the work May All Your Children Be Acrobats written in 1981 by David A. Jaffe, and scored for eight guitars, mezzo-soprano and computer-generated stereo tape, with a text based on Carl Sandburg's The People, Yes. Jaffe continued to explore the musical and technical possibilities of the algorithm in Silicon Valley Breakdown, for computer-generated plucked strings (1982), as well as in later works such as Telegram to the President, 1984 for string quartet and tape, and Grass for female chorus and tape (1987).\\n\\nThe patent was licensed first to Mattel Electronics, which failed as a company before any product using the algorithm was developed, then to a startup company founded by some of the laid-off Mattel executives. They never got sufficient funding to finish development, and so never brought a product to market either. Eventually Yamaha licensed the patent, as part of the Sondius package of patents from Stanford. It is unknown whether any hardware using the algorithm was ever sold, though many software implementations (which did not pay any license fees to the inventors) have been released.\\n\\nWhile they may not adhere strictly to the algorithm, many hardware components for modular systems have been commercially produced that invoke the basic principles of Karplus-Strong Synthesis: using an inverted, scaled control system for very small time values in a filtered delay line to create playable notes in the Western Tempered tuning system, controlled with volt per octave tracking or MIDI data. The Inventors were not specifically credited, though the term \\"Karplus-Strong Synthesis\\" is referenced in some of the manuals.\\n\\nHardware components capable of Karplus-Strong style synthesis include the Moog Clusterflux 108M, Mutable Instruments Elements and Rings, 4ms Company Dual Looping Delay, 2HP Pluck, Make Noise Mimeophon, Arturia MicroFreak and the Strymon Starlab.\\n","frontmatter":{"title":"Karplus–Strong string","description":"A method of physical modelling synthesis","date":"2023-11-14T00:00:00.000Z","cover":"/media_files/cover/theory-synthesis-karplus-strong-ksa.png"},"url":"/theory/synthesis/karplus-strong/"},{"src":"---\\ntitle: Modulation techniques\\ndescription: Signal cross relation\\ndate: 2023-10-18\\n---\\n\\n## Analog Modulation\\n\\n<youtube-embed video=\\"XnoHXyb7dkY\\" />\\n\\n### AM - Amplitude modulation\\n\\n### FM - Frequency modulation\\n\\n<youtube-embed video=\\"AzvxefRDT84\\" />\\n\\n<youtube-embed video=\\"wn71QBApCRg\\" />\\n","frontmatter":{"title":"Modulation techniques","description":"Signal cross relation","date":"2023-10-18T00:00:00.000Z"},"url":"/theory/synthesis/modulation/"},{"src":"---\\ntitle: Distortion \\ndescription: Linear and non-linear harmonic distortion\\ndate: 2023-10-12\\ncover: bernie-almanzar.jpg\\n---\\n\\n<youtube-embed video=\\"4QeqSYIXDr4\\" />\\n\\nDistortion and overdrive are forms of audio signal processing used to alter the sound of amplified electric musical instruments, usually by increasing their gain, producing a \\"fuzzy\\", \\"growling\\", or \\"gritty\\" tone. Distortion is most commonly used with the electric guitar, but may also be used with other electric instruments such as electric bass, electric piano, synthesizer and Hammond organ. Guitarists playing electric blues originally obtained an overdriven sound by turning up their vacuum tube-powered guitar amplifiers to high volumes, which caused the signal to distort. While overdriven tube amps are still used to obtain overdrive, especially in genres like blues and rockabilly, a number of other ways to produce distortion have been developed since the 1960s, such as distortion effect pedals. The growling tone of a distorted electric guitar is a key part of many genres, including blues and many rock music genres, notably hard rock, punk rock, hardcore punk, acid rock, and heavy metal music, while the use of distorted bass has been essential in a genre of hip hop music and alternative hip hop known as \\"SoundCloud rap\\".\\n\\n<youtube-embed video=\\"7dLArMd-y64\\" />\\n\\nThe effects alter the instrument sound by clipping the signal (pushing it past its maximum, which shears off the peaks and troughs of the signal waves), adding sustain and harmonic and inharmonic overtones and leading to a compressed sound that is often described as \\"warm\\" and \\"dirty\\", depending on the type and intensity of distortion used. The terms distortion and overdrive are often used interchangeably; where a distinction is made, distortion is a more extreme version of the effect than overdrive. Fuzz is a particular form of extreme distortion originally created by guitarists using faulty equipment (such as a misaligned valve (tube); see below), which has been emulated since the 1960s by a number of \\"fuzzbox\\" effects pedals.\\n\\nDistortion, overdrive, and fuzz can be produced by effects pedals, rackmounts, pre-amplifiers, power amplifiers (a potentially speaker-blowing approach), speakers and (since the 2000s) by digital amplifier modeling devices and audio software. These effects are used with electric guitars, electric basses (fuzz bass), electronic keyboards, and more rarely as a special effect with vocals. While distortion is often created intentionally as a musical effect, musicians and sound engineers sometimes take steps to avoid distortion, particularly when using PA systems to amplify vocals or when playing back prerecorded music.\\n\\n## History\\n\\nThe guitar solo on Chuck Berry's 1955 single \\"Maybellene\\" features \\"warm\\" overtone distortion produced by an inexpensive valve (tube) amplifier.\\n\\n### Early uses of amplified distortion\\n\\nThe first guitar amplifiers were relatively low-fidelity, and would often produce distortion when their volume (gain) was increased beyond their design limit or if they sustained minor damage. Around 1945, Western swing guitarist Junior Barnard began experimenting with a rudimentary humbucker pick-up and a small amplifier to obtain his signature \\"low-down and dirty\\" bluesy sound. Many electric blues guitarists, including Chicago bluesmen such as Elmore James and Buddy Guy, experimented in order to get a guitar sound that paralleled the rawness of blues singers such as Muddy Waters and Howlin' Wolf, replacing often their originals with the powerful Valco \\"Chicagoan\\" pick-ups, originally created for lap-steel, to obtain a louder and fatter tone. In early rock music, Goree Carter's \\"Rock Awhile\\" (1949) featured an over-driven electric guitar style similar to that of Chuck Berry several years later, as well as Joe Hill Louis' \\"Boogie in the Park\\" (1950).\\n\\nIn the early 1950s, guitar distortion sounds started to evolve based on sounds created earlier in the decade by accidental damage to amps, such as in the popular early recording of the 1951 Ike Turner and the Kings of Rhythm song \\"Rocket 88\\", where guitarist Willie Kizart used a vacuum tube amplifier that had a speaker cone slightly damaged in transport. Electric guitarists began intentionally \\"doctoring\\" amplifiers and speakers in order to emulate this form of distortion.\\n\\nElectric blues guitarist Willie Johnson of Howlin' Wolf′s band began deliberately increasing gain beyond its intended levels to produce \\"warm\\" distorted sounds. Guitar Slim also experimented with distorted overtones, which can be heard in his hit electric blues song \\"The Things That I Used to Do\\" (1953). Chuck Berry's 1955 classic \\"Maybellene\\" features a guitar solo with warm overtones created by his small valve amplifier. Pat Hare produced heavily distorted power chords on his electric guitar for records such as James Cotton's \\"Cotton Crop Blues\\" (1954) as well as his own \\"I'm Gonna Murder My Baby\\" (1954), creating \\"a grittier, nastier, more ferocious electric guitar sound,\\" accomplished by turning the volume knob on his amplifier \\"all the way to the right until the speaker was screaming.\\"\\n\\nIn 1956, guitarist Paul Burlison of the Johnny Burnette Trio deliberately dislodged a vacuum tube in his amplifier to record \\"The Train Kept A-Rollin\\" after a reviewer raved about the sound Burlison's damaged amplifier produced during a live performance. According to other sources Burlison's amp had a partially broken loudspeaker cone. Pop-oriented producers were horrified by that eerie \\"two-tone\\" sound, quite clean on trebles but strongly distorted on basses, but Burnette insisted on releasing the sessions, arguing that \\"that guitar sounds like a nice horn section\\".\\n\\nIn the late 1950s, Guitarist Link Wray began intentionally manipulating his amplifiers' vacuum tubes to create a \\"noisy\\" and \\"dirty\\" sound for his solos after a similarly accidental discovery. Wray also poked holes in his speaker cones with pencils to further distort his tone, used electronic echo chambers (then usually employed by singers), the recent powerful and \\"fat\\" Gibson humbucker pickups, and controlled \\"feedback\\" (Larsen effect). The resultant sound can be heard on his highly influential 1958 instrumental, \\"Rumble\\" and Rawhide.\\n\\n### 1960s: fuzz, distortion, and introduction of commercial devices\\n\\nIn 1961, Grady Martin scored a hit with a fuzzy tone caused by a faulty preamplifier that distorted his guitar playing on the Marty Robbins song \\"Don't Worry\\". Later that year Martin recorded an instrumental tune under his own name, using the same faulty preamp. The song, on the Decca label, was called \\"The Fuzz.\\" Martin is generally credited as the discoverer of the \\"fuzz effect.\\" The recording engineer from Martin's sessions, Glenn Snoddy, partnered with fellow WSM radio engineer Revis V. Hobbs to design and build a stand-alone device that would intentionally create the fuzzy effect. The two engineers sold their circuit to Gibson, who introduced it as the Maestro FZ-1 Fuzz-Tone in 1962, one of the first commercially-successful mass-produced guitar pedals.\\n\\nShortly thereafter, the American instrumental rock band The Ventures asked their friend, session musician and electronics enthusiast Orville \\"Red\\" Rhodes for help recreating the Grady Martin \\"fuzz\\" sound. Rhodes offered The Ventures a fuzzbox he had made, which they used to record \\"2000 Pound Bee\\" in 1962.\\n\\nIn 1964, a fuzzy and somewhat distorted sound gained widespread popularity after guitarist Dave Davies of The Kinks used a razor blade to slash his speaker cones for the band's single \\"You Really Got Me\\".\\n\\nIn May 1965 Keith Richards used a Maestro FZ-1 Fuzz-Tone to record \\"(I Can't Get No) Satisfaction\\". The song's success greatly boosted sales of the device, and all available stock sold out by the end of 1965. Other early fuzzboxes include the Mosrite FuzzRITE and Arbiter Group Fuzz Face used by Jimi Hendrix, the Electro-Harmonix Big Muff Pi used by Hendrix and Carlos Santana, and the Vox Tone Bender used by Paul McCartney to play fuzz bass on \\"Think for Yourself\\" and other Beatles recordings.\\n\\nIn 1966, Jim Marshall of the British company Marshall Amplification began modifying the electronic circuitry of his amplifiers so as to achieve a \\"brighter, louder\\" sound and fuller distortion capabilities. Also in 1966, Syd Barrett of Pink Floyd created the song Interstellar Overdrive, a song made entirely in electric distortion. It was released a year later in modified form on their debut album The Piper at the Gates of Dawn.\\n\\nIn the late 1960s and early 1970s hard rock bands such as Deep Purple, Led Zeppelin and Black Sabbath forged what would eventually become the heavy metal sound through a combined use of high volumes and heavy distortion.\\n\\n<youtube-embed video=\\"DZ4IGAR7iio\\" />\\n\\n## Theory and circuits\\n\\nWaveform plot showing the different types of clipping. Valve overdrive is a form of soft limiting, while transistor clipping or extremely overdriven valves resemble hard clipping.\\n\\nThe word distortion refers to any modification of wave form of a signal, but in music it is used to refer to nonlinear distortion (excluding filters) and particularly to the introduction of new frequencies by memoryless nonlinearities. In music the different forms of linear distortion have specific names describing them. The simplest of these is a distortion process known as \\"volume adjustment\\", which involves distorting the amplitude of a sound wave in a proportional (or 'linear') way in order to increase or decrease the volume of the sound without affecting the tone quality. In the context of music, the most common source of (nonlinear) distortion is clipping in amplifier circuits and is most commonly known as overdrive.\\n\\nClipping is a non-linear process that produces frequencies not originally present in the audio signal. These frequencies can be harmonic overtones, meaning they are whole number multiples of one of the signal's original frequencies, or \\"inharmonic\\", resulting from general intermodulation distortion. The same nonlinear device will produce both types of distortion, depending on the input signal. Intermodulation occurs whenever the input frequencies are not already harmonically related. For instance, playing a power chord through distortion results in intermodulation that produces new subharmonics.\\n\\n\\"Soft clipping\\" gradually flattens the peaks of a signal which creates a number of higher harmonics which share a harmonic relationship with the original tone. \\"Hard clipping\\" flattens peaks abruptly, resulting in higher power in higher harmonics. As clipping increases, a tone input progressively begins to resemble a square wave which has odd number harmonics. This is generally described as sounding \\"harsh\\".\\n\\nDistortion and overdrive circuits each 'clip' the signal before it reaches the main amplifier (clean boost circuits do not necessarily create 'clipping') as well as boost signals to levels that cause distortion to occur at the main amplifier's front end stage (by exceeding the ordinary input signal amplitude, thus overdriving the amplifier) Note : product names may not accurately reflect type of circuit involved - see above.\\n\\nA fuzz box alters an audio signal until it is nearly a square wave and adds complex overtones by way of a frequency multiplier.\\n\\n<youtube-embed video=\\"YuojAtE8YCY\\" />\\n\\n### Valve overdrive\\n\\nVacuum tube or \\"valve\\" distortion is achieved by \\"overdriving\\" the valves in an amplifier. In layman's terms, overdriving is pushing the tubes beyond their normal rated maximum. Valve amplifiers—particularly those using class-A triodes—tend to produce asymmetric soft clipping that creates both even and odd harmonics. The increase in even harmonics is considered to create \\"warm\\"-sounding overdrive effects.\\n\\nA basic triode valve (tube) contains a cathode, a plate and a grid. When a positive voltage is applied to the plate, a current of negatively charged electrons flows to it from the heated cathode through the grid. This increases the voltage of the audio signal, amplifying its volume. The grid regulates the extent to which plate voltage is increased. A small negative voltage applied to the grid causes a large decrease in plate voltage.\\n\\nValve amplification is more or less linear—meaning the parameters (amplitude, frequency, phase) of the amplified signal are proportional to the input signal—so long as the voltage of the input signal does not exceed the valve's \\"linear region of operation\\". The linear region falls between\\n\\nThe saturation region: the voltages at which plate current stops responding to positive increases in grid voltage and\\nThe cutoff region: the voltages at which the charge of the grid is too negative for electrons to flow to the plate. If a valve is biased within the linear region and the input signal's voltage exceeds this region, overdrive and non-linear clipping will occur.\\nMultiple stages of valve gain/clipping can be \\"cascaded\\" to produce a thicker and more complex distortion sound. In layperson's terms, a musician will plug a fuzz pedal into a tube amp that is being \\"cranked\\" to a clipping \\"overdriven\\" condition; as such, the musician will get the distortion from the fuzz which is then distorted further by the amp. During the 1990s, some Seattle grunge guitarists chained together as many as four fuzz pedals to create a thick \\"wall of sound\\" of distortion.\\n\\nIn some modern valve effects, the \\"dirty\\" or \\"gritty\\" tone is actually achieved not by high voltage, but by running the circuit at voltages that are too low for the circuit components, resulting in greater non-linearity and distortion. These designs are referred to as \\"starved plate\\" configurations, and result in an \\"amp death\\" sound.[citation needed]\\n\\n### Solid-state distortion\\n\\nSolid-state amplifiers incorporating transistors and/or op amps can be made to produce hard clipping. When symmetrical, this adds additional high-amplitude odd harmonics, creating a \\"dirty\\" or \\"gritty\\" tone. When asymmetrical, it produces both even and odd harmonics. Electronically, this is usually achieved by either amplifying the signal to a point where it is clipped by the DC voltage limitation of the power supply rail, or by clipping the signal with diodes.[citation needed] Many solid-state distortion devices attempt to emulate the sound of overdriven vacuum valves using additional solid-state circuitry. Some amplifiers (notably the Marshall JCM 900) utilize hybrid designs that employ both valve and solid-state components.[citation needed]\\n\\n## Approaches\\n\\nGuitar distortion can be produced by many components of the guitar's signal path, including effects pedals, the pre-amplifier, power amplifier, and speakers. Many players use a combination of these to obtain their \\"signature\\" tone.\\n\\n### Pre-amplifier distortion\\n\\nThe pre-amplifier section of a guitar amplifier serves to amplify a weak instrument signal to a level that can drive the power amplifier. It often also contains circuitry to shape the tone of the instrument, including equalization and gain controls. Often multiple cascading gain/clipping stages are employed to generate distortion. Because the first component in a valve amplifier is a valve gain stage, the output level of the preceding elements of the signal chain has a strong influence on the distortion created by that stage. The output level of the guitar's pickups, the setting of the guitar's volume knob, how hard the strings are plucked, and the use of volume-boosting effects pedals can drive this stage harder and create more distortion.\\n\\nDuring the 1980s and 1990s, most valve amps featured a \\"master volume\\" control, an adjustable attenuator between the preamp section and the power amp. When the preamp volume is set high to generate high distortion levels, the master volume lowered, keeping the output volume at manageable levels.\\n\\n### Overdrive/distortion pedals\\n\\nAnalog overdrive/distortion pedals work on similar principles to preamplifier distortion. Because most effects pedals are designed to operate from battery voltages, using vacuum tubes to generate distortion and overdrive is impractical; instead, most pedals use solid-state transistors, op-amps and diodes. Classic examples of overdrive/distortion pedals include the Boss OD series (overdrives), the Ibanez Tube Screamer (an overdrive), the Electro-Harmonix Big Muff Pi (a fuzz box) and the Pro Co RAT (a distortion). Typically, \\"overdrive\\" pedals are designed to produce sounds associated with classic rock or blues, with \\"distortion\\" pedals producing the \\"high gain, scooped mids\\" sounds associated with heavy metal; fuzz boxes are designed to emulate the distinctive sound of the earliest overdrive pedals such as the Big Muff and the Fuzz Face.[citation needed]\\n\\nMost overdrive/distortion pedals can be used in two ways: a pedal can be used as a \\"boost\\" with an already overdriven amplifier to drive it further into saturation and \\"color\\" the tone, or it can be used with a completely clean amplifier to generate the whole overdrive/distortion effect. With care—and with appropriately chosen pedals—it is possible to \\"stack\\" multiple overdrive/distortion pedals together, allowing one pedal to act as a 'boost' for another.\\n\\nFuzz boxes and other heavy distortions can produce unwanted dissonances when playing chords. To get around this, guitar players (and keyboard players) using these effects may restrict their playing to single notes and simple \\"power chords\\" (root, fifth, and octave). Indeed, with the most extreme fuzz pedals, players may choose to play mostly single notes, because the fuzz can make even single notes sound very thick and heavy. Heavy distortion also tends to limit the player's control of dynamics (loudness and softness)—similar to the limitations imposed on a Hammond organ player (Hammond organ does not produce louder or softer sounds depending on how hard or soft the performer plays the keys; however, the performer can still control the volume with drawbars and the expression pedal). Heavy metal music has evolved around these restrictions, using complex rhythms and timing for expression and excitement. Lighter distortions and overdrives can be used with triadic chords and seventh chords; as well, lighter overdrive allows more control of dynamics.[citation needed]\\n\\n### Power amplifier distortion\\n\\nPower valves (tubes) can be overdriven in the same way that pre-amplifier valves can, but because these valves are designed to output more power, the distortion and character they add to the guitar's tone is unique. During the 1960s to early 1970s, distortion was primarily created by overdriving the power valves. Because they have become accustomed to this sound[dubious – discuss], many guitar players[who?] favour this type of distortion, and thus set their amps to maximum levels in order to drive the power section hard. Many valve-based amplifiers in common use have a push-pull output configuration in their power section, with matched pairs of tubes driving the output transformer. Power amplifier distortion is normally entirely symmetric, generating predominantly odd-order harmonics.\\n\\nBecause driving the power valves this hard also means maximum volume, which can be difficult to manage in a small recording or rehearsal space, many solutions have emerged that in some way divert some of this power valve output from the speakers, and allow the player to generate power valve distortion without excessive volume. These include built-in or separate power attenuators and power-supply-based power attenuation, such as a VVR, or Variable Voltage Regulator to drop the voltage on the valves' plates, to increase distortion whilst lowering volume. Guitarists such as Eddie Van Halen have been known to use variacs before VVR technology was invented.[specify] Lower-power valve amps [such as a quarter-watt or less](citation needed), speaker isolation cabinets, and low-efficiency guitar speakers are also used to tame the volume.\\n\\nPower-valve distortion can also be produced in a dedicated rackmount valve power amp. A modular rackmount setup often involves a rackmount preamp, a rackmount valve power amp, and a rackmount dummy load to attenuate the output to desired volume levels. Some effects pedals internally produce power-valve distortion, including an optional dummy load for use as a power-valve distortion pedal. Such effects units can use a preamp valve such as the 12AX7 in a power-valve circuit configuration (as in the Stephenson's Stage Hog), or use a conventional power valve, such as the EL84 (as in the H&K Crunch Master compact tabletop unit). However, because these are usually placed before the pre-amplifier in the signal chain, they contribute to the overall tone in a different way. Power amplifier distortion may damage speakers.\\n\\nA Direct Inject signal can capture the power-tube distortion sound without the direct coloration of a guitar speaker and microphone. This DI signal can be blended with a miked guitar speaker, with the DI providing a more present, immediate, bright sound, and the miked guitar speaker providing a colored, remote, darker sound. The DI signal can be obtained from a DI jack on the guitar amp, or from the Line Out jack of a power attenuator.\\n\\n### Output transformer distortion\\n\\nThe output transformer sits between the power valves and the speaker, serving to match impedance. When a transformer's ferromagnetic core becomes electromagnetically saturated a loss of inductance takes place, since the back E.M.F. is reliant on a change in flux in the core. As the core reaches saturation, the flux levels off and cannot increase any further. With no change in flux there is no back E.M.F. and hence no reflected impedance. The transformer and valve combination then generate large 3rd order harmonics. So long as the core does not go into saturation, the valves will clip naturally as they drop the available voltage across them. In single ended systems the output harmonics will be largely even ordered due to the valve's relatively non linear characteristics at large signal swings. This is only true however if the magnetic core does NOT saturate.\\n\\n### Power supply \\"sag\\"\\n\\nEarly valve amplifiers used unregulated power supplies. This was due to the high cost associated with high-quality high-voltage power supplies. The typical anode (plate) supply was simply a rectifier, an inductor and a capacitor. When the valve amplifier was operated at high volume, the power supply voltage would dip, reducing power output and causing signal attenuation and compression. This dipping effect is known as \\"sag\\", and is sought-after by some electric guitarists. Sag only occurs in class-AB amplifiers. This is because, technically, sag results from more current being drawn from the power supply, causing a greater voltage drop over the rectifier valve. Class AB amplifiers draw the most power at both the maximum and minimum point of the signal, putting more stress on the power supply than class A, which only draws maximum power at the peak of the signal.\\n\\nAs this effect is more pronounced with higher input signals, the harder \\"attack\\" of a note will be compressed more heavily than the lower-voltage \\"decay\\", making the latter seem louder and thereby improving sustain. Additionally, because the level of compression is affected by input volume, the player can control it via their playing intensity: playing harder results in more compression or \\"sag\\". In contrast, modern amplifiers often use high-quality, well-regulated power supplies.\\n\\n### Speaker distortion\\n\\nGuitar loudspeakers are designed differently from high fidelity stereo speakers or public address system speakers. While hi-fi and public address speakers are designed to reproduce the sound with as little distortion as possible, guitar speakers are usually designed so that they will shape or color the tone of the guitar, either by enhancing some frequencies or attenuating unwanted frequencies.\\n\\nWhen the power delivered to a guitar speaker approaches its maximum rated power, the speaker's performance degrades, causing the speaker to \\"break up\\", adding further distortion and colouration to the signal. Some speakers are designed to have much clean headroom, while others are designed to break up early to deliver grit and growl.\\n\\n### Amp modeling for distortion emulation\\n\\nGuitar amp modeling devices and software can reproduce various guitar-specific distortion qualities that are associated with a range of popular \\"stomp box\\" pedals and amplifiers. Amp modeling devices typically use digital signal processing to recreate the sound of plugging into analogue pedals and overdriven valve amplifiers. The most sophisticated devices allow the user to customize the simulated results of using different preamp, power-tube, speaker distortion, speaker cabinet, and microphone placement combinations. For example, a guitarist using a small amp modeling pedal could simulate the sound of plugging their electric guitar into a heavy vintage valve amplifier and a stack of 8 X 10\\" speaker cabinets.\\n\\n## Voicing with equalization\\n\\nGuitar distortion is obtained and shaped at various points in the signal processing chain, including multiple stages of preamp distortion, power valve distortion, output and power transformer distortion, and guitar speaker distortion. Much of the distortion character or voicing is controlled by the frequency response before and after each distortion stage. This dependency of distortion voicing on frequency response can be heard in the effect that a wah pedal has on the subsequent distortion stage, or by using tone controls built into the guitar, the preamp or an EQ pedal to favor the bass or treble components of the guitar pickup signal prior to the first distortion stage. Some guitarists place an equalizer pedal after the distortion effect, to emphasize or de-emphasize different frequencies in the distorted signal.\\n\\nIncreasing the bass and treble while reducing or eliminating the centre midrange (750 Hz) results in what is popularly known as a \\"scooped\\" sound (since the midrange frequencies are \\"scooped\\" out). Conversely, decreasing the bass while increasing the midrange and treble creates a punchy, harsher sound. Rolling off all of the treble produces a dark, heavy sound.\\n\\n## Avoiding distortion\\n\\nElectronic audio compression devices, such as this DBX 566, are used by audio engineers to prevent signal peaks from causing unwanted distortion.\\n\\nWhile musicians intentionally create or add distortion to electric instrument signals or vocals to create a musical effect, there are some musical styles and musical applications where as little distortion as possible is sought. When DJs are playing recorded music in a nightclub, they typically seek to reproduce the recordings with little or no distortion. In many musical styles, including pop music, country music and even genres where the electric guitars are almost always distorted, such as heavy metal, punk and hard rock, sound engineers usually take a number of steps to ensure that the vocals sounding through the sound reinforcement system are undistorted (the exception is the rare cases where distortion is purposely added to vocals in a song as a special effect).\\n\\nSound engineers prevent unwanted, unintended distortion and clipping using a number of methods. They may reduce the gain on microphone preamplifiers on the audio console; use attenuation \\"pads\\" (a button on audio console channel strips, DI unit and some bass amplifiers); and use electronic audio compressor effects and limiters to prevent sudden volume peaks from vocal mics from causing unwanted distortion.\\n\\nThough some bass guitar players in metal and punk bands intentionally use fuzz bass to distort their bass sound, in other genres of music, such as pop, big band jazz and traditional country music, bass players typically seek an undistorted bass sound. To obtain a clear, undistorted bass sound, professional bass players in these genres use high-powered amplifiers with a lot of \\"headroom\\" and they may also use audio compressors to prevent sudden volume peaks from causing distortion. In many cases, musicians playing stage pianos or synthesizers use keyboard amplifiers that are designed to reproduce the audio signal with as little distortion as possible. The exceptions with keyboards are the Hammond organ as used in blues and the Fender Rhodes as used in rock music; with these instruments and genres, keyboardists often purposely overdrive a tube amplifier to get a natural overdrive sound. Another example of instrument amplification where as little distortion as possible is sought is with acoustic instrument amplifiers, designed for musicians playing instruments such as the mandolin or fiddle in a folk or bluegrass style.\\n\\n## Links\\n\\n- https://www.izotope.com/en/learn/what-is-distortion-in-music-when-and-how-to-use-it.html\\n","frontmatter":{"title":"Distortion","description":"Linear and non-linear harmonic distortion","date":"2023-10-12T00:00:00.000Z","cover":"/media_files/cover/theory-synthesis-distortion-bernie-almanzar.jpg"},"url":"/theory/synthesis/distortion/"},{"src":"---\\ntitle: Euclidean rhythms\\ndescription: Mathematical algorithm to create well-formed rhythm patterns\\ndate: 2022-05-11\\ncover: 8.png\\n---\\n\\n‘Euclidean’ rhythms are one of the few ideas for algorithmically generating musical material that has gained relative popularity over the last few years. We say ‘relative’ because we really don’t know how many composers/electronic producers really have heard of them in the grand scheme of things, but if you do a google search on this you’ll get far more hits than searching for, for example, music from L-systems. Many DAWs, iOS apps, MAX/MSP patches etc, allow music makers to generate Euclidean rhythms.\\n\\n## What are Euclidean rhythms?\\n\\nSo what does it mean, and why has it become popular? What does Euclid have to do with this? Euclidean rhythms are essentially a way of spacing out **n** events (let's call them ‘onsets’) across **m** positions (essentially, pulses or beats) as evenly possible. If you space out, for example, 4 onsets across 16 positions, the result is just 4 evenly spaced onsets. But if the number of onsets is relatively prime with respect to the number of pulses, the resulting pattern is more interesting. The term ‘Euclidean rhythm’ comes from a paper by McGill University computer scientist Godfried T. Toussaint, and fortunately his paper is [available online](/media/pdf/banff.pdf).\\n\\nIn the paper, Toussaint starts by explaining an algorithm by E. Bjorklund used in certain components of spallation neutron source (SNS) accelerators that require spacing out pulses across a certain number of time events as equidistantly as possible. After giving an example of how Bjorklund’s algorithm works, he shows that it has a parallel structure to Euclid’s algorithm from the Elements which uses repeated subtraction to establish the **greatest common divisor** (GCD) for two numbers.\\n\\n### Here is a simple example of Bjorklund’s algorithm spacing 5 onsets across 12 intervals (pulses).\\n\\nWe start with **five onsets** on the left (the ‘front’ group) and the **seven non-onsets** on the right (the ‘back’ group). We pair up one element from the front with one from the back until either the front or back group is exhausted. When we’re finished the newly combined elements will form the front group at the next iteration, and whatever is left over will form the new back group (in this case the two non-onsets):\\n\\n<img src=\\"./images/1.gif\\" />\\n\\nWe then repeat the process. Note that the combined elements from stage 1, are treated as single units here. At this stage, we start with five elements in the front and only two in the back. We combine them as before, but this time we will exhaust the back group first, with three elements left at the front — these will form the new back group, and the combined elements again are the new front group:\\n\\n<img src=\\"./images/2.gif\\" />\\n\\n\\nWe just recursively repeat these steps until the back group has one (or zero) elements. At the start of third iteration, we have two elements in the front and three at the back and after combining them, the back group has a single element and so we are finished.\\n\\n<img src=\\"./images/3.gif\\" />\\n\\n\\nIn conventional notation, the rhythm would look like this:\\n\\n<img src=\\"./images/4.png\\" />\\n\\n\\nEuclidean rhythms are often understood as ‘rhythm necklaces’, that is, you could rotate this pattern so that each of the five onsets could be in the first position, and those five patterns would share the maximally equidistant property that this procedure generates. We could say that this algorithm generates five patterns (in this case) that belong to the same necklace.\\n\\nBy the way, if you want to get a better sense of what these patterns sound like, I’ve included a CodePen below that will sound out these patterns for you (and generate all of their rotations).\\n\\nHere is an animation of 7 onsets in 16 pulses:\\n\\n<img src=\\"./images/5.gif\\" />\\n\\n\\nAnd again the resultant rhythm in standard notation:\\n\\n<img src=\\"./images/6.png\\" />\\n\\n\\nToussaint could have called them Bjorklund rhythms, but Euclidean rhythm has a more timeless feel. As I will discuss later, there are other ways of deriving the same set of patterns.\\n\\n## Euclidean rhythm in code\\n\\nThis is fairly basic to code. As an input, we’ll use the number of onsets, and a total number of pulses. To keep things simple we’ll have our end result be an array of 1s (onset) and 0s (no onset). Conceptually, we need keep track of two groups: a front group and a back group. To start, the front group will be an array consisting of the onsets (each in their own array) and the back array will consist of one array for each non-onset pulse. Then recursively we create a new front array by concatenating pairs from the old front and back until we run out of elements in either the front or the back, and the new back array will be whatever elements are left over. We keep going until the back array has one (or zero) elements, then we flatten the resulting 2nd array. Our Swift code looks something like this:\\n\\n\`\`\`swift\\nfunc generateEuclidean(onsets: Int, pulses: Int) -> [Int] {\\n    let front:[[Int]] = Array(repeating: [1], count: onsets)\\n    let back:[[Int]] = Array(repeating: [0], count: pulses - onsets)\\n    return euclidRecursive(front: front, back: back).flatMap {$0}\\n}\\n\\nprivate func euclidRecursive (front: [[Int]], back: [[Int]]) -> [[Int]] {\\n    var back = back\\n    var front = front\\n    \\n    guard back.count > 1 else { return front + back }\\n    \\n    var newFront = [[Int]]()\\n    while front.count > 0 && back.count > 0 {\\n        newFront.append(front.popLast()! + back.popLast()!)\\n    }\\n    return euclidRecursive(front: newFront, back: front + back)\\n}\\n\`\`\`\\n\\n\\n## An alternate approach: Bresenham’s line algorithm\\n\\nAs we mentioned earlier, there are other ways to get at this set of patterns. In rather quirky little book called [Creating Rhythms by Stephan Hollis and J. Richard Hollis](https://www.amazon.co.jp/Creating-Rhythms-English-Stefan-Hollos-ebook/dp/B00IQWM8EA/ref=sr_1_1?ie=UTF8&qid=1505108854&sr=8-1&keywords=creating+rhythm), it is pointed out that Toussaint’s rhythms can also be derived using [Christoffel words](https://en.wikipedia.org/wiki/Christoffel_symbols). A related, but more direct approach, is to use [Bresenham’s line algorithm](https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm) which I will explain here.\\n\\nBasically Bresenham’s algorithm is used for drawing a line in a raster graphics environment. In raster graphics we have essentially a bitmap, i.e., a two-dimensional grid of discrete points or pixels. If we want to draw a straight diagonal line with a slope of 1 in a bitmap, we colour a pixel, then colour the pixel that is up and to its right, then the next pixel that is up and to the right of that one, and so on.\\n\\n<img src=\\"./images/7.png\\" />\\n\\nWhile this is straight forward when the rise evenly divides into the run, when they are relatively prime the situation is more interesting. Some of the pixels will need to be directly adjacent to each other, while some will need to move up and to the right. For example, if our line has a slope of 7/16, it will need to go up 7 times per 16 squares. What principle can we use to determine when we need to go up? To make the line appear straight, we will need to space out those rises as evenly as possible. It becomes essentially the same problem that Bjorklund solved. And we don’t even need a fancy algorithm for it, we can get it directly from the slope of the line. We could just take the floor (or the ceiling) of the y-value at each integer x-point and use that as our y-coordinate.\\n\\n<img src=\\"./8.png\\" />\\n\\nAnd to get our rhythm, we can just say that if floor of the y-value at each x is the same as the previous value, then it is a continuation of the previous onset, and if it has a new y-value, it is the beginning of a new onset.\\n\\n<img src=\\"./images/9.png\\" />\\n\\nHere is the algorithm in Swift. Not that the Bjorklund approach was difficult, but the Bresenham approach is incredibly simple to code.\\n\\n\`\`\`swift\\nfunc bresenhamEuclidean(onsets: Int, pulses: Int) -> [Int] {\\n    let slope = Double(onsets) / Double(pulses)\\n    var result = [Int]()\\n    var previous: Int? = nil\\n    for i in 0..<pulses {\\n        let current = Int(floor(Double(i) * slope))\\n        result.append(current != previous ? 1 : 0)\\n        previous = current\\n    }\\n    return result\\n}\\n\`\`\`\\n\\n\\n## And what does it sound like?\\n\\nYou can listen to any Euclidean pattern in the [Circular metronome app](./../../../../practice/rhythm/circle/index.md), the algorhithm is used to set a default position for mutes along the beat cycle. Just mute some notes in a cycle and press the reset button. It will create the rhythm for you. There're also ‘rotate buttons’ that will rotate the pattern by taking the final onset and moving it to the start of the pattern (recall that although the algorithms discussed here generate a single pattern, they stand for a ‘rhythm necklace’ that includes all the rotations of that pattern that start with an onset).\\n\\n\\n## A musical analysis\\n\\nWhat are some of the properties of these rhythms? Well, most importantly, the locations of the onsets are spaced out as evenly as possible. If the number of time events is an integer multiple of the number of pulses, then they will be completely even (e.g., four groups of four), and the result is entirely trivial. But when number of onsets and pulses are relatively prime, the results will have some interesting characteristics. There are two properties that we can observe from this maximal spacing.\\n\\nFirst, if we look at the distance (in pulses) between adjacent onsets, we can see that each rhythm generated by these algorithms will have at most two possible distances between adjacent onsets, and that these distances differ by at most one pulse. In the first example (5 of 12), some of the onsets are three pulses apart and other are two pulses apart. In the 9 of 16 example, the distances are two and one.\\n\\nWhenever we have these two distances (i.e, when the two numbers are relatively prime) we will usually have a syncopated rhythm, because the two duration lengths in use will be interleaved as much as possible. That is, if we have some groups of two and some groups of three, they will alternate whenever they can, creating large chunks often with one having an odd number of pulses. So when the repetition of some rhythm pattern occurs (for example, the two instances of [x o o x o] in the 5 in 12 example), the first instance will start on the beat, and the second will start off the beat. This gives this set of rhythms a characteristic sound.\\n\\nSo what is the big deal about these rhythms? Are they special? I would say that from a composer’s point of view, they aren’t anything to write home about. A composer/songwriter/improvising musician can easily come up with many rhythms that will resonate with a listener, many of which will not be Euclidean.\\n\\nIt is true that these rhythms do occur frequently in world music (from Toussaint’s point of view, notably Afro-Cuban, and sub-Saharan music). The maximally distributed property of these rhythms might somehow have some appeal to the human perceptual system. And rhythms where there is some repeating odd length fragment are interesting, but there is nothing magical about them. They aren’t necessary, and I don’t think the average composers, discovering these rhythms would think them worth adding to their bag of tricks.\\n\\nBut from the point of view of someone generating a rhythm algorithmically, they are more significant. There are many many ways to arbitrarily generate a rhythm of some length — and most of them sound, well, arbitrary.  \\n\\nThe point here is that patterns that form the set of Euclidean rhythms are highly reliable. Many Euclidean rhythms are not at all interesting (e.g., all of them where the onset number is a factor of the total pulse number), but they will almost never sound bad. For someone trying to quickly make something out of nothing on a music creation app, they clearly have some value.\\n\\n## Relationship to MOS (Well-Formed) Rhythms\\n\\nEuclidean rhythms are a special case of MOS/well-formed rhythms, in which the generator is an integer division of the period, and the relationship between the large and small step sizes is a [superparticular number](https://en.xen.wiki/w/Superparticular).\\n\\nThus, Euclidean rhythms are the direct analogy of [maximally even MOS scales](https://en.xen.wiki/w/Maximal_evenness) in equal temperaments.\\n\\n## Relationship to aksak\\n\\nAksak, a Turkic/Balkan rhythmic concept in which a meter (usually uneven) is divided into cells of two and three steps, is represented in any metric length, given a certain density. So not only are the majority of traditional aksak rhythms represented, Euclidean rhythms offer a way to extend the concept even further.\\n\\nEuclidean rhythms consisting of only groups of two and three will be labeled aksak-compatible.\\n\\n- [Original article by Jeff Holtzkener](https://medium.com/code-music-noise/euclidean-rhythms-391d879494df)\\n- [Euclidean rhythm by Godfried T. Toussaint](/media/pdf/banff.pdf) + [русский перевод](https://habr.com/ru/post/278265/)\\n- [Geometry of Musical Rhythm](https://en.wikipedia.org/wiki/The_Geometry_of_Musical_Rhythm)\\n- [Music and Euclid's algorithm](https://plus.maths.org/content/os/issue40/features/wardhaugh/index)\\n- [Maximum Evenness, Maximum Groove](https://www.lawtonhall.com/blog/euclidean-rhythms-pt1)","frontmatter":{"title":"Euclidean rhythms","description":"Mathematical algorithm to create well-formed rhythm patterns","date":"2022-05-11T00:00:00.000Z","cover":"/media_files/cover/theory-rhythm-system-euclidean-8.png"},"url":"/theory/rhythm/system/euclidean/"},{"src":"---\\ntitle: Audio illusions\\ndescription: Deeper explorations of subtle psychoacoustic effects\\n\\ndate: 2021-11-10\\n---\\n\\n<youtube-embed video=\\"OiW8gzBGz1A\\" />\\n\\n<youtube-embed video=\\"fBMli2YAR8k\\" />\\n\\n<youtube-embed video=\\"TVsMiSrlSSc\\" />\\n\\n<youtube-embed video=\\"WMHyYCk7OqE\\" />\\n\\n<youtube-embed video=\\"YQNsCg4z6L8\\" />\\n","frontmatter":{"title":"Audio illusions","description":"Deeper explorations of subtle psychoacoustic effects","date":"2021-11-10T00:00:00.000Z"},"url":"/theory/sound/psychoacoustics/illusions/"},{"src":"---\\ntitle: Afro-Cuban clave\\ndescription: African, Cuban and Latin American rhythm patterns\\ndate: 2021-10-21\\ncover: yuting-gao.jpg\\nurls:\\n  - https://en.wikipedia.org/wiki/Tumbao\\n  - https://en.wikipedia.org/wiki/Clave_(rhythm)\\n  - https://en.wikipedia.org/wiki/Tresillo_(rhythm)\\n---\\n\\n<script setup>\\nimport afro from '#/db/rhythm/afro-cuban.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"afro\\" />\\n\\n## Clave\\n\\nThe clave (/ˈklɑːveɪ, kleɪv/; Spanish: [ˈklaβe]) is a rhythmic pattern used as a tool for temporal organization in Afro-Cuban music. In Spanish, clave literally means key, clef, code, or keystone. It is present in a variety of genres such as Abakuá music, rumba, conga, son, mambo, salsa, songo, timba and Afro-Cuban jazz. The five-stroke clave pattern represents the structural core of many Afro-Cuban rhythms.\\n\\nThe clave pattern originated in sub-Saharan African music traditions, where it serves essentially the same function as it does in Cuba. In ethnomusicology, clave is also known as a key pattern, guide pattern, phrasing referent, timeline, or asymmetrical timeline. The clave pattern is also found in the African diaspora music of Haitian Vodou drumming, Afro-Brazilian music, African-American music, Louisiana Voodoo drumming, and Afro-Uruguayan music (candombe). The clave pattern (or hambone, as it is known in the United States) is used in North American popular music as a rhythmic motif or simply a form of rhythmic decoration.\\n\\nThe historical roots of the clave are linked to transnational musical exchanges within the African diaspora. For instance, influences of the African “bomba” rhythm are reflected in the clave. In addition to this, the emphasis and role of the drum within the rhythmic patterns speaks further to these diasporic roots.\\n\\nThe clave is the foundation of reggae, reggaeton, and dancehall. In this sense, it is the “heartbeat” that underlies the essence of these genres. The rhythms and vibrations are universalized in that they demonstrate a shared cultural experience and knowledge of these roots. Ultimately, this embodies the diasporic transnational exchange.\\n\\nIn considering the clave as this basis of cultural understanding, relation, and exchange, this speaks to the transnational influence and interconnectedness of various communities. This musical fusion is essentially what constitutes the flow and foundational “heartbeat” of a variety of genres.\\n\\n<youtube-embed video=\\"d1tiv0Ep0kA\\" />\\n\\n## Etymology\\n\\nClave is a Spanish word meaning 'code,' 'key,' as in key to a mystery or puzzle, or 'keystone,' the wedge-shaped stone in the center of an arch that ties the other stones together. Clave is also the name of the patterns played on claves; two hardwood sticks used in Afro-Cuban music ensembles.\\n\\n## The key to Afro-Cuban rhythm\\n\\nThe clave pattern holds the rhythm together in Afro-Cuban music. The two main clave patterns used in Afro-Cuban music are known in North America as son clave and the rumba clave. Both are used as [bell patterns](https://en.wikipedia.org/wiki/Bell_pattern) across much of Africa. Son and rumba clave can be played in either a triple-pulse (12/8 or 6/1) or duple-pulse (4/4, 2/4 or 2/2) structure. The contemporary Cuban practice is to write the duple-pulse clave in a single measure of 4/4. It is also written in a single measure in ethnomusicological writings about African music.\\n\\nAlthough they subdivide the beats differently, the 12/8 and 4/4 versions of each clave share the same pulse names. The correlation between the triple-pulse and duple-pulse forms of clave, as well as other patterns, is an important dynamic of sub-Saharan-based rhythm. Every triple-pulse pattern has its duple-pulse correlative.\\n\\nBoth clave patterns are used in rumba. What we now call son clave (also known as Havana clave) used to be the key pattern played in Havana-style yambú and guaguancó. Some Havana-based rumba groups still use son clave for yambú. The musical genre known as son probably adopted the clave pattern from rumba when it migrated from eastern Cuba to Havana at the beginning of the 20th century.\\n\\n> During the nineteenth century, African music and European music sensibilities were blended in original Cuban hybrids. Cuban popular music became the conduit through which sub-Saharan rhythmic elements were first codified within the context of European ('Western') music theory. The first written music rhythmically based on clave was the Cuban danzón, which premiered in 1879. The contemporary concept of clave with its accompanying terminology reached its full development in Cuban popular music during the 1940s. Its application has since spread to folkloric music as well. In a sense, the Cubans standardized their myriad rhythms, both folkloric and popular, by relating nearly all of them to the clave pattern. The veiled code of African rhythm was brought to light due to the clave’s omnipresence. Consequently, the term clave has come to mean both the five-stroke pattern and the total matrix it exemplifies. In other words, the rhythmic matrix is the clave matrix. Clave is the key that unlocks the enigma; it de-codes the rhythmic puzzle. It is commonly understood that the actual clave pattern does not need to be played for the music to be 'in clave'.  \\n> — Peñalosa (2009)\\n\\n> One of the most difficult applications of the clave is in the realm of composition and arrangement of Cuban and Cuban-based dance music. Regardless of the instrumentation, the music for all of the instruments of the ensemble must be written with a very keen and conscious rhythmic relationship to the clave . . . Any ‘breaks’ and/or ‘stops’ in the arrangements must also be ‘in clave’. If these procedures are not properly taken into consideration, then the music is 'out of clave' which, if not done intentionally, is considered an error. When the rhythm and music are ‘in clave,’ a great natural ‘swing’ is produced, regardless of the tempo. All musicians who write and/or interpret Cuban-based music must be ‘clave conscious,’ not just the percussionists.  \\n> — Santos (1986)\\n\\n<youtube-embed video=\\"LlDgRYKyQAE\\" />\\n\\n## Clave theory\\n\\nThere are three main branches of what could be called clave theory.\\n\\n### Cuban popular music\\n\\nFirst is the set of concepts and related terminology, which were created and developed in Cuban popular music from the mid-19th to the mid-20th centuries. In Popular Cuban Music, Emilio Grenet defines in general terms how the duple-pulse clave pattern guides all members of the music ensemble. An important Cuban contribution to this branch of music theory is the concept of the clave as a musical period, which has two rhythmically opposing halves. The first half is antecedent and moving, and the second half is consequent and grounded.\\n\\n### Ethnomusicological studies of African rhythm\\n\\nThe second branch comes from the ethnomusicological studies of sub-Saharan African rhythm. In 1959, Arthur Morris Jones published his landmark work Studies in African Music, in which he identified the triple-pulse clave as the guide pattern for many pieces of music from ethnic groups across Africa. An important contribution of ethnomusicology to clave theory is the understanding that the clave matrix is generated by cross-rhythm.\\n\\n### The 3–2/2–3 clave concept and terminology\\n\\nThe third branch comes from the United States. An important North American contribution to clave theory is the worldwide propagation of the 3–2/2–3 concept and terminology, which arose from the fusion of Cuban rhythms with jazz in New York City.\\n\\nOnly in the last couple of decades have the three branches of clave theory begun to reconcile their shared and conflicting concepts. Thanks to the popularity of Cuban-based music and the vast amount of educational material available on the subject, many musicians today have a basic understanding of clave. Contemporary books that deal with clave, share a certain fundamental understanding of what clave means.\\n\\n> Chris Washburne considers the term to refer to the rules that govern the rhythms played with the claves. Bertram Lehman regards the clave as a concept with wide-ranging theoretical syntactic implications for African music in general, and for David Peñalosa, the clave matrix is a comprehensive system for organizing music.  \\n> —Toussaint (2013)\\n\\n## Mathematical analysis\\n\\nIn addition to these three branches of theory, clave has in recent years been thoroughly analyzed mathematically. The structure of clave can be understood in terms of cross-rhythmic ratios, above all, three-against-two (3:2). Godfried Toussaint, a Research Professor of Computer Science, has published a book and several papers on the mathematical analysis of clave and related African bell patterns. Toussaint uses geometry and the Euclidean algorithm as a means of exploring the significance of clave.\\n\\n## Types\\n\\n### Son clave\\n\\nSon clave has strokes on 1, 1a, 2&, 3&, 4.\\n\\n4/4:\\n\\n    1 e & a 2 e & a 3 e & a 4 e & a ||\\n    X . . X . . X . . . X . X . . . ||\\n\\n12/8:\\n\\n    1 & a 2 & a 3 & a 4 & a ||\\n    X . X . X . . X . X . . ||\\n\\nThe most common clave pattern used in Cuban popular music is called the son clave, named after the Cuban musical genre of the same name. Clave is the basic period, composed of two rhythmically opposed cells, one antecedent and the other consequent. Clave was initially written in two measures of 2/4 in Cuban music. When written this way, each cell or clave half is represented within a single measure.\\n\\n### Three-side / two-side\\n\\nThe antecedent half has three strokes and is called the three-side of the clave. The consequent half (second measure above) of clave has two strokes and is called the two-side.\\n\\n> Going only slightly into the rhythmic structure of our music we find that all its melodic design is constructed on a rhythmic pattern of two measures, as though both were only one, the first is antecedent, strong, and the second is consequent, weak.  \\n> — Grenet (1939)\\n\\n> [With] clave... the two measures are not at odds, but rather, they are balanced opposites like positive and negative, expansive and contractive or the poles of a magnet. As the pattern is repeated, an alternation from one polarity to the other takes place creating the pulse and rhythmic drive. Were the pattern to be suddenly reversed, the rhythm would be destroyed as in a reversing of one magnet within a series... the patterns are held in place according to both the internal relationships between the drums and their relationship with clave... Should the drums fall out of clave (and in contemporary practice they sometimes do) the internal momentum of the rhythm will be dissipated and perhaps even broken.  \\n> — Amira and Cornelius (1992)\\n\\n### Tresillo\\n\\nIn Cuban popular music, the first three strokes of son clave are also known collectively as [tresillo](<https://en.wikipedia.org/wiki/Tresillo_(rhythm)>), a Spanish word meaning triplet i.e. three almost equal beats in the same time as two main beats. However, in the vernacular of Cuban popular music, the term refers to the figure shown here. https://en.wikipedia.org/wiki/Contradanza\\n\\n<youtube-embed video=\\"1QFU5tJc9ok\\" />\\n\\n[Tresillo club music @ The Fader](https://www.thefader.com/2015/06/10/tresillo-club-music)\\n\\n#### Cinquillo\\n\\nThe cinquillo pattern is another common embellishment of tresillo. Cinquillo is used frequently in the Cuban contradanza (the \\"habanera\\") and the danzón. The figure is also a common bell pattern found throughout sub-Saharan Africa.\\n\\n## Rumba clave\\n\\n### The rumba clave rhythm\\n\\nRumba clave has strokes on 1, 1a, 2a, 3&, 4.\\n\\n#### 4/4\\n\\n    1 e & a 2 e & a 3 e & a 4 e & a ||\\n    X . . X . . . X . . X . X . . . ||\\n\\n#### 12/8\\n\\n    1 & a 2 & a 3 & a 4 & a ||\\n    X . X . . X . X . X . . ||\\n\\nThe other main clave pattern is the rumba clave. Rumba clave is the key pattern used in Cuban rumba. The use of the triple-pulse form of the rumba clave in Cuba can be traced back to the iron bell (ekón) part in abakuá music. The form of rumba known as columbia is culturally and musically connected with abakuá which is an Afro Cuban cabildo that descends from the Kalabari of Cameroon. Columbia also uses this pattern. Sometimes 12/8 rumba clave is clapped in the accompaniment of Cuban batá drums. The 4/4 form of rumba clave is used in yambú, guaguancó and popular music.\\n\\nThere is some debate as to how the 4/4 rumba clave should be notated for guaguancó and yambú. In actual practice, the third stroke on the three-side and the first stroke on the two-side often fall in rhythmic positions that do not fit neatly into music notation. Triple-pulse strokes can be substituted for duple-pulse strokes. Also, the clave strokes are sometimes displaced in such a way that they don't fall within either a triple-pulse or duple-pulse \\"grid\\". Therefore, many variations are possible.\\n\\nThe first regular use of the rumba clave in Cuban popular music began with the mozambique, created by Pello el Afrikan in the early 1960s. When used in popular music (such as songo, timba or Latin jazz) rumba clave can be perceived in either a 3–2 or 2–3 sequence.\\n\\n### Standard bell pattern\\n\\nThe seven-stroke standard bell pattern contains the strokes of both clave patterns. Some North American musicians call this pattern clave. Other North American musicians refer to the triple-pulse form as the 6/8 bell because they write the pattern in two measures of 6/8.\\n\\nLike clave, the standard pattern is expressed in both triple and duple-pulse. The standard pattern has strokes on: **1, 1a, 2& 2a, 3&, 4, 4a.**\\n\\n#### 12/8\\n\\n    1 & a 2 & a 3 & a 4 & a ||\\n    X . X . X X . X . X . X ||\\n\\n#### 4/4\\n\\n    1 e & a 2 e & a 3 e & a 4 e & a ||\\n    X . . X . . X X . . X . X . . X ||\\n\\nThe ethnomusicologist A.M. Jones observes that what we call son clave, rumba clave, and the standard pattern are the most commonly used key patterns (also called bell patterns, timeline patterns and guide patterns) in Sub-Saharan African music traditions and he considers all three to be basically the same pattern. Clearly, they are all expressions of the same rhythmic principles. The three key patterns are found within a large geographic belt extending from Mali in northwest Africa to Mozambique in southeast Africa.\\n\\n### \\"6/8 clave\\" as used by North American musicians\\n\\nIn Afro-Cuban folkloric genres the triple-pulse (12/8 or 6/1) rumba clave is the archetypal form of the guide pattern. Even when the drums are playing in duple-pulse (4\\n4), as in guaguancó, the clave is often played with displaced strokes that are closer to triple-pulse than duple-pulse. John Santos states: \\"The proper feel of this [rumba clave] rhythm, is closer to triple [pulse].”\\n\\nConversely, in salsa and Latin jazz, especially as played in North America, 4/4 is the basic framework and 6/8 is considered something of a novelty and in some cases, an enigma. The cross-rhythmic structure (multiple beat schemes) is frequently misunderstood to be metrically ambiguous. North American musicians often refer to Afro-Cuban 6/8 rhythm as a feel, a term usually reserved for those aspects of musical nuance not practically suited for analysis. As used by North American musicians, \\"6/8 clave\\" can refer to one of three types of triple-pulse key patterns.\\n\\n#### Triple-pulse standard pattern\\n\\nWhen one hears triple-pulse rhythms in Latin jazz the percussion is most often replicating the Afro-Cuban rhythm bembé. The standard bell is the key pattern used in bembé and so with compositions based on triple-pulse rhythms, it is the seven-stroke bell, rather than the five-stroke clave that is the most familiar to jazz musicians. Consequently, some North American musicians refer to the triple-pulse standard pattern as \\"6/8 clave\\".\\n\\n#### Triple-pulse rumba clave\\n\\nSome refer to the triple-pulse form of rumba clave as \\"6/8 clave\\". When rumba clave is written in 6/8 the four underlying main beats are counted: 1, 2, 1, 2.\\n\\n    1 & a 2 & a |1 & a 2 & a ||\\n    X . X . . X |. X . X . . ||\\n\\n> Claves... are not usually played in Afro-Cuban 6/8 feels... [and] the clave [pattern] is not traditionally played in 6/8 though it may be helpful to do so to relate the clave to the 6/8 bell pattern.  \\n> —Thress (1994)\\n\\nThe main exceptions are: the form of rumba known as Columbia, and some performances of abakuá by rumba groups, where the 6/8 rumba clave pattern is played on claves.\\n\\n#### Triple-pulse son clave\\n\\nTriple-pulse son clave is the least common form of clave used in Cuban music. It is, however, found across an enormously vast area of sub-Saharan Africa. The first published example (1920) of this pattern identified it as a hand-clap part accompanying a song from Mozambique.\\n\\n## Cross-rhythm and the correct metric structure\\n\\nBecause 6/8 clave-based music is generated from cross-rhythm, it is possible to count or feel the 6/8 clave in several different ways. The ethnomusicologist Arthur Morris Jones correctly identified the importance of this key pattern, but he mistook its accents as indicators of meter rather than the counter-metric phenomena they are. Similarly, while Anthony King identified the triple-pulse \\"son clave\\" as the ‘standard pattern’ in its simplest and most basic form, he did not correctly identify its metric structure. King represented the pattern in a polymetric 7+5/8 time signature.\\n\\nIt wasn't until African musicologists like C.K. Ladzekpo entered into the discussion in the 1970s and 80s that the metric structure of sub-Saharan rhythm was unambiguously defined. The writings of Victor Kofi Agawu and David Locke must also be mentioned in this regard.\\n\\nObserving the dancer's steps almost always reveals the main beats of the music. Because the main beats are usually emphasized in the steps and not the music, it is often difficult for an \\"outsider\\" to feel the proper metric structure without seeing the dance component. Kubik states: \\"To understand the emotional structure of any music in Africa, one has to look at the dancers as well and see how they relate to the instrumental background\\" (2010: 78).\\n\\n> For cultural insiders, identifying the... ‘dance feet’ occurs instinctively and spontaneously. Those not familiar with the choreographic supplement, however, sometimes have trouble locating the main beats and expressing them in movement. Hearing African music on recordings alone without prior grounding in its dance-based rhythms may not convey the choreographic supplement. Not surprisingly, many misinterpretations of African rhythm and meter stem from a failure to observe the dance.  \\n>  — Agawu, (2003)[59]\\n\\n## Controversy over use and origins\\n\\nPerhaps the greatest testament to the musical vitality of the clave is the spirited debate it engenders, both in terms of musical usage and historical origins. This section presents examples from non-Cuban music, which some musicians (not all) hold to be representative of the clave. The most common claims, those of Brazilian and subsets of American popular music, are described below.\\n\\n### In Africa\\n\\n#### A widely used bell pattern\\n\\nClave is a Spanish word and its musical usage as a pattern played on claves was developed in the western part of Cuba, particularly the cities of Matanzas and Havana. Some writings have claimed that the clave patterns originated in Cuba. One frequently repeated theory is that the triple-pulse African bell patterns morphed into duple-pulse forms as a result of the influence of European musical sensibilities. \\"The duple meter feel [of 4/4 rumba clave] may have been the result of the influence of marching bands and other Spanish styles...\\"— Washburne (1995).\\n\\nHowever, the duple-pulse forms have existed in sub-Saharan Africa for centuries. The patterns the Cubans call clave are two of the most common bell parts used in Sub-Saharan African music traditions. Natalie Curtis, A.M. Jones, Anthony King and John Collins document the triple-pulse forms of what we call “son clave” and “rumba clave” in West, Central, and East Africa. Francis Kofi and C.K. Ladzekpo document several Ghanaian rhythms that use the triple or duple-pulse forms of \\"son clave\\". Percussion scholar royal hartigan identifies the duple-pulse form of \\"rumba clave\\" as a timeline pattern used by the Yoruba and Ibo of Nigeria, West Africa. He states that this pattern is also found in the high-pitched boat-shaped iron bell known as atoke played in the Akpese music of the Eve people of Ghana. There are many recordings of traditional African music where one can hear the five-stroke \\"clave\\" used as a bell pattern.\\n\\n#### Popular dance music\\n\\nCuban music has been popular in sub-Saharan Africa since the mid-twentieth century. To the Africans, clave-based Cuban popular music sounded both familiar and exotic. Congolese bands started doing Cuban covers and singing the lyrics phonetically. Soon, they were creating their original Cuban-like compositions, with lyrics sung in French or Lingala, a lingua franca of the western Congo region. The Congolese called this new music rumba, although it was based on the son. The Africans adapted guajeos to electric guitars and gave them their regional flavor. The guitar-based music gradually spread out from the Congo, increasingly taking on local sensibilities. This process eventually resulted in the establishment of several different distinct regional genres, such as soukous.\\n\\n#### Highlife\\n\\nHighlife was the most popular genre in Ghana and Nigeria during the 1960s. This arpeggiated highlife guitar part is essentially a [guajeo](https://en.wikipedia.org/wiki/Guajeo). The rhythmic pattern is known in Cuba as baqueteo. The pattern of attack-points is nearly identical to the 3–2 clave motif guajeo shown earlier in this article. The bell pattern known in Cuba as clave, is indigenous to Ghana and Nigeria, and is used in highlife.\\n\\n#### Afrobeat\\n\\nAfrobeat guitar part is a variant of the 2–3 onbeat/offbeat motif. Even the melodic contour is guajeo-based. 2–3 claves are shown above the guitar for reference only. The clave pattern is not ordinarily played in afrobeat.\\n\\n### Guide-patterns in Cuban versus non-Cuban music\\n\\nThere is some debate as to whether or not clave, as it appears in Cuban music, functions in the same way as its sister rhythms in other forms of music (Brazilian, North American and African). Certain forms of Cuban music demand a strict relationship between the clave and other musical parts, even across genres. This same structural relationship between the guide-pattern and the rest of the ensemble is easily observed in many sub-Saharan rhythms, as well as rhythms from Haiti and Brazil. However, the 3–2/2–3 concept and terminology are limited to certain types of Cuban-based popular music and are not used in the music of Africa, Haiti, Brazil or in Afro-Cuban folkloric music. In American pop music, the clave pattern tends to be used as an element of rhythmic color, rather than a guide-pattern and as such is superimposed over many types of rhythms.\\n\\n#### In Brazilian music\\n\\nBoth Cuba and Brazil imported Yoruba, Fon and Congolese slaves. Therefore, it is not surprising that we find the bell pattern the Cubans call clave in the Afro-Brazilian music of Macumba and Maculelê (dance). \\"Son clave\\" and \\"rumba clave\\" are also used as a tamborim part in some batucada arrangements. The structure of Afro-Brazilian bell patterns can be understood in terms of the clave concept (see below).\\n\\nBell pattern 1 is used in maculelê (dance) and some Candomblé and Macumba rhythms. Pattern 1 is known in Cuba as son clave. Bell 2 is used in afoxê and can be thought of as pattern 1 embellished with four additional strokes. Bell 3 is used in batucada. Pattern 4 is the maracatu bell and can be thought of as pattern 1 embellished with four additional strokes.\\n\\n#### Bossa nova pattern\\n\\nThe so-called \\"bossa nova clave\\" (or \\"Brazilian clave\\") has a similar rhythm to that of the son clave, but the second note on the two-side is delayed by one pulse (subdivision). The rhythm is typically played as a snare rim pattern in bossa nova music. The pattern is shown below in 2\\n4, as it is written in Brazil. In North American charts it is more likely to be written in cut-time.\\n\\nAccording to drummer Bobby Sanabria the Brazilian composer Antonio Carlos Jobim, who developed the pattern, considers it to be merely a rhythmic motif and not a clave (guide pattern). Jobim later regretted that Latino musicians misunderstood the role of this bossa nova pattern.\\n\\n#### Other Brazilian examples\\n\\nThe examples below are transcriptions of several patterns resembling the Cuban clave that is found in various styles of Brazilian music, on the ago-gô and surdo instruments.\\n\\nLegend: Time signature: 2/4; L=low bell, H=high bell, O = open surdo hit, X = muffled surdo hit, and | divides the measure:\\n\\n- Style: Samba 3:2; LL.L.H.H|L.L.L.H. (More common 3:2: .L.L.H.H|L.L.L.H.)\\n- Style: Maracatu 3:2; LH.HL.H.|L.H.LH.H\\n- Style: Samba 3:2; L|.L.L..L.|..L..L.L|\\n- Instrument: 3rd Surdo 2:3; X...O.O.|X...OO.O\\n- Variation of samba style: Partido Alto 2:3; L.H..L.L|.H..L.L.\\n- Style: Maracatu 2:3; L.H.L.H.|LH.HL.H.\\n- Style: Samba-Reggae or Bossanova 3:2; O..O..O.|..O..O..\\n- Style: Ijexa 3:2; LL.L.LL.|L.L.L.L. (HH.L.LL.|H.H.L.L.)\\n\\nFor 3rd example above, the clave pattern is based on a common accompaniment pattern played by the guitarist. B=bass note played by guitarist's thumb, C=chord played by fingers.\\n\\n    &|1 & 2 & 3 & 4 &|1 & 2 & 3 & 4 &||\\n    C|B C . C B . C .|B . C . B C . C||\\n\\nThe singer enters on the wrong side of the clave and the ago-gô player adjusts accordingly. This recording cuts off the first bar so that it sounds like the bell comes in on the third beat of the second bar. This is suggestive of a pre-determined rhythmic relationship between the vocal part and the percussion and supports the idea of a clave-like structure in Brazilian music.\\n\\n<youtube-embed video=\\"DhOLGoBCDjw\\" />\\n\\n### In Jamaican and French Caribbean music\\n\\nThe son clave rhythm is present in Jamaican mento music, and can be heard on 1950s-era recordings such as \\"Don’t Fence Her In\\", \\"Green Guava\\" or \\"Limbo\\" by Lord Tickler, \\"Mango Time\\" by Count Lasher, \\"Linstead Market/Day O\\" by The Wigglers, \\"Bargie\\" by The Tower Islanders, \\"Nebuchanezer\\" by Laurel Aitken and others. The Jamaican population is part of the same origin (Congo) as many Cubans, which perhaps explains the shared rhythm. It is also heard frequently in Martinique's biguine and Dominica's Jing ping. Just as likely however is the possibility that claves and the clave rhythm spread to Jamaica, Trinidad and the other small islands of the Caribbean through the popularity of Cuban son recordings from the 1920s onward.\\n\\n### Experimental clave music\\n\\n#### Art music\\n\\nThe clave rhythm and clave concept have been used in some modern art music (\\"classical\\") compositions. \\"Rumba Clave\\" by Cuban percussion virtuoso Roberto Vizcaiño has been performed in recital halls around the world. Another clave-based composition that has \\"gone global\\" is the snare drum suite \\"Cross\\" by Eugene D. Novotney.\\n\\n#### Odd meter \\"clave\\"\\n\\nTechnically speaking, the term odd meter clave is an oxymoron. Clave consists of two even halves, in a divisive structure of four main beats. However, in recent years jazz musicians from Cuba and outside of Cuba have been experimenting with creating new \\"claves\\" and related patterns in various odd meters. Clave which is traditionally used in a divisive rhythm structure, has inspired many new creative inventions in an additive rhythm context.\\n\\n> . . . I developed the concept of adjusting claves to other time signatures, with varying degrees of success. What became obvious to me quite quickly was that the closer I stuck to the general rules of clave the more natural the pattern sounded. Clave has a natural flow with a certain tension and resolves points. I found if I kept these points in the new meters they could still flow seamlessly, allowing me to play longer phrases. It also gave me many reference points and reduced my reliance on \\"one\\".  \\n> — Guilfoyle (2006: 10)\\n\\n##### Recommended listening for odd-meter \\"clave\\"\\n\\nHere are some examples of recordings that use odd meter clave concepts.\\n\\n- Dafnis Prieto About the Monks (Zoho).\\n- Sebastian Schunke Symbiosis (Pimienta Records).\\n- Paoli Mejias Mi Tambor (JMCD).\\n- John Benitez Descarga in New York (Khaeon).\\n- Deep Rumba A Calm in the Fire of Dances (American Clave).\\n- Nachito Herrera Bembe en mi casa (FS Music).\\n- Bobby Sanabria Quarteto Aché (Zoho).\\n- Julio Barretto Iyabo (3d).\\n- Michel Camilo Triangulo (Telarc).\\n- Samuel Torres Skin Tones (www.samueltorres.com).\\n- Horacio \\"el Negro\\" Hernandez Italuba (Universal Latino).\\n- Tony Lujan Tribute (Bella Records).\\n- Edward Simon La bikina (Mythology).\\n- Jorge Sylvester In the Ear of the Beholder (Jazz Magnet).\\n- Uli Geissendoerfer \\"The Extension\\" (CMO)\\n- Manuel Valera In Motion (Criss Cross Jazz).\\n","frontmatter":{"title":"Afro-Cuban clave","description":"African, Cuban and Latin American rhythm patterns","date":"2021-10-21T00:00:00.000Z","cover":"/media_files/cover/theory-rhythm-system-clave-yuting-gao.jpg","urls":["https://en.wikipedia.org/wiki/Tumbao","https://en.wikipedia.org/wiki/Clave_(rhythm)","https://en.wikipedia.org/wiki/Tresillo_(rhythm)"]},"url":"/theory/rhythm/system/clave/"},{"src":"---\\ntitle: Sound\\ndescription: The ingenious hearing system and it's medium\\ncover: waves.jpg\\ndate: 2021-10-20 \\n---\\n\\nWhat's the ultimate [Nature of sound](./nature/index.md) and how do humans [Percieve it aurally](./hearing/index.md)? There's a whole science of [Psychoacoustics](./psychoacoustics/index.md) to answer these and even deeper questions about the sound and hearing phenomena.\\n\\nThe main parameter that makes a sound musical is it's [Pitch](./pitch/index.md) and it's [Overtones](./timbre/index.md) composition.\\n\\n<youtube-embed video=\\"cD7YFUYLpDc\\" />\\n","frontmatter":{"title":"Sound","description":"The ingenious hearing system and it's medium","cover":"/media_files/cover/theory-sound-waves.jpg","date":"2021-10-20T00:00:00.000Z"},"url":"/theory/sound/"},{"src":"---\\ntitle: Indian tala\\ndescription: The Indian rhythmic language and art of konnakkol\\n\\ncover: ricky-singh.jpg\\ndate: 2021-10-19\\n---\\n\\n<script setup>\\nimport tala from '#/db/rhythm/tala.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"tala\\" />\\n\\n## Tala\\n\\nA [Tala](<https://en.wikipedia.org/wiki/Tala_(music)>) (IAST tāla), sometimes spelled Titi or Pipi, literally means a \\"clap, tapping one's hand on one's arm, a musical measure\\". It is the term used in Indian classical music to refer to musical meter, that is any rhythmic beat or strike that measures musical time. The measure is typically established by hand clapping, waving, touching fingers on thigh or the other hand, verbally, striking of small cymbals, or a percussion instrument in the Indian subcontinental traditions. Along with raga which forms the fabric of a melodic structure, the tala forms the life cycle and thereby constitutes one of the two foundational elements of Indian music.\\n\\nTala is an ancient music concept traceable to Vedic era texts of Hinduism, such as the Samaveda and methods for singing the Vedic hymns. The music traditions of the North and South India, particularly the raga and tala systems, were not considered as distinct till about the 16th century. There on, during the tumultuous period of Islamic rule of the Indian subcontinent, the traditions separated and evolved into distinct forms. The tala system of the north is called Hindustaani, while the south is called Carnaatic. However, the tala system between them continues to have more common features than differences.\\n\\nTala in the Indian tradition embraces the time dimension of music, the means by which musical rhythm and form were guided and expressed. While a tala carries the musical meter, it does not necessarily imply a regularly recurring pattern. In the major classical Indian music traditions, the beats are hierarchically arranged based on how the music piece is to be performed. The most widely used tala in the South Indian system is Adi tala. In the North Indian system, the most common tala is teental.\\n\\n## Etymology\\n\\nTāļa (ताळ) is a Sanskrit word, which means \\"being established\\". Adi tala is one of the most used talas in Carnatic music.\\n\\n## Terminology and definitions\\n\\nAccording to David Nelson – an Ethnomusicology scholar specializing in Carnatic music, a tala in Indian music covers \\"the whole subject of musical meter\\". Indian music is composed and performed in a metrical framework, a structure of beats that is a tala. The tala forms the metrical structure that repeats, in a cyclical harmony, from the start to end of any particular song or dance segment, making it conceptually analogous to meters in Western music. However, talas have certain qualitative features that classical European musical meters do not. For example, some talas are much longer than any classical Western meter, such as a framework based on 29 beats whose cycle takes about 45 seconds to complete when performed. Another sophistication in talas is the lack of \\"strong, weak\\" beat composition typical of the traditional European meter. In classical Indian traditions, the tala is not restricted to permutations of strong and weak beats, but its flexibility permits the accent of a beat to be decided by the shape of musical phrase.\\n\\n> ![](./Narada.jpg)\\n> A painting depicting the Vedic sage-musician Narada, with a tala instrument in his left hand.\\n\\nA tala measures musical time in Indian music. However, it does not imply a regular repeating accent pattern, instead its hierarchical arrangement depends on how the musical piece is supposed to be performed. A metric cycle of a tala contains a specific number of beats, which can be as short as 3 beats or as long as 128 beats. The pattern repeats, but the play of accent and empty beats are an integral part of Indian music architecture. Each tala has subunits. In other words, the larger cyclic tala pattern has embedded smaller cyclic patterns, and both of these rhythmic patterns provide the musician and the audience to experience the play of harmonious and discordant patterns at two planes. A musician can choose to intentionally challenge a pattern at the subunit level by contradicting the tala, explore the pattern in exciting ways, then bring the music and audience experience back to the fundamental pattern of cyclical beats.\\n\\nThe tala as the time cycle, and the raga as the melodic framework, are the two foundational elements of classical Indian music. The raga gives an artist the ingredients palette to build the melody from sounds, while the tala provides her with a creative framework for rhythmic improvisation using time.\\n\\nThe basic rhythmic phrase of a tala when rendered on a percussive instrument such as tabla is called a **theka**. The beats within each rhythmic cycle are called **matras**, and the first beat of any rhythmic cycle is called the **sam**. An empty beat is called **khali**. The subdivisions of a tala are called **vibhagas** or **khands**. In the two major systems of classical Indian music, the first count of any tala is called sam. The cyclic nature of a tala is a major feature of the Indian tradition, and this is termed as **avartan**. Both raga and tala are open frameworks for creativity and allow theoretically infinite number of possibilities, however, the tradition considers 108 talas as basic.\\n\\n<youtube-embed video=\\"xcPUnpOLDYM\\"/>\\n\\n## History\\n\\nThe roots of tala and music in ancient India are found in the Vedic literature of Hinduism. The earliest Indian thought combined three arts, instrumental music (vadya), vocal music (gita) and dance (nrtta). As these fields developed, sangita became a distinct genre of art, in a form equivalent to contemporary music. This likely occurred before the time of Yāska (~500 BCE), since he includes these terms in his nirukta studies, one of the six Vedanga of ancient Indian tradition. Some of the ancient texts of Hinduism such as the Samaveda (~1000 BCE) are structured entirely to melodic themes, it is sections of Rigveda set to music.\\n\\nThe Samaveda is organized into two formats. One part is based on the musical meter, another by the aim of the rituals. The text is written with embedded coding, where svaras (octave note) is either shown above or within the text, or the verse is written into parvans (knot or member). These markings identify which units are to be sung in a single breath, each unit based on multiples of one eighth. The hymns of Samaveda contain melodic content, form, rhythm and metric organization. This structure is, however, not unique or limited to Samaveda. The Rigveda embeds the musical meter too, without the kind of elaboration found in the Samaveda. For example, the **Gayatri mantra** contains three metric lines of exactly eight syllables, with an embedded ternary rhythm.\\n\\nAccording to Lewis Rowell – a professor of Music specializing on classical Indian music, the need and impulse to develop mathematically precise musical meters in the Vedic era may have been driven by the Indian use of oral tradition for transmitting vast amounts of Vedic literature. Deeply and systematically embedded structure and meters may have enabled the ancient Indians a means to detect and correct any errors of memory or oral transmission from one person or generation to the next. According to Michael Witzel,\\n\\n> The Vedic texts were orally composed and transmitted, without the use of script, in an unbroken line of transmission from teacher to student that was formalized early on. This ensured an impeccable textual transmission superior to the classical texts of other cultures; it is, in fact, something like a tape-recording.... Not just the actual words, but even the long-lost musical (tonal) accent (as in old Greek or in Japanese) has been preserved up to the present.  \\n> — Michael Witzel\\n\\nThe Samaveda also included a system of chironomy, or hand signals to set the recital speed. These were mudras (finger and palm postures) and jatis (finger counts of the beat), a system at the foundation of talas. The chants in the Vedic recital text, associated with rituals, are presented to be measured in matras and its multiples in the invariant ratio of 1:2:3. This system is also the basis of every tala.\\n\\n> ![](./five-gandharva.jpg)\\n> Five Gandharvas (celestial musicians) from 4th-5th century CE, northwest Indian subcontinent, carrying the four types of musical instruments. Gandharvas are discussed in Vedic era literature.\\n\\nIn the ancient traditions of Hinduism, two musical genre appeared, namely Gandharva (formal, composed, ceremonial music) and Gana (informal, improvised, entertainment music). The Gandharva music also implied celestial, divine associations, while the Gana also implied singing. The Vedic Sanskrit musical tradition had spread widely in the Indian subcontinent, and according to Rowell, the ancient Tamil classics make it \\"abundantly clear that a cultivated musical tradition existed in South India as early as the last few pre-Christian centuries\\".\\n\\nThe classic Sanskrit text Natya Shastra is at the foundation of the numerous classical music and dance of India. Before Natyashastra was finalized, the ancient Indian traditions had classified musical instruments into four groups based on their acoustic principle (how they work, rather than the material they are made of). These four categories are accepted as given and are four separate chapters in the Natyashastra, one each on **stringed** instruments (chordophones), **hollow** instruments (aerophones), **solid** instruments (idiophones), and **covered** instruments (membranophones). Of these, states Rowell, the idiophone in the form of \\"small bronze cymbals\\" were used for tala. Almost the entire chapter of Natyashastra on idiophones, by Bharata, is a theoretical treatise on the system of tala. Time keeping with idiophones was considered a separate function than that of percussion (membranophones), in the early Indian thought on music theory.\\n\\nThe early 13th century Sanskrit text Sangitaratnakara (literally, \\"Ocean of Music and Dance\\"), by Śārṅgadeva patronized by King Sighana of the Yadava dynasty in Maharashtra, mentions and discusses ragas and talas. He identifies seven tala families, then subdivides them into rhythmic ratios, presenting a methodology for improvisation and composition that continues to inspire modern era Indian musicians. Sangitaratnakara is one of the most complete historic medieval era Hindu treatises on this subject that has survived into the modern era, that relates to the structure, technique and reasoning behind ragas and talas.\\n\\nThe centrality and significance of Tala to music in ancient and early medieval India is also expressed in numerous temple reliefs, in both Hinduism and Jainism, such as through the carving of musicians with cymbals at the fifth century Pavaya temple sculpture near Gwalior, and the Ellora Caves.\\n\\n<youtube-embed video=\\"XyUxY9huI_s\\"/>\\n\\n## Description\\n\\nIn the South Indian system (Carnatic), a full tala is a group of seven suladi talas. These are cyclic (avartana), with three parts (anga) traditionally written down with laghu, drutam and anudrutam symbols. Each tala is divided in two ways to perfect the musical performance, one is called kala (kind) and the other gati (pulse).\\n\\nEach repeated cycle of a tala is called an avartan. This is counted additively in sections (vibhag or anga) which roughly correspond to bars or measures but may not have the same number of beats (matra, akshara) and may be marked by accents or rests. So the Hindustani **Jhoomra tal** has 14 beats, counted 3+4+3+4, which differs from **Dhamar tal**, also of 14 beats but counted 5+2+3+4. The spacing of the vibhag accents makes them distinct, otherwise, again, since **Rupak tal** consists of 7 beats, two cycles of it of would be indistinguishable from one cycle of the related Dhamar tal. However the most common Hindustani tala, Teental, is a regularly-divisible cycle of four measures of four beats each.\\n\\nThe first beat of any tala, called **sam** (pronounced as the English word 'sum' and meaning even or equal) is always the most important and heavily emphasised. It is the point of resolution in the rhythm where the percussionist's and soloist's phrases culminate: a soloist has to sound an important note of the raga there, and a North Indian classical dance composition must end there. However, melodies do not always begin on the first beat of the tala but may be offset, for example to suit the words of a composition so that the most accented word falls upon the sam. The term talli, literally \\"shift\\", is used to describe this offset in Tamil. A composition may also start with an anacrusis on one of the last beats of the previous cycle of the tala, called ateeta eduppu in Tamil.\\n\\nThe tāla is indicated visually by using a series of rhythmic hand gestures called **kriyas** that correspond to the angas or \\"limbs\\", or vibhag of the tāla. These movements define the tala in Carnatic music, and in the Hindustani tradition too, when learning and reciting the tala, the first beat of any vibhag is known as **tali** (\\"clap\\") and is accompanied by a clap of the hands, while an \\"empty\\" (khali) vibhag is indicated with a sideways wave of the dominant clapping hand (usually the right) or the placing of the back of the hand upon the base hand's palm instead. But northern definitions of tala rely far more upon specific drum-strokes, known as bols, each with its own name that can be vocalized as well as written. In one common notation the sam is denoted by an 'X' and the khali, which is always the first beat of a particular vibhag, denoted by '0' (zero).\\n\\nA tala does not have a fixed tempo (laya) and can be played at different speeds. In Hindustani classical music a typical recital of a raga falls into two or three parts categorized by the quickening tempo of the music; **Vilambit** (delayed, i.e., slow), **Madhya** (medium tempo) and **Drut** (fast). Carnatic music adds an extra slow and fast category, categorised by divisions of the pulse; **Chauka** (1 stroke per beat), **Vilamba** (2 strokes per beat), **Madhyama** (4 strokes per beat), **Drut**(8 strokes per beat) and lastly **Adi-drut**(16 strokes per beat).\\n\\nIndian classical music, both northern and southern, have theoretically developed since ancient times numerous tala, though in practice some talas are very common, and some are rare.\\n\\n## In Carnatic music\\n\\nTala was introduced to Karnataka music by its founder Purandara Dasa. Carnatic music uses various classification systems of tālas such as the **Chapu** (4 talas), **Chanda** (108 talas) and **Melakarta** (72 talas). The **Suladi Sapta Tāla** system (35 talas) is used here, according to which there are seven families of tāla. A tāla cannot exist without reference to one of five jatis, differentiated by the length in beats of the laghu, thus allowing thirty-five possible tālas. With all possible combinations of tala types and laghu lengths, there are 5 x 7 = 35 talas having lengths ranging from 3 (Tisra-jati Eka tala) to 29 (sankeerna jati dhruva tala) aksharas. The seven tala families and the number of aksharas for each of the 35 talas are;\\n\\n| Tala    | Anga Notation | Tisra (3) | Chatusra (4) | Khanda (5) | Misra (7) | Sankeerna (9) |\\n| ------- | ------------- | --------- | ------------ | ---------- | --------- | ------------- |\\n| Dhruva  | lOll          | 11        | **14**       | 17         | 23        | 29            |\\n| Matya   | lOl           | 8         | **10**       | 12         | 16        | 20            |\\n| Rupaka  | Ol            | 5         | **6**        | 7          | 9         | 11            |\\n| Jhampa  | lUO           | **6**     | 7            | 8          | 10        | 12            |\\n| Triputa | lOO           | 7         | **8**        | 9          | 11        | 13            |\\n| Ata     | llOO          | 10        | **12**       | 14         | 18        | 22            |\\n| Eka     | l             | 3         | **4**        | 5          | 7         | 9             |\\n\\nIn practice, only a few talas have compositions set to them. The most common tala is **Chaturasra-nadai Chaturasra-jaati Triputa tala**, also called Adi tala (Adi meaning primordial in Sanskrit). Nadai is a term which means subdivision of beats. Many kritis and around half of the varnams are set to this tala. Other common talas include:\\n\\n- Chaturasra-nadai Chaturasra-jaati Rupaka tala (or simply Rupaka tala). A large body of krtis is set to this tala.\\n- Khanda Chapu (a 10-count) and Misra Chapu (a 14-count), both of which do not fit very well into the suladi sapta tala scheme. Many padams are set to Misra Chapu, while there are also krtis set to both the above talas.\\n- Chatusra-nadai Khanda-jati Ata tala (or simply Ata tala). Around half of the varnams are set to this tala.\\n- Tisra-nadai Chatusra-jati Triputa tala (Adi Tala Tisra-Nadai). A few fast-paced kritis are set to this tala. As this tala is a twenty-four beat cycle, compositions in it can be and sometimes are sung in Rupaka talam.\\n\\n<youtube-embed video=\\"NvcILiwkaDc\\"/>\\n\\n### Strokes\\n\\nThere are 6 main angas/strokes in talas;\\n\\n- **Anudhrutam**, a single beat, notated 'U', a downward clap of the open hand with the palm facing down.\\n- **Dhrutam**, a pattern of 2 beats, notated 'O', a downward clap with the palm facing down followed by a second downward clap with the palm facing up.\\n- **Laghu**, a pattern with a variable number of beats, 3, 4, 5, 7 or 9, depending on the jati. It is notated 'l' and consists of a downward clap with the palm facing down followed by counting from little finger to thumb and back, depending on the jati.\\n- **Guru**, a pattern represented by a 8 beats . It is notated ‘8’ and consists of a downward clap with the palm facing down followed by circling movement of the right hand with closed fingers in the clockwise direction.\\n- **Plutham**, a pattern of 12 beats notated ‘3’, it consists of a downward clap with the palm facing down followed by counting from little finger to the middle finger, a krishya (waving the hand towards the left hand side 4 times) and a sarpini (waving the hand towards the right 4 times)\\n- **Kakapadam**, a pattern of 16 beats notated ’x’, it consists of a downward clap with the palm facing down followed by counting from little finger to the middle finger, a pathakam (waving the hand upwards 4 times),a krishya and a sarpini\\n\\n### Jatis\\n\\nEach tala can incorporate one of the five following jatis.\\n\\n| Jati       | Number of Aksharas |\\n| ---------- | ------------------ |\\n| Chaturasra | 4                  |\\n| Thisra     | 3                  |\\n| Khanda     | 5                  |\\n| Misra      | 7                  |\\n| Sankeerna  | 9                  |\\n\\nEach tala family has a default jati associated with it; the tala name mentioned without qualification refers to the default jati.\\n\\n- **Dhruva tala** is by default chaturasra jati\\n- **Matya** tala is chaturasra jati\\n- **Rupaka** tala is chaturasra jati\\n- **Jhampa** tala is misra jati\\n- **Triputa** tala is tisra jati (chaturasra jati type is also known as Adi tala)\\n- **Ata** tala is kanda jati\\n- **Eka** tala is chaturasra jati\\n- For all the 72 melakarta talas and the 108 talas the jathi is mostly chatusram\\n\\nFor example, one cycle of khanda-jati rupaka tala comprises a 2-beat dhrutam followed by a 5-beat laghu. The cycle is, thus, 7 aksharas long. Chaturasra nadai khanda-jati Rupaka tala has 7 aksharam, each of which is 4 matras long; each avartana of the tala is 4 x 7 = 28 matras long. For Misra nadai Khanda-jati Rupaka tala, it would be 7 x 7 = 49 matra.\\n\\n### Jati (nadai in Tamil, nadaka in Telugu, nade in Kannada)\\n\\nThe number of maatras in an akshara is called the nadai. This number can be 3, 4, 5, 7 or 9, and take the same name as the jatis. The default nadai is Chatusram:\\n\\n| Jati      | Maatras | Phonetic representation of beats |\\n| --------- | ------- | -------------------------------- |\\n| Tisra     | 3       | Tha Ki Ta                        |\\n| Chatusra  | 4       | Tha Ka Dhi Mi                    |\\n| Khanda    | 5       | Tha Ka Tha Ki Ta                 |\\n| Misra     | 7       | Tha Ki Ta Tha Ka Dhi Mi          |\\n| Sankeerna | 9       | Tha Ka Dhi Mi Tha Ka Tha Ki Ta   |\\n\\nSometimes, pallavis are sung as part of a Ragam Thanam Pallavi exposition in some of the rarer, more complicated talas; such pallavis, if sung in a non-Chatusra-nadai tala, are called nadai pallavis. In addition, pallavis are often sung in chauka kale (slowing the tala cycle by a magnitude of four times), although this trend seems to be slowing.\\n\\n### Kāla\\n\\nKāla refers to the change of tempo during a rendition of song, typically doubling up the speed. Onnaam kaalam is 1st speed, Erandaam kaalam is 2nd speed and so on. Erandaam kaalam fits in twice the number of aksharaas (notes) into the same beat, thus doubling the tempo. Sometimes, Kāla is also used similar to Layā, for example Madhyama Kālam or Chowka Kālam.\\n\\n<youtube-embed video=\\"MBvAYPvfmEk\\" />\\n\\n## In Hindustani music\\n\\nTalas have a vocalised and therefore recordable form wherein individual beats are expressed as phonetic representations of various strokes played upon the tabla. Various Gharanas (literally \\"Houses\\" which can be inferred to be \\"styles\\" – basically styles of the same art with cultivated traditional variances) also have their own preferences. For example, the Kirana Gharana uses Ektaal more frequently for Vilambit Khayal while the Jaipur Gharana uses Trital. Jaipur Gharana is also known to use Ada Trital, a variation of Trital for transitioning from Vilambit to Drut laya.\\n\\nThe Khyal vibhag has no beats on the bayan, i.e. no bass beats this can be seen as a way to enforce the balance between the usage of heavy (bass dominated) and fine (treble) beats or more simply it can be thought of another mnemonic to keep track of the rhythmic cycle (in addition to Sam). The khali is played with a stressed syllable that can easily be picked out from the surrounding beats.\\n\\nSome rare talas even contain a \\"half-beat\\". For example, Dharami is an 11 1/2 beat cycle where the final \\"Ka\\" only occupies half the time of the other beats. This tala's 6th beat does not have a played syllable – in western terms it is a \\"rest\\".\\n\\n### Common Hindustani talas\\n\\nSome talas, for example Dhamaar, Ek, Jhoomra and Chau talas, lend themselves better to slow and medium tempos. Others flourish at faster speeds, like Jhap or Rupak talas. Trital or Teental is one of the most popular, since it is as aesthetic at slower tempos as it is at faster speeds.\\n\\nThere are many talas in Hindustani music, some of the more popular ones are:\\n\\n| Name                          | Beats | Division    | Vibhaga     |\\n| ----------------------------- | ----- | ----------- | ----------- |\\n| Tintal (or Trital or Teental) | 16    | 4+4+4+4     | X 2 0 3     |\\n| Jhoomra                       | 14    | 3+4+3+4     | X 2 0 3     |\\n| Tilwada                       | 16    | 4+4+4+4     | X 2 0 3     |\\n| Dhamar                        | 14    | 5+2+3+4     | X 2 0 3     |\\n| Ektal and Chautal             | 12    | 2+2+2+2+2+2 | X 0 2 0 3 4 |\\n| Jhaptal                       | 10    | 2+3+2+3     | X 2 0 3     |\\n| Keherwa                       | 8     | 4+4         | X 0         |\\n| Rupak (Mughlai/Roopak)        | 7     | 3+2+2       | X 2 3       |\\n| Dadra                         | 6     | 3+3         | X 0         |\\n\\n### 72 melakarta talas\\n\\n<table class=\\"wikitable\\">\\n<tbody><tr>\\n<td><b>S.No</b>\\n</td>\\n<td><b>Name of Raga</b>\\n</td>\\n<td><b>Pattern of the symbols of angas</b>\\n</td>\\n<td><b>Aksharas</b>\\n</td></tr>\\n<tr>\\n<td>1\\n</td>\\n<td>Kanakaangi\\n</td>\\n<td>1 Anudhrutha, 1 Dhrutha, 1 Guru, 1 Laghu\\n</td>\\n<td>15\\n</td></tr>\\n<tr>\\n<td>2\\n</td>\\n<td>Rathnaangi\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu\\n</td>\\n<td>20\\n</td></tr>\\n<tr>\\n<td>3\\n</td>\\n<td>Ganamurthi\\n</td>\\n<td>1 Laghu, 2 Anudhruthas, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Anudhrutha\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>4\\n</td>\\n<td>Vanaspathi\\n</td>\\n<td>1 Laghu, 2 Anudhruthas, 1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>5\\n</td>\\n<td>Maanavathi\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>20\\n</td></tr>\\n<tr>\\n<td>6\\n</td>\\n<td>Dhanarupi\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhritha\\n</td>\\n<td>15\\n</td></tr>\\n<tr>\\n<td>7\\n</td>\\n<td>Senaavathi\\n</td>\\n<td>1 Gurus, 1 Dhrutha Sekara Viraamam, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>25\\n</td></tr>\\n<tr>\\n<td>8\\n</td>\\n<td>Hanumathodi\\n</td>\\n<td>1 Guru, 2 Anudhruthas, 1 Laghu, 1 Dhrutha, 1 Pluta, 1 Dhrutha, 1 Laghu\\n</td>\\n<td>34\\n</td></tr>\\n<tr>\\n<td>9\\n</td>\\n<td>Dhenuka\\n</td>\\n<td>1 Pluta, 2 Anudhruthas, 1 Dhrutha\\n</td>\\n<td>16\\n</td></tr>\\n<tr>\\n<td>10\\n</td>\\n<td>Natakapriya\\n</td>\\n<td>3 Dhruthas, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>12\\n</td></tr>\\n<tr>\\n<td>11\\n</td>\\n<td>Kokilapriya\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Dhrutha, 2 Laghus, 1 Dhrutha\\n</td>\\n<td>21\\n</td></tr>\\n<tr>\\n<td>12\\n</td>\\n<td>Rupaavathi\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>19\\n</td></tr>\\n<tr>\\n<td>13\\n</td>\\n<td>Gayakapriya\\n</td>\\n<td>1 Laghu, 1 Anudhrutha, 2 Dhruthas, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>15\\n</td></tr>\\n<tr>\\n<td>14\\n</td>\\n<td>Vagula bharanam\\n</td>\\n<td>1 Laghu, 1 Anudhrutha, 2 Dhruthas, 1 Laghu, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>28\\n</td></tr>\\n<tr>\\n<td>15\\n</td>\\n<td>Maya malava goulam\\n</td>\\n<td>1 Laghu, 2 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Anudhrutha\\n</td>\\n<td>31\\n</td></tr>\\n<tr>\\n<td>16\\n</td>\\n<td>Chakravaham\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 2 Laghus, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>24\\n</td></tr>\\n<tr>\\n<td>17\\n</td>\\n<td>Suryakantham\\n</td>\\n<td>1 Guru, 1 Dhrutha Sekara Viraamam, 1 Dhrutha, 1 Guru, 1 Pluta\\n</td>\\n<td>33\\n</td></tr>\\n<tr>\\n<td>18\\n</td>\\n<td>Haata kambari\\n</td>\\n<td>1 Guru, 2 Dhruthas, 1 Guru, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>19\\n</td>\\n<td>Jankaradh wani\\n</td>\\n<td>1 Pluta, 3 Dhrutha Sekara Viraamams, 1 Pluta, 1 Dhrutha, 1 Anudhrutha\\n</td>\\n<td>36\\n</td></tr>\\n<tr>\\n<td>20\\n</td>\\n<td>Nata bhairavi\\n</td>\\n<td>1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Laghu, 2 Dhrutha Sekara Viraamams, 1 Laghu, 1 Anudhrutha\\n</td>\\n<td>19\\n</td></tr>\\n<tr>\\n<td>21\\n</td>\\n<td>Keeravani\\n</td>\\n<td>2 Dhrutha Sekara Viraamams, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>18\\n</td></tr>\\n<tr>\\n<td>22\\n</td>\\n<td>Karahara priya\\n</td>\\n<td>2 Dhrutha Sekara Viraamams, 1 Guru, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>24\\n</td></tr>\\n<tr>\\n<td>23\\n</td>\\n<td>Gowri manohari\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 2 Laghus, 1 Dhrutha, 2 Gurus, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>37\\n</td></tr>\\n<tr>\\n<td>24\\n</td>\\n<td>Varuna priya\\n</td>\\n<td>1 Laghu, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>20\\n</td></tr>\\n<tr>\\n<td>25\\n</td>\\n<td>Maara ranjani\\n</td>\\n<td>1 Laghu, 2 Dhrutha Sekara Viraamams, 2 Gurus, 2 Anudhruthas\\n</td>\\n<td>28\\n</td></tr>\\n<tr>\\n<td>26\\n</td>\\n<td>Charukesi\\n</td>\\n<td>1 Guru, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>27\\n</td>\\n<td>Sarasaangi\\n</td>\\n<td>1 Guru, 1 Dhrutha Sekara Viraamam, 1 Pluta, 1 Dhrutha, 1 Laghu\\n</td>\\n<td>29\\n</td></tr>\\n<tr>\\n<td>28\\n</td>\\n<td>Harikamboji\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Pluta, 1 Guru, 1 Anudhrutha\\n</td>\\n<td>41\\n</td></tr>\\n<tr>\\n<td>29\\n</td>\\n<td>Dheera sankara bharanam\\n</td>\\n<td>1 Guru, 2 Dhrutha Sekara Viraamams, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Dhrutha, 2 Laghus, 1 Anudhrutha, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>50\\n</td></tr>\\n<tr>\\n<td>30\\n</td>\\n<td>Nagaa nandhini\\n</td>\\n<td>1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha, 1 Guru, 2 Anudhruthas\\n</td>\\n<td>23\\n</td></tr>\\n<tr>\\n<td>31\\n</td>\\n<td>Yagapriya\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 2 Laghus, 1 Dhrutha\\n</td>\\n<td>13\\n</td></tr>\\n<tr>\\n<td>32\\n</td>\\n<td>Raga vardhini\\n</td>\\n<td>3 Laghus, 1 Anudhrutha, 1 Guru, 1 Dhrutha, 1 Anudhrutha\\n</td>\\n<td>24\\n</td></tr>\\n<tr>\\n<td>33\\n</td>\\n<td>Gangeya bhushani\\n</td>\\n<td>1 Guru, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Dhrutha, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>38\\n</td></tr>\\n<tr>\\n<td>34\\n</td>\\n<td>Vaga dheeshwari\\n</td>\\n<td>1 Laghu, 1 Dhrutha, 1 Laghu, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Guru, Dhrutha, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>34\\n</td></tr>\\n<tr>\\n<td>35\\n</td>\\n<td>Soolini\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha\\n</td>\\n<td>12\\n</td></tr>\\n<tr>\\n<td>36\\n</td>\\n<td>Chala Naata\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 2 Dhruthas\\n</td>\\n<td>15\\n</td></tr>\\n<tr>\\n<td>37\\n</td>\\n<td>Chalagam\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Guru, 1 Anudhrutha\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>38\\n</td>\\n<td>Jalaarnavam\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 2 Gurus, 1 Dhrutha\\n</td>\\n<td>32\\n</td></tr>\\n<tr>\\n<td>39\\n</td>\\n<td>Jaalavarali\\n</td>\\n<td>1 Guru, 1 Dhrutha Sekara Viraamam, 2 Laghus, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha\\n</td>\\n<td>25\\n</td></tr>\\n<tr>\\n<td>40\\n</td>\\n<td>Navaneetham\\n</td>\\n<td>1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>15\\n</td></tr>\\n<tr>\\n<td>41\\n</td>\\n<td>Paavani\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 1 Laghu, 2 Anudhruthas\\n</td>\\n<td>9\\n</td></tr>\\n<tr>\\n<td>42\\n</td>\\n<td>Raghupriya\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 1 Laghu, Anudhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>14\\n</td></tr>\\n<tr>\\n<td>43\\n</td>\\n<td>Kavaambothi\\n</td>\\n<td>1 Laghu, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Pluta, 1 Guru, 1 Anudhrutha\\n</td>\\n<td>36\\n</td></tr>\\n<tr>\\n<td>44\\n</td>\\n<td>Bhavapriya\\n</td>\\n<td>1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>16\\n</td></tr>\\n<tr>\\n<td>45\\n</td>\\n<td>Subha panthuvarali\\n</td>\\n<td>1 Laghu, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha\\n</td>\\n<td>35\\n</td></tr>\\n<tr>\\n<td>46\\n</td>\\n<td>Shadvitha maargini\\n</td>\\n<td>1 Guru, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Guru, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>44\\n</td></tr>\\n<tr>\\n<td>47\\n</td>\\n<td>Swarnaangi\\n</td>\\n<td>1 Guru, 1 Laghu, 1 Dhrutha, 1 Pluta, 1 Dhrutha, 1 Laghu\\n</td>\\n<td>32\\n</td></tr>\\n<tr>\\n<td>48\\n</td>\\n<td>Divyamani\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>49\\n</td>\\n<td>Davalaambari\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>28\\n</td></tr>\\n<tr>\\n<td>50\\n</td>\\n<td>Naama narayani\\n</td>\\n<td>1 Dhrutha, 1 Laghu, 2 Dhruthas, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>51\\n</td>\\n<td>Kaamavartha\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Pluta, 1 Anudhrutha\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>52\\n</td>\\n<td>Raamapriya\\n</td>\\n<td>2 Laghus, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>16\\n</td></tr>\\n<tr>\\n<td>53\\n</td>\\n<td>Gamanashrama\\n</td>\\n<td>2 Laghus, 1 Dhrutha, 1 Anudhrutha, 1 Laghu , 1 Dhrutha\\n</td>\\n<td>17\\n</td></tr>\\n<tr>\\n<td>54\\n</td>\\n<td>Viswambari\\n</td>\\n<td>1 Laghu, 1 Anudhrutha, 1 Pluta, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>55\\n</td>\\n<td>Syamalangi\\n</td>\\n<td>1 Guru, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu\\n</td>\\n<td>25\\n</td></tr>\\n<tr>\\n<td>56\\n</td>\\n<td>Shanmukha priya\\n</td>\\n<td>1 Pluta, 1 Laghu, 1 Dhrutha, 1Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>57\\n</td>\\n<td>Simhendra madhyamam\\n</td>\\n<td>1 Guru, 1 Kakapada, 1 Laghu, 1 Dhrutha, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>69\\n</td></tr>\\n<tr>\\n<td>58\\n</td>\\n<td>Hemaavathi\\n</td>\\n<td>1 Pluta, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>30\\n</td></tr>\\n<tr>\\n<td>59\\n</td>\\n<td>Dharmavathi\\n</td>\\n<td>1 Pluta, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>30\\n</td></tr>\\n<tr>\\n<td>60\\n</td>\\n<td>Neethimathi\\n</td>\\n<td>1Dhrutha, 1Laghu, 1Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>22\\n</td></tr>\\n<tr>\\n<td>61\\n</td>\\n<td>Kaanthamani\\n</td>\\n<td>2 Gurus, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>28\\n</td></tr>\\n<tr>\\n<td>62\\n</td>\\n<td>Rishabhapriya\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>21\\n</td></tr>\\n<tr>\\n<td>63\\n</td>\\n<td>Lathaangi\\n</td>\\n<td>1 Laghu, 1 Pluta, 1 Anudhrutha, 1 Laghu\\n</td>\\n<td>21\\n</td></tr>\\n<tr>\\n<td>64\\n</td>\\n<td>Vachaspathi\\n</td>\\n<td>1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>29\\n</td></tr>\\n<tr>\\n<td>65\\n</td>\\n<td>Mecha Kalyani\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Dhrutha, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>30\\n</td></tr>\\n<tr>\\n<td>66\\n</td>\\n<td>Chithraambari\\n</td>\\n<td>1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Pluta, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam\\n</td>\\n<td>29\\n</td></tr>\\n<tr>\\n<td>67\\n</td>\\n<td>Sucharithra\\n</td>\\n<td>1 Guru, 1 Laghu, 2 Dhrutha Sekara Viraamams, 1 Guru, 1 Anudhrutha\\n</td>\\n<td>27\\n</td></tr>\\n<tr>\\n<td>68\\n</td>\\n<td>Jyothi swarupini\\n</td>\\n<td>1 Kakapada, 1 Anudhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Pluta, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>48\\n</td></tr>\\n<tr>\\n<td>69\\n</td>\\n<td>Dathuvardhani\\n</td>\\n<td>1 Guru, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Anudhrutha, 1 Pluta, 1 Anudhrutha\\n</td>\\n<td>36\\n</td></tr>\\n<tr>\\n<td>70\\n</td>\\n<td>Naasikha bhushani\\n</td>\\n<td>1 Dhrutha, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha, 1 Laghu, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>32\\n</td></tr>\\n<tr>\\n<td>71\\n</td>\\n<td>Kosalam\\n</td>\\n<td>1 Guru, 1 Anudhrutha, 2 Gurus, 1 Anudhruthas\\n</td>\\n<td>26\\n</td></tr>\\n<tr>\\n<td>72\\n</td>\\n<td>Rasikapriya\\n</td>\\n<td>1 Dhrutha Sekara Viraamam, 1 Guru, 1 Dhrutha Sekara Viraamam, 1 Laghu, 1 Dhrutha\\n</td>\\n<td>20\\n</td></tr></tbody></table>\\n\\n<youtube-embed video=\\"2IBah0k836A\\" />\\n\\n### 7 Saptangachakram (7 angas)\\n\\n| Anga                  | Symbol | Aksharakala |\\n| --------------------- | ------ | ----------- |\\n| Anudrutam             | U      | 1           |\\n| Druta                 | O      | 2           |\\n| Druta-virama          | UO     | 3           |\\n| Laghu (Chatusra-jati) | l      | 4           |\\n| Guru                  | 8      | 8           |\\n| Plutam                | 3      | 12          |\\n| Kakapadam             | x      | 16          |\\n\\nhttps://www.mridangams.com/2007/09/tala-dhasa-pranas.html\\n\\n---\\n\\n## Konnakkol\\n\\nKonnakol (also spelled Konokol, Konakkol, Konnakkol) (Tamil: கொன்னக்கோல் koṉṉakkōl) (Malayalam: വായ്ത്താരി) is the art of performing percussion syllables vocally in South Indian Carnatic music. Konnakol is the spoken component of solkattu, which refers to a combination of konnakol syllables spoken while simultaneously counting the tala (meter) with the hand. It is comparable in some respects to bol in Hindustani music, but allows the composition, performance or communication of rhythms. A similar concept in Hindustani classical music is called padhant.\\n\\n<youtube-embed video=\\"DYEh5uXrL4w\\"/>\\n\\n### Usage\\n\\nMusicians from a variety of traditions have found konnakol useful in their practice. Prominent among these is John McLaughlin, who led the Mahavishnu Orchestra and has long used konnakol as a compositional aid. V. Selvaganesh, who plays alongside McLaughlin in the group Remember Shakti, and Ranjit Barot, who plays with McLaughlin in the group 4th Dimension, are other noted konnakol virtuosos. Few of the prominent names performing konnakol are B K Chandramouli, Dr T K Murthy, B C Manjunath, Somashekhar Jois.\\n\\nDanish musician Henrik Andersen wrote the book Shortcut To Nirvana (2005) and the DVD Learn Konnakol (2014). Andersen was a student of Trilok Gurtu (India) and Pete Lockett (U.K.).\\n\\nSubash Chandran's disciple Dr Joel, who teaches konnakol in the U.K., is noted for incorporating it into rock and Western classical music, notably in a concerto commissioned in 2007 by the viola soloist Rivka Golani. The trio J G Laya (Chandran, Sri Thetakudi Harihara Vinayakram, and Dr Joel) showcased the konnakol of Chandran and helped the previously fading art form return to prominence in the 1980s. Chandran released an instructional DVD on konnakol in 2007. McLaughlin and Selvaganesh also released an instructional DVD on konnakol in 2007.\\n\\n<youtube-embed video=\\"mOMLRMfIYf0\\"/>\\n\\nJazz saxophonist, konnakol artist, and composer Arun Luthra incorporates konnakol and Carnatic music rhythms (as well as Hindustani classical music rhythms) in his work. More recently, drummer Steve Smith has also incorporated Konnakol in his performances with Vital Information and his clinics.\\n\\nKonnakol should not be confused with the practice in Hindustani music (the classical music of northern India) of speaking tabla \\"bols\\", which indicate the finger placement to be used by a percussionist. By contrast, konnakol syllables are aimed at optimising vocal performance, and vastly outnumber any commonly used finger placements on mridangam or any other hand percussion instrument. Further, all the differences between Carnatic and north Indian rhythms apply equally to konnakol and tabla bols.\\n\\nThe artist improvises within a structure that interrelates with the raga being played and within the talam preferred in the compositions. In mridangam, kanjira, or ghatam, the percussion is limited to physical characteristics of their structure and construction: the resonance of skin over jackfruit wood, clay shells, or clay pots. The human voice has a direct and dramatic way of expressing the percussive aspects in music directly.\\n\\nTrichy Shri R Thayumanavar gave a rebirth to konnakol. His disciple Andankoil AVS Sundararajan, a vocal and miruthangam Vidwan, is a konnakol expert, as is Mridangam Vidwan Shri T S Nandakumar.\\n\\n### Solkattu\\n\\n| Sol    | Sollu-Solkattus | Jatti    |\\n| ------ | --------------- | -------- |\\n| Letter | Word            | Sentence |\\n\\nKonnakol uses rhythmic solfege for different subdivisions of the beat called \\"Solkattu.\\" Common ones are:\\n\\n| N   | Name                  | Syllables                                                                   |\\n| --- | --------------------- | --------------------------------------------------------------------------- |\\n| 2   | Chatusra 1/2 Speed    | Tha Ka                                                                      |\\n| 3   | Tisra                 | Tha Ki Ta                                                                   |\\n| 4   | Chatusra              | Tha Ka Dhi Mi                                                               |\\n| 5   | Khanda                | Tha Dhi Gi Na Thom                                                          |\\n| 6   | Tisra Double Speed    | Tha Ka Dhi Mi Tha Ka                                                        |\\n| 7   | Misra                 | Tha Ka Di Mi Tha Ki Ta                                                      |\\n| 8   | Chatusra Double Speed | Tha Ka Dhi Mi Tha Ka Jhu No                                                 |\\n| 9   | Sankirna              | Tha Ka Dhi Mi Ta Dhi Gi Na Thom                                             |\\n| 10  | Khanda Double Speed   | Tha Ka Tha Ki Ta Tha Dhi Gi Na Thom, or Tha Ki Ta Dhim†2 Tha Dhi Gi Na Thom |\\n\\n†'2' suffix signifies solfege syllable is held twice as long.\\n\\n<youtube-embed video=\\"ZuZF8BaOt58\\"/>\\n\\n## Tihai - the rhythmic cadence\\n\\n[Tihai](https://en.wikipedia.org/wiki/Tihai) (pronounced ti-'ha-yi) is a polyrhythmic technique found in Indian classical music, and often used to conclude a piece. Tihais can be either sung or played on an instrument. Tihais are sometimes used to distort the listeners’ perception of time, only to reveal the consistent underlying cycle at the sam.\\n\\n### Definition\\n\\nTihai is the repetition of specific group of BOL or BEATS by three times.\\n\\n### Usage\\n\\nTypically, a tihai is used as a rhythmic cadence, i.e., a rhythmic variation that marks the end of a melody or rhythmic composition, creating a transition to another section of the music.\\n\\n<youtube-embed video=\\"0kJ4PA2yOSU\\" />\\n\\n### Structure\\n\\nThe basic internal format of the tihai is three equal repetitions of a rhythmic pattern (or rhythmo-melodic pattern), interspersed with 2 (usually) equal rests.\\n\\nThe ending point of the tihai is calculated to fall on a significant point in the rhythmic cycle (called tala), most often the first beat (called sum and pronounced \\"some\\"). The other most common ending point of a tihai is the beginning of the gat or bandish, which is often found several beats before the sum.\\n\\nIf the three groupings are played with two groupings of rests, which are equally long, then the tihai is called Dumdaar.\\n\\nOtherwise, if there are no rests between the three groupings, then the tihai is called Bedumdaar (or for short, Bedum).\\n\\nSometimes, a pattern is played on the tabla that is almost identical to a tihai, except for the fact that it ends on the beat just before the sum. Such patterns are known as anagat.\\n\\n<youtube-embed video=\\"HXLGO-yTgzo\\" />\\n","frontmatter":{"title":"Indian tala","description":"The Indian rhythmic language and art of konnakkol","cover":"/media_files/cover/theory-rhythm-system-tala-ricky-singh.jpg","date":"2021-10-19T00:00:00.000Z"},"url":"/theory/rhythm/system/tala/"},{"src":"---\\ntitle: Pulse, beat and tempo\\ndescription: Time feeling of humans\\ncover: austin-ban.jpg\\ndate: 2021-10-16\\n---\\n\\n## Pulse\\n\\nIn music theory, the pulse is a musical piece's either audible or implied series of uniformly spaced beats—in other words, uniformly timed instants of punctuating sound—and thus is the monotonous \\"tapping\\" that sets the tempo and that underlies or anchors the rhythm. Whereas the rhythm, being a musical creation that at times can intricately depart from the pulse, may become too difficult for an untrained listener to fully match, nearly any listener instinctively matches the pulse by simply tapping uniformly, despite rhythmic variations in timing of sounds atop the pulse. A performance may leave certain beats silent, not literally sounded, but the pulse remains as an abstraction. For example, even after a silent passage in a piece, the piece typically resumes on beat, as it were, by referencing the implied pulse, established before the silence.\\n\\nThe pulse may be audible or implied. The **tempo** of the piece is the speed of the pulse. If a pulse becomes too fast it would become a drone; one that is too slow would be perceived as unconnected sounds. When the period of any continuous beat is faster than 8–10 per second or slower than 1 per 1.5–2 seconds, it cannot be perceived as such. \\"Musical\\" pulses are generally specified in the range 40 to 240 beats per minute. The pulse is not necessarily the fastest or the slowest component of the rhythm but the one that is perceived as basic. This is currently most often designated as a crotchet or quarter note when written.\\n\\nPulse is related to and distinguished from rhythm (grouping), beats, and meter:\\n\\n> A pulse is one of a series of regularly recurring, precisely equivalent [\\"undifferentiated\\"] stimuli. Like the tick of a metronome or a watch, pulses mark off equal units in the temporal continuum.... A sense of regular pulses, once established, tends to be continued in the mind and musculature of the listener, even though the sound has stopped.... The human mind tends to impose some sort of organization upon such equal pulses. ...  \\n> [Pulse is] an important part of musical experience. Not only is pulse necessary for the existence of meter [\\"there can be no meter without an underlying pulse to establish the units of measurement\\"], but it generally, though not always, underlies and reinforces rhythmic experience.  \\n> Meter is the measurement of the number of pulses between more or less regularly recurring accents. Therefore, in order for meter to exist, some of the pulses in a series must be accented—marked for consciousness—relative to others. When pulses are thus counted within a metric context, they are referred to as beats.\\n> — Leonard B. Meyer and Cooper (1960)\\n\\n<youtube-embed video=\\"2UphAzryVpY\\" />\\n\\n## Pulse groups\\n\\nWhile ideal pulses are identical, when pulses are variously accented, this produces two- or three-pulse pulse groups such as **strong-weak** and **strong-weak-weak** and any longer group may be broken into such groups of two and three. In fact there is a natural tendency to perceptually group or differentiate an ideal pulse in this way. A repetitive, regularly accented pulse-group is called a **metre**.\\n\\nPulses can occur at multiple metric levels. Pulse groups may be distinguished as synchronous, if all pulses on slower levels coincide with those on faster levels, and nonsynchronous, if not.\\n\\nAn isochronal or equally spaced pulse on one level that uses varied pulse groups (rather than just one pulse group the whole piece) create a pulse on the (slower) multiple level that is non-isochronal (a stream of 2+3... at the eighth note level would create a pulse of a quarter note+dotted quarter note as its multiple level).\\n\\n## Tempo\\n\\n[Tempo](https://en.wikipedia.org/wiki/Tempo) (Italian for \\"time\\"; plural tempos, or tempi from the Italian plural) is the speed or pace of a given piece. In classical music, tempo is typically indicated with an instruction at the start of a piece (often using conventional Italian terms) and is usually measured in beats per minute (or BPM). In modern classical compositions, a \\"metronome mark\\" in beats per minute may supplement or replace the normal tempo marking, while in modern genres like electronic dance music, tempo will typically simply be stated in BPM.\\n\\nTempo may be separated from articulation and meter, or these aspects may be indicated along with tempo, all contributing to the overall texture. While the ability to hold a steady tempo is a vital skill for a musical performer, tempo is changeable. Depending on the genre of a piece of music and the performers' interpretation, a piece may be played with slight tempo rubato or drastic variances. In ensembles, the tempo is often indicated by a conductor or by one of the instrumentalists, for instance the drummer.\\n\\n### Measurement of the tempo\\n\\nWhile tempo is described or indicated in many different ways, including with a range of words (e.g., \\"Slowly\\", \\"Adagio\\" and so on), it is typically measured in beats per minute (BPM or BPM). For example, a tempo of 60 beats per minute signifies one beat per second, while a tempo of 120 beats per minute is twice as rapid, signifying one beat every 0.5 seconds. The note value of a beat will typically be that indicated by the denominator of the time signature. For instance, in 4/4 the beat will be a crotchet, or quarter note.\\n\\nThis measurement and indication of tempo became increasingly popular during the first half of the 19th century, after Johann Nepomuk Maelzel invented the metronome. Beethoven was one of the first composers to use the metronome; in the 1810s he published metronomic indications for the eight symphonies he had composed up to that time.\\n\\nInstead of beats per minute, some 20th-century classical composers (e.g., Béla Bartók, Alberto Ginastera, and John Cage) specify the total playing time for a piece, from which the performer can derive tempo.\\n\\nWith the advent of modern electronics, BPM became an extremely precise measure. Music sequencers use the BPM system to denote tempo. In popular music genres such as electronic dance music, accurate knowledge of a tune's BPM is important to DJs for the purposes of beatmatching.\\n\\nThe speed of a piece of music can also be gauged according to measures per minute (mpm) or bars per minute (BPM), the number of measures of the piece performed in one minute. This measure is commonly used in ballroom dance music.\\n\\n## Choosing speed\\n\\nIn different musical contexts, different instrumental musicians, singers, conductors, bandleaders, music directors or other individuals will select the tempo of a song or piece. In a popular music or traditional music group or band, the bandleader or drummer may select the tempo. In popular and traditional music, whoever is setting the tempo often counts out one or two bars in tempo. In some songs or pieces in which a singer or solo instrumentalist begins the work with a solo introduction (prior to the start of the full group), the tempo they set will provide the tempo for the group. In an orchestra or concert band, the conductor normally sets the tempo. In a marching band, the drum major may set the tempo. In a sound recording, in some cases a record producer may set the tempo for a song (although this would be less likely with an experienced bandleader).\\n\\n## Basic tempo markings\\n\\nHere follows a list of common tempo markings. The beats per minute (BPM) values are very rough approximations for 4/4 time.\\n\\nThese terms have also been used inconsistently through time and in different geographical areas. One striking example is that Allegretto hastened as a tempo from the 18th to the 19th century: originally it was just above Andante, instead of just below Allegro as it is now. As another example, a modern largo is slower than an adagio, but in the Baroque period it was faster.\\n\\nFrom slowest to fastest:\\n\\n- **Larghissimo** – very, very slow (24 BPM and under)\\n- **Adagissimo** – very slow (24-40 BPM)\\n- **Grave** – very slow (25–45 BPM)\\n- **Largo** – slow and broad (40–60 BPM)\\n- **Lento** – slow (45–60 BPM)\\n- **Larghetto** – rather slow and broad (60–66 BPM)\\n- **Adagio** – slow with great expression (66–76 BPM)\\n- **Adagietto** – slower than andante (72–76 BPM) or slightly faster than adagio (70–80 BPM)\\n- **Andante** – at a walking pace (76–108 BPM)\\n- **Andantino** – slightly faster than andante (although, in some cases, it can be taken to mean slightly slower than andante) (80–108 BPM)\\n- **Marcia moderato** – moderately, in the manner of a march (83–85 BPM)\\n- **Moderato** – at a moderate speed (108–120 BPM)\\n- **Andante moderato** – between andante and moderato (thus the name) (92–112 BPM)\\n- **Allegretto** – by the mid-19th century, moderately fast (112–120 BPM); see paragraph above for earlier usage\\n- **Allegro moderato** – close to, but not quite allegro (116–120 BPM)\\n- **Allegro** – fast, quick, and bright (120–156 BPM) (molto allegro is slightly faster than allegro, but always in its range; 124-156 BPM)\\n- **Vivace** – lively and fast (156–176 BPM)\\n- **Vivacissimo** – very fast and lively (172–176 BPM)\\n- **Allegrissimo** or Allegro vivace – very fast (172–176 BPM)\\n- **Presto** – very, very fast (168–200 BPM)\\n- **Prestissimo** – even faster than presto (200 BPM and over)\\n\\nAdditional terms\\n\\n- **A piacere** – the performer may use their own discretion with regard to tempo and rhythm; literally \\"at pleasure\\"\\n- **Assai** – (very) much\\n- **A tempo** – resume previous tempo\\n- **Con grazia** – with grace, or gracefully\\n- **Con moto** – Italian for \\"with movement\\"; can be combined with a tempo indication, e.g., Andante con moto\\n- **Lamentoso** – sadly, plaintively\\n- **L'istesso**, L'istesso tempo, or Lo stesso tempo – at the same speed; L'istesso is used when the actual speed of the music has not changed, despite apparent signals to the contrary, such as changes in time signature or note length (half notes in 4\\n- 4 could change to whole notes in 2\\n- 2, and they would all have the same duration)\\n- **Ma non tanto** – but not so much; used in the same way and has the same effect as Ma non troppo (see immediately below) but to a lesser degree\\n- **Ma non troppo** – but not too much; used to modify a basic tempo to indicate that the basic tempo should be reined in to a degree; for example, Adagio ma non troppo to mean ″Slow, but not too much″, Allegro ma non troppo to mean ″Fast, but not too much″\\n- **Maestoso** – majestically, stately\\n- **Molto** – very\\n- **meno** - Less\\n- **Più** - more\\n- **Poco** – a little\\n- **Subito** – suddenly\\n- **Tempo comodo** – at a comfortable speed\\n- **Tempo di...** – the speed of a ... (such as Tempo di valzer (speed of a waltz, dotted quarter note. ≈ 60 BPM or quarter note≈ 126 BPM), Tempo di marcia (speed of a march, quarter note ≈ 120 BPM))\\n- **Tempo giusto** – at a consistent speed, at the 'right' speed, in strict tempo\\n- **Tempo primo** – resume the original (first) tempo\\n- **Tempo semplice** – simple, regular speed, plainly\\n\\n### English tempo markings\\n\\nEnglish indications, for example quickly, have also been used, by Benjamin Britten and Percy Grainger, among many others. In jazz and popular music lead sheets and fake book charts, terms like \\"fast\\", \\"laid back\\", \\"steady rock\\", \\"medium\\", \\"medium-up\\", \\"ballad\\", \\"brisk\\", \\"brightly\\" \\"up\\", \\"slowly\\", and similar style indications may appear. In some lead sheets and fake books, both tempo and genre are indicated, e.g., \\"slow blues\\", \\"fast swing\\", or \\"medium Latin\\". The genre indications help rhythm section instrumentalists use the correct style. For example, if a song says \\"medium shuffle\\", the drummer plays a shuffle drum pattern; if it says \\"fast boogie-woogie\\", the piano player plays a boogie-woogie bassline.\\n\\n\\"Show tempo\\", a term used since the early days of Vaudeville, describes the traditionally brisk tempo (usually 160–170 BPM) of opening songs in stage revues and musicals.\\n\\nHumourist Tom Lehrer uses facetious English tempo markings in his anthology Too Many Songs by Tom Lehrer. For example, \\"National Brotherhood Week\\" is to be played \\"fraternally\\"; \\"We Will All Go Together\\" is marked \\"eschatologically\\"; and \\"Masochism Tango\\" has the tempo \\"painstakingly\\". His English contemporaries Flanders and Swann have similarly marked scores, with the music for their song \\"The Whale (Moby Dick)\\" shown as \\"oceanlike and vast\\".\\n\\n## Electronic music\\n\\nTypical tempo ranges for most common elecytonic music genres:\\n\\n- **Dub:** 60-90 BPM\\n- **Hip-hop:** 60-100 BPM\\n- **Triphop/Downtempo:** 90-110 BPM\\n- **House:** 115-130 BPM\\n- **UK garage/2-step:** 130-135 BPM\\n- **Grime:** 140 BPM\\n- **Techno/Trance:** 120-140 BPM\\n- **Acid Techno:** 135-150\\n- **Schranz:** 150\\n- **Dubstep:** 135-145 BPM (70-75 BPM in half-time)\\n- **Hardstyle:** 150 BPM\\n- **Juke/Footwork:** 160 BPM\\n- **Drum and bass:** 160-180 BPM\\n\\n### Extreme tempo\\n\\nMore extreme tempos are achievable at the same underlying tempo with very fast drum patterns, often expressed as drum rolls. Such compositions often exhibit a much slower underlying tempo, but may increase the tempo by adding additional percussive beats. Extreme metal subgenres such as speedcore and grindcore often strive to reach unusually fast tempo. The use of extreme tempo was very common in the fast bebop jazz from the 1940s and 1950s. A common jazz tune such as \\"Cherokee\\" was often performed at quarter note equal to or sometimes exceeding 368 BPM. Some of Charlie Parker's famous tunes (\\"Bebop\\", \\"Shaw Nuff\\") have been performed at 380 BPM plus.\\n\\n<youtube-embed video=\\"GH2k8GccrqI\\" />\\n\\nThere is also a subgenre of speedcore known as Extratone, which is defined by music with a BPM over 3,600, or sometimes 1,000 BPM or over.\\n\\n### Beatmatching\\n\\nIn popular music genres such as disco, house music and electronic dance music, beatmatching is a technique that DJs use that involves speeding up or slowing down a record (or CDJ player, a speed-adjustable CD player for DJ use) to match the tempo of a previous or subsequent track, so both can be seamlessly mixed. Having beatmatched two songs, the DJ can either seamlessly crossfade from one song to another, or play both tracks simultaneously, creating a layered effect.\\n\\nDJs often beatmatch the underlying tempos of recordings, rather than their strict BPM value suggested by the kick drum, particularly when dealing with high tempo tracks. A 240 BPM track, for example, matches the beat of a 120 BPM track without slowing down or speeding up, because both have an underlying tempo of 120 quarter notes per minute. Thus, some soul music (around 75–90 BPM) mixes well with a drum and bass beat (from 150–185 BPM). When speeding up or slowing down a record on a turntable, the pitch and tempo of a track are linked: spinning a disc 10% faster makes both pitch and tempo 10% higher. Software processing to change the pitch without changing the tempo is called pitch-shifting. The opposite operation, changing the tempo without changing the pitch, is called time-stretching.\\n","frontmatter":{"title":"Pulse, beat and tempo","description":"Time feeling of humans","cover":"/media_files/cover/theory-rhythm-pulse-austin-ban.jpg","date":"2021-10-16T00:00:00.000Z"},"url":"/theory/rhythm/pulse/"},{"src":"---\\ntitle: Rhythm, timeline, ostinato\\ndescription: Definitions of the temporal dimension in music\\ncover: roger-hoover.jpg\\ndate: 2021-10-16\\n---\\n\\n<youtube-embed video=\\"YPU5XrmORCQ\\" />\\n\\nA few examples of definitions and characterizations of rhythm, both ancient and modern. (from the book [\\"The geometry of musical rhythm: What makes a 'Good' Rhythm good?\\"](https://en.wikipedia.org/wiki/The_Geometry_of_Musical_Rhythm) by [Godfried T. Toussaint](http://cgm.cs.mcgill.ca/~godfried/) [(abstract)](http://cgm.cs.mcgill.ca/~godfried/publications/geometry-of-rhythm.pdf)\\n\\n## Definitions\\n\\n- **Plato:** “An order of movement.”\\n- **Baccheios the Elder:** “A measuring of time by means of some kind of movement.”††† Phaedrus: “Some measured thesis of syllables, placed together in certain ways.”‡‡‡ Aristoxenus: “Time, divided by any of those things that are capable of being rhythmed.”\\n- **Nichomacus:** “Well marked movement of ‘times’.”\\n- **Leophantus:** “Putting together of ‘times’ in due proportion, considered with regard to symmetry amongst them.”\\n- **Didymus:** “A schematic arrangement of sounds.”\\n- **D. Wright:** “Rhythm is the way in which time is organized within measures.”\\n- **A. C. Lewis:** “Rhythm is the language of time.”\\n- **J. Martineau:** “Rhythm is the component of music that punctuates time, carrying us from one beat to the next, and it subdivides into simple ratios.”\\n- **A. C. Hall:** “Rhythm is made by durations of sound and silence and by accent.”\\n- **T. H. Garland and C. V. Kahn:** “Rhythm is created whenever the time continuum is split up into pieces by some sound or movement.”\\n- **J. Bamberger:** “The many different ways in which time is organized in music.”\\n- **J. Clough, J. Conley, and C. Boge:** “Patterns of duration and accent of musical sounds moving through time.”\\n- **G. Cooper and L. B. Meyer:** “Rhythm may be defined as the way in which one or more unaccented beats are grouped in relation to an accented one.”\\n- **D. J. Levitin:** “Rhythm refers to the durations of a series of notes, and to the way that they group together into units.”\\n- **A. D. Patel:** “The systematic patterning of sound in terms of timing, accent, and grouping.”\\n- **R. Parncutt:** “A musical rhythm is an acoustic sequence evoking a sensation of pulse.”\\n- **C. B. Monahan and E. C. Carterette:** “Rhythm is the perception of both regular and irregular accent patterns and their interaction.”\\n- **M. Clayton:** “Rhythm, then, may be interpreted either as an alternation of stresses or as a succession of durations.”\\n- **B. C. Wade:** “A rhythm is a specific succession of durations.”\\n- **S. Arom:** “For there to be rhythm, sequences of audible events must be characterized by contrasting features.”‡‡‡‡ Arom goes on to specify that there are three types of con- trasting features that may operate in combination: duration, accent, and tone color (timbre). Contrast in each of these may be present or absent, and when accentuation or tone contrasts are present they may be regular or irregular. With these marking parameters, Arom generates a combinatorial classification of rhythms.\\n- **C. Egerton Lowe writes:** “There is, I think, no other term used in music over which more ambiguity is shown.” Then he provides a discussion of a dozen definitions found in the literature.\\n\\n<youtube-embed video=\\"gy2kyRrXm2g\\" />\\n\\n### Timelines, Ostinatos and Meter\\n\\nIn much traditional, classical, and contemporary music around the world, one hears a distinctive and characteristic rhythm that appears to be an essential feature of the music, that stands out above the other rhythms, and that repeats throughout most if not the entire piece. Sometimes this essential feature will be merely an isochronous pulsation without any recognizable periodicity. At other times, the music will be characterized by unique periodic patterns. These special rhythms are generally called **timelines**.\\\\* Timelines should be distinguished from the more general term rhythmic ostinatos. A rhythmic **ostinato** (from the word obstinate) refers to a rhythm or phrase that is continually repeated during a musical piece. Timelines, on the other hand, are more particular ostinatos that are easily recognized and remembered, play a distinguished role in the music, and also serve the functions of conductor and regulator, by signaling to other musicians the fundamen- tal cyclic structure of the piece. Thus, timelines act as an orienting device that facilitates musicians to stay together and helps soloists navigate the rhythmic landscape offered by the other instruments.\\n\\nIn ethnomusicology, the use of the word timeline is generally limited to asymmetric durational patterns of sub-Saharan origin such as the **tresillo**. In this book, however, the term is expanded to cover similar notions used in other cultures such as **compás** in the flamenco music of Southern Spain, **tala** in India, **loop** in electronic dance music (EDM), and just plain rhythmic ostinatos in any type of music. A word is in order concerning the ubiquitous related concept referred to as meter in Western music. There is slightly less vagueness present in the many definitions of **meter** published, as there is of the definitions of rhythm listed above. There is also much discussion about the differences between meter and rhythm. Meter is usually defined in terms of a hierarchy of accent pat- terns, and considered to be more regular than rhythm. Some music, such as sub-Saharan African music is claimed to have only pulsation as a temporal reference, and no meter in the strict sense of the word. Christopher Hasty’s book titled Meter as Rhythm considers meter to be a special case of rhythm. In this book, the word “timeline” is expanded to include all those meters used in music around the world, that function as time-keepers, or ostinatos, and determine the predominant underlying rhythmic structure of a piece. Here, meter is viewed as just another rhythm that may be sounded or merely felt by the performer or listener, and it is also represented as a binary sequence. While consideration of a metric context is indispensable for a complete understanding of rhythm, the underlying assumption in this book is that it can also be profitable to focus on purely inter-onset durational issues.\\n\\n<youtube-embed video=\\"uDhwFTw4VnI\\" />\\n\\nhttps://en.wikipedia.org/wiki/Additive_rhythm_and_divisive_rhythm\\n","frontmatter":{"title":"Rhythm, timeline, ostinato","description":"Definitions of the temporal dimension in music","cover":"/media_files/cover/theory-rhythm-study-roger-hoover.jpg","date":"2021-10-16T00:00:00.000Z"},"url":"/theory/rhythm/study/"},{"src":"---\\ntitle: Flamenco compás\\ndescription: A variety of both contemporary and traditional musical styles typical of southern Spain\\ncover: flam.jpg\\ndate: 2021-10-16\\nurls:\\n  - https://en.wikipedia.org/wiki/Flamenco\\n  - http://www.compas-flamenco.com/en/palos.html#Table\\n\\n---\\n\\n<script setup>\\nimport flamenco from '#/db/rhythm/flamenco.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"flamenco\\" />\\n\\n\\nFlamenco (Spanish pronunciation: [flaˈmeŋko]), in its strictest sense, is an art form based on the various folkloric music traditions of southern Spain, developed within the gitano subculture of the region of Andalusia, but also having a historical presence in Extremadura and Murcia. In a wider sense, it is a portmanteau term used to refer to a variety of both contemporary and traditional musical styles typical of southern Spain. Flamenco is closely associated to the gitanos of the Romani ethnicity who have contributed significantly to its origination and professionalization. However, its style is uniquely Andalusian and flamenco artists have historically included Spaniards of both gitano and non-gitano heritage.\\n\\n<youtube-embed video=\\"z0dtTRhAGVE\\" />\\n\\nThe oldest record of flamenco music dates to 1774 in the book Las Cartas Marruecas by José Cadalso. The development of flamenco over the past two centuries is well documented: \\"the theatre movement of sainetes (one-act plays) and tonadillas, popular song books and song sheets, customs, studies of dances, and toques, perfection, newspapers, graphic documents in paintings and engravings. ... in continuous evolution together with rhythm, the poetic stanzas, and the ambiance.”\\n\\n<youtube-embed video=\\"sCpjPWWQB3s\\" />\\n\\nFlamenco is rooted in various Andalusian popular musical styles, although its origins and influences are the subject of many hypotheses which may or may not have ideological implications and none of which are necessarily mutually exclusive. The most widespread is that flamenco was developed through the cross-cultural interchange among the various groups which coexisted in close proximity in Andalusia's lower classes, combining southern Spain's indigenous, Byzantine, Moorish and Romani musical traditions.\\n\\nOn 16 November 2010, UNESCO declared flamenco one of the Masterpieces of the Oral and Intangible Heritage of Humanity.\\n\\n<youtube-embed video=\\"zZ1456V7WlQ\\" />\\n\\n\\nList of Important Flamenco Forms for Guitar and their Compás:\\n=============================================================\\n\\nLearning the difference between flamenco forms can be challenging. However, once you become familiar with the forms you’ll have a much deeper appreciation for the music and culture of flamenco!\\n\\n**Here’s a list of most Important flamenco guitar Toques (Palos) and their Compás:**\\n\\n[**Soleares**](#soleares)  \\n[Alegrías](#alegrias)  \\n[Bulerías](#bulerias)  \\n[Soleá](#solea)\\n\\n[**Fandangos**](#fandangos)  \\n[Fandango de Huelva](#fandango-de-huelva)  \\n[Granaína/Granadinas](#granaina-granadinas)  \\n[Malagueña](#malaguena)\\n\\n[**Siguiriyas**](#siguiriyas)  \\n[Serranas](#serranas)\\n\\n[**Tangos**](#tangos)  \\n[Farruca](#farruca)  \\n[Garrotín](#garrotin)  \\n[Tarantas/Tarantos](#tarrantas-tarrantos)  \\n[Tientos](#tientos)\\n\\n[**Ida y Vuelta**](#ida-y-vuelta)  \\n[Colombianas](#colombianas)  \\n[Guajiras](#guajiras)  \\n[Rumba](#rumba)\\n\\n[**Other Toques**](#other-toques)  \\n[Sevillanas](#sevillanas)  \\n[Zambra](#zambra)  \\n[Zapateado](#zapateado)\\n\\nLearning Flamenco guitar is a riveting adventure, full of historical intrigue and technical challenges. For those of us who haven’t lived extensively in Spain or other places where flamenco music is an integral part of life, it can be difficult to know where to begin.\\n\\n**Perhaps the best introductory approach is to become familiar with the most common flamenco styles, known as _palo_s or _toques_** (from the guitarist perspective).\\n\\n![El Jaleo, a painting of flamenco dancer and guitarists by John Singer Sargent](./el_jaleo-painting.webp)\\n\\n> _El Jaleo,_ painting by John Singer Sargent\\n\\n### What does flamenco Toque or Palo mean?\\n\\nYou can consider a flamenco _toque_ or _palo_ as a musical form (compositional structure).\\n\\nEach form signifies the following:\\n\\n*   Rhythmic structure (compás)\\n*   Tempo\\n*   Key or Mode\\n*   Harmonic patterns (such as chord progressions)\\n*   Melodic phrasing elements that have been established, developed, and transmitted for hundreds of years\\n\\nSo how is this helpful? Simply put, saying the name of a form conveys a lot of meaning that otherwise takes a long time to describe.\\n\\nFor instance, without the name of a form, I would have to say “play this piece Andante in 3/4 time, E phrygian mode. You should place accents on beat 12, 3, 6, 8, and 10. The chord progression is…” blah blah blah.\\n\\nInstead, one can simply say this is a “Soleá” _toque_, and know generally what to expect!\\n\\nWhile flamenco guitar is usually improvisational based on the norms of a given toque, there are well-known compositions, familiar ‘licks’, and standard phrases that players will incorporate on a regular basis.¹\\n\\n### What’s the difference between Palo and Toque?\\n\\nFirst of all, **what’s the difference between a _palo_ and _toque_** in flamenco? The short answer is there is no practical difference other than _palo_ is a more general term to describe the classification system whereas **_toque_ is guitar-specific**.\\n\\nThe word _palo_ in Spanish has several definitions, but in this context a “branch” or “suit of cards” is the best translation as it refers to a categorization or classification system.\\n\\nThe word _toque_, meaning “to touch”, refers to the same exact system but from the guitarist perspective. Secondly, the term ‘_tocoar_‘ refers to a particular guitarist, and their particular repertoire and style of playing.\\n\\n![Paco de Lucía holding his flamenco guitar](./paco-de-lucia-flamenco.jpg)\\n\\n> Paco de Lucía, flamenco guitarist and composer\\n\\nThe Flamenco _palos_ system is extremely robust. In fact, there’s dozens of regional, historical, and of course musical distinctions to consider. Each of these forms has special nuances that inform a guitarist as to which form is which.\\n\\n### What are the three top-level flamenco form categories?\\n\\nThe codified Flamenco _palo_ system has been classified in many different ways.² However, the forms generally fall into three main categories:\\n\\n*   _**Cante**_ (singing)\\n*   _**Toque**_ (guitar playing)\\n*   _**Baile**_ (dance)\\n\\nSince our focus is on flamenco guitar (_toque_), the remainder of this article will refer to the Flamenco style as _toque_.\\n\\nTo get a better sense of what a _toque_ is, it’s worth referring to an excerpt by Juan Martín’s _El Arte Flamenco de la Guitarra_:\\n\\n> _“There is no exact English equivalent for ‘toque’…. but as you become more familiar with Flamenco you will soon find that the different toques are easily distinguished. Each has a characteristic and recurring pattern of beats and accents (i.e. its compás) and it also has its own kinds of key and harmonic structure. As a result, it has not only a particular rhythmic form but also a characteristic sound and range of expression.”_\\n> \\n> – Juan Martín, _El Arte Flamenco de la Guitarra_: Volume 1\\n\\nAs Martín so eloquently describes, once you become familiar with the various _toques_, their rhythmic structures (_compás_), harmonic and even melodic nuances, you’ll be able to quickly identify which style is being played–ultimately allowing you to understand and enjoy flamenco music in a more intimate and purposeful way!\\n\\nList of Common & Popular Toques\\n-------------------------------\\n\\nHere’s the list and basic description of the most common popular flamenco guitar toques and subcategories, classified by origin and _compás_:\\n\\nSoleares\\n--------\\n\\nMany people consider the Soleares (plural of [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/)) the most important and fundamental toque in flamenco guitar pedagogy.\\n\\nAs Juan Martín states, “_the rhythm of Soleares takes you deep into the heart of Flamenco, for it is a toque which embodies many of Flamenco’s most vital elements of rhythm and harmony and from which many other toques are derived. In Andalucía, every student of the flamenco guitar will start with it_.”\\n\\nLike many aspects of Flamenco, historical origins of the Soleares are uncertain and highly controversial. However, the Soleares became most well-known in the regions of Seville and Cadíz.\\n\\n**The basic compás for Soleares ([Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/)), the most widely used in all Flamenco music is:**\\n\\n![The basic Solea (Soleares) Compás rhythm cycle with accent marks on the 3, 6, 8, 10, and 12 beat. ](./solea-compas-accents-01.png)\\n\\n> Basic Soleares Compás, accents on beats 3, 6, 8, 10, and 12\\n\\n### Alegrías\\n\\n[Alegrías](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/alegrias/) (meaning joy) are a lively branch of Soleares (usually 100-180 BPM) that originated in Cadíz. [Alegrías](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/alegrias/) are in a major key (typically E major or A major), and are popular to perform with a dancer or as a solo.\\n\\nThe [Alegría](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/alegrias/) includes two sections for the dancer: the _silencio_, a minor key section; and the _escobilla_, which includes a virtuosic guitar solo and gradual increase in rhythm.\\n\\n### Bulerías\\n\\n[Bulerías](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/bulerias/) is the fastest branch of Soleares, with a lively, intense dissonance that compliments the advanced rhythmic structure of the _compás_. [Bulerías](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/bulerias/) are possibly the most popular, yet also the most virtuosic and demanding for flamenco guitarists. There are many variations of the [Bulería](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/bulerias/) _compás_ and accent patterns, which you can learn about [here](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/bulerias/).\\n\\nSoleá\\n--------\\n\\nSynonymous with the name Soleares, [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/) is a slow, solemn, and majestic form that likely comes from the Spanish word _soledad_, meaning solitude or loneliness. [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/) is known as the “Mother of Flamenco”.\\n\\nTragedy, death, and desperation are the common subject matter for the [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/) _cante_ (singers)– passion that you can also hear in the guitar playing. After a long night of dancing and singing lively toques, a guitarist may play a [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/) as a melancholy conclusion. When the shot glasses are dry and there’s a stillness in the air when sun is on the verge of rising, play the [Soleá](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/).\\n\\nFandangos\\n------------------\\n\\nCompared to other toques, [Fandangos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/) have a shorter rhythmic cycle that may feel more familiar to musicians trained in classical or other Western music styles. [Fandangos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/) were influenced from Arab-Moorish music, and Portuguese music.\\n\\nFlamenco [Fandangos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/) have a 3/4 rhythm (previously 6/8, now 3/4 or 3/8), with an accent on the first beat. Some [Fandangos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/) are very metric and appropriate for dance, whereas others have more of a free-form atmosphere (known as _en toque libre_ or “very freely”).\\n\\nFandango de Huelva\\n-----------\\n\\nWithin the [Fandango](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/) _toque_ are regional styles known as ‘_fandangos locales’_. Fandangos de Huelva is one such example.\\n\\nUnlike the _toque libre_ fandango styles, Fandangos de Huelva follows a strict _compás_ structure that can be danced to.\\n\\nYou can count the 12 beat _compás_ of Fandango de Huelva into beats of 3 as seen here:\\n\\n![Fandangos de Huelva 12 beat compás, silent beats are indicated with quarter rests.](./fandangos-de-huelva-compas-01.png)\\n\\n> Fandangos de Huelva Compás, silent beats indicated with quarter rests\\n\\n### Granaína/Granadinas\\n\\n[Granadinas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/granadinas/) or Granaína is a variant of the Granada fandangos. [Granaína](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/granadinas/) is relatively slow, with a freeing rhythm (_toque libre_) and rich embellishments that convey both a dreamlike and flowing quality. The [Granaína](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/granadinas/) is unique in that it’s in Phrygian mode based on the B note.\\n\\n### • Malagueña\\n\\n[Malagueñas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/malaguenas/) are another _toque libre_ fandango from the area of Málaga. The [Malagueña](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/malaguenas/) began as a relatively fast metric form in 6/8 time to accompany dance, then slowed the tempo down and added more embellishments in the 19th century.\\n\\nLater, guitarists like [Ramón Montoya (1879-1949)](https://en.wikipedia.org/wiki/Ram%C3%B3n_Montoya) began playing [Malagueñas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/malaguenas/) freely, while still incorporating the distinctive melodic phrases that gave rise to the form’s popularity.\\n\\nSiguiriyas\\n--------------------------\\n\\n[Siguiriyas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/seguiriyas/), also spelled _seguiriyas_, _siguerillas_, or _siguirillas_, is a deep, expressive style evoking a tragic feeling similar to the Soleá. Slow, somber, and sentimental, the [Siguiriyas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/seguiriyas/) _compás_ follows the 12 beat cycle but with a different accent pattern than the Soleares as seen here:\\n\\n![Siguiriya Compás with accent marks and simpler counting system](./seguiriya-compas-01.png)\\n\\n> Siguiriya Compás with accent marks and simpler counting system\\n\\n### Serranas\\n\\n[Serranas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/serranas/) originated as a melodious [Siguiriya](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/seguiriyas/) style in the rural Ronda (Málaga) area. The guitarist [Silverio Franconetti (1831-1889)](https://en.wikipedia.org/wiki/Silverio_Franconetti) developed the [Serrana](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/serranas/) form in his performance interpretations.\\n\\n[Serranas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/serranas/) have a characteristic emphasis on melodic “third” intervals, whereas most flamenco melodies are only minor second or major second apart.\\n\\nTangos\\n------\\n\\nFirst, it’s important to note that Flamenco Tangos are unrelated to the Latin-American form by the same name found in Argentina. Tangos are joyous, upbeat, and follow a relatively straightforward four-beat rhythm structure displayed in 4/4/ time.\\n\\nTangos came from the regions of Cadíz (most prominent), Jerez, Málaga, and Seville.\\n\\n### Farruca\\n\\nPeople believe that the [Farruca](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/farruca/) originated in Galicia, Spain. Men traditionally dance to this form with no singing component. The [Farruca](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/farruca/) is played in A minor, with a _compás_ of two measures of 4/4 time signature with accents on beats 1, 3, 5, and 7. You can see the accent pattern example below:\\n\\n![Farruca Compás  of 8 beat cycle with accented beats on 1, 3, 5, and 7.](./farruca-compas-01.png)\\n\\n> Farruca Compás and accented beats\\n\\n### Garrotín\\n\\nThe [Garrotín](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/garrotin/) is a festive and cheerful style in major mode, 2/4 time. The [Garrotín](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/garrotin/) originated in northern Spain near Asturias, and can include singing or dancing as well as guitar accompaniment. The renowned flamenco singer [La Niña de los Peines](https://en.wikipedia.org/wiki/La_Ni%C3%B1a_de_los_Peines) helped popularize the [Garrotín](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/garrotin/).\\n\\n### Tarantas/Tarantos\\n\\n[Tarantas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantas/) is a quintessential _toque libre_, with very lofty, repetitive _ligado_ phrases (hammer ons/pull offs). [Tarrantas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantas/) have a characteristic technique called _arrastre_, in which the right hand ring finger (a) drags from the high to the low strings in a quick successive manner (similar to an upstroke but a bit slower and disconnected). [Tarantas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantas/) are commonly notated with no measure bar lines to indicate the free manner in which you should play it.\\n\\nThe [**Tarantos**](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantos/) contrasts to the _toque libre_ [Tarantas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantas/), with a strong rhythmic feel structured in a _compás_ of 4s (2/4 or 4/4 time). The key signature and basic chord structure of [Tarantos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantos/) is the same as [Tarantas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tarantas/) (two sharps), so their harmonic relationship is clear and distinct.\\n\\n### Tientos\\n\\nThe Tientos is often danced, and is a bit slower than other tangos. However every [Tientos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tientos/) does speed up and become a tango by the end following the dance _escobilla_ sections. You can count the [Tientos](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/tientos/) four beat _compás_ with accents on beats 2 and 4.\\n\\nThere is a distinctive syncopation in the rhythm of the Tientos. You can see one of the simplest variations below:\\n\\n![Tientos Compás simple variation with syncopation.](./tientos-compas-01.png)\\n\\n> Basic Tientos Compás\\n\\nIda y Vuelta\\n------------\\n\\nThe Spanish expression Ida y Vuelta (“departure and return” or “round trip”) refers to _palos_ that were exported from Spain to the New World, particularly Cuba, where they evolved with African and Native American music influences. Immigrants later imported these forms back to Spain with a new flair.\\n\\n### Colombianas\\n\\nPeople credit the famous flamenco singer [Pepe Marchena](https://en.wikipedia.org/wiki/Pepe_Marchena) for creating the [Colombiana](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/colombianas/) (or _Colombina_) in 1931. The guitarist Ramon Montoya accompanied Marchena in recordings of the [Colombiana](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/colombianas/) the following year. [Colombianas](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/colombianas/) are in a major mode and follow a 4-beat _compás_ similar to the Rumba:\\n\\n![Flamenco Colombiana basic compás rhythm with accents. ](./colombiana-compas-01.png)\\n\\n> Basic Colombiana Compás\\n\\n### Guajiras\\n\\n[Guajiras](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/guajiras/) is a _toque_ based on a Cuban rural genre known as Punto Guajira Cubana. The [Guajira](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/guajiras/) is in a major mode, and follows a 12 beat _compás_ similar to the [Solea](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/solea/), with accents on beats 3, 6, 8, 10, and 12. [Guajiras](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/guajiras/) is in a major mode, with a characteristic descending melodic phrase in the bass from F# to F to E. For more info on the [Guajiras](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/guajiras/) _compás_ and examples, check out [this page](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/guajiras/).\\n\\n### Rumba\\n\\nThe [Rumba](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/), meaning “party”, originated in Havana, Cuba. The flamenco [Rumba](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/) became popular in the late 20th century by artists such as [Paco de Lucia](https://richterguitar.com/flamenco-guitar/flamenco-guitarists-and-albums/), and Rodrigo Y Gabriella and Gipsy Kings, among others. The [Rumba](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/) is in a minor mode, and notated in 4/4 time.\\n\\nHowever, you can also count the [Rumba’s](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/) rhythm as 8 beats (3+3+2) in a single measure. The [Rumba’s](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/) characteristic accents on beats 1, 4, and 7, give the [Rumba](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/rumba/) an exciting drive:\\n> \\n![Rumba 4/4 Rhythm with a cycle of 3+3+2 structure, including accents on 1, 4, and 7.](./rumba-rhythm-compas-01.png)\\n\\n> Basic Rumba Rhythmic Cycle\\n\\nOther Toques\\n------------\\n\\n### • Sevillanas\\n\\nSevillanas are a lively, popular toque with dance accompaniment, usually notated in 3/4 time similar to the _[Fandango](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/fandangos/)_ rhythm.\\n\\nPeople usually play the Sevillianas in a set of four short sequential pieces. In other words, a “Sevillianas performance” will have four or more short Sevillianas that immediately follow one another. Each one is in a different key or mode.\\n\\nSevillanas begin with a series of rhythmic _rasgueado_, followed by a brief melodic sequence (_salida_), followed by more _reasgueado_, then the full melody (_copla_). The third _copla_ is usually a slight variation from the previous two.\\n\\n### Zambra\\n\\n[Zambra](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zambra/) is a flamenco style that originated in Granada and Almeira. People believe that the [Zambra](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zambra/) is from earlier Moorish dance styles, and thus the melodies usually have an arabesque quality.\\n\\n[Zambras](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zambra/) are very metric, typically have a bouncy, alternating bass on strong beats. To play a [Zambra](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zambra/), guitarists will usually tune their guitar bass string down to drop D.\\n\\n### Zapateado\\n\\n[Zapateado](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zapateado/) is a lively style in 6/8 time and popular dance form (in Spanish, _zapato_ means shoe). The form originally appeared in Cadíz. However, one can find similar forms in Mexico (the _Zapateo_). Guitarists usually play the [Zapateado](https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/zapateado/) in C major, although [Sabicas](https://richterguitar.com/flamenco-guitar/flamenco-guitarists-and-albums/) has a unique well-known composition “[Zapateado in Re](https://www.youtube.com/watch?v=DyNwpxPjfYg)” (D major).\\n\\n##### Footnotes\\n\\n¹ Parallels can be drawn to jazz guitarists learning licks and solos of famous jazz predecessors. Contemporary players will often incorporate and/or elaborate on these phrases on the spot during a performance as an homage.\\n\\n² Another way to classify these styles is by mood: _cante jondo_ (serious and solemn), _cante chico_ (lighter and festive), and _cante intermedio_ (a style that doesn’t fit into either category).\\n\\nSources\\n====\\n\\n- https://richterguitar.com/flamenco-guitar/flamenco-guitar-toques-and-palos/","frontmatter":{"title":"Flamenco compás","description":"A variety of both contemporary and traditional musical styles typical of southern Spain","cover":"/media_files/cover/theory-rhythm-system-flamenco-flam.jpg","date":"2021-10-16T00:00:00.000Z","urls":["https://en.wikipedia.org/wiki/Flamenco","http://www.compas-flamenco.com/en/palos.html#Table"]},"url":"/theory/rhythm/system/flamenco/"},{"src":"---\\ntitle: Rhythm\\ndescription: Musical exploration of time\\ndate: 2021-10-15\\ncover: brent-ninaber.jpg\\nlinks:\\n  - https://en.wikipedia.org/wiki/Rhythm\\n  - https://en.wikipedia.org/wiki/Beat_(music)\\n---\\n\\n[What is Rhythm](./study/index.md) and how does the temporal dimension of music evolve? How we can conceptualize the human [Musical time feeling](./pulse/index.md)? How can we [Count fast enough](./counting/index.md) to understand the inner relations of different rhythmic patterns?\\n\\nThe main concept in modern Western rhythmic tradition is the [Meters](./meter/index.md) differentiation. While there's a plenty of other [national musical time organisation systems](./system/index.md), that may emphasize some other aspects of the temporal music feel, such as [Syncopation, swing and groove](./groove/index.md).\\n\\nAnd there's so much to explore in practice while learning basic [Drum rudiments](./rudiments/index.md) on your own.\\n\\n## Embodiment of music\\n\\n| Timescale   | Movement | Time        |\\n|-------------|----------|-------------|\\n| Phrase      | Breath   | 2-8 sec     |\\n| Pulse       | Walking  | 250-2000 ms |\\n| Note        | Fingers  | 100-1000 ms |\\n| Microrhythm | Talk     | 5-50 ms     |\\n","frontmatter":{"title":"Rhythm","description":"Musical exploration of time","date":"2021-10-15T00:00:00.000Z","cover":"/media_files/cover/theory-rhythm-brent-ninaber.jpg","links":["https://en.wikipedia.org/wiki/Rhythm","https://en.wikipedia.org/wiki/Beat_(music)"]},"url":"/theory/rhythm/"},{"src":"---\\ntitle: Counting\\ndescription: A system of regularly occurring sounds that serve to assist with the performance or audition of music by allowing the easy identification of the beat.\\ncover: claire-brear.jpg\\ndate: 2021-10-13\\n---\\n\\nCounting is a system of regularly occurring sounds that serve to assist with the performance or audition of music by allowing the easy identification of the beat. Commonly, this involves verbally counting the beats in each measure as they occur, whether there be 2 beats, 3 beats, 4 beats, or even 5 beats. In addition to helping to normalize the time taken up by each beat, counting allows easier identification of the beats that are stressed. Counting is most commonly used with rhythm (often to decipher a difficult rhythm) and form and often involves subdivision.\\n\\n## Introduction to Systems - Numbers and Syllables\\n\\nThe method involving numbers may be termed count chant, \\"to identify it as a unique instructional process.\\"\\n\\nIn lieu of simply counting the beats of a measure, other systems can be used which may be more appropriate to the particular piece of music. Depending on the tempo, the divisions of a beat may be vocalized as well (for slower times), or skipping numbers altogether (for faster times). As an alternative to counting, a metronome can be used to accomplish the same function.\\n\\nTriple meter, such as 3/4, is often counted **1 2 3**, while compound meter, such as 6\\n8, is often counted in two and subdivided **One-and-ah-Two-and-ah** but may be articulated as **One-la-lee-Two-la-lee**.\\n\\nFor each subdivision employed a new syllable is used. For example, sixteenth notes in 4/4 are counted **1 e & a 2 e & a 3 e & a 4 e & a**, using numbers for the quarter note, \\"&\\" for the eighth note, and \\"e\\" and \\"a\\" for the sixteenth note level.\\n\\nTriplets may be counted **1 tri ple 2 tri ple 3 tri ple 4 tri ple** and sixteenth note triplets **1 la li + la li 2 la li + la li**. Quarter note triplets, due to their different rhythmic feel, may be articulated differently as **1 dra git 3 dra git**.\\n\\nRather than numbers or nonsense syllables, a random word may be assigned to a rhythm to clearly count each beat. An example is with a triplet, so that a triplet subdivision is often counted **\\"tri-po-let\\"**. The Kodály Method uses **\\"Ta\\"** for quarter notes and **\\"Ti-Ti\\"** for eighth notes. For sextuplets simply say triplet twice, while quintuplets may be articulated as **\\"un-i-vers-i-ty\\"**. In some approaches, \\"rote-before-note\\", the fractional definitions of notes are not taught to children until after they are able to perform syllable or phrase-based versions of these rhythms.\\n\\n> \\"However the counting may be syllabized, the important skill is to keep the pulse steady and the division exact.\\" – Alfred Blatter 2007\\n\\n## Numbers Systems\\n\\n### Numbers\\n\\nUltimately, musicians count using **numbers**, **“ands”** and vowel sounds. Downbeats within a measure are called **1, 2, 3…** Upbeats are represented with a plus sign and are called “and” (i.e. **1 + 2 +**), and further subdivisions receive the sounds “ee” and “uh” (i.e. **1 e + a 2 e + a**). Musicians do not agree on what to call triplets: some simply say the word triplet (“**trip-a-let**”), or another three-syllable word (like pineapple or elephant) with an antepenultimate accent. Some use numbers along with the word triplet (i.e. “**1-trip-let**”). Still others have devised sounds like “ah-lee” or “la-li” added after the number (i.e. **1-la-li, 2-la-li** or **1-tee-duh, 2-tee-duh**).\\n\\n### Traditional American system\\n\\nCounts the beat **number** on the tactus, **&** on the half beat, and **n-e-&-a** for four sixteenth notes, **n-&-a** for a triplet or three eighth notes in compound meter, where n is the beat number.\\n\\n### Eastman System\\n\\nThe beat **numbers** are used for the tactus, **te** for the half beat, and **n-ti-te-ta** for four sixteenths. Triplets or three eighth notes in compound meter are **n-la-li** and six sixteenth notes in compound meter is **n-ta-la-ta-li-ta**.\\n\\n### Froseth System\\n\\nCounting system using **n-ne**, **n-ta-ne-ta**, **n-na-ni**, and **n-ta-na-ta-ni-ta**. All three systems have internal consistency for all divisions of the beat except the tactus, which changes according to the beat number.\\n\\n## Syllables Systems\\n\\nSyllables systems are categorized as \\"Beat Function Systems\\" - when the tactus (pulse) has certain syllable A, and the half-beat is always certain syllable B, regardless of how the rest of the measure is filled out.\\n\\n### French System\\n\\nThe French \\"Time-Names system\\", also called the \\"Galin-Paris-Cheve system\\", originally used French words. Toward the middle of the nineteenth century the American musician Lowell Mason (affectionately named the \\"Father of Music Education\\") adapted the French Time-Names system for use in the United States, and instead of using the French names of the notes, he replaced these with a system that identified the value of each note within a meter and the measure.\\n\\n- Whole Note: **Ta-a-a-a**\\n- Half Note: **Ta-a**\\n- Quarter Note: **Ta**\\n- 2 Eighth Note: **Ta Te**\\n- 4 Sixteenth Notes: **Tafa Tefe**\\n\\n### Kodály Method\\n\\n- Whole Note: **Ta-a-a-a** or **ta-o-o-o**\\n- Half Note: **Ta-a** or **ta-o**\\n- Quarter Note: **Ta**\\n- 1 Eighth Note: **Ti**\\n- 2 Eighth Notes: **Ti-Ti**\\n- 4 Sixteenth Notes: **Ti-ri-ti-ri**\\n- Eighth Note Triplet: **Tri-o-la**\\n- Eighth Note followed by a Quarter Note and another Eighth Note: **Syn-co-pa**\\n\\n### Ward Method\\n\\n- Whole Note: **Lang-ng-ng-ng**\\n- Half Note: **Lang-ng**\\n- Quarter Note: **La**\\n- 2 Eighth Notes: **Lira**\\n- Dotted Quarter followed by Eighth: **La-ira**\\n\\n### Edwin Gordon System\\n\\n#### Usual Duple Meter\\n\\n- Whole Note: **Du-u-u-u**\\n- Half Note: **Du-u**\\n- Quarter Note: **Du**\\n- 2 Eighth Notes: **Du-De**\\n- 4 Sixteenth Notes: **Du-Ta-De-Ta**\\n\\n#### Usual Triple Meter\\n\\n- Dotted Quarter Note: **Du**\\n- 3 Eighth Notes: **Du-Da-Di**\\n- 6 Sixteenth Notes: **Du-Ta-Da-Ta-Di-Ta**\\n\\nUnusual meters pair the duple and triple meter syllables, and employ the \\"b\\" consonant.\\n\\n### Takadimi\\n\\nThe beat is always called ta. In simple meters, the division and subdivision are always **ta-di** and **ta-ka-di-mi**. Any note value can be the beat, depending on the time signature. In compound meters (wherein the beat is generally notated with dotted notes), the division and subdivision are always **ta-ki-da** and **ta-va-ki-di-da-ma**.\\n\\nThe note value does not receive a particular name; the note’s position within the beat gets the name. This system allows children to internalize a steady beat and to naturally discover the subdivisions of beat, similar to the **down-ee-up-ee** system.\\n\\n#### Examples of Simple Meter Rhythms (Takadimi)\\n\\n- Whole Note = **ta-a-a-a**\\n- Half Note = **Ta-a**\\n- Quarter Note = **Ta**\\n- Two Eighth Notes = **Ta-Di**\\n- Four Sixteenth Notes = **Ta-Ka-Di-Mi**\\n- Eighth Rest + Eighth Note = **X-Di**\\n- Eighth Note + Two Sixteenth Notes = **Taaa-Di-Mi**\\n- Two Sixteenth Notes + Eighth Note = **Ta-Ka-Diii**\\n\\n#### Examples of Compound Meter Rhythms (Takadimi)\\n\\n- Dotted Whole Note = **Ta-a-a-a**\\n- Dotted Half Note = **Ta-a**\\n- Dotted Quarter Note = **Ta**\\n- Three Eighth Notes Beamed Together = **Ta-Ki-Da**\\n- Eighth Note + Eighth Rest + Eighth Note = **Ta-X-Da**\\n- Six Sixteenth Notes = **Ta-Va-Ki-Di-Da-Ma**\\n- Eighth Note + Four Sixteenth Notes = **Ta-aa-Ki-Di-Da-Ma**\\n- Four Sixteenth Notes + Eighth Note = **Ta-Va-Ki-Di-Da-aa**\\n- Two Sixteenth Notes + Eighth Note + Two Sixteenth Notes = **Ta-Va-Ki-ii-Da-Ma**\\n\\n<youtube-embed video=\\"8gNM51Q55XY\\" />\\n\\n### Takatiki\\n\\nThis is a beat-function system used by some Kodály teachers that was developed by Laurdella Foulkes-Levy, and was designed to be easier to say than Gordon's system or the Takadimi system while still honoring the beat-function. The beat is said as \\"Ta\\" in both duple and triple meters, but the beat divisions are performed differently between the two meters. The \\"t\\" consonant always falls on the main beat and beat division, and the \\"k\\" consonant is always when the beat divides again. Alternating \\"t\\" and \\"k\\" in quick succession is easy to say, as they fall on two different parts of the tongue, making it very easy to say these syllables at a fast tempo (much like tonguing on recorder or flute). It is also a logical system since it always alternates between the same two consonants.\\n\\n#### Duple Meter\\n\\n- Whole Note: **Ta-a-a-a** (no added accent on each beat)\\n- Half Note: **Ta-a** (no added accent on each beat)\\n- Quarter Note: **Ta**\\n- 2 Eighth Notes: **Ta-Ti**\\n- 4 Sixteenth Notes: **Ta-Ka-Ti-Ki**\\n- Sixteenth Note Combinations: **Ta---Ti-Ki**, **Ta-Ka-Ti---**, **Ta-Ka---Ki**\\n- Eighth Note followed by a Quarter Note and another Eighth Note: **Ta-Ti---Ti**\\n- Eighth Note Triplet: **Ta-Tu-Te**\\n- Rests: (silent)\\n\\n#### Triple Meter\\n\\n- Dotted Half Note: **Ta-a-a-** (no added accent on each beat)\\n- Dotted Quarter Note : **Ta-**\\n- 3 Eighth Notes: **Ta-Tu-Te**\\n- Eighth Note Combinations: **Ta----Te**, **Ta-Tu-----**\\n- 6 Sixteenth Notes: **Ta-Ka-Tu-Ku-Te-Ke**\\n- Sixteenth Note Combinations: **Ta--Tu-Ku-Te**, **Ta-Ka-Tu---Te**, **Ta--Tu--Te-Ke**\\n- Rests: (silent)\\n\\n### Ta Titi\\n\\n- Whole Note: **Toe / ta-ah-ah-ah**\\n- Dotted Half Note: **Toom / ta-ah-ah**\\n- Half Note: **Too / ta-ah**\\n- Dotted Quarter Note: **Tom / ta-a**\\n- Quarter Note: **Ta**\\n- 1 Eighth Note: **Ti**\\n- 2 Eighth Notes: **Ti-Ti**\\n- Eighth Note Triplet: **Tri-o-la**\\n- 2 Sixteenth Notes: **Tika / Tiri**\\n- 4 Sixteenth Notes: **TikaTika / Tiritiri**\\n- 2 Sixteenth Notes and 1 Eighth Note: **Tika-Ti / Tiri-Ti**\\n- 1 Eighth Note and 2 Sixteenths: **Ti-Tika / Ti-Tiri**\\n\\nThis system allows the value of each note to be clearly represented no matter its placement within the beat/measure\\n","frontmatter":{"title":"Counting","description":"A system of regularly occurring sounds that serve to assist with the performance or audition of music by allowing the easy identification of the beat.","cover":"/media_files/cover/theory-rhythm-counting-claire-brear.jpg","date":"2021-10-13T00:00:00.000Z"},"url":"/theory/rhythm/counting/"},{"src":"---\\ntitle: African cross-beats\\ndescription: Combinations of two and more rhuthms as a basis of music\\ncover: african-drums.jpg\\ndate: 2021-10-13\\n---\\n\\n## Cross-beat\\n\\nIn music, a [cross-beat](https://en.wikipedia.org/wiki/Cross-beat) or cross-rhythm is a specific form of [polyrhythm](https://en.wikipedia.org/wiki/Polyrhythm). The term cross rhythm was introduced in 1934 by the musicologist Arthur Morris Jones (1889–1980). It refers to when the rhythmic conflict found in polyrhythms is the basis of an entire musical piece.\\n\\n## Etymology\\n\\nThe term \\"cross rhythm\\" was introduced in 1934 by the musicologist Arthur Morris Jones (1889–1980), who, with Klaus Wachsmann, took-up extended residence in Zambia and Uganda, respectively, as missionaries, educators, musicologists, and museologists.\\n\\n> Cross-rhythm. A rhythm in which the regular pattern of accents of the prevailing meter is contradicted by a conflicting pattern and not merely a momentary displacement that leaves the prevailing meter fundamentally unchallenged.  \\n> — The New Harvard Dictionary of Music (1986: 216)\\n\\n## African music\\n\\n### One main system\\n\\nAfrican cross-rhythm is most prevalent within the greater Niger-Congo linguistic group, which dominates the continent south of the Sahara Desert. (Kubik, p. 58) Cross-rhythm was first identified as the basis of sub-Saharan rhythm by A.M. Jones. Later, the concept was more fully explained in the lectures of Ewe master drummer and scholar C.K. Ladzekpo, and in the writings of David Locke. Jones observes that the shared rhythmic principles of Sub-Saharan African music traditions constitute one main system. Similarly, Ladzekpo affirms the profound homogeneity of sub-Saharan African rhythmic principles. In Sub-Saharan African music traditions (and many of the diaspora musics) cross-rhythm is the generating principle; the meter is in a permanent state of contradiction.\\n\\n### An embodiment of the people\\n\\n> At the center of a core of rhythmic traditions and composition is the technique of cross-rhythm. The technique of cross-rhythm is a simultaneous use of contrasting rhythmic patterns within the same scheme of accents or meter … By the very nature of the desired resultant rhythm, the main beat scheme cannot be separated from the secondary beat scheme. It is the interplay of the two elements that produces the cross-rhythmic texture.  \\n> — Ladzekpo, a: \\"Myth\\"\\n\\n> From the philosophical perspective of the African musician, cross-beats can symbolize the challenging moments or emotional stress we all encounter. Playing cross-beats while fully grounded in the main beats, prepares one for maintaining a life-purpose while dealing with life’s challenges. Many sub-Saharan languages do not have a word for rhythm, or even music. From the African viewpoint, the rhythms represent the very fabric of life itself; they are an embodiment of the people, symbolizing interdependence in human relationships.  \\n> — Clave Matrix, p. 21\\n\\n## Cross-rhythmic ratios\\n\\n### 3:2\\n\\nThe cross-rhythmic ratio three-over-two (3:2) or vertical [hemiola](https://en.wikipedia.org/wiki/Hemiola), is the most significant rhythmic cell found in sub-Saharan rhythms. The following measure is evenly divided by three beats and two beats. The two cycles do not share equal status though. The two bottom notes are the primary beats, the ground, the main temporal referent. The three notes above are the secondary beats. Typically, the dancer's feet mark the primary beats, while the secondary beats are accented musically.\\n\\n> We have to grasp the fact that if from childhood you are brought up to regard beating 3 against 2 as being just as normal as beating in synchrony, then you develop a two dimensional attitude to rhythm... This bi-podal conception is... part of the African's nature  \\n> — Jones (1959: 102)\\n\\nNovotney observes: \\"The 3:2 relationship (and [its] permutations) is the foundation of most typical polyrhythmic textures found in West African musics.\\" 3:2 is the generative or theoretic form of sub-Saharan rhythmic principles. Agawu succinctly states: \\"[The] resultant (3:2) rhythm holds the key to understanding … there is no independence here, because 2 and 3 belong to a single Gestalt.\\"\\n\\nAfrican Xylophones such as the balafon and gyil play cross-rhythms, which are often the basis of ostinato melodies. In the following example, a Ghanaian gyil sounds the three-against-two cross-rhythm. The left hand (lower notes) sounds the two main beats, while the right hand (upper notes) sounds the three cross-beats. (Clave Matrix p. 22)\\nGhanaian gyil\\nGhanaian gyil sounds 3:2 cross-rhythm. About this soundPlay (help·info)\\n\\n### 6:4\\n\\n#### The primary cycle of four beats\\n\\nA great deal of African music is built upon a cycle of four main beats. This basic musical period has a bipartite structure; it is made up of two cells, consisting of two beats each. Ladzekpo states: \\"The first most useful measure scheme consists of four main beats with each main beat measuring off three equal pulsations [12/8] as its distinctive feature … The next most useful measure scheme consists of four main beats with each main beat flavored by measuring off four equal pulsations [4/4].\\" (b: \\"Main Beat Schemes\\") The four-beat cycle is a shorter period than what is normally heard in European music. This accounts for the stereotype of African music as \\"repetitive.\\" (Kubik, p. 41) A cycle of only two main beats, as in the case of 3:2, does not constitute a complete primary cycle. (Kubik, Vol. 2, p. 63) Within the primary cycle there are two cells of 3:2, or, a single cycle of six-against-four (6:4). The six cross-beats are represented below as quarter-notes for visual emphasis.\\nSix-against-four cross-rhythm (note that this is identical to the three-over-two cross-rhythm above, played twice).\\n\\n> Interacting the four recurrent triple structure main beat schemes (four beat scheme) simultaneously with the six recurrent two pulse beat schemes (six beat scheme) produces the first most useful cross rhythmic texture in the development of Anlo-Ewe dance-drumming.  \\n> — Ladzekpo (c: \\"Six Against Four\\")\\n\\nThe following notated example is from the kushaura part of the traditional mbira piece \\"Nhema Mussasa.\\" The left hand plays the ostinato \\"bass line,\\" built upon the four main beats, while the right hand plays the upper melody, consisting of six cross-beats. The composite melody is an embellishment of the 6:4 cross-rhythm. (Clave Matrix p. 35)\\n\\n### 3:4\\n\\nIf every other cross-beat is sounded, the three-against-four (3:4) cross-rhythm is generated. The \\"slow\\" cycle of three beats is more metrically destabilizing and dynamic than the six beats. The Afro-Cuban rhythm abakuá (Havana-style) is based on the 3:4 cross-rhythm. The three-beat cycle is represented as half-notes in the following example for visual emphasis.\\n\\n> In contrast to the four main beat scheme, the rhythmic motion of the three beat scheme is slower. A simultaneous interaction of these two beat schemes with contrasting rhythmic motions produces the next most useful cross rhythmic texture in the development of sub-Saharan dance-drumming. The composite texture of the three-against-four cross rhythm produces a motif covering a length of the musical period. The motif begins with the component beat schemes coinciding and continues with the beat schemes in alternate motions thus showing a progression from a \\"static\\" beginning to a \\"dynamic\\" continuation  \\n> — Ladzekpo (\\"Three Against Four\\")\\n\\nThe following pattern is an embellishment of the three-beat cycle, commonly heard in African music. It consists of three sets of three strokes each.\\n\\n### 1.5:4 (or 3:8)\\n\\nEven more metrically destabilizing and dynamic than 3:4, is the one and a half beat-against-four (1.5:4) cross-rhythm. Another way to think of it is as three \\"very slow\\" cross-beats spanning two main beat cycles (of four beats each), or three beats over two periods (measures), a type of macro \\"hemiola.\\" In terms of the beat scheme comprising the complete 24-pulse cross-rhythm, the ratio is 3:8. The three cross-beats are shown as whole notes below for visual emphasis.\\n\\nThe 1.5:4 cross-rhythm is the basis for the open tone pattern of the enú (large batá drum head) for the Afro-Cuban rhythm changó (Shango). It is the same pattern as the previous figure, but the strokes occur at half the rate.\\n\\nThe following bell pattern is used in the Ewe rhythm kadodo. The pattern consists of three modules—two pairs of strokes, and a single stroke. The three single stroke are muted. The pattern is another embellishment of the 1.5:4 cross-rhythm.\\n\\n### 4:3\\n\\nWhen duple pulses (4/1) are grouped in sets of three, the four-against-three (4:3) cross-rhythm is generated. The four cross-beats cycle every three main beats. In terms of cross-rhythm only, this is the same as having duple cross-beats in a triple beat scheme, such as 3/4 or 6/4. The pulses on the top line are grouped in threes for visual emphasis.\\n\\nHowever, this 4:3 is within a duple beat scheme, with duple (quadruple) subdivisions of the beats. Since the musical period is a cycle of four main beats, the 4:3 cross-rhythm significantly contradicts the period by cycling every three main beats. The complete cross-beat cycle is shown below in relation to the key pattern known in Afro-Cuban music as clave. (Rumba, p. xxxi) The subdivisions are grouped (beamed) in sets of four to reflect the proper metric structure. The complete cross-beat cycle is three claves in length. Within the context of the complete cross-rhythm, there is a macro 4:3—four 4:3 modules-against-three claves. Continuous duple-pulse cross-beats are often sounded by the quinto, the lead drum in the Cuban genres rumba and conga. (Rumba, pps. 69–86)\\n\\n> While 3:2 pervades ternary music, quaternary music seldom uses tuplets; instead, a set of dotted notes may temporarily make 2:3 and 4:3 temporal structures.  \\n> — Locke (\\"Metric Matric\\")\\n\\n### Duple-pulse correlative of 3:2\\n\\nIn sub-Saharan rhythm the four main beats are typically divided into three or four pulses, creating a 12-pulse (12/8), or 16-pulse (4/1) cycle. (Ladzekpo, b: \\"Main Beat Scheme\\") Every triple-pulse pattern has its duple-pulse correlative; the two pulse structures are two sides of the same coin. Cross-beats are generated by grouping pulses contrary to their given structure, for example: groups of two or four in 12\\n8 or groups of three or six in 4/4. (Rumba, p. 180) The duple-pulse correlative of the three cross-beats of the hemiola, is a figure known in Afro-Cuban music as tresillo. Tresillo is a Spanish word meaning ‘triplet’—three equal notes within the same time span normally occupied by two notes. As used in Cuban popular music, tresillo refers to the most basic duple-pulse rhythmic cell. The pulse names of tresillo and the three cross-beats of the hemiola are identical: one, one-ah, two-and.\\n\\nThe composite pattern of tresillo and the main beats is commonly known as the habanera, congo, tango-congo, or tango. The habanera rhythm is the duple-pulse correlative of the vertical hemiola (above). The three cross-beats of the hemiola are generated by grouping triple pulses in twos: 6 pulses ÷ 2 = 3 cross-beats. Tresillo is generated by grouping duple pulses in threes: 8 pulses ÷ 3 = 2 cross-beats (consisting of three pulses each), with a remainder of a partial cross-beat (spanning two pulses). In other words, 8 ÷ 3 = 2, r2. Tresillo is a cross-rhythmic fragment. It contains the first three cross-beats of 4:3. (Rumba, p. xxx)\\n\\n## Cross-rhythm, not polymeter\\n\\nEarly ethnomusicological analysis often perceived African music as polymetric. Pioneers such as A.M. Jones and Anthony King identified the prevailing rhythmic emphasis as metrical accents (main beats), instead of the contrametrical accents (cross-beats) they in fact are. Some of their music examples are polymetric, with multiple and conflicting main beat cycles, each requiring its own separate time signature. King shows two Yoruba dundun pressure drum (\\"talking drum\\") phrases in relation to the five-stroke standard pattern, or \\"clave,\\" played on the kagano dundun (top line). The standard pattern is written in a polymetric 7/8 + 5/8 time signature. One dundun phrase is based on a grouping of three pulses written in 3/8, and the other, a grouping of four pulses written in 4/1. Complicating the transcription further, one polymetric measure is offset from the other two.\\n\\n> African music is often characterized as polymetric, because, in contrast to most Western music, African music cannot be notated without assigning different meters to the different instruments of an ensemble  \\n> — Chernoff (1979: 45).\\n\\nMore recent writings represent African music as cross-rhythmic, within a single meter.\\n\\n> Of the many reasons why the notion of polymeter must be rejected, I will mention three. First, if polymeter were a genuine feature of African music, we would expect to find some indication of its pertinence in the discourses and pedagogical schemes of African musicians, carriers of the tradition. As far as I know, no such data is available...Second, because practically all the ensemble music in which polymeter is said to be operative in dance music, and given the grounding demanded by choreography, it is more likely that these musics unfold within polyrhythmic matrices in single meters rather than in ... \\"mixed\\" meters ... Third, decisions about how to represent drum ensemble music founder on the assumption, made most dramatically by Jones, that accents are metrical rather than phenomenal...phenomenal accents play a more important role in African music than metrical accents. Because meter and grouping are distinct, postulating a single meter in accordance with the dance allows phenomenal or contrametric accents to emerge against a steady background. Polymeter fails to convey the true accentual structure of African music insofar as it creates the essential tension between a firm and stable background and a fluid foreground  \\n> — Agawu (2003: 84, 85)\\n\\n> [The] term ‘polymetric’ is only applicable to a very special kind of phenomenon. If we take \\"metre\\" in its primary sense of metrum (the metre being the temporal reference unit), ‘polymetric’ would describe the simultaneous unfolding of several parts in a single work at different tempos so as not to be reducible to a single metrum. This happens in some modern music, such as some of Charles Ives' works, Elliott Carter’s Symphony, B.A. Zimmermann’s opera \\"Die Soldaten,\\" and Pierre Boulez’s \\"Rituel.\\" Being polymetric in the strict sense, these works can only be performed with several simultaneous conductors\\n> — Arom (1991: 205)\\n\\nWhen written within a single meter, we see that the dundun in the second line sounds the main beats, and the subdivision immediately preceding it. The first cell (half measure) of the top line is a hemiola. The two dunduns shown in the second and third lines sound an embellishment of the three-over-four (3:4) cross-rhythm—expressed as three pairs of strokes against four pairs of strokes. (Clave Matrix p. 216)\\n\\n### Adaptive instruments\\n\\nSub-Saharan instruments are constructed in a variety of ways to generate cross-rhythmic melodies. Some instruments organize the pitches in a uniquely divided alternate array – not in the straight linear bass to treble structure that is so common to many western instruments such as the piano, harp, and marimba.\\n\\nLamellophones including mbira, mbila, mbira huru, mbira njari, mbira nyunga, marimba, karimba, kalimba, likembe, and okeme. These instruments are found in several forms indigenous to different regions of Africa and most often have equal tonal ranges for right and left hands. The kalimba is a modern version of these instruments originated by the pioneer ethnomusicologist Hugh Tracey in the early 20th century which has over the years gained world-wide popularity.\\n\\nChordophones, such as the West African kora, and Doussn'gouni, part of the harp-lute family of instruments, also have this African separated double tonal array structure. Another instrument, the Marovany from Madagascar is a double sided box zither which also employs this divided tonal structure. The Gravikord is a new American instrument closely related to both the African kora and the kalimba. It was created to exploit this adaptive principle in a modern electro-acoustic instrument.\\n\\nOn these instruments one hand of the musician is not primarily in the bass nor the other primarily in the treble, but both hands can play freely across the entire tonal range of the instrument. Also the fingers of each hand can play separate independent rhythmic patterns and these can easily cross over each other from treble to bass and back, either smoothly or with varying amounts of syncopation. This can all be done within the same tight tonal range, without the left and right hand fingers ever physically encountering each other. These simple rhythms will interact musically to produce complex cross rhythms including repeating on beat/off beat pattern shifts that would be very difficult to create by any other means. This characteristically African structure allows often simple playing techniques to combine with each other and produce cross-rhythmic music of great beauty and complexity.\\n\\n## Jazz\\n\\nThe New Harvard Dictionary of Music calls swing \\"an intangible rhythmic momentum in jazz,\\" adding that \\"swing defies analysis; claims to its presence may inspire arguments.\\" The only specific description offered is the statement that \\"triplet subdivisions contrast with duple subdivisions.\\" The argument could be made that by nature of its simultaneous triple and duple subdivisions, swing is fundamentally a form of polyrhythm. However, the use of true systematic cross-rhythm in jazz did not occur until the second half of the twentieth century.\\n\\n### 3:2 (or 6:4)\\n\\nIn 1959 Mongo Santamaria recorded \\"Afro Blue,\\" the first jazz standard built upon a typical African 3:2 cross-rhythm. The song begins with the bass repeatedly playing 3 cross-beats per each measure of 6/8 (3:2), or 6 cross-beats per 12/8 measure (6:4). The following example shows the original ostinato \\"Afro Blue\\" bass line. The slashed noteheads are not bass notes, but are shown to indicate the main beats, where you would normally tap your foot to \\"keep time.\\"\\n\\n### 3:4\\n\\nOn the original \\"Afro Blue,\\" drummer Willie Bobo played an abakuá bell pattern on a snare drum, using brushes. This cross-rhythmic figure divides the twelve-pulse cycle into three sets of four pulses. Since the main beats (four sets of three pulses) are present whether sounded or not, this bell pattern can be considered an embellishment of the three-against-four (3:4) cross-rhythm. Bobo used this same pattern and instrumentation on the Herbie Hancock jazz-descarga \\"Succotash.\\"\\n\\n### 2:3\\n\\nIn 1963 John Coltrane recorded \\"Afro Blue\\" with the great jazz drummer Elvin Jones. Jones inverted the metric hierarchy of Santamaria's composition, performing it instead as duple cross-beats over a 3/4 \\"jazz waltz\\" (2:3). This 2:3 in a swung 3/4 is perhaps the most common example of overt cross-rhythm in jazz.\\n\\n## Duple-pulse correlative of 3:2\\n\\nThe Wayne Shorter composition \\"Footprints\\" may have been the first overt expression of the 6:4 cross-rhythm (two cycles of 3:2) used by a straight ahead jazz group. On the version recorded on Miles Smiles by Miles Davis, the bass switches to 4/4 at 2:20. The 4/4 figure is known as tresillo in Latin music and is the duple-pulse correlative of the cross-beats in triple-pulse. Throughout the piece, the four main beats are maintained.\\n\\nIn recent decades, jazz has incorporated many different types of complex cross-rhythms, as well as other types of polyrhythms.\\n\\n<youtube-embed video=\\"lVPLIuBy9CY\\" />\\n","frontmatter":{"title":"African cross-beats","description":"Combinations of two and more rhuthms as a basis of music","cover":"/media_files/cover/theory-rhythm-system-crossbeat-african-drums.jpg","date":"2021-10-13T00:00:00.000Z"},"url":"/theory/rhythm/system/crossbeat/"},{"src":"---\\ntitle: Meters\\ndescription: Recurring patterns of accents\\n\\ndate: 2021-10-12\\n---\\n\\nBasic meters are:\\n\\n- [Simple](./simple/index.md)\\n- [Complex](./complex/index.md)\\n- [Compound](./compound/index.md)\\n\\nAnd [Double time](./time/index.md) makes it even more fun.","frontmatter":{"title":"Meters","description":"Recurring patterns of accents","date":"2021-10-12T00:00:00.000Z"},"url":"/theory/rhythm/meter/"},{"src":"---\\ntitle: Simple meters\\ndescription: Rhythmic meters\\ndate: 2021-10-12\\n---\\n\\n<script setup>\\nimport rhythm from '#/db/rhythm/meters.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"rhythm.simple\\" />\\n\\nSimple metre (or simple time) is a metre in which each beat of the bar divides naturally into two (as opposed to three) equal parts. The top number in the time signature will be 2, 3, 4, 5, etc.\\n\\nSimple time signatures consist of two numerals, one stacked above the other:\\n\\n- The lower numeral indicates the note value that represents one beat (the beat unit). This number is typically a power of 2.\\n- The upper numeral indicates how many such beats constitute a bar.\\n\\nFor instance, 2/4 means two quarter-note (crotchet) beats per bar, while 3/8 means three eighth-notes (quavers) per bar, which are beats at slower tempos (but at faster tempos, 3/8 becomes compound time, with one beat per bar). The most common simple time signatures are 2/4, 3/4, and 4/4.\\n\\n# Simple time\\n\\n## Simple duple time\\n\\nTwo or four beats to a bar, each divided by two, the top number being \\"2\\" or \\"4\\" (2/4, 2/8, 2/2 ... 4/4, 4/8, 4/2 ...). When there are four beats to a bar, it is alternatively referred to as \\"quadruple\\" time.\\n\\n### 2/2\\n\\nAlla breve, cut time: Used for marches and fast orchestral music.\\n\\n### 2/4\\n\\nUsed for polkas, galops, and marches.\\n\\n## Simple triple time\\n\\nThree beats to a bar, each divided by two, the top number being \\"3\\" (3/4, 3/8, 3/2 ...)\\n\\n### 3/4\\n\\nIn the time signature 3/4, each bar contains three quarter-note beats, and each of those beats divides into two eighth notes, making it a simple metre. More specifically, it is a simple triple metre because there are three beats in each measure; simple duple (two beats) or simple quadruple (four) are also common metres.\\n\\nUsed for waltzes, minuets, scherzi, polonaises, mazurkas, country & western ballads, R&B, sometimes used in pop\\n\\n### 3/8\\n\\nAlso used for the above but usually suggests higher tempo or shorter hypermeter\\n\\n## Simple quadruple time\\n\\n### 4/4\\n\\nCommon time: Widely used in most forms of Western popular music. Most common time signature in rock, blues, country, funk, and pop.\\n","frontmatter":{"title":"Simple meters","description":"Rhythmic meters","date":"2021-10-12T00:00:00.000Z"},"url":"/theory/rhythm/meter/simple/"},{"src":"---\\ntitle: Compound meters\\ndescription: Rhythmic meters\\ndate: 2021-10-10\\n---\\n\\n<script setup>\\n  import rhythm from '#/db/rhythm/meters.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"rhythm.compound\\" />\\n\\nCompound metre (or compound time), is a metre in which each beat of the bar divides naturally into three equal parts. That is, each beat contains a triple pulse. The top number in the time signature will be 6, 9, 12, 15, 18, 24, etc.\\n\\nCompound metres are written with a time signature that shows the number of divisions of beats in each bar as opposed to the number of beats. For example, compound duple (two beats, each divided into three) is written as a time signature with a numerator of six, for example, 6/8. Contrast this with the time signature 3/4, which also assigns six eighth notes to each measure, but by convention connotes a simple triple time: 3 quarter-note beats.\\n\\n### 6/8\\n\\nDuple time - 2 strong beats in a bar dividing into 3 eighth notes\\n\\nAlthough 3/4 and 6/8 are not to be confused, they use bars of the same length, so it is easy to \\"slip\\" between them just by shifting the location of the accents.\\n\\n### 9/8\\n\\nCompound tripple time - 3 strong beats in a bar dividing into 3 eighth notes\\n\\n### 12/8\\n\\nCompound quadruple time - 4 strong beats in a bar dividing into 3 eighth notes\\n\\nCompound metre divided into three parts could theoretically be transcribed into musically equivalent simple metre using triplets. Likewise, simple metre can be shown in compound through duples. In practice, however, this is rarely done because it disrupts conducting patterns when the tempo changes. When conducting in 6/8, conductors typically provide two beats per bar; however, all six beats may be performed when the tempo is very slow.\\n\\nCompound time is associated with \\"lilting\\" and dancelike qualities. Folk dances often use compound time. Many Baroque dances are often in compound time: some gigues, the courante, and sometimes the passepied and the siciliana.\\n","frontmatter":{"title":"Compound meters","description":"Rhythmic meters","date":"2021-10-10T00:00:00.000Z"},"url":"/theory/rhythm/meter/compound/"},{"src":"---\\ntitle: Complex meters\\ndescription: Asymmetric, irregular, unusual, or odd meters\\n\\ndate: 2021-10-08\\n\\n---\\n\\n<script setup>\\n  import rhythm from '#/db/rhythm/meters.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"rhythm.complex\\" />\\n\\nSignatures that do not fit the usual duple or triple categories are called complex, asymmetric, irregular, unusual, or odd. The term odd meter, however, sometimes describes time signatures in which the upper number is simply odd rather than even, including 3/4 and 9/8.\\n\\nThe irregular meters (not fitting duple or triple categories) are common in some non-Western music, but rarely appeared in formal written Western music until the 19th century. Early anomalous examples appeared in Spain between 1516 and 1520, but the Delphic Hymns to Apollo (one by Athenaeus is entirely in quintuple meter, the other by Limenius predominantly so), carved on the exterior walls of the Athenian Treasury at Delphi in 128 BC are in the relatively common cretic meter, with five beats to a foot.\\n\\nThe third movement of Frédéric Chopin's Piano Sonata No. 1 (1828) is an early, but by no means the earliest, example of 5/4 time in solo piano music. Anton Reicha's Fugue No. 20 from his Thirty-six Fugues, published in 1803, is also for piano and is in 5/8. The waltz-like second movement of Tchaikovsky's Pathétique Symphony (shown below), often described as a \\"limping waltz\\", is a notable example of 5/4 time in orchestral music.\\n\\nExamples from 20th-century classical music include:\\n\\n- Gustav Holst's \\"Mars, the Bringer of War\\" and \\"Neptune, the Mystic\\" from The Planets (both in 5/4)\\n- Paul Hindemith's \\"Fuga secunda\\" in G from Ludus Tonalis (5/8)\\n- the ending of Stravinsky's The Firebird (7/4)\\n- the fugue from Heitor Villa-Lobos's Bachianas Brasileiras No. 9 (11/8)\\n- the themes for the Mission: Impossible television series by Lalo Schifrin (in 5/4) and for Room 222 by Jerry Goldsmith (in 7/4)\\n\\nIn the Western popular music tradition, unusual time signatures occur as well, with progressive rock in particular making frequent use of them. The use of shifting meters in The Beatles' \\"Strawberry Fields Forever\\" and the use of quintuple meter in their \\"Within You, Without You\\" are well-known examples, as is Radiohead's \\"Paranoid Android\\" (includes 7/8).\\n\\nPaul Desmond's jazz composition \\"Take Five\\", in 5/4 time, was one of a number of irregular-meter compositions that The Dave Brubeck Quartet played. They played other compositions in 11/4 (\\"Eleven Four\\"), 7/4 (\\"Unsquare Dance\\"), and 9/8 (\\"Blue Rondo à la Turk\\"), expressed as 2+2+2+3/8. This last is an example of a work in a signature that, despite appearing merely compound triple, is actually more complex. Brubeck's title refers to the characteristic aksak meter of the Turkish karşılama dance.\\n\\nHowever, such time signatures are only unusual in most Western music. Traditional music of the Balkans uses such meters extensively. Bulgarian dances, for example, include forms with 5, 7, 9, 11, 13, 15, 22, 25 and other numbers of beats per measure. These rhythms are notated as additive rhythms based on simple units, usually 2, 3 and 4 beats, though the notation fails to describe the metric \\"time bending\\" taking place, or compound meters.\\n\\n## Quintuple meter\\n\\n[Quintuple meter](https://en.wikipedia.org/wiki/Quintuple_meter) or quintuple time is a musical meter characterized by five beats in a measure.\\n\\nThey may consist of any combination of variably stressed or equally stressed beats.\\n\\nLike the more common duple, triple, and quadruple meters, it may be simple, with each beat divided in half, or compound, with each beat divided into thirds. The most common time signatures for simple quintuple meter are 5/4 and 5/8, and compound quintuple meter is most often written in 15/8.\\n\\n<youtube-embed video=\\"kXl0F9oF92E\\" />\\n\\n### Notation\\n\\nSimple quintuple meter can be written in 5/4 or 5/8 time, but may also be notated by using regularly alternating bars of triple and duple meters, for example 2/4 + 3/1. Compound quintuple meter, with each of its five beats divided into three parts, can similarly be notated using a time signature of 15/8, by writing triplets on each beat of a simple quintuple signature, or by regularly alternating meters such as 6/8 + 9/8.\\n\\nAnother notational variant involves compound meters, in which two or three numerals take the place of the expected numerator. In simple quintuple meter, the 5 may be replaced as 2+3/8 or 2+1+2/8 for example. A time signature of 15/8, however, does not necessarily mean the music is in a compound quintuple meter. It may, for example, indicate a bar of triple meter in which each beat is subdivided into five parts. In this case, the meter is sometimes characterized as \\"triple quintuple time\\".\\n\\nIt is also possible for a 15/8 time signature to be used for an irregular, or additive, metrical pattern, such as groupings of 3+3+3+2+2+2 eighth notes or, for example in the Hymn to the Sun and Hymn to Nemesis by Mesomedes of Crete, 2+2+2+2+2+3+2, which may alternatively be given the composite signature 8+7/8.\\n\\nSimilarly, the presence of some bars with a 5/4 or 5/8 meter signature does not necessarily mean that the music is in quintuple meter overall. The regular alternation of 5/4 and 4/4 in Bruce Hornsby's \\"The Tango King\\" (from the album Hot House), for example, results in an overall nonuple meter (5+4 = 9).\\n\\n<youtube-embed video=\\"PHdU5sHigYQ\\" />\\n\\n[Sextuple meters](https://en.wikipedia.org/wiki/Sextuple_metre) are rather rare.\\n\\n## Septuple meter\\n\\n[Septuple meter](https://en.wikipedia.org/wiki/Septuple_meter) is a meter with each bar divided into 7 notes of equal duration, usually 7/4 or 7/8 (or in compound meter, 21/8 time). The stress pattern can be 2+2+3, 3+2+2, or occasionally 2+3+2, although a survey of certain forms of mostly American popular music suggests that 2+2+3 is the most common among these three in these styles.\\n\\nA time signature of 21/8, however, does not necessarily mean that the bar is a compound septuple meter with seven beats, each divided into three. This signature may, for example, be used to indicate a bar of triple meter in which each beat is subdivided into seven parts. In this case, the meter is sometimes characterized as \\"triple septuple time\\". It is also possible for a 21/8 time signature to be used for an irregular, or \\"additive\\" metrical pattern, such as groupings of 3 + 3 + 3 + 2 + 3 + 2 + 3 + 2 eighth notes.\\n\\nSeptuple meter can also be notated by using regularly alternating bars of triple and duple or quadruple meters, for example 4/4 + 3/4, or 6/8 + 6/8 + 9/8, or through the use of compound meters, in which two or three numerals take the place of the expected numerator 7, for example, 2+2+3/8, or 5+2/8.\\n\\n<youtube-embed video=\\"_yExwkQYcp0\\" />\\n\\n### Balkan folk music\\n\\nSeptuple rhythms are characteristic of some European folk idioms, particularly in the Balkan countries. An example from Macedonia is the traditional tune \\"Jovano Jovanke\\", which can be transcribed in 7/8. Bulgarian dances are particularly noted for the use of a variety of irregular, or heterometric rhythms. The most popular of these is the rachenitsa, a type of khoro in a rapid septuple meter divided 2+2+3. In the Pirin area, the khoro has a rhythm subdivided 3+2+2, and two varieties of it are the pravo makedonsko (\\"straight Macedonian\\") and the mazhka rachenitsa (\\"men's rachenitsa\\"). Septuple rhythms are also found in Bulgarian vocal music, such as the koleda ritual songs sung by young men on Christmas Eve and Christmas to bless livestock, households, or specific family members.\\n\\n<youtube-embed video=\\"xVgUKgORUnc\\" />\\n\\n## Additive meters\\n\\nTo indicate more complex patterns of stresses, such as additive rhythms, more complex time signatures can be used. Additive meters have a pattern of beats that subdivide into smaller, irregular groups. Such meters are sometimes called imperfect, in contrast to perfect meters, in which the bar is first divided into equal units.\\n\\nFor example, the time signature 3+2+3/8 means that there are 8 quaver beats in the bar, divided as the first of a group of three eighth notes (quavers) that are stressed, then the first of a group of two, then first of a group of three again. The stress pattern is usually counted as 3+2+3/8: **one** two three _one_ two _one_ two three ...\\n\\nThis kind of time signature is commonly used to notate folk and non-Western types of music. In classical music, Béla Bartók and Olivier Messiaen have used such time signatures in their works. The first movement of Maurice Ravel's Piano Trio in A Minor is written in 8\\n8, in which the beats are likewise subdivided into 3+2+3 to reflect Basque dance rhythms.\\n\\nRomanian musicologist Constantin Brăiloiu had a special interest in compound time signatures, developed while studying the traditional music of certain regions in his country. While investigating the origins of such unusual meters, he learned that they were even more characteristic of the traditional music of neighboring peoples (e.g., the Bulgarians). He suggested that such timings can be regarded as compounds of simple two-beat and three-beat meters, where an accent falls on every first beat, even though, for example in Bulgarian music, beat lengths of 1, 2, 3, 4 are used in the metric description. In addition, when focused only on stressed beats, simple time signatures can count as beats in a slower, compound time. However, there are two different-length beats in this resulting compound time, a one half-again longer than the short beat (or conversely, the short beat is 2⁄3 the value of the long). This type of meter is called aksak (the Turkish word for \\"limping\\"), impeded, jolting, or shaking, and is described as an irregular bichronic rhythm. A certain amount of confusion for Western musicians is inevitable, since a measure they would likely regard as 7\\n16, for example, is a three-beat measure in aksak, with one long and two short beats (with subdivisions of 2+2+3, 2+3+2, or 3+2+2).\\n\\nFolk music may make use of metric time bends, so that the proportions of the performed metric beat time lengths differ from the exact proportions indicated by the metric. Depending on playing style of the same meter, the time bend can vary from non-existent to considerable; in the latter case, some musicologists may want to assign a different meter. For example, the Bulgarian tune \\"Eleno Mome\\" is written in one of three forms: (1) 7 = 2+2+1+2, (2) 13 = 4+4+2+3, or (3) 12 = 3+4+2+3, but an actual performance (e.g., \\"Eleno Mome\\") may be closer to 4+4+2+3. The Macedonian 3+2+2+3+2 meter is even more complicated, with heavier time bends, and use of quadruples on the threes. The metric beat time proportions may vary with the speed that the tune is played. The Swedish Boda Polska (Polska from the parish Boda) has a typical elongated second beat.\\n\\nIn Western classical music, metric time bend is used in the performance of the Viennese waltz. Most Western music uses metric ratios of 2:1, 3:1, or 4:1 (two-, three- or four-beat time signatures)—in other words, integer ratios that make all beats equal in time length. So, relative to that, 3:2 and 4:3 ratios correspond to very distinctive metric rhythm profiles. Complex accentuation occurs in Western music, but as syncopation rather than as part of the metric accentuation.\\n\\nBrăiloiu borrowed a term from Turkish medieval music theory: aksak. Such compound time signatures fall under the \\"aksak rhythm\\" category that he introduced along with a couple more that should describe the rhythm figures in traditional music. The term Brăiloiu revived had moderate success worldwide, but in Eastern Europe it is still frequently used. However, aksak rhythm figures occur not only in a few European countries, but on all continents, featuring various combinations of the two and three sequences. The longest are in Bulgaria. The shortest aksak rhythm figures follow the five-beat timing, comprising a two and a three (or three and two).\\n\\n<youtube-embed video=\\"j9GgmGLPbWU\\" />\\n\\nThe term additive rhythm is also often used to refer to what are also incorrectly called asymmetric rhythms and even irregular rhythms – that is, meters which have a regular pattern of beats of uneven length. For example, the time signature 4/4 indicates each bar is eight quavers long, and has four beats, each a crotchet (that is, two quavers) long. The asymmetric time signature 3+3+2/8, on the other hand, while also having eight quavers in a bar, divides them into three beats, the first three quavers long, the second three quavers long, and the last just two quavers long.\\n\\nThese kinds of rhythms are used, for example, by Béla Bartók, who was influenced by similar rhythms in Bulgarian folk music. The third movement of Bartók's String Quartet No. 5, a scherzo marked alla bulgarese features a \\"9/8 rhythm (4+2+3)\\". Stravinsky's Octet for Wind Instruments \\"ends with a jazzy 3+3+2 = 8 swung coda\\". Additive patterns also occur in some music of Philip Glass, and other minimalists, most noticeably the \\"one-two-one-two-three\\" chorus parts in Einstein on the Beach. They may also occur in passing in pieces which are on the whole in conventional meters. In jazz, Dave Brubeck's song \\"Blue Rondo à la Turk\\" features bars of nine quavers grouped into patterns of 2+2+2+3 at the start. George Harrison's song \\"Here Comes the Sun\\" on the Beatles' album Abbey Road features a rhythm \\"which switches between 11/8, 4/4 and 7/8 on the bridge\\". \\"The special effect of running even eighth notes accented as if triplets against the grain of the underlying backbeat is carried to a point more reminiscent of Stravinsky than of the Beatles\\".\\n\\nOlivier Messiaen made extensive use of additive rhythmic patterns, much of it stemming from his close study of the rhythms of Indian music. His \\"Danse de la fureur, pour les sept trompettes\\" from The Quartet for the End of Time is a bracing example. A gentler exploration of additive patterns can be found in \\"Le Regard de la Vierge\\" from the same composer's piano cycle Vingt Regards sur l'enfant-Jésus.\\n\\nGyörgy Ligeti's Étude No. 13, \\"L'escalier du diable\\" features patterns involving quavers grouped in twos and threes. The rhythm at the start of the study follows the pattern 2+2+3, then 2+2+2+3. According to the composer's note, the 12/8 time signature \\"serves only as a guideline, the actual meter consists of 36 quavers (three 'bars'), divided assymetrically\\".\\n\\nhttps://en.wikipedia.org/wiki/List_of_musical_works_in_unusual_time_signatures\\n\\n<youtube-embed video=\\"_1d-Axi4mhY\\" />\\n","frontmatter":{"title":"Complex meters","description":"Asymmetric, irregular, unusual, or odd meters","date":"2021-10-08T00:00:00.000Z"},"url":"/theory/rhythm/meter/complex/"},{"src":"---\\ntitle: Common time\\ndescription: Common time and half- and double-time changes\\ndate: 2021-10-06\\n---\\n\\n<script setup>\\nimport rhythm from '#/db/rhythm/meters.yaml'\\n<\/script>\\n\\n<beat-bars v-bind=\\"rhythm.times\\" />\\n\\n## Common-time\\n\\nRhythm pattern characteristic of much popular music including rock, quarter note (crotchet) or \\"regular\\" time: \\"bass drum on beats 1 and 3 and snare drum on beats 2 and 4 of the measure [bar]...add eighth notes [quavers] on the hi-hat\\".\\n\\nTime signatures are defined by how they divide the measure (in 9/8, complex triple time, each measure is divided in three, each of which is divided into three eighth notes: 3×3=9). In \\"common\\" time, often considered 4/4, each level is divided in two (simple duple time: 2×2=4). In a common-time rock drum pattern each measure (a whole note) is divided in two by the bass drum (half note), each half is divided in two by the snare drum (quarter note, collectively the bass and snare divide the measure into four), and each quarter note is divided in two by a ride pattern (eighth note). \\"Half\\"-time refers to halving this division (divide each measure into quarter notes with the ride pattern), while \\"double\\"-time refers to doubling this division (divide each measure into sixteenth notes with the ride pattern).\\n\\n## Half-time\\n\\nIn popular music, half-time is a type of meter and tempo that alters the rhythmic feel by essentially doubling the tempo resolution or metric division/level in comparison to common-time. Thus, two measures of 4/4 approximate a single measure of 8/8, while a single measure of 4/4 emulates 2/2. Half-time is not to be confused with alla breve or odd time. Though notes usually get the same value relative to the tempo, the way the beats are divided is altered. While much music typically has a backbeat on quarter note (crotchet) beats two and four, half time would increase the interval between backbeats to double, thus making it hit on beats three and seven, or the third beat of each measure (count out of an 8 beat measure [bar], common practice in half time):\\n\\n    1   2   3   4   1   2   3   4\\n    1   2   3   4   5   6   7   8\\n    1       2       3       4\\n\\nEssentially, a half time 'groove' is one that expands one measure over the course of two. The length of each note is doubled while its frequency is halved.\\n\\nA classic example is the half-time shuffle, a variation of a shuffle rhythm, which is used extensively in hip-hop and some blues music. Some of the variations of the basic groove are notoriously difficult to play on drum set. It is also a favorite in some pop and rock tunes. Some classic examples are the Purdie Shuffle by Bernard Purdie which appears in \\"Home At Last\\" and \\"Babylon Sisters\\", both of which are Steely Dan songs. \\"Fool in the Rain\\" by Led Zeppelin uses a derivation of the Purdie Shuffle, and Jeff Porcaro of Toto created a hybridization of the Zeppelin and Purdie shuffles called the Rosanna shuffle for the track \\"Rosanna\\".\\n\\n<youtube-embed video=\\"g41Ab8iDaD0\\" />\\n\\nIn half time, the feel of notes are chopped in half, but the actual time value remains the same. For example, at the same tempo, 8th notes (quavers) would sound like 16ths (semiquavers). In the case of the half time shuffle, triplets sound like 16th note (semiquaver) triplets, etc. By preserving the tempo, the beat is stretched by a factor of 2.\\n\\n> ![](./Double,_common,_and_half_times_same_tempo.png)\\n> Double-, common, and half- time offbeats at the same tempo.\\n\\n> ![](./Double,_common,_and_half_times_equivalent_tempo.png)\\n> Double-, common, and half- time offbeats at equivalent tempos.\\n\\n## Double time\\n\\nIn music and dance, double-time is a type of meter and tempo or rhythmic feel by essentially halving the tempo resolution or metric division/level. It is also associated with specific time signatures such as 2/2. Contrast with half time.\\n\\nIn jazz the term means using note values twice as fast as previously but without changing the pace of the chord progressions. It is often used during improvised solos.\\n\\n\\"Double time [is] doubling a rhythm pattern within its original bar structure.\\":\\n\\n    1   2   3   4\\n    1 2 3 4 1 2 3 4\\n\\nIt may help to picture the way musicians count each metric level in 4/4:\\n\\n    quarter:    1           2           3           4\\n    eighth:     1     &     2     &     3     &     4     &\\n    sixteenth:  1  e  &  a  2  e  &  a  3  e  &  a  4  e  &  a\\n","frontmatter":{"title":"Common time","description":"Common time and half- and double-time changes","date":"2021-10-06T00:00:00.000Z"},"url":"/theory/rhythm/meter/time/"},{"src":"---\\ntitle: Rhythmic systems\\ndescription: Different systems of rhythmic organisation\\ncover: korean-drums.jpg\\ndate: 2021-10-02\\nlinks:\\n  - https://en.wikipedia.org/wiki/Isorhythm\\n---\\n\\nDifferent cultures have different rhytmic systems evolved through ages. India has [Tala](./tala/index.md) system, Spain has grown it's [Flamenco](./flamenco/index.md) tradition, Latin America has the [Clave](./clave/index.md) sound and many approaches have evolved from [African cross-beats](./crossbeat/index.md).\\n\\n<youtube-embed video=\\"ZROR_E5bFEI\\" />\\n","frontmatter":{"title":"Rhythmic systems","description":"Different systems of rhythmic organisation","cover":"/media_files/cover/theory-rhythm-system-korean-drums.jpg","date":"2021-10-02T00:00:00.000Z","links":["https://en.wikipedia.org/wiki/Isorhythm"]},"url":"/theory/rhythm/system/"},{"src":"---\\ntitle: Study of scales\\ndescription: The principles for analyzing different combinations of notes\\n\\ndate: 2021-09-30\\n---\\n\\n> This original text is from [The Exciting Universe Of Music Theory by Ian Ring](https://ianring.com/musictheory/scales/)\\n\\nThere is no rule stating how many notes a scale must include. The most common scales in Western music contain seven pitches and are thus called “heptatonic” (meaning “seven tones”). Other scales have fewer notes—five-note “pentatonic” scales are quite common in popular music. There’s even a scale that uses all 12 pitches: it’s called the “chromatic” scale.\\n\\nWhat we have in the 12-tone system is a binary \\"word\\" made of 12 bits. We can assign one bit to each degree of the chromatic scale, and use the power of binary arithmetic and logic to do some pretty awesome analysis with them. When represented as bits it reads from right to left - the lowest bit is the root, and each bit going from right to left ascends by one semitone.\\n\\nThe total number of possible combinations of on and off bits is called the \\"power set\\". The number of sets in a power set of size n is (2^n). Using a word of 12 bits, the power set (2^12) is equal to 4096. The fun thing about binary power sets is that we can produce every possible combination, by merely invoking the integers from 0 (no tones) to 4095 (all 12 tones).\\n\\nThis means that every possible combination of tones in the 12-tone set can be represented by a number between 0 and 4095. We don't need to remember the fancy names like \\"phrygian\\", we can just call it scale number 1451. Convenient!\\n\\n> An important concept here is that any set of tones can be represented by a number. This number is not \\"ordinal\\" - it's not merely describing the position of the set in an indexed scheme; it's also not \\"cardinal\\" because it's not describing an amount of something. This is a nominal number because the number _is_ the scale. You can do binary arithmetic with it, and you are adding and subtracting scales with no need to convert the scale into some other representation.\\n\\n<youtube-embed video=\\"Vq2xt2D3e3E\\" />\\n\\n## Interval Pattern\\n\\nAnother popular way of representing a scale is by its interval pattern. When I was learning the major scale, I was taught to say aloud: \\"tone, tone, semitone, tone, tone, tone, semitone\\". Many music theorists like to represent a scale this way because it's accurate and easy to understand: \\"TTSTTTS\\". Having a scale's interval pattern has merit as an intermediary step can make some kinds of analysis simpler. Expressed numerically - which is more convenient for computation - the major scale is [2,2,1,2,2,2,1].\\n\\n## Pitch Class Sets\\n\\nYet another way to represent a scale is as a \\"pitch class set\\", where the tones are assigned numbers 0 to 11 (sometimes using \\"T\\" and \\"E\\" for 10 and 11), and the set enumerates the ones present in the scale. A pitch class set for the major scale is notated like this: {0,2,4,5,7,9,11}. The \\"scales\\" we'll study here are a subset of Pitch Classes (ie those that have a root, and obey Zeitler's Rules) and we can use many of the same mathematical tricks to manipulate them.\\n\\n## What is a scale?\\n\\nOr more importantly, what is _not_ a scale?\\n\\nNow that we have the superset of all possible sets of tones, we can whittle it down to exclude ones that we don't consider to be a legitimate \\"scale\\". We can do this with just two rules.\\n\\n### A scale starts on the root tone.\\n\\nThis means any set of notes that doesn't have that first bit turned on is not eligible to be called a scale. This cuts our power set in exactly half, leaving 2048 sets.\\n\\nIn binary, it's easy to see that the first bit is on or off. In decimal, you can easily tell this by whether the number is odd or even. All even numbers have the first bit off; therefore all scales are represented by an odd number.\\n\\nWe could have cut some corners in our discussion of scales by omitting the root tone (always assumed to be on) to work with 11 bits instead of 12, but there are compelling reasons for keeping the 12-bit number for our scales, such as simplifying the analysis of symmetry, simplifying the calculation of modes, and performing analysis of sonorities that do not include the root, where an even number is appropriate.\\n\\nScales remaining: **2048**\\n\\n### A scale does not have any leaps greater than n semitones.\\n\\nFor the purposes of this exercise we are saying n = 4, a.k.a. a major third. Any collection of tones that has an interval greater than a major third is not considered a \\"scale\\". This configuration is consistent with Zeitler's constant used to generate his comprehensive list of scales.\\n\\nScales remaining: **1490**\\n\\nNow that we've whittled our set of tones to only the ones we'd call a \\"scale\\", let's count how many there are with each number of tones.\\n\\n| number of tones | how many scales |\\n| :-------------- | :-------------- |\\n| 1               | 0               |\\n| 2               | 0               |\\n| 3               | 1               |\\n| 4               | 31              |\\n| 5               | 155             |\\n| 6               | 336             |\\n| 7               | 413             |\\n| 8               | 322             |\\n| 9               | 165             |\\n| 10              | 55              |\\n| 11              | 11              |\\n| 12              | 1               |\\n\\n## Modes\\n\\nThere is a lot of confusion about what is a \\"mode\\", chiefly because the word is used slightly differently in various contexts.\\n\\nWhen we say \\"C major\\", the word \\"major\\" refers to a specific pattern of whole- and half-steps. The \\"C\\" tells us to begin that pattern on the root tone of \\"C\\".\\n\\nModes are created when you use the same patterns of whole- and half-steps, but you begin on a different step. For instance, the \\"D Dorian\\" mode uses all the same notes as C major (the white keys on a piano), but it begins with D. Compared with the Major (also known as \\"Ionian\\" mode), the Dorian sounds different, because relative to the root note D, it has a minor third and a minor seventh.\\n\\nThe best way to understand modes is to think of a toy piano where the black keys are just painted on - all you have are the white keys: C D E F G A B. Can you play a song that sounds like it's in a minor key? You can't play a song in C minor, because that would require three flats. So instead you play the song with A as the root (A B C D E F G). That scale is a mode of the major scale, called the Aeolian Mode.\\n\\nWhen you play that minor scale, you're not playing \\"C minor\\", you're playing the relative minor of C, which is \\"A minor\\". Modes are relatives of each other if they have the same pattern of steps, starting on different steps.\\n\\nTo compute a mode of the current scale, we \\"rotate\\" all the notes down one semitone. Then if the rotated notes have an on bit in the root, then it is a mode of the original scale. It's as if you take the bracelet diagram that we've been using throughout this study, and twist it like a dial so that a different note is at the top, in the root position.\\n\\n- 101010110101 = 2741 - major scale, \\"ionian\\" mode\\n- 110101011010 = 3418 - rotated down 1 semitone - not a scale\\n- 011010101101 = 1709 - rotated down 2 semitones - \\"dorian\\"\\n- 101101010110 = 2902 - rotated down 3 semitones - not a scale\\n- 010110101011 = 1451 - rotated down 4 semitones - \\"phrygian\\"\\n- 101011010101 = 2773 - rotated down 5 semitones - \\"lydian\\"\\n- 110101101010 = 3434 - rotated down 6 semitones - not a scale\\n- 011010110101 = 1717 - rotated down 7 semitones - \\"mixolydian\\"\\n- 101101011010 = 2906 - rotated down 8 semitones - not a scale\\n- 010110101101 = 1453 - rotated down 9 semitones - \\"aeolian\\"\\n- 101011010110 = 2774 - rotated down 10 semitones - not a scale\\n- 010101101011 = 1387 - rotated down 11 semitones - \\"locrian\\"\\n\\nWhen we do this to every scale, we see modal relationships between scales, and we also discover symmetries when a scale is a mode of itself on another degree.\\n\\n## Imperfection\\n\\nImperfection is a concept invented (so far as I can tell) by William Zeitler, to describe the presence or absense of perfect fifths in the scale tones. Any tone in the scale that does not have the perfect fifth above it represented in the scale is an \\"imperfect\\" tone. The number of imperfections is a metric that plausibly correlates with the perception of dissonance in a sonority.\\n\\nThe only scale that has no imperfections is the 12-tone chromatic scale.\\n\\nhttps://ianring.com/musictheory/scales/\\n","frontmatter":{"title":"Study of scales","description":"The principles for analyzing different combinations of notes","date":"2021-09-30T00:00:00.000Z"},"url":"/theory/scales/study/"},{"src":"---\\ntitle: Ring Tone Text Transfer Language\\ndescription: Note encoding format for ringtones\\ndate: 2021-09-20\\n---\\n\\n[Ring Tone Text Transfer Language](https://en.wikipedia.org/wiki/Ring_Tone_Text_Transfer_Language) (RTTTL) was developed by Nokia[citation needed] to be used to transfer ringtones to cellphone by Nokia.\\n\\nThe RTTTL format is a string divided into three sections: name, default value, and data.\\n\\nThe jintu section consists of a string describing the name of the ringtone. It can be no longer than 10 characters, and cannot contain a colon \\":\\" character. (However, since the Smart Messaging specification allows names up to 15 characters in length, some applications processing RTTTL also do so.)\\n\\nThe default value section is a set of values separated by commas, where each value contains a key and a value separated by an = character, which describes certain defaults which should be adhered to during the execution of the ringtone. Possible names are\\n\\n- d - duration\\n- o - octave\\n- b - beat, tempo\\n\\nThe data section consists of a set of character strings separated by commas, where each string contains a duration, pitch, octave and optional dotting (which increases the duration of the note by one half).\\n\\nThe format of RTTTL notation is similar to the Music Macro Language found in BASIC implementations present on many early microcomputers.\\n\\n## Technical specification\\n\\nTo be recognized by ringtone programs, an RTTTL/Nokring format ringtone must contain three specific elements: name, settings, and notes.\\n\\nFor example, here is the RTTTL ringtone for Haunted House:\\n\\n\`\`\`\\nHauntHouse: d=4,o=5,b=108: 2a4, 2e, 2d#, 2b4, 2a4, 2c, 2d, 2a#4, 2e., e, 1f4, 1a4, 1d#, 2e., d, 2c., b4, 1a4, 1p, 2a4, 2e, 2d#, 2b4, 2a4, 2c, 2d, 2a#4, 2e., e, 1f4, 1a4, 1d#, 2e., d, 2c., b4, 1a4\\n\`\`\`\\n\\nThe three parts are separated by a colon.\\n\\n- Part 1: name of the ringtone (here: \\"HauntHouse\\"), a string of characters represents the name of the ringtone\\n\\n- Part 2: settings (here: d=4,o=5,b=108), where \\"d=\\" is the default duration of a note. In this case, the \\"4\\" means that each note with no duration specifier (see below) is by default considered a quarter note. \\"8\\" would mean an eighth note, and so on. Accordingly, \\"o=\\" is the default octave. There are four octaves in the Nokring/RTTTL format. And \\"b=\\" is the tempo, in \\"beats per minute\\".\\n\\n- Part 3: the notes. Each note is separated by a comma and includes, in sequence: a duration specifier, a standard music note, either a, b, c, d, e, f or g, and an octave specifier, as in scientific pitch notation. If no duration or octave specifier are present, the default applies.\\n\\n### Durations\\n\\nStandard musical durations are denoted by the following notations:\\n\\n- 1 - whole note\\n- 2 - half note\\n- 4 - quarter note\\n- 8 - eighth note\\n- 16 - sixteenth note\\n- 32 - thirty-second note\\n\\nDotted rhythm patterns can be formed by appending a period (\\".\\") character to the end of a duration/beat/octave element.\\n\\n### Pitch\\n\\n    P - rest or pause\\n    A - A\\n    A# - A♯ / B♭\\n    B - B / C♭\\n    C - C\\n    C# - C♯ / D♭\\n    D - D\\n    D# - D♯ / E♭\\n    E - E / F♭\\n    F - F / E♯\\n    F# - F♯ / G♭\\n    G - G\\n    G# - G♯ / A♭\\n\\n### Octave\\n\\nThe RTTTL format allows octaves starting from the A below middle C and going up four octaves. This corresponds with the inability of cellphones to reproduce certain tones audibly. These octaves are numbered from lowest pitch to highest pitch from 4 to 7.\\n\\nThe octave should be left out of the notation in the case of a rest or pause in the pattern.\\nExample\\n\\nAn example of the RTTTL format would be\\n\\n\`fifth:d=4,o=5,b=63:8P,8G5,8G5,8G5,2D#5\`\\n","frontmatter":{"title":"Ring Tone Text Transfer Language","description":"Note encoding format for ringtones","date":"2021-09-20T00:00:00.000Z"},"url":"/theory/notes/computer/ring-tone/"},{"src":"---\\ntitle: Temperaments\\ndescription: Tuning systems\\ncover: derek-story.jpg\\ndate: 2021-09-20\\n---\\n\\nThere's a plenty of ways to get all the notes to play with. The natural [Just intonation](./just/index.md) is based on simple ratios. If we take only one ratio of 2:3 we can construct the [Pythagorean](./pythagorean/index.md) tuning.\\n\\nLogarithms are in the base of the modern [12-TET](./equal/index.md) and anyone can [compare it](./tunings/index.md) to other systems easily.","frontmatter":{"title":"Temperaments","description":"Tuning systems","cover":"/media_files/cover/theory-notes-temperaments-derek-story.jpg","date":"2021-09-20T00:00:00.000Z"},"url":"/theory/notes/temperaments/"},{"src":"---\\ntitle: Notes\\ndescription: Historical and cultorological research on different notation systems\\ndate: 2021-09-18\\ncover: Grand_staff.svg\\n---\\n\\n<YoutubeEmbed video=\\"Eq3bUFgEcb4\\" />\\n\\nLet's first learn about [Temperaments](./temperaments/index.md) as ways to divide an octave into distinct notes to play. Then let's find out how these notes got their names with [Solmization](./solmization/index.md) and how they were written down in [National notation systems](./national/index.md). The West-European tradition and it's [Classic staff notation](./staff/index.md) is one of the most influential worldwide, but still there's a plenty of ancient and modern [Alternative notation systems](./alternative/index.md) to explore and experiment with. There's a whole world of [Computer notation](./computer/index.md) in the digital realm.\\n","frontmatter":{"title":"Notes","description":"Historical and cultorological research on different notation systems","date":"2021-09-18T00:00:00.000Z","cover":"/media_files/cover/theory-notes-Grand_staff.svg"},"url":"/theory/notes/"},{"src":"---\\ntitle: Pentatonic scales\\ndescription: 5 very consonant notes to play easily together\\ndate: 2021-09-16\\n\\npentatonics:\\n  major:\\n    title: Major pentatonic\\n    chroma: \\"101010010100\\"\\n  minor:\\n    title: Minor pentatonic\\n    chroma: \\"100101010010\\"\\n  suspended:\\n    title: Suspended pentatonic\\n    chroma: \\"101001010010\\"\\n  blues:\\n    title: Blues minor pentatonic\\n    chroma: \\"100101001010\\"\\n  ms7:\\n    title: \\"Minor #7 pentatonic\\"\\n    chroma: \\"100101010001\\"\\n  m6:\\n    title: Minor Six pentatonic\\n    chroma: \\"100101010100\\"\\njapanese:\\n  hirajoshi:\\n    title: Hirajoshi\\n    chroma: \\"101100011000\\"\\n  ritusen:\\n    title: Ritusen\\n    chroma: \\"101001010100\\"\\n  iwato:\\n    title: Iwato\\n    chroma: \\"110001100010\\"\\n  kumoijoshi:\\n    title: Kumoijoshi\\n    chroma: \\"110001011000\\"\\n  insen:\\n    title: In-sen\\n    chroma: \\"110001010010\\"\\n---\\n\\nMusicology commonly classifies [pentatonic scales](https://en.wikipedia.org/wiki/Pentatonic_scale) as either hemitonic or anhemitonic. Hemitonic scales contain one or more semitones and anhemitonic scales do not contain semitones.\\n\\n## Major pentatonic scale\\n\\nAnhemitonic pentatonic scales can be constructed in many ways. The major pentatonic scale may be thought of as a gapped or incomplete major scale. However, the pentatonic scale has a unique character and is complete in terms of tonality. One construction takes five consecutive pitches from the circle of fifths; starting on C, these are C, G, D, A, and E. Transposing the pitches to fit into one octave rearranges the pitches into the major pentatonic scale: C, D, E, G, A.\\n\\nAnother construction works backward: It omits two pitches from a diatonic scale. If one were to begin with a C major scale, for example, one might omit the fourth and the seventh scale degrees, F and B. The remaining notes then make up the major pentatonic scale: C, D, E, G, and A.\\n\\nOmitting the third and seventh degrees of the C major scale obtains the notes for another transpositionally equivalent anhemitonic pentatonic scale: F, G, A, C, D. Omitting the first and fourth degrees of the C major scale gives a third anhemitonic pentatonic scale: G, A, B, D, E.\\n\\nThe black keys on a piano keyboard comprise a G-flat major (or equivalently, F-sharp major) pentatonic scale: G-flat, A-flat, B-flat, D-flat, and E-flat, which is exploited in Chopin's black key étude.\\n\\n<audio class=\\"my-4\\" controls>\\n<source src=\\"/audio/Frederic_Chopin_-_Opus_10_-_Twelve_Grand_Etudes_-_G_Flat_Major.mp3\\" type=\\"audio/mpeg\\">\\n</audio>\\n\\n## Minor pentatonic scale\\n\\nAlthough various hemitonic pentatonic scales might be called minor, the term is most commonly applied to the relative minor pentatonic derived from the major pentatonic, using scale tones 1, 3, 4, 5, and 7 of the natural minor scale. (It may also be considered a gapped blues scale.) The C minor pentatonic scale, the relative of the E-flat pentatonic scale is C, E-flat, F, G, B-flat. The A minor pentatonic, the relative minor of C pentatonic, comprises the same tones as the C major pentatonic, starting on A, giving A, C, D, E, G. This minor pentatonic contains all three tones of an A minor triad.\\n\\nThe standard tuning of a guitar uses the notes of an E minor pentatonic scale: E-A-D-G-B-E, contributing to its frequency in popular music.\\n\\n<chroma-profile-collection :collection=\\"$frontmatter.pentatonics\\" />\\n\\n## Japanese scales\\n\\nThe organization of notes to create a musical scale has many different applications in different cultures and types of music. One of the most common approaches to organizing musical structures is known as the Mode or Mode(s). Since the Heian Period, there has been disagreement and contention between musical scholars regarding Japanese music and modal theory. There has long been a debate about Japanese modes and what defines them, to this day there is not a single modal theory that can completely explain Japanese music. Music scales are critical in clarifying and identifying musical pieces, however, there has been no single scale model that can identify all Japanese music into one classification or category of music. In order to be understood by western scholars, The different variations of Japanese modal scales are often compared to the western Major Scale. Various modal theories from around the world have been imported to attempt and analyze Japanese music structure, but often the modal theories suggested do not reflect what is actually present in the music it is being applied to. The classical structures of most Japanese music originates in China and was not concerned with developing a universal scale or mode until Western music had been imported. After the Heian period began was when Western modal theories became widely acknowledged by Japanese society, though it often stayed in its own category as it could not entirely explain Japanese music across all its different iterations.\\n\\nThe most common version of the Japanese mode is a somewhat inaccurate term for a pentatonic musical scale which is used commonly in traditional Japanese music. The intervals of the scale are major second, minor third, perfect fifth, and minor sixth (for example, the notes A, B, C, E, F and up to A.) - which is essentially a natural minor scale in Western music theory without the subdominant and subtonic, which is the same operation performed on the major scale to produce the pentatonic major scale. The more correct term would be kumoijoshi, as given by William P. Malm for one of the three tuning scales of the koto adapted from shamisen music.\\n\\nIn addition to being used almost exclusively in traditional Japanese compositions, it is found frequently in video game music and the pieces of contemporary composers such as Anne Boyd.\\n\\n<chroma-profile-collection :collection=\\"$frontmatter.japanese\\" />\\n","frontmatter":{"title":"Pentatonic scales","description":"5 very consonant notes to play easily together","date":"2021-09-16T00:00:00.000Z","pentatonics":{"major":{"title":"Major pentatonic","chroma":"101010010100"},"minor":{"title":"Minor pentatonic","chroma":"100101010010"},"suspended":{"title":"Suspended pentatonic","chroma":"101001010010"},"blues":{"title":"Blues minor pentatonic","chroma":"100101001010"},"ms7":{"title":"Minor #7 pentatonic","chroma":"100101010001"},"m6":{"title":"Minor Six pentatonic","chroma":"100101010100"}},"japanese":{"hirajoshi":{"title":"Hirajoshi","chroma":"101100011000"},"ritusen":{"title":"Ritusen","chroma":"101001010100"},"iwato":{"title":"Iwato","chroma":"110001100010"},"kumoijoshi":{"title":"Kumoijoshi","chroma":"110001011000"},"insen":{"title":"In-sen","chroma":"110001010010"}}},"url":"/theory/scales/pentatonic/"},{"src":"---\\ntitle: Diatonic scales\\ndescription: The seven 7-notes set rotations\\n\\ndate: 2021-09-15\\n\\n---\\n\\n\\n# All diatonic scales and modes\\n\\n<youtube-embed video=\\"YJO-Fm7uRX4\\"></youtube-embed>\\n\\n## What Is a Diatonic Scale?\\n\\nA diatonic scale is a type of musical scale that contains seven tones of a note per octave (the distance between one note and the following note that also bears its name).\\n\\n### Tones\\n\\nDiatonic scales consist of five whole tones, also known as whole steps or the major second, and two half steps (semitones), which are the shortest musical intervals (the distance between tones) in Western music, separated by either two or three tones. A whole step on a piano keyboard represents two keys, while a half step is a single key.\\n\\n### Letter names\\n\\nAlso known as a heptatonic scale in music theory, diatonic scales use all seven letter names, or notes in a sequence. Chords built from the seven notes in each key are called diatonic chords. Tonality, or the system of organizing keys and chords in Western music, has been based on the diatonic system from the Middle Ages to the present day.\\n\\n### Scales\\n\\nDiatonic scales include both the major scale, or Ionian mode, which is the most frequently used musical scale, and the natural minor scale, or Aeolian mode, which uses the same number of notes as the major scale, but in a different pitch. Both scales are part of the six [“church mode”](<https://en.wikipedia.org/wiki/Mode_(music)>) scales established for religious music during the medieval period, which continue to form the basis for contemporary diatonic scales.\\n\\n## Tonic - the root note\\n\\nThese scales always have a tonal center to which all the notes relate and lead to in different ways. It is called the root note of the scale or tonic.\\n\\n## The 7 Modes of the Diatonic Scale\\n\\n\\n<script setup>\\n  import diatonic from '#/db/scale/diatonic.yaml'\\n<\/script>\\n\\n<chroma-profile-collection :collection=\\"diatonic\\" />\\n","frontmatter":{"title":"Diatonic scales","description":"The seven 7-notes set rotations","date":"2021-09-15T00:00:00.000Z"},"url":"/theory/scales/diatonic/"},{"src":"---\\ntitle: Melodic minor\\ndescription: The melodic minor scale is essentially a natural minor scale with raised sixth and seventh scale degrees. \\ndate: 2021-09-14\\n---\\n\\nA great deal of modern jazz harmony arises from the modes of the ascending form of the melodic minor scale, also known as the jazz melodic minor scale. This scale is essentially a diatonic major scale with a lowered third, for example C–D–E♭–F–G–A–B–C. As with any other scale, the modes are derived from playing the scale from different root notes, causing a series of jazz scales to emerge.\\n\\n## The 7 modes of the Melodic Minor Scale\\n\\n<script setup>\\n  import melodic from '#/db/scale/melodic.yaml'\\n<\/script>\\n\\n<chroma-profile-collection :collection=\\"melodic\\" />\\n","frontmatter":{"title":"Melodic minor","description":"The melodic minor scale is essentially a natural minor scale with raised sixth and seventh scale degrees.","date":"2021-09-14T00:00:00.000Z"},"url":"/theory/scales/melodic/"},{"src":"---\\ntitle: Double harmonic\\ndescription: Balanced heptatonic scales with two augmented second intervals\\ndate: 2021-09-13\\n---\\n\\nThe double harmonic major scale is a musical scale with a flattened second and sixth degree. This is also known as Mayamalavagowla, Bhairav Raga, Byzantine scale, Arabic (Hijaz Kar), and Gypsy major. It can be likened to a gypsy scale because of the diminished step between the 1st and 2nd degrees. Arabic scale may also refer to any Arabic mode, the simplest of which, however, to Westerners, resembles the double harmonic major scale.\\n\\n## The 7 modes of the Double harmonic major\\n\\n<script setup>\\n  import double from '#/db/scale/double.yaml'\\n<\/script>\\n\\n<chroma-profile-collection :collection=\\"double\\" />\\n\\n<youtube-embed video=\\"jiAo-ZA7Ijg\\" />\\n\\nIt is referred to as the \\"double harmonic\\" scale because it contains two harmonic tetrads featuring augmented seconds. By contrast, both the harmonic major and harmonic minor scales contain only one augmented second, located between their sixth and seventh degrees.\\n\\nThe scale contains a built-in tritone substitution, a dominant seventh chord a half step above the root, with strong harmonic movement towards the tonic chord.\\n\\nThe double harmonic scale is not commonly used in classical music from Western culture, as it does not closely follow any of the basic musical modes, nor is it easily derived from them. It also does not easily fit into common Western chord progressions such as the authentic cadence. This is because it is mostly used as a modal scale, not intended for much movement through chord progressions.\\n\\nThe Arabic scale (in the key of E) was used in Nikolas Roubanis's \\"Misirlou\\", and in the Bacchanale from the opera Samson and Delilah by Saint-Saëns. Claude Debussy used the scale in \\"Soirée dans Grenade\\", \\"La Puerta del Vino\\", and \\"Sérénade interrompue\\" to evoke Spanish flamenco music or Moorish heritage. In popular music, Ritchie Blackmore of Deep Purple and Rainbow used the scale in pieces such as \\"Gates of Babylon\\" and \\"Stargazer\\". The Miles Davis jazz standard \\"Nardis\\" also makes use of the double harmonic. Opeth used this scale in their song \\"Bleak\\" from the album Blackwater Park. Megadeth use the scale in a guitar solo from their song \\"The Threat Is Real\\" from their 2015 album Dystopia. It is also used by Hans Zimmer in his score for Dune.\\n\\n<youtube-embed video=\\"n7hSabSnCEg\\" />\\n\\n## Symmetry and balance\\n\\nThe double harmonic scale features radial symmetry, or symmetry around its root, or center note. Breaking up the three note chromaticism and removing this symmetry by sharpening the 2nd or flattening the 7th note respectively by one semitone yields the harmonic major and Phrygian Dominant mode of the harmonic minor scales respectively, each of which, unlike the double harmonic minor scale, has a full diminished chord backbone.\\n\\nThis scale (and its modes like the Hungarian minor scale) is the only seven-note scale (in 12-tone equal temperament) that is perfectly balanced; this means that when its pitches are represented as points on a circle (whose full circumference represents an octave), their average position (or \\"centre of mass\\") is the centre of the circle.\\n\\n<youtube-embed video=\\"hNHAdf8XOik\\" />\\n\\n## Tetrads\\n\\nThe main chords of the double harmonic major are:\\n\\nI7M bII7M iii6 iv7M V7(b5) bVI7M(#5) viisus2add13(b5)\\n\\nThere are other possibilities of tetrad:\\n\\nI7M(#5) bII7 bii7M bii7 bii7(b5) III6 iv° V6(b5) bvi°\\n\\n## Modes\\n\\nLike all heptatonic (seven-pitch) scales, the double harmonic scale has a mode for each of its individual scale degrees. The most commonly known of these modes is the 4th mode, the Hungarian minor scale, most similar to the harmonic minor scale with a raised 4th degree. The modes are as follows:\\n\\n| Mode | Name of scale                                                                                                                                                                                                                                                                                                                                                                   | Degrees |\\n| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------- |\\n|  |\\n| 1    | Double harmonic major                                                                                                                                                                                                                                                                                                                                                           | 1       | ♭2 | 3 | 4 | 5 | ♭6 | 7 | 8 |\\n| 2    | Lydian ♯2 ♯6                                                                                                                                                                                                                                                                                                                                                                    | 1       | ♯2 | 3 | ♯4 | 5 | ♯6 | 7 | 8 |\\n| 3    | Ultraphrygian                                                                                                                                                                                                                                                                                                                                                                   | 1       | ♭2 | ♭3 | ♭4 | 5 | ♭6 | 7 | 8 |\\n| 4    | [Hungarian/Gypsy minor](https://en.wikipedia.org/wiki/Hungarian_minor_scale \\"Hungarian minor scale\\")                                                                                                                                                                                                                                                                            | 1       | 2 | ♭3 | ♯4 | 5 | ♭6 | 7 | 8 |\\n| 5    | [Oriental](https://en.wikipedia.org/w/index.php?title=Oriental_mode&action=edit&redlink=1 \\"Oriental mode (page does not exist)\\")                                                                                                                                                                                                                                                | 1       | ♭2 | 3 | 4 | ♭5 | 6 | ♭7 | 8 |\\n| 6    | Ionian ♯2 ♯5                                                                                                                                                                                                                                                                                                                                                                    | 1       | ♯2 | 3 | 4 | ♯5 | 6 | 7 | 8 |\\n| 7    | Locrian bb3 bb7 | 1       | ♭2 | bb3 | 4 | ♭5 | ♭6 | bb7 | 8 |\\n\\n<youtube-embed video=\\"LW6qGy3RtwY\\" />\\n\\n## Related scales\\n\\nSome of the closest existing scales to the double harmonic major scale are the Phrygian dominant scale, the fifth mode of the harmonic minor scale, as they are alike save for the Phrygian dominant's flattened seventh degree. The harmonic major scale (also known as major flat 6 and Ionian flat 6) is identical to the standard major scale aside from the sixth scale degree being flattened by a semitone, differing from the double harmonic major in having a natural second degree.\\n","frontmatter":{"title":"Double harmonic","description":"Balanced heptatonic scales with two augmented second intervals","date":"2021-09-13T00:00:00.000Z"},"url":"/theory/scales/double/"},{"src":"---\\ntitle: Symmetrical scales\\ndescription: Modes of limited transpostions and interval cycles\\ndate: 2021-09-12\\n---\\n\\n<script setup>\\nimport limited from '#/db/scale/limited.yaml'\\n<\/script>\\n\\nAsymmetric scales are \\"far more common\\" than symmetric scales and this may be accounted for by the inability of symmetric scales to possess the property of uniqueness (containing each interval class a unique number of times) which assists with determining the location of notes in relation to the first note of the scale.\\n\\nModes of limited transposition are musical modes or scales that fulfill specific criteria relating to their symmetry and the repetition of their interval groups. These scales may be transposed to all twelve notes of the chromatic scale, but at least two of these transpositions must result in the same pitch classes, thus their transpositions are \\"limited\\". They were compiled by the French composer Olivier Messiaen, and published in his book La technique de mon langage musical (\\"The Technique of my Musical Language\\").\\n\\n> Based on our present chromatic system, a tempered system of 12 sounds, these modes are formed of several symmetrical groups, the last note of each group always being common with the first of the following group. At the end of a certain number of chromatic transpositions which varies with each mode, they are no longer transposable, giving exactly the same notes as the first.\\n\\nMessiaen found ways of employing all of the modes of limited transposition harmonically, melodically, and sometimes polyphonically. The whole-tone and octatonic scales have enjoyed quite widespread use since the turn of the 20th century, particularly by Debussy (the whole-tone scale) and Stravinsky (the octatonic scale).\\n\\nThe symmetry inherent in these modes (which means no note can be perceived as the tonic), together with certain rhythmic devices, Messiaen described as containing \\"the charm of impossibilities\\".\\n\\nThe composer Tōru Takemitsu made frequent use of Messiaen's modes, particularly the third mode.\\n\\n## Definition by chromatic transposition\\n\\nTransposing the diatonic major scale up in semitones results in a different set of notes being used each time. For example, C major consists of C, D, E, F, G, A, B, and the scale a semitone higher (D♭ major) consists of D♭, E♭, F, G♭, A♭, B♭, C. By transposing D♭ major up another semitone, another new set of notes (D major) is produced, and so on, giving 12 different diatonic scales in total. When transposing a mode of limited transposition this is not the case. For example, the mode of limited transposition that Messiaen labelled \\"Mode 1\\", which is the whole tone scale, contains the notes C, D, E, F♯, G♯, A♯; transposing this mode up a semitone produces C♯, D♯, F, G, A, B. Transposing this up another semitone produces D, E, F♯, G♯, A♯, C, which is the same set of notes as the original scale. Since transposing the mode up a whole tone produces the same set of notes, mode 1 has only 2 transpositions.\\n\\nAny scale having 12 different transpositions is not a mode of limited transposition.\\n\\n## Definition by shifting modal degrees\\n\\nConsider the intervals of the major scale: tone, tone, semitone, tone, tone, tone, semitone. Starting the scale on a different degree will always create a new mode with individual interval layouts—for example starting on the second degree of a major scale gives the \\"Dorian mode\\"—tone, semitone, tone, tone, tone, semitone, tone. This is not so of the modes of limited transposition, which can be modally shifted only a limited number of times. For example, mode 1, the whole tone scale, contains the intervals tone, tone, tone, tone, tone, tone. Starting on any degree of the mode gives the same sequence of intervals, and therefore the whole tone scale has only 1 mode. Messiaen's mode 2, or the diminished scale, consists of semitone, tone, semitone, tone, semitone, tone, semitone, tone, which can be arranged only 2 ways, starting with either a tone or a semitone. Therefore mode 2 has two modes.\\n\\nAny scale having the same number of modes as notes is not a mode of limited transposition.\\n\\n### Whole tone scale\\n\\nInterval cycle 2 (C2).\\n\\nA whole-tone scale is a scale in which each note is separated from its neighbors by the interval of a whole tone. In twelve-tone equal temperament, there are only two complementary whole-tone scales, both six-note or hexatonic scales. A single whole tone scale can also be thought of as a \\"six-tone equal temperament\\".\\n\\nThe whole-tone scale has no leading tone and because all tones are the same distance apart, \\"no single tone stands out, and the scale creates a blurred, indistinct effect\\". This effect is especially emphasised by the fact that triads built on such scale tones are all augmented triads. Indeed, all six tones of a whole-tone scale can be played simply with two augmented triads whose roots are a major second apart. Since they are symmetrical, whole-tone scales do not give a strong impression of the tonic or tonality.\\n\\nWhole tone scale was used notably by Bach and Mozart, Glinka and Rimsky-Korsakov. H. C. Colles names as the \\"childhood of the whole-tone scale\\" the music of Berlioz and Schubert in France and Austria and then Russians Glinka and Dargomyzhsky. Claude Debussy, who had been influenced by Russians, along with other impressionist composers made extensive use of whole tone scales. Voiles, the second piece in Debussy's first book of Préludes, is almost entirely within one whole-tone scale.\\n\\nThe rāga Sahera in Hindustani classical music uses the same intervals as the whole-tone scale.\\n\\n### From second to the seventh modes\\n\\n<chroma-profile-collection :collection=\\"limited\\" />\\n","frontmatter":{"title":"Symmetrical scales","description":"Modes of limited transpostions and interval cycles","date":"2021-09-12T00:00:00.000Z"},"url":"/theory/scales/symmetrical/"},{"src":"---\\ntitle: Scale degrees\\ndescription: Positions of notes on a scale\\ndate: 2021-09-10\\n---\\n\\nThe term scale degree refers to the position of a particular note on a scale relative to the tonic, the first and main note of the scale from which each octave is assumed to begin. Degrees are useful for indicating the size of intervals and chords and whether they are major or minor.\\n\\nIn the most general sense, the scale degree is the number given to each step of the scale, usually starting with 1 for tonic. In a more specific sense, scale degrees are given names that indicate their particular function within the scale. This definition implies a functional scale, as is the case in tonal music.\\n\\n<scale-degrees />\\n\\nThe degrees of the traditional major and minor scales may be identified several ways:\\n\\n- by their ordinal numbers, as the first, second, third, fourth, fifth, sixth, or seventh degrees of the scale, sometimes raised or lowered;\\n- by Arabic numerals (1, 2, 3, 4 …), as in the Nashville Number System, sometimes with carets (scale degree 1, scale degree 2, scale degree 3, scale degree 4 …);\\n- by their name according to the movable do solfège system: do, re, mi, fa, so(l), la, and si (or ti).\\n- by Roman numerals (I, II, III, IV …);\\n- by the English name for their function:\\n  - tonic,\\n  - supertonic,\\n  - mediant,\\n  - subdominant,\\n  - dominant,\\n  - submediant,\\n  - subtonic or leading note (leading tone in the United States),\\n  - and tonic again.\\n\\nThese names are derived from a scheme where the tonic note is the 'centre'. Then the supertonic and subtonic are, respectively, a second above and below the tonic; the mediant and submediant are a third above and below it; and the dominant and subdominant are a fifth above and below the tonic.\\n","frontmatter":{"title":"Scale degrees","description":"Positions of notes on a scale","date":"2021-09-10T00:00:00.000Z"},"url":"/theory/scales/degrees/"},{"src":"---\\ntitle: Syncopation, swing and groove\\ndescription: The propulsive quality or \\"feel\\" of a rhythm and swung notes to serve it\\ncover: jadson-thomas.jpg\\ndate: 2021-09-05\\n---\\n\\n## Syncopation\\n\\n[Syncopation](https://en.wikipedia.org/wiki/Syncopation) is a musical term meaning a variety of rhythms played together to make a piece of music, making part or all of a tune or piece of music off-beat. More simply, syncopation is \\"a disturbance or interruption of the regular flow of rhythm\\": a \\"placement of rhythmic stresses or accents where they wouldn't normally occur\\". It is the correlation of at least two sets of time intervals.\\n\\nSyncopation is used in many musical styles, especially dance music. According to music producer Rick Snoman, \\"All dance music makes use of syncopation, and it's often a vital element that helps tie the whole track together\\". In the form of a back beat, syncopation is used in virtually all contemporary popular music.\\n\\nSyncopation can also occur when a strong harmony is simultaneous with a weak beat, for instance, when a 7th-chord is played on the second beat of 3/4 measure or a dominant chord is played at the fourth beat of a 4/4 measure. The latter occurs frequently in tonal cadences for 18th- and early-19th-century music and is the usual conclusion of any section.\\n\\n<youtube-embed video=\\"RuvA4b_2pk0\\" />\\n\\n### Types of syncopation\\n\\nTechnically, \\"syncopation occurs when a temporary displacement of the regular metrical accent occurs, causing the emphasis to shift from a strong accent to a weak accent\\". \\"Syncopation is\\", however, \\"very simply, a deliberate disruption of the two- or three-beat stress pattern, most often by stressing an off-beat, or a note that is not on the beat.\\"\\n\\n#### Suspension\\n\\nFor the following example, there are two points of syncopation where the third beats are sustained from the second beats. In the same way, the first beat of the second bar is sustained from the fourth beat of the first bar.\\n\\nThough syncopation may be very complex, dense or complex-looking rhythms often contain no syncopation. However, whether it is a placed rest or an accented note, any point in a piece of music that changes the listener's sense of the downbeat is a point of syncopation because it shifts where the strong and weak accents are built.\\n\\n#### Off-beat syncopation\\n\\nThe stress can shift by less than a whole beat, so it occurs on an offbeat, whereas the notes are expected to occur on the beat. Playing a note ever so slightly before, or after, a beat is another form of syncopation because this produces an unexpected accent:\\n\\nIt can be helpful to think of a 4/4 rhythm in eighth notes and count it as \\"1-and-2-and-3-and-4-and\\". In general, emphasizing the \\"and\\" would be considered the off-beat.\\n\\n#### Anticipated bass\\n\\nAnticipated bass is a bass tone that comes syncopated shortly before the downbeat, which is used in Son montuno Cuban dance music. Timing can vary, but it usually occurs on the 2+ and the 4 of the 4/4 time, thus anticipating the third and first beats. This pattern is known commonly as the Afro-Cuban bass tumbao.\\n\\n#### Transformation\\n\\nRichard Middleton suggests adding the concept of transformation to Narmour's prosodic rules which create rhythmic successions in order to explain or generate syncopations. \\"The syncopated pattern is heard 'with reference to', 'in light of', as a remapping of, its partner.\\" He gives examples of various types of syncopation: Latin, backbeat, and before-the-beat.\\n\\n**Latin equivalent of simple 4/4:** a syncopated rhythm in which the first and fourth beat are provided as expected, but the accent occurs unexpectedly in between the second and third beats, creating a familiar \\"Latin rhythm\\" known as tresillo.\\n\\n**Backbeat transformation of simple 4/4**: the accent may be shifted from the first to the second beat in duple meter (and the third to fourth in quadruple), creating the backbeat rhythm. Different crowds will \\"clap along\\" at concerts either on 1 and 3 or on 2 and 4.\\n\\nThis demonstrates how each syncopated pattern may be heard as a remapping, \\"with reference to\\" or \\"in light of\\", an unsyncopated pattern.\\n\\n## Swing\\n\\nThe term [swing](<https://en.wikipedia.org/wiki/Swing_(jazz_performance_style)>) has two main uses. Colloquially, it is used to describe the propulsive quality or \\"feel\\" of a rhythm, especially when the music prompts a visceral response such as foot-tapping or head-nodding. This sense can also be called \\"groove\\".\\n\\nThe term swing, as well as swung note(s) and swung rhythm, is also used more specifically to refer to a technique (most commonly associated with jazz but also used in other genres) that involves alternately lengthening and shortening the first and second consecutive notes in the two part pulse-divisions in a beat.\\n\\n### Overview\\n\\nLike the term \\"groove\\", which is used to describe a cohesive rhythmic \\"feel\\" in a funk or rock context, the concept of \\"swing\\" can be hard to define. Indeed, some dictionaries use the terms as synonyms: \\"Groovy ... denotes music that really swings.\\" The Jazz in America glossary defines swing as, \\"when an individual player or ensemble performs in such a rhythmically coordinated way as to command a visceral response from the listener (to cause feet to tap and heads to nod); an irresistible gravitational buoyancy that defies mere verbal definition.\\"\\n\\nWhen jazz performer Cootie Williams was asked to define it, he joked, \\"Define it? I'd rather tackle Einstein's theory!\\" When Louis Armstrong was asked on the Bing Crosby radio show what swing was, he said, \\"Ah, swing, well, we used to call it syncopation—then they called it ragtime, then blues—then jazz. Now, it's swing. Ha! Ha! White folks, yo'all sho is a mess.\\"\\n\\nBenny Goodman, the 1930s-era bandleader nicknamed the \\"King of Swing\\", called swing \\"free speech in music\\", whose most important element is \\"the liberty a soloist has to stand and play a chorus in the way he feels it\\". His contemporary Tommy Dorsey gave a more ambiguous definition when he proposed that \\"Swing is sweet and hot at the same time and broad enough in its creative conception to meet every challenge tomorrow may present.\\" Boogie-woogie pianist Maurice Rocco argues that the definition of swing \\"is just a matter of personal opinion\\". When asked for a definition of swing, Fats Waller replied, \\"Lady, if you gotta ask, you'll never know.\\"\\n\\n> What is Swing? Perhaps the best answer, after all, was supplied by the hep-cat who rolled her eyes, stared into the far-off and sighed, \\"You can feel it, but you just can't explain it. Do you dig me?\\"\\n> — Treadwell (1946), p.10\\n\\nStanley Dance, in The World of Swing, devoted the two first chapters of his work to discussions of the concept of swing with a collection of the musicians who played it. They described a kinetic quality to the music. It was compared to flying; \\"take off\\" was a signal to start a solo. The rhythmic pulse continued between the beats, expressed in dynamics, articulation, and inflection. Swing was as much in the music anticipating the beat, like the swing of a jumprope anticipating the jump, as in the beat itself. Swing has been defined in terms of formal rhythmic devices, but according to the Jimmie Lunceford tune, \\"T'aint whatcha do, it's the way thatcha do it\\" (say it so it swings).\\n\\n### Swing as a rhythmic style\\n\\nIn swing rhythm, the pulse is divided unequally, such that certain subdivisions (typically either eighth note or sixteenth note subdivisions) alternate between long and short durations. Certain music of the Baroque and Classical era is played using notes inégales, which is analogous to swing. In shuffle rhythm, the first note in a pair may be twice (or more) the duration of the second note. In swing rhythm, the ratio of the first note's duration to the second note's duration can take on a range of magnitudes. The first note of each pair is often understood to be twice as long as the second, implying a triplet feel, but in practice the ratio is less definitive and is often much more subtle. In traditional jazz, swing is typically applied to eighth notes. In other genres, such as funk and jazz-rock, swing is often applied to sixteenth notes.\\n\\nIn most jazz music, especially of the big band era and later, the second and fourth beats of a 4/4 measure are emphasized over the first and third, and the beats are lead-in—main-beat couplets (dah-DUM, dah-DUM....). The \\"dah\\" anticipates, or leads into, the \\"DUM.\\" The \\"dah\\" lead-in may or may not be audible. It may be occasionally accented for phrasing or dynamic purposes.\\n\\nThe instruments of a swing rhythm section express swing in different ways from each other, and the devices evolved as the music developed. During the early development of swing music, the bass was often played with lead-in—main-note couplets, often with a percussive sound. Later, the lead-in note was dropped but incorporated into the physical rhythm of the bass player to help keep the beat \\"solid.\\"\\n\\nSimilarly, the rhythm guitar was played with the lead-in beat in the player's physical rhythm but inaudible. The piano was played with a variety of devices for swing. Chord patterns played in the rhythm of a dotted-eight—sixteenth couplet were characteristic of boogie-woogie playing (sometimes also used in boogie-woogie horn section playing). The \\"swing bass\\" left hand, used by James P. Johnson, Fats Waller, and Earl Hines, used a bass note on the first and third beats, followed by a mid-range chord to emphasize the second and fourth beats. The lead-in beats were not audible, but expressed in the motion of the left arm.\\n\\nSwing piano also put the first and third beats a role anticipatory to the emphasized second and fourth beats in two-beat bass figures.\\n\\nAs swing music developed, the role of the piano in the ensemble changed to emphasize accents and fills; these were often played on the lead-in to the main beat, adding a punch to the rhythm. Count Basie's style was sparse, played as accompaniment to the horn sections and soloists.\\n\\nThe bass and snare drums started the swing era as the main timekeepers, with the snare usually used for either lead-ins or emphasis on the second and fourth beats. It was soon found that the high-hat cymbal could add a new dimension to the swing expressed by the drum kit when played in a two-beat \\"ti-tshhh-SH\\" figure, with the \\"ti\\" the lead-in to the \\"tshhh\\" on the first and third beats, and the \\"SH\\" the emphasized second and fourth beats.\\n\\nWith that high-hat figure, the drummer expressed three elements of swing: the lead-in with the \\"ti,\\" the continuity of the rhythmic pulse between the beats with the \\"tshhh,\\" and the emphasis on the second and fourth beats with the \\"SH\\". Early examples of that high-hat figure were recorded by the drummer Chick Webb. Jo Jones carried the high-hat style a step further, with a more continuous-sounding \\"t'shahhh-uhh\\" two beat figure while reserving the bass and snare drums for accents. The changed role of the drum kit away from the heavier style of the earlier drumming placed more emphasis on the role of the bass in holding the rhythm.\\n\\nHorn sections and soloists added inflection and dynamics to the rhythmic toolbox, \\"swinging\\" notes and phrases. One of the characteristic horn section sounds of swing jazz was a section chord played with a strong attack, a slight fade, and a quick accent at the end, expressing the rhythmic pulse between beats. That device was used interchangeably or in combination with a slight downward slur between the beginning and the end of the note.\\n\\nSimilarly, section arrangements sometimes used a series of triplets, either accented on the first and third notes or with every other note accented to make a 3/2 pattern. Straight eighth notes were commonly used in solos, with dynamics and articulation used to express phrasing and swing. Phrasing dynamics built swing across two or four measures or, in the innovative style of tenor saxophonist Lester Young, across odd sequences of measures, sometimes starting or stopping without regard to place in the measure.\\n\\nThe rhythmic devices of the swing era became subtler with bebop. Bud Powell and other piano players influenced by him mostly did away with left-hand rhythmic figures, replacing them with chords. The ride cymbal played in a \\"ting-ti-ting\\" pattern took the role of the high-hat, the snare drum was mainly used for lead-in accents, and the bass drum was mainly used for occasional \\"bombs.\\" But the importance of the lead-in as a rhythmic device was still respected. Drummer Max Roach emphasized the importance of the lead-in, audible or not, in \\"protecting the beat.\\" Bebop soloists rose to the challenge of keeping a swinging feel in highly sophisticated music often played at a breakneck pace. The groundbreakers of bebop had come of age as musicians with swing and, while breaking the barriers of the swing era, still reflected their swing heritage.\\n\\nVarious rhythmic swing approximations:\\n\\n- ≈1:1 = eighth note + eighth note, \\"straight eighths.\\"\\n- ≈3:2 = long eighth + short eighth.\\n- ≈2:1 = triplet quarter note + triplet eighth, triple meter;\\n- ≈3:1 = dotted eighth note + sixteenth note.\\n\\nThe subtler end of the range involves treating written pairs of adjacent eighth notes (or sixteenth notes, depending on the level of swing) as slightly asymmetrical pairs of similar values. On the other end of the spectrum, the \\"dotted eighth – sixteenth\\" rhythm, consists of a long note three times as long as the short. Prevalent \\"dotted rhythms\\" such as these in the rhythm section of dance bands in the mid-20th century are more accurately described as a \\"shuffle\\"; they are also an important feature of baroque dance and many other styles.\\n\\nIn jazz, the swing ratio typically lies somewhere between 1:1 and 3:1, and can vary considerably. Swing ratios in jazz tend to be wider at slower tempos and narrower at faster tempos. In jazz scores, swing is often assumed, but is sometimes explicitly indicated. For example, \\"Satin Doll\\", a swing era jazz standard, was notated in 4/4 time and in some versions includes the direction, medium swing.\\n\\n### Genres using swing rhythm\\n\\nSwing is commonly used in swing jazz, ragtime, blues, jazz, western swing, new jack swing, big band jazz, swing revival, funk, funk blues, R&B, soul music, rockabilly, neo rockabilly, rock and hip-hop. Much written music in jazz is assumed to be performed with a swing rhythm. Styles that always use traditional (triplet) rhythms, resembling \\"hard swing\\", include foxtrot, quickstep and some other ballroom dances, Stride piano, and 1920s-era Novelty piano (the successor to Ragtime style).\\n\\n## Groove\\n\\n[Groove](<https://en.wikipedia.org/wiki/Groove_(music)>) is the sense of an effect (\\"feel\\") of changing pattern in a propulsive rhythm or sense of \\"swing\\". In jazz, it can be felt as a quality of persistently repeated rhythmic units, created by the interaction of the music played by a band's rhythm section (e.g. drums, electric bass or double bass, guitar, and keyboards). Groove is a significant feature of popular music, and can be found in many genres, including salsa, rock, soul, funk, and fusion.\\n\\nCharacteristic rock groove: \\"bass drum on beats 1 and 3 and snare drum on beats 2 and 4 of the measure...add eighth notes on the hi-hat\\".\\n\\nFrom a broader ethnomusicological perspective, groove has been described as \\"an unspecifiable but ordered sense of something that is sustained in a distinctive, regular and attractive way, working to draw the listener in.\\" Musicologists and other scholars have analyzed the concept of \\"groove\\" since around the 1990s. They have argued that a \\"groove\\" is an \\"understanding of rhythmic patterning\\" or \\"feel\\" and \\"an intuitive sense\\" of \\"a cycle in motion\\" that emerges from \\"carefully aligned concurrent rhythmic patterns\\" that stimulates dancing or foot-tapping on the part of listeners. The concept can be linked to the sorts of ostinatos that generally accompany fusions and dance musics of African derivation (e.g. African-American, Afro-Cuban, Afro-Brazilian, etc.).\\n\\nThe term is often applied to musical performances that make one want to move or dance, and enjoyably \\"groove\\" (a word that also has sexual connotations). The expression \\"in the groove\\" (as in the jazz standard) was widely used from around 1936 to 1945, at the height of the swing era, to describe top-notch jazz performances. In the 1940s and 1950s, groove commonly came to denote musical \\"routine, preference, style, [or] source of pleasure.\\"\\n\\n### Description\\n\\n#### Musicians' perspectives\\n\\nLike the term \\"swing\\", which is used to describe a cohesive rhythmic \\"feel\\" in a jazz context, the concept of \\"groove\\" can be hard to define. Marc Sabatella's article Establishing The Groove argues that \\"groove is a completely subjective thing.\\" He claims that \\"one person may think a given drummer has a great feel, while another person may think the same drummer sounds too stiff, and another may think he is too loose.\\" Similarly, a bass educator states that while \\"groove is an elusive thing\\" it can be defined as \\"what makes the music breathe\\" and the \\"sense of motion in the context of a song\\".\\n\\nIn a musical context, general dictionaries define a groove as \\"a pronounced, enjoyable rhythm\\" or the act of \\"creat[ing], danc[ing] to, or enjoy[ing] rhythmic music\\". Steve Van Telejuice explains the \\"groove\\" as the point in this sense when he defines it as a point in a song or performance when \\"even the people who can't dance wanna feel like dancing...\\" due to the effect of the music.\\n\\nBernard Coquelet argues that the \\"groove is the way an experienced musician will play a rhythm compared with the way it is written (or would be written)\\" by playing slightly \\"before or after the beat\\". Coquelet claims that the \\"notion of groove actually has to do with aesthetics and style\\"; \\"groove is an artistic element, that is to say human,...and \\"it will evolve depending on the harmonic context, the place in the song, the sound of the musician's instrument, and, in interaction with the groove of the other musicians\\", which he calls \\"collective\\" groove\\". Minute rhythmic variations by the rhythm section members such as the bass player can dramatically change the feel as a band plays a song, even for a simple singer-songwriter groove.\\n\\n#### Theoretical analysis\\n\\nUK musicologist Richard Middleton (1999) notes that while \\"the concept of groove\\" has \\"long [been] familiar in musicians' own usage\\", musicologists and theorists have only more recently begun to analyze this concept. Middleton states that a groove \\"... marks an understanding of rhythmic patterning that underlies its role in producing the characteristic rhythmic 'feel' of a piece\\". He notes that the \\"feel created by a repeating framework\\" is also modified with variations. \\"Groove\\", in terms of pattern-sequencing, is also known as \\"shuffle note\\"—where there is deviation from exact step positions.\\n\\nWhen the musical slang phrase \\"Being in the groove\\" is applied to a group of improvisers, this has been called \\"an advanced level of development for any improvisational music group\\", which is \\"equivalent to Bohm and Jaworski's descriptions of an evoked field\\", which systems dynamics scholars claim are \\"forces of unseen connection that directly influence our experience and behaviour\\". Peter Forrester and John Bailey argue that the \\"chances of achieving this higher level of playing\\" (i.e., attain a \\"groove\\") are improved when the musicians are \\"open to other's musical ideas\\", \\"finding ways of complementing other participant's [sic] musical ideas\\", and \\"taking risks with the music\\".\\n\\nTurry and Aigen cite Feld's definition of groove as \\"an intuitive sense of style as process, a perception of a cycle in motion, a form or organizing pattern being revealed, a recurrent clustering of elements through time\\". Aigen states that \\"when [a] groove is established among players, the musical whole becomes greater than the sum of its parts, enabling a person [...] to experience something beyond himself which he/she cannot create alone (Aigen 2002, p.34)\\".\\n\\nJeff Pressing's 2002 article claimed that a \\"groove or feel\\" is \\"a cognitive temporal phenomenon emerging from one or more carefully aligned concurrent rhythmic patterns, characterized by...perception of recurring pulses, and subdivision of structure in such pulses,...perception of a cycle of time, of length 2 or more pulses, enabling identification of cycle locations, and...effectiveness of engaging synchronizing body responses (e.g. dance, foot-tapping)\\".\\n\\n#### Neuroscientific perspectives\\n\\nThe \\"groove\\" has been cited as an example of sensory-motor coupling between neural systems. Sensory-motor coupling is the coupling or integration of the sensory system and motor system. Sensorimotor integration is not a static process. For a given stimulus, there is no one single motor command. \\"Neural responses at almost every stage of a sensorimotor pathway are modified at short and long timescales by biophysical and synaptic processes, recurrent and feedback connections, and learning, as well as many other internal and external variables\\". Recent research has shown that at least some styles of modern groove-oriented rock music are characterized by an \\"aesthetics of exactitude\\" and the strongest groove stimulation could be observed for drum patterns without microtiming deviations.\\n\\n### Use in different genres\\n\\n#### Jazz\\n\\nIn some more traditional styles of jazz, the musicians often use the word \\"swing\\" to describe the sense of rhythmic cohesion of a skilled group. However, since the 1950s, musicians from the organ trio and latin jazz subgenres have also used the term \\"groove\\". Jazz flute player Herbie Mann talks a lot about \\"the groove.\\" In the 1950s, Mann \\"locked into a Brazilian groove in the early '60s, then moved into a funky, soulful groove in the late '60s and early '70s. By the mid-'70s he was making hit disco records, still cooking in a rhythmic groove.\\" He describes his approach to finding the groove as follows: \\"All you have to do is find the waves that are comfortable to float on top of.\\" Mann argues that the \\"epitome of a groove record\\" is \\"Memphis Underground or Push Push\\", because the \\"rhythm section [is] locked all in one perception.\\"\\n\\n#### Reggae\\n\\nIn Jamaican reggae, dancehall, and dub music, the creole term \\"riddim\\" is used to describe the rhythm patterns created by the drum pattern or a prominent bassline. In other musical contexts a \\"riddim\\" would be called a \\"groove\\" or beat. One of the widely copied \\"riddims\\", Real Rock, was recorded in 1967 by Sound Dimension. \\"It was built around a single, emphatic bass note followed by a rapid succession of lighter notes. The pattern repeated over and over hypnotically. The sound was so powerful that it gave birth to an entire style of reggae meant for slow dancing called rub a dub.\\"\\n\\n<youtube-embed video=\\"ne1oIaPIyIw\\" />\\n\\n#### R&B\\n\\nThe \\"groove\\" is also associated with funk performers, such as James Brown's drummers Clyde Stubblefield and Jabo Starks, and with soul music. \\"In the 1950s, when 'funk' and 'funky' were used increasingly as adjectives in the context of soul music—the meaning being transformed from the original one of a pungent odor to a re-defined meaning of a strong, distinctive groove.\\" As \\"[t]he soul dance music of its day, the basic idea of funk was to create as intense a groove as possible.\\" When a drummer plays a groove that \\"is very solid and with a great feel...\\", this is referred to informally as being \\"in the pocket\\"; when a drummer \\"maintains this feel for an extended period of time, never wavering, this is often referred to as a deep pocket.\\"\\n\\n<youtube-embed video=\\"jczjHqV2IUg\\" />\\n\\n#### Hip hop\\n\\nA concept similar to \\"groove\\" or \\"swing\\" is also used in other African-American genres such as hip hop. The rhythmic groove that jazz artists call a sense of “swing” is sometimes referred to as having \\"flow\\" in the hip hop scene. \\"Flow is as elemental to hip hop as the concept of swing is to jazz\\". Just as the jazz concept of \\"swing\\" involves performers deliberately playing behind or ahead of the beat, the hip-hop concept of flow is about \\"funking with one's expectations of time\\"—that is, the rhythm and pulse of the music. \\"Flow is not about what is being said so much as how one is saying it\\".\\n","frontmatter":{"title":"Syncopation, swing and groove","description":"The propulsive quality or \\"feel\\" of a rhythm and swung notes to serve it","cover":"/media_files/cover/theory-rhythm-groove-jadson-thomas.jpg","date":"2021-09-05T00:00:00.000Z"},"url":"/theory/rhythm/groove/"},{"src":"---\\ntitle: Indian Raga\\ndescription: Improvisational music framework\\ndate: 2021-09-03\\n\\ncover: five-gandharva.jpg\\n---\\n\\n<scale-raga />\\n\\nA raga or raag (IAST: rāga; also raaga or ragam; literally \\"coloring, tingeing, dyeing\\") is a melodic framework for improvisation akin to a melodic mode in Indian classical music. The rāga is a unique and central feature of the classical Indian music tradition, and as a result has no direct translation to concepts in classical European music. Each rāga is an array of melodic structures with musical motifs, considered in the Indian tradition to have the ability to \\"colour the mind\\" and affect the emotions of the audience.\\n\\nEach rāga provides the musician with a musical framework within which to improvise. Improvisation by the musician involves creating sequences of notes allowed by the rāga in keeping with rules specific to the rāga. Rāgas range from small rāgas like Bahar and Shahana that are not much more than songs to big rāgas like Malkauns, Darbari and Yaman, which have great scope for improvisation and for which performances can last over an hour. Rāgas may change over time, with an example being Marwa, the primary development of which has been going down into the lower octave, in contrast with the traditional middle octave. Each rāga traditionally has an emotional significance and symbolic associations such as with season, time and mood. The rāga is considered a means in the Indian musical tradition to evoking specific feelings in an audience. Hundreds of rāga are recognized in the classical tradition, of which about 30 are common, and each rāga has its \\"own unique melodic personality\\".\\n\\nEvery raga has a swara (a note or named pitch) called shadja, or adhara sadja, whose pitch may be chosen arbitrarily by the performer. This is taken to mark the beginning and end of the saptak (loosely, octave). The raga also contains an adhista, which is either the swara Ma or the swara Pa. The adhista divides the octave into two parts or anga - the purvanga, which contains lower notes, and the uttaranga, which contains higher notes. Every raga has a vadi and a samvadi. The vadi is the most prominent swara, which means that an improvising musician emphasizes or pays more attention to the vadi than to other notes. The samvadi is consonant with the vadi (always from the anga that does not contain the vadi) and is the second most prominent swara in the raga.\\n\\n <img src=\\"./sarigama.svg\\" />\\n\\nAccording to Monier Monier-Williams, the term comes from a Sanskrit word for \\"the act of colouring or dyeing\\", or simply a \\"colour, hue, tint, dye\\". The term also connotes an emotional state referring to a \\"feeling, affection, desire, interest, joy or delight\\", particularly related to passion, love, or sympathy for a subject or something. In the context of ancient Indian music, the term refers to a harmonious note, melody, formula, building block of music available to a musician to construct a state of experience in the audience.\\n\\nThe word appears in the ancient Principal Upanishads of Hinduism, as well as the Bhagavad Gita.[ For example, verse 3.5 of the Maitri Upanishad and verse 2.2.9 of the Mundaka Upanishad contain the word rāga. The Mundaka Upanishad uses it in its discussion of soul (Atman-Brahman) and matter (Prakriti), with the sense that the soul does not \\"color, dye, stain, tint\\" the matter. The Maitri Upanishad uses the term in the sense of \\"passion, inner quality, psychological state\\". The term rāga is also found in ancient texts of Buddhism where it connotes \\"passion, sensuality, lust, desire\\" for pleasurable experiences as one of three impurities of a character. Alternatively, rāga is used in Buddhist texts in the sense of \\"color, dye, hue\\".\\n\\n<youtube-embed video=\\"J8QgzZQ3hyc\\" />\\n\\nIn 1933, states José Luiz Martinez – a professor of music, Stern refined this explanation to \\"the rāga is more fixed than mode, less fixed than the melody, beyond the mode and short of melody, and richer both than a given mode or a given melody; it is mode with added multiple specialities\\".\\n\\nAccording to Walter Kaufmann, though a remarkable and prominent feature of Indian music, a definition of rāga cannot be offered in one or two sentences. rāga is a fusion of technical and ideational ideas found in music, and may be roughly described as a musical entity that includes note intonation, relative duration and order, in a manner similar to how words flexibly form phrases to create an atmosphere of expression. In some cases, certain rules are considered obligatory, in others optional. The rāga allows flexibility, where the artist may rely on simple expression, or may add ornamentations yet express the same essential message but evoke a different intensity of mood.\\n\\nA rāga has a given set of notes, on a scale, ordered in melodies with musical motifs. A musician playing a rāga, states Bruno Nettl, may traditionally use just these notes, but is free to emphasize or improvise certain degrees of the scale. The Indian tradition suggests a certain sequencing of how the musician moves from note to note for each rāga, in order for the performance to create a rasa (mood, atmosphere, essence, inner feeling) that is unique to each rāga. A rāga can be written on a scale. Theoretically, thousands of rāga are possible given 5 or more notes, but in practical use, the classical tradition has refined and typically relies on several hundred. For most artists, their basic perfected repertoire has some forty to fifty rāgas. Rāga in Indian classic music is intimately related to tala or guidance about \\"division of time\\", with each unit called a matra (beat, and duration between beats).\\n\\n## 72 Melakarta ragas\\n\\nHere’s a list of an aesthetic and scientifically designed chart of the 72 parent ragas which have been assigned to 12 chakras/wheel each comprising six ragas.\\n\\n<img src=\\"./Melakarta.katapayadi.sankhya.png\\" />\\n\\nContinuing the extremely complex system from which our Carnatic classical music was derived we here arrive at a very aesthetic and scientifically designed chart of the 72 parent ragas. These are called melakarta ragas which numbering 72 have been re-scheduled into 36 each taking the ‘shuddha madhyama’ and ‘prati (sharp) madhyama’, namely the note ‘Ma’ respectively. Again, these 72 ragas have been assigned to 12 chakras/wheel each comprising six ragas. Therefore, we have six chakras in the Ma1 (shuddha madhyama) scale and six in the Ma2 (prati madhyama).\\n\\nThe nomenclature given to the chakras carries great import. For instance, the first chakra being numero uno is called ‘Indu’ after the moon of which we have just one in our universe; chakra two is named after the eyes: netra; the third after agni (fire) which exists in three forms (treat agni); the fourth after the four Vedas, the fifth is the bana chakra after the pancha bana (five arrows of Manmatha/Cupid), the sixth Rithu after the seasons (shat rithu); the seventh is Rishi after the sapta (7)rishis; the eighth is called ‘Vasu chakra’ (our mythology speaks of 8 Vasus/superhumans); the ninth is ‘Brahma’ of which we are told there are 9 (nava brahma/creators); the tenth is ‘Disi’ or direction and in Indian system we count 10 directions; the eleventh is Rudra chakra named after 11 rudras/deities and finally the 12th chakra is the ‘Aditya’ or sun of which there are 12 in the galaxy apart from ours.\\n\\n<youtube-embed video=\\"mrFJ9MLR7do\\" />\\n\\nThis apart, the entire chart is made user-friendly by assigning the syllabic notes in an order that facilitates easy memorising for a student of music. For instance, all the ragas in the Indu chakra have a common note in rishabha and gandhara, viz,. ‘ra-ga’ (shuddha rishabha and shuddha gandhara-ri1 and ga1). The only notes that change their position in numerical order are the daivatha and nishadha (dha & ni). Similarly, in Netra chakra, it is ‘ra and gi’. The rishabha remains the same (ri1) while the gandhara changes to ‘sadharana gandharam (ga2). The third Agni chakra is identified with ‘ra-gu’ which means no change in the placement of rishabha but then the gandhara changes to antara gandhara (ga3). When it comes to the fourth Veda chakra, it is ‘ri-gi’ where the rishabha undergoes a change in position to chatursruti rishabha (ri2) with the gandhara remaining constant at sadharana gandhara (ga2). In the Bana chakra (ri-gu) the chatusruti rishabha is constant ‘ri2’ while the gandhara turns ‘ga3’. Finally, in the sixth Rithu chakra which completes the shuddha madhyama ragas, it is ‘ru-gu’ where the rishabha is placed in shatsruti (ri3) and the gandhara remains in ‘ga3’. The same is repeated in the next six chakras (37-72) which come under the prati madhayama melakarta ragas corresponding to the 36 shuddha madhyama ragas.\\n\\n<youtube-embed video=\\"G5xfoEVyJRg\\" />\\n\\nNow let’s get the list of these 72 ragas: Kanakangi, Ratnangi, Ganamurti, Vanaspati, Manavati, Tanarupi (Indu chakra); Senavati, Hanumathodi (todi), Dhenuka, Natakapriya, Kokilapriya, Rupavathi (Netra chakra); Gayakapriya, Vakulapriya, Mayamalavagowla, Chakravakam, Suryakantam, Hatakambari (Agni Chakra); Jhankaradwani, Natabhairavi, Keeravani, Kharaharapriya, Gourimanohari, Varunapriya (Veda chakra); Mara ranjani, Charukesi, Sarasangi, Harikambhoji, Dheera Sankarabharanam (Sankarabharanam), Naganandini (Bana chakra); Yagapriya, Ragavardhini, Gaangeyabhushani, Vagadeeshwari, Shulini, Chalanata (Naata) (Ritu chakra); Salagam, Jalarnavam, Jhalavarali, Navaneetam, Pavani, Raghupriya (Rishi chakra); Shadvidhamargini, Shuba Panthuvarali, Gavambhodi, Suvarnangi, Divyamani, Bhavapriya (Vasu chakra); Dhavalambari, Naamanarayani, Kamavardhini, Ramapriya, Gamanashrama, Vishwambari (Brahma chakra); Shyamalangi, Shanmukhapriya, Simhendra Madhyamam, Hemavathi, Dharmavathi, Neethimathi (Disi chakra); Kantamani, Rishabapriya, Lataangi, Vaachaspati, Meccha Kalyani (Kalyani), Chitrambari (Rudra chakra); Sucharita, Jyothiswaroopini, Dhatuvardhini, Kosalam, Nasika bhushani, Rasikapriya (Aditya chakra).\\n\\n## Katapayadi system\\n\\n[ka·ṭa·pa·yā·di](https://en.wikipedia.org/wiki/Katapayadi_system) (Devanagari: कटपयादि) system (also known as Paralppēru, Malayalam: പരല്‍പ്പേര്) of numerical notation is an ancient Indian alphasyllabic numeral system to depict letters to numerals for easy remembrance of numbers as words or verses. Assigning more than one letter to one numeral and nullifying certain other letters as valueless, this system provides the flexibility in forming meaningful words out of numbers which can be easily remembered.\\n\\nFollowing verse found in Śaṅkaravarman's Sadratnamāla explains the mechanism of the system.\\n\\n> नञावचश्च शून्यानि संख्या: कटपयादय:।  \\n> मिश्रे तूपान्त्यहल् संख्या न च चिन्त्यो हलस्वर:॥\\n\\nTransiliteration:\\n\\n> nanyāvacaśca śūnyāni saṃkhyāḥ kaṭapayādayaḥ  \\n> miśre tūpāntyahal saṃkhyā na ca cintyo halasvaraḥ\\n\\nTranslation: na (न), nya (ञ) and a (अ)-s, i.e., vowels represent zero. The nine integers are represented by consonant group beginning with ka, ṭa, pa, ya. In a conjunct consonant, the last of the consonants alone will count. A consonant without a vowel is to be ignored.\\n\\nExplanation: The assignment of letters to the numerals are as per the following arrangement (In Devanagari, Kannada, Telugu & Malayalam respectively)\\n\\n| 1          | 2           | 3          | 4           | 5             | 6           | 7           | 8          | 9           | 0           |\\n| ---------- | ----------- | ---------- | ----------- | ------------- | ----------- | ----------- | ---------- | ----------- | ----------- |\\n| ka क ಕ క ക | kha ख ಖ ఖ ഖ | ga ग ಗ గ ഗ | gha घ ಘ ఘ ഘ | nga ङ ಙ జ్ఞ ങ | ca च ಚ చ ച  | cha छ ಛ ఛ ഛ | ja ज ಜ జ ജ | jha झ ಝ ఝ ഝ | nya ञ ಞ ఞ ഞ |\\n| ṭa ट ಟ ట ട | ṭha ठ ಠ ఠ ഠ | ḍa ड ಡ డ ഡ | ḍha ढ ಢ ఢ ഢ | ṇa ण ಣ ణ ണ    | ta त ತ త ത  | tha थ ಥ థ ഥ | da द ದ ద ദ | dha ध ಧ ధ ധ | na न ನ న ന  |\\n| pa प ಪ ప പ | pha फ ಫ ఫ ഫ | ba ब బ ബ   | bha भ ಭ భ ഭ | ma म ಮ మ മ    | –           | –           | –          | –           | –           |\\n| ya य ಯ య യ | ra र ರ ర ര  | la ल ల ల ല | va व ವ వ വ  | śha श ಶ శ ശ   | sha ष ಷ ష ഷ | sa स ಸ స സ  | ha ह ಹ హ ഹ | –           | –           |\\n\\n- Consonants have numerals assigned as per the above table. For example, ba (ब) is always 3 whereas 5 can be represented by either nga (ङ) or ṇa (ण) or ma (म) or śha (श).\\n- All stand-alone vowels like a (अ) and ṛ (ऋ) are assigned to zero.\\n- In case of a conjunct, consonants attached to a non-vowel will be valueless. For example, kya (क्या) is formed by k (क्) + ya (य) + a (अ). The only consonant standing with a vowel is ya (य). So the corresponding numeral for kya (क्या) will be 1.\\n- There is no way of representing the decimal separator in the system.\\n- Indians used the Hindu–Arabic numeral system for numbering, traditionally written in increasing place values from left to right. This is as per the rule \\"अङ्कानां वामतो गतिः\\" which means numbers go from right to left.\\n\\nThe melakarta ragas of the Carnatic music is named so that the first two syllables of the name will give its number. This system is sometimes called the Ka-ta-pa-ya-di sankhya. The Swaras 'Sa' and 'Pa' are fixed, and here is how to get the other swaras from the melakarta number.\\n\\nMelakartas 1 through 36 have Ma1 and those from 37 through 72 have Ma2.\\nThe other notes are derived by noting the (integral part of the) quotient and remainder when one less than the melakarta number is divided by 6. If the melakarta number is greater than 36, subtract 36 from the melakarta number before performing this step.\\n'Ri' and 'Ga' positions: the raga will have:\\nRi1 and Ga1 if the quotient is 0\\nRi1 and Ga2 if the quotient is 1\\nRi1 and Ga3 if the quotient is 2\\nRi2 and Ga2 if the quotient is 3\\nRi2 and Ga3 if the quotient is 4\\nRi3 and Ga3 if the quotient is 5\\n'Da' and 'Ni' positions: the raga will have:\\nDa1 and Ni1 if remainder is 0\\nDa1 and Ni2 if remainder is 1\\nDa1 and Ni3 if remainder is 2\\nDa2 and Ni2 if remainder is 3\\nDa2 and Ni3 if remainder is 4\\nDa3 and Ni3 if remainder is 5\\n\\n### Raga Dheerasankarabharanam\\n\\nThe katapayadi scheme associates dha ↔ \\"title\\" 9 and ra ↔ \\"title\\" 2, hence the raga's melakarta number is 29 (92 reversed). Now 29 ≤ \\"title\\" 36, hence Dheerasankarabharanam has Ma1. Divide 28 (1 less than 29) by 6, the quotient is 4 and the remainder 4. Therefore, this raga has Ri2, Ga3 (quotient is 4) and Da2, Ni3 (remainder is 4). Therefore, this raga's scale is Sa Ri2 Ga3 Ma1 Pa Da2 Ni3 SA.\\n\\n### Raga MechaKalyani\\n\\nFrom the coding scheme Ma ↔ \\"title\\" 5, Cha ↔ \\"title\\" 6. Hence the raga's melakarta number is 65 (56 reversed). 65 is greater than 36. So MechaKalyani has Ma2. Since the raga's number is greater than 36 subtract 36 from it. 65–36=29. 28 (1 less than 29) divided by 6: quotient=4, remainder=4. Ri2 Ga3 occurs. Da2 Ni3 occurs. So MechaKalyani has the notes Sa Ri2 Ga3 Ma2 Pa Da2 Ni3 SA.\\n\\n### Exception for Simhendramadhyamam\\n\\nAs per the above calculation, we should get Sa ↔ \\"title\\" 7, Ha ↔ \\"title\\" 8 giving the number 87 instead of 57 for Simhendramadhyamam. This should be ideally Sa ↔ \\"title\\" 7, Ma ↔ \\"title\\" 5 giving the number 57. So it is believed that the name should be written as Sihmendramadhyamam (as in the case of Brahmana in Sanskrit).\\n\\n## Chakras\\n\\nThe 72 melakarta ragas are split into 12 groups called chakras, each containing 6 ragas. The ragas within the chakra differ only in the dhaivatham and nishadham notes (D and N), as illustrated below. The name of each of the 12 chakras suggest their ordinal number as well.[2][4]\\n\\n- **Indu** stands for the moon, of which we have only one - hence it is the first chakra.\\n- **Netra** means eyes, of which we have two - hence it is the second.\\n- **Agni** is the third chakra as it denotes the three agnis or the holy fires (laukikaagni - earthly fire, daavaagni - lightning, and divyaagni - the Sun).\\n- **Veda** denoting four Vedas or scriptures namely Rigveda, Samaveda, Yajurveda, Atharvaveda is the name of the fourth chakra.\\n- **Bana** comes fifth as it stands for the five banas of Manmatha.\\n- **Rutu** is the sixth chakra standing for the 6 seasons of Hindu calendar.\\n- **Rishi**, meaning sage, is the seventh chakra representing the seven sages.\\n- **Vasu** stands for the eight vasus of Hinduism.\\n- **Brahma** comes next of which there are 9.\\n- The 10 directions, including akash (sky) and patal (nether region), is represented by the tenth chakra, **Disi**.\\n- Eleventh chakra is **Rudra** of which represents the eleven names of Lord Shiva.\\n- Twelfth comes **Aditya** of which stands for the twelve names of Lord Surya or the Sun God.\\n\\n## Asampurna Melakarta\\n\\nhttps://en.wikipedia.org/wiki/Asampurna_Melakarta\\n\\nThe Asampurna Melakarta (transliterated as Asaṃpūrṇa Mēḷakarta) scheme is the system of 72 ragas (musical scales) originally proposed in the 17th century by Venkatamakhin in his Chaturdanda Prakasikha. This proposal used scales with notes that do not conform to the sampurna raga system. Skipped notes or repeated notes, etc., were used in some of the ragas. Some of the ragas of any Melakarta system will use Vivadi swaras (discordant notes). The original system is supposed to avoid such ill-effects and was followed by the Muthuswami Dikshitar school. The naming of the original system followed Katapayadi system. Muthuswami Dikshitar's compositions use the name of these ragas in the lyrics of the songs and is still referred to by those names even in radio / TV announcements of these songs.\\n\\nLater Govindacharya came up with a more mathematical and regular system of 72 ragas, which is currently considered fundamental ragas (musical scales) in Carnatic music (South Indian classical music). These melakarta ragas were sampurna ragas. Some of the names of the ragas had to be modified to fit into the Katapayadi system.\\n\\nIn the Asampurna Melakarta system, there is no set rule for the ragas in contrast to the currently used system of Melakarta ragas. Some ragas though are the same in both systems (like 15 - Mayamalavagowla and 29 - Dheerasankarabharanam), and in some cases the scales are same, while names are different (like 8 - Janatodi and Hanumatodi, 56 - Chamaram and Shanmukhapriya).\\n\\nhttp://music-raagaa.blogspot.com/p/72-melakartha-raagas_17.html\\n\\nhttps://www.ragasurabhi.com/index.html\\n\\nhttp://carnatica.net/origin.htm\\n\\nhttp://www.melakarta.com/index.html\\n\\nhttp://www.carnaticcorner.com/articles/22_srutis.htm\\n","frontmatter":{"title":"Indian Raga","description":"Improvisational music framework","date":"2021-09-03T00:00:00.000Z","cover":"/media_files/cover/theory-scales-raga-five-gandharva.jpg"},"url":"/theory/scales/raga/"},{"src":"---\\ntitle: Sight reading\\ndescription: The complexity of perfecting staff notaion reading\\ndate: 2021-09-02\\ncover: Michelangelo_Caravaggio_026.jpg\\n---\\n\\nSight-singing is used to describe a singer who is sight-reading. Both activities require the musician to play or sing the notated rhythms and pitches.\\n\\n## Psychology\\n\\nThe ability to sight-read partly depends on a strong short-term musical memory. An experiment on sight reading using an eye tracker indicates that highly skilled musicians tend to look ahead further in the music, storing and processing the notes until they are played; this is referred to as the eye–hand span.\\n\\nStorage of notational information in working memory can be expressed in terms of the amount of information (load) and the time for which it must be held before being played (latency). The relationship between load and latency changes according to tempo, such that t = x/y, where t is the change in tempo, x is the change in load, and y is the change in latency. Some teachers and researchers have proposed that the eye–hand span can be trained to be larger than it would otherwise be under normal conditions, leading to more robust sight-reading ability.\\n\\nHuman memory can be divided into three broad categories: long-term memory, sensory memory, and short-term (working) memory. According to the formal definition, working memory is \\"a system for temporarily storing and managing the information required to carry out complex cognitive tasks such as learning, reasoning, and comprehension\\". The paramount feature that distinguishes the working memory from both the long-term and sensory memory is this system's ability to simultaneously process and store information. The knowledge has what is called a \\"limited capacity\\", so there is only a certain amount of information that can be stored and it is easily accessible for only a small window of time after it has been processed, with a recall time block of roughly fifteen seconds to one minute.\\n\\nExperiments dealing with memory span have been conducted by George Miller in 1956 that indicated, \\"Most common number of items that can be stored in the working memory is five plus or minus two.” However, if this information is not retained and stored (“consolidated”) in one's long-term memory, it will fade quickly.\\n\\nResearch indicates that the main area of the brain associated with the working memory is the prefrontal cortex. The prefrontal cortex is located in the frontal lobe of the brain. This area deals with cognition and contains two major neural loops or pathways that are central to processing tasks via the working memory: the visual loop, which is necessary for the visual component of the task, and the phonological loop, which deals with the linguistic aspects of the task (i.e. repeating the word or phrase). Although the hippocampus, in the temporal lobe, is the brain structure most frequently paired with memories, studies have indicated that its role is more vital for consolidation of the short-term memories into long-term ones than the ability to process, carry out, and briefly recall certain tasks.\\n\\nThis type of memory has specifically come into focus when discussing sight reading, since the process of looking at musical notes for the first time and deciphering them while playing an instrument can be considered a complex task of comprehension. The main conclusion in terms of this idea is that working memory, short-term memory capacity and mental speed are three important predictors for sight reading achievement. Although none of the studies discredits the correlation between the amount of time one spends practicing and musical ability, specifically sight-reading proficiency, more studies are pointing to the level at which one’s working memory functions as the key factor in sight-reading abilities. As stated in one such study, \\"Working memory capacity made a statistically significant contribution as well (about 7 percent, a medium-size effect). In other words, if you took two pianists with the same amount of practice, but different levels of working memory capacity, it's likely that the one higher in working memory capacity would have performed considerably better on the sight-reading task.\\"\\n\\nBased on the research and opinions of multiple musicians and scientists, the take home message about one's sight-reading ability and working memory capacity seems to be that “The best sight-readers combined strong working memories with tens of thousands of hours of practice.”\\n\\nSight-reading also depends on familiarity with the musical idiom being performed; this permits the reader to recognize and process frequently occurring patterns of notes as a single unit, rather than individual notes, thus achieving greater efficiency. This phenomenon, which also applies to the reading of language, is referred to as chunking. Errors in sight-reading tend to occur in places where the music contains unexpected or unusual sequences; these defeat the strategy of \\"reading by expectation\\" that sight-readers typically employ.\\n\\n## Professional use\\n\\nStudio musicians (e.g., musicians employed to record pieces for commercials, etc.) often record pieces on the first take without having seen them before. Often, the music played on television is played by musicians who are sight-reading. This practice has developed through intense commercial competition in these industries.\\n\\nKevin McNerney, jazz musician, professor, and private instructor, describes auditions for University of North Texas Jazz Lab Bands as being almost completely based on sight-reading: \\"you walk into a room and see three or four music stands in front of you, each with a piece of music on it (in different styles ...). You are then asked to read each piece in succession.\\"\\n\\nThis emphasis on sight-reading, according to McNerney, prepares musicians for studio work \\"playing backing tracks for pop performers or recording [commercials]\\". The expense of the studio, musicians, and techs makes sight-reading skills essential. Typically, a studio performance is \\"rehearsed\\" only once to check for copying errors before recording the final track. Many professional big bands also sight-read every live performance. They are known as \\"rehearsal bands\\", even though their performance is the rehearsal.\\n\\nAccording to Frazier, score reading is an important skill for those interested in the conducting profession and \\"Conductors such as the late Robert Shaw and Yoel Levi have incredibly strong piano skills and can read at sight full orchestral scores at the piano\\" (a process which requires the pianist to make an instant piano reduction of the key parts of the score).\\n\\n## Pedagogy\\n\\nAlthough 86% of piano teachers polled rated sight-reading as the most important or a highly important skill, only 7% of them said they address it systematically. Reasons cited were a lack of knowledge of how to teach it, inadequacy of the training materials they use, and deficiency in their own sight-reading skills. Teachers also often emphasize rehearsed reading and repertoire building for successful recitals and auditions to the detriment of sight-reading and other functional skills.\\n\\nHardy reviewed research on piano sight-reading pedagogy and identified a number of specific skills essential to sight-reading proficiency:\\n\\n- Technical fundamentals in reading and fingering\\n- Visualization of keyboard topography\\n- Tactile facility (psychomotor skills) and memory\\n- Ability to read, recognize, and remember groups of notes (directions, patterns, phrases, chords, rhythmic groupings, themes, inversions, intervals, etc.)\\n- Ability to read and remember ahead of playing with more and wider progressive fixations\\n- Aural imagery (ear-playing and sight-singing improves sight-reading)\\n- Ability to keep the basic pulse, read, and remember rhythm\\n- Awareness and knowledge of the music's structure and theory\\n\\nBeauchamp identifies five building blocks in the development of piano sight-reading skills:\\n\\n- Grand-staff knowledge\\n- Security within the five finger positions\\n- Security with keyboard topography\\n- Security with basic accompaniment patterns\\n- Understanding of basic fingering principles\\n\\nGrand-staff knowledge consists of fluency in both clefs such that reading a note evokes an automatic and immediate physical response to the appropriate position on the keyboard. Beauchamp asserts it is better to sense and know where the note is than what the note is. The performer does not have time to think of the note name and translate it to a position, and the non-scientific note name does not indicate the octave to be played. Beauchamp reports success using a Key/Note Visualizer, note-reading flashcards, and computer programs in group and individual practice to develop grand-staff fluency.\\n\\nUdtaisuk also reports that a sense of keyboard geography and an ability to quickly and efficiently match notes to keyboard keys is important for sight-reading. He found that \\"computer programs and flash cards are effective ways to teach students to identify notes [and] enhance a sense of keyboard geography by highlighting the relationships between the keyboard and the printed notation\\".\\n\\nMost students do not sight-read well because it requires specific instruction, which is seldom given. A major challenge in sight-reading instruction, according to Hardy, is obtaining enough practice material. Since practicing rehearsed reading does not help improve sight-reading, a student can only use a practice piece once. Moreover, the material must be at just the right level of difficulty for each student, and a variety of styles is preferred. Hardy suggests music teachers cooperate to build a large lending library of music and purchase inexpensive music from garage sales and store sales.\\n\\nhttps://en.wikipedia.org/wiki/Sight-reading\\n","frontmatter":{"title":"Sight reading","description":"The complexity of perfecting staff notaion reading","date":"2021-09-02T00:00:00.000Z","cover":"/media_files/cover/theory-notes-staff-sight-reading-Michelangelo_Caravaggio_026.jpg"},"url":"/theory/notes/staff/sight-reading/"},{"src":"---\\ntitle: Solmization\\ndescription: Systems of attributing a distinct syllable to each note of a musical scale.\\n\\ndate: 2021-08-31\\ncover: The_Hand_of_Guido.jpg\\n---\\n\\nSolmization is a system of attributing a distinct syllable to each note of a musical scale. Various forms of solmization are in use and have been used throughout the world, but solfège is the most common convention in countries of Western culture.\\n\\n## Solfège\\n\\nSyllables are assigned to the notes of the scale and enable the musician to audiate, or mentally hear, the pitches of a piece of music being seen for the first time and then to sing them aloud. Through the Renaissance (and much later in some shapenote publications) various interlocking 4, 5 and 6-note systems were employed to cover the octave. The tonic sol-fa method popularized the seven syllables commonly used in English-speaking countries: do (or doh in tonic sol-fa), re, mi, fa, so(l), la, and ti (or si).\\n\\nThe seven syllables normally used for this practice in English-speaking countries are: do, re, mi, fa, sol, la, and ti (with sharpened notes of di, ri, fi, si, li and flattened notes of te, le, se, me, ra). The system for other Western countries is similar, though si is often used as the final syllable rather than ti.\\n\\nThere are two current ways of applying solfège:\\n\\n1. **fixed do**, where the syllables are always tied to specific pitches (e.g. \\"do\\" is always \\"C-natural\\")\\n2. **movable do**, where the syllables are assigned to scale degrees, with \\"do\\" always the first degree of the major scale.\\n\\n![](./The_Hand_of_Guido.jpg)\\n\\nIn eleventh-century Italy, the music theorist Guido of Arezzo in his work \\"Micrologus\\" invented a notational system that named the six notes of the hexachord after the first syllable of each line of the Latin hymn Ut queant laxis, the \\"Hymn to St. John the Baptist\\", yielding ut, re, mi, fa, sol, la. Each successive line of this hymn begins on the next scale degree, so each note's name was the syllable sung at that pitch in this hymn.\\n\\n> **Ut** queant laxīs\\n> **re**sonāre fībrīs\\n> **Mī**ra gestōrum\\n> **fa**mulī tuōrum,\\n> **Sol**ve pollūtī\\n> **la**biī reātum,\\n> **S**ancte **I**ōhannēs.\\n\\nThe words were written by Paulus Diaconus in the 8th century. They translate as:\\n\\n> So that your servants may, with loosened voices,\\n> Resound the wonders of your deeds,\\n> Clean the guilt from our stained lips,\\n> O St. John.\\n\\n\\"Ut\\" was changed in the 1600s in Italy to the open syllable Do, at the suggestion of the musicologist Giovanni Battista Doni (based on the first syllable of his surname), and Si (from the initials for \\"Sancte Iohannes\\") was added to complete the diatonic scale. In Anglophone countries, \\"si\\" was changed to \\"ti\\" by Sarah Glover in the nineteenth century so that every syllable might begin with a different letter. \\"Ti\\" is used in tonic sol-fa (and in the famed American show tune \\"Do-Re-Mi\\").\\n\\n## Movable do\\n\\nIn Movable do or tonic sol-fa, each syllable corresponds to a scale degree. This is analogous to the Guidonian practice of giving each degree of the hexachord a solfège name.\\n\\nMovable do is frequently employed in Australia, China, Japan (with 5th being so, and 7th being si), Ireland, the United Kingdom, the United States, Hong Kong, and English-speaking Canada. The movable do system is a fundamental element of the Kodály method used primarily in Hungary, but with a dedicated following worldwide. In the movable do system, each solfège syllable corresponds not to a pitch, but to a scale degree: The first degree of a major scale is always sung as \\"do\\", the second as \\"re\\", etc. (For minor keys, see below.) In movable do, a given tune is therefore always sol-faed on the same syllables, no matter what key it is in.\\n\\nPassages in a minor key may be sol-faed in one of two ways in movable do: either starting on do (using \\"me\\", \\"le\\", and \\"te\\" for the lowered third, sixth, and seventh degrees, and \\"la\\" and \\"ti\\" for the raised sixth and seventh degrees), which is referred to as \\"do-based minor\\", or starting on la (using \\"fi\\" and \\"si\\" for the raised sixth and seventh degrees). The latter (referred to as \\"la-based minor\\") is sometimes preferred in choral singing, especially with children.\\n\\n### Tonic sol-fa\\n\\nTonic sol-fa (or tonic sol-fah) is a pedagogical technique for teaching sight-singing, invented by Sarah Ann Glover (1785–1867) of Norwich, England and popularised by John Curwen, who adapted it from a number of earlier musical systems. It uses a system of musical notation based on movable do solfège, whereby every note is given a name according to its relationship with other notes in the key: the usual staff notation is replaced with anglicized solfège syllables (e.g. do, re, mi, fa, sol, la, ti, do) or their abbreviations (d, r, m, f, s, l, t, d). \\"Do\\" is chosen to be the tonic of whatever key is being used (thus the terminology moveable Do in contrast to the fixed Do system used by John Pyke Hullah). The original solfège sequence started with \\"Ut\\" which later became \\"Do\\".\\n\\n![](./Solfege_Ireland.jpg)\\n\\nSolmization that represents the functions of pitches (such as tonic sol-fa) is called \\"functional\\" solmization. All musicians that use functional solmization use \\"do\\" to represent the tonic (also known as the \\"keynote\\") in the major mode. However, approaches to the minor mode fall into two camps. Some musicians use \\"do\\" to represent the tonic in minor (a parallel approach), whereas others prefer to label the tonic in minor as \\"la\\" (a relative approach) Both systems have their advantages: The former system more directly represents the scale-degree functions of the pitches in a key; the latter more directly represents the intervals between pitches in any given key signature.\\n\\n![](./Curwen_Hand_Signs_MT.jpg)\\n\\n## Fixed do\\n\\nIn Fixed do, each syllable corresponds to the name of a note. This is analogous to the Romance system naming pitches after the solfège syllables, and is used in Romance and Slavic countries, among others, including Spanish-speaking countries.\\n\\nIn the major Romance and Slavic languages, the syllables Do, Re, Mi, Fa, Sol, La, and Si are used to name notes the same way that the letters C, D, E, F, G, A, and B are used to name notes in English. For native speakers of these languages, solfège is simply singing the names of the notes, omitting any modifiers such as \\"sharp\\" or \\"flat\\" to preserve the rhythm.\\n\\n### Chromatic variants\\n\\nSeveral chromatic fixed-do Systems that have also been devised to account for chromatic notes, and even for double-sharp and double-flat variants. The Yehnian being the first 24-EDO solfège, proposed even quartertonal syllables while having no exceptions of its rules, and usability for both Si and Ti users.\\n\\n<table class=\\"m-auto text-center\\" dir=\\"ltr\\"  cellspacing=\\"0\\" cellpadding=\\"0\\">\\n<tbody>\\n<tr >\\n<td colspan=\\"2\\" rowspan=\\"1\\" >Note name</td>\\n<td colspan=\\"5\\" rowspan=\\"1\\" >Syllable</td>\\n<td colspan=\\"1\\" rowspan=\\"2\\" >\\nPitch class\\n</td>\\n</tr>\\n<tr >\\n<td >English</td>\\n<td >Romance</td>\\n<td >Traditional</td>\\n<td >Shearer</td>\\n<td >Siler</td>\\n<td >Sotorrio</td>\\n<td >Yehnian (chromatic)</td>\\n</tr>\\n<tr >\\n<td >C♭</td>\\n<td >Do♭</td>\\n<td>&nbsp;</td>\\n<td >de</td>\\n<td >do</td>\\n<td >(Tsi)</td>\\n<td >Də</td>\\n<td >11</td>\\n</tr>\\n<tr >\\n<td >C</td>\\n<td >Do</td>\\n<td >do</td>\\n<td >do</td>\\n<td >da</td>\\n<td >Do</td>\\n<td >Do</td>\\n<td >0</td>\\n</tr>\\n<tr >\\n<td >C♯</td>\\n<td >Do♯</td>\\n<td>&nbsp;</td>\\n<td >di</td>\\n<td >de</td>\\n<td >Ga</td>\\n<td >Du</td>\\n<td >1</td>\\n</tr>\\n<tr >\\n<td >D♭</td>\\n<td >Re♭</td>\\n<td>&nbsp;</td>\\n<td >ra</td>\\n<td >ro</td>\\n<td >Ga</td>\\n<td >Rə</td>\\n<td >1</td>\\n</tr>\\n<tr >\\n<td >D</td>\\n<td >Re</td>\\n<td >re</td>\\n<td >re</td>\\n<td >ra</td>\\n<td >Ray</td>\\n<td >Re</td>\\n<td >2</td>\\n</tr>\\n<tr >\\n<td >D♯</td>\\n<td >Re♯</td>\\n<td>&nbsp;</td>\\n<td >ri</td>\\n<td >re</td>\\n<td >Nu</td>\\n<td >Ru</td>\\n<td >3</td>\\n</tr>\\n<tr >\\n<td >E♭</td>\\n<td >Mi♭</td>\\n<td>&nbsp;</td>\\n<td >me</td>\\n<td >mo</td>\\n<td >Nu</td>\\n<td >Mə</td>\\n<td >3</td>\\n</tr>\\n<tr >\\n<td >E</td>\\n<td >Mi</td>\\n<td >mi</td>\\n<td >mi</td>\\n<td >ma</td>\\n<td >Mi</td>\\n<td >Mi</td>\\n<td >4</td>\\n</tr>\\n<tr >\\n<td >E♯</td>\\n<td >Mi♯</td>\\n<td>&nbsp;</td>\\n<td >mai</td>\\n<td >me</td>\\n<td >(Fa)</td>\\n<td >Mu</td>\\n<td >5</td>\\n</tr>\\n<tr >\\n<td >F♭</td>\\n<td >Fa♭</td>\\n<td>&nbsp;</td>\\n<td >fe</td>\\n<td >fo</td>\\n<td >(Mi)</td>\\n<td >Fə</td>\\n<td >4</td>\\n</tr>\\n<tr >\\n<td >F</td>\\n<td >Fa</td>\\n<td >fa</td>\\n<td >fa</td>\\n<td >fa</td>\\n<td >Fa</td>\\n<td >Fa</td>\\n<td >5</td>\\n</tr>\\n<tr >\\n<td >F♯</td>\\n<td >Fa♯</td>\\n<td>&nbsp;</td>\\n<td >fi</td>\\n<td >fe</td>\\n<td >Jur</td>\\n<td >Fu</td>\\n<td >6</td>\\n</tr>\\n<tr >\\n<td >G♭</td>\\n<td >Sol♭</td>\\n<td>&nbsp;</td>\\n<td >se</td>\\n<td >so</td>\\n<td >Jur</td>\\n<td >Səl / Sə</td>\\n<td >6</td>\\n</tr>\\n<tr >\\n<td >G</td>\\n<td >Sol</td>\\n<td >sol</td>\\n<td >so</td>\\n<td >sa</td>\\n<td >Sol</td>\\n<td >Sol</td>\\n<td >7</td>\\n</tr>\\n<tr >\\n<td >G♯</td>\\n<td >Sol♯</td>\\n<td>&nbsp;</td>\\n<td >si</td>\\n<td >se</td>\\n<td >Ki</td>\\n<td >Sul / Su</td>\\n<td >8</td>\\n</tr>\\n<tr >\\n<td >A♭</td>\\n<td >La♭</td>\\n<td>&nbsp;</td>\\n<td >le</td>\\n<td >lo</td>\\n<td >Ki</td>\\n<td >Lə</td>\\n<td >8</td>\\n</tr>\\n<tr >\\n<td >A</td>\\n<td >La</td>\\n<td >la</td>\\n<td >la</td>\\n<td >la</td>\\n<td >La</td>\\n<td >La</td>\\n<td >9</td>\\n</tr>\\n<tr >\\n<td >A♯</td>\\n<td >La♯</td>\\n<td>&nbsp;</td>\\n<td >li</td>\\n<td >le</td>\\n<td >Pe</td>\\n<td >Lu</td>\\n<td >10</td>\\n</tr>\\n<tr >\\n<td >B♭</td>\\n<td >Si♭</td>\\n<td>&nbsp;</td>\\n<td >te</td>\\n<td >to</td>\\n<td >Pe</td>\\n<td >Sə / Tə</td>\\n<td >10</td>\\n</tr>\\n<tr >\\n<td >B</td>\\n<td >Si</td>\\n<td >si</td>\\n<td >ti</td>\\n<td >ta</td>\\n<td >Tsi</td>\\n<td >Si / Ti</td>\\n<td >11</td>\\n</tr>\\n<tr >\\n<td >B♯</td>\\n<td >Si♯</td>\\n<td>&nbsp;</td>\\n<td >tai</td>\\n<td >te</td>\\n<td >(Do)</td>\\n<td >Su / Tu</td>\\n<td >0</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n### Comparison of the two systems\\n\\nMovable Do corresponds to our psychological experience of normal tunes. If the song is sung a tone higher it is still perceived to be the same song, and the notes have the same relationship to each other, but in a fixed Do all the note names would be different. A movable Do emphasizes the musicality of the tune as the psychological perception of the notes is always relative to a key for the vast majority of people that do not have absolute pitch.\\n\\nJose Sotorrio argues that fixed-do is preferable for serious musicians, as music involving complex modulations and vague tonality is often too ambiguous with regard to key for any movable system. That is, without a prior analysis of the music, any movable-do system would inevitably need to be used like a fixed-do system anyway, thus causing confusion. With fixed-do, the musician learns to regard any syllable as the tonic, which does not force them to make an analysis as to which note is the tonic when ambiguity occurs. Instead, with fixed-do the musician will already be practiced in thinking in multiple/undetermined tonalities using the corresponding syllables.\\n\\nIn comparison to the movable do system, which draws on short-term relative pitch skills involving comparison to a pitch identified as the tonic of the particular piece being performed, fixed do develops long-term relative pitch skills involving comparison to a pitch defined independently of its role in the piece, a practice closer to the definition of each note in absolute terms as found in absolute pitch.\\n\\nInstrumentalists who begin sight-singing for the first time in college as music majors find movable do to be the system more consistent with the way they learned to read music.\\n\\nFor choirs, sight-singing fixed do using chromatic movable do syllables is more suitable than sight-singing movable do for reading atonal music, polytonal music, pandiatonic music, music that modulates or changes key often, or music in which the composer simply did not write a key signature. It is not uncommon for this to be the case in modern or contemporary choral works.\\n\\n## Tonic sol-fa notation\\n\\nIn Curwen's system, the notes of the major scale (of any key) are notated with the single letters d, r, m, f, s, l, and t. For notes above the principal octave, an apostrophe follows the letter; notes below the principal octave have a subscript mark. Chromatic alterations are marked by the following vowel, \\"e\\" for sharp (pronounced \\"ee\\") and \\"a\\" for flat (pronounced \\"aw\\"). Thus, the ascending and descending chromatic scale is notated:\\n\\n> d de r re m f fe s se l le t d'\\n>\\n> d' t ta l la s sa f m ma r ra d\\n\\nSuch chromatic notes appear only as ornaments or as preparation for a modulation; once the music has modulated, then the names for the new key are used. The modulation itself is marked by superscript of the old note name preceding its new name; for example, in modulation to the dominant, the new tonic is notated as sd. The music then proceeds in the new key until another modulation is notated.\\n\\n## Arabic system\\n\\nAn alternative theory argues that the solfège syllables (do, re, mi, fa, sol, la, ti) derive from the syllables of an Arabic solmization system درر مفصّلات Durar Mufaṣṣalāt (\\"Detailed Pearls\\") (**dāl, rā', mīm, fā', ṣād, lām, tā**), mentioned in the works of Francisci a Mesgnien Meninski in 1680 and later discussed by Jean-Benjamin de La Borde in 1780. However, there is no documentary evidence for this theory.\\n\\n## Indian sargam\\n\\nThe Svara solmization of India has origins in Vedic texts like the Upanishads, which discuss a musical system of seven notes, realized ultimately in what is known as sargam. In Indian classical music, the notes in order are: **sa, re, ga, ma, pa, dha, and ni**, which correspond to the Western solfege system.\\n\\nThese seven degrees are shared by both major rāga system, that is the North Indian (Hindustani) and South Indian (Carnatic). The solfege (sargam) is learnt in abbreviated form: sa, ri (Carnatic) or re (Hindustani), ga, ma, pa, dha, ni, sa. Of these, the first that is \\"sa\\", and the fifth that is \\"pa\\", are considered anchors that are unalterable, while the remaining have flavors that differs between the two major systems.\\n\\n## Byzantine system\\n\\nByzantine music uses syllables derived from the Greek alphabet to name notes: starting with A, the notes are **pa (alpha), vu (beta, pronounced v in modern greek), ga (gamma), di (delta), ke (epsilon), zo (zeta), ni (eta)**.\\n\\n## Asian systems\\n\\nFor Han people's music in China, the words used to name notes are (from fa to mi): **上 (siong or shàng), 尺 (cei or chǐ), 工 (gōng), 凡 (huan or fán), 六 (liuo or liù), 五 (ngou or wǔ), 乙 (yik or yǐ)**. The system is used for teaching sight-singing.\\n\\nFor Japanese music, the first line of Iroha, an ancient poem used as a tutorial of traditional kana, is used for solmization. The syllables representing the notes A, B, C, D, E, F, G are **i, ro, ha, ni, ho, he, to** respectively. Shakuhachi musical notation uses another solmization system beginning \\"Fu Ho U\\".\\n\\nJavanese musicians derive syllables from numbers: **ji-ro-lu-pat-ma-nem-pi**. These names derive from one-syllable simplification of the Javanese numerals siji, loro, telu, papat, lima, enem, pitu. ([Pa]pat and pi[tu], corresponding to 4 and 7, are skipped in the pentatonic slendro scale.)\\n\\n## DODEKA system\\n\\nThe objective was to create 2-letter names that convey a relationship between the names of the notes and their position on the staff.\\n\\nWe did that using letters that are not present in the English (anglo-saxon) designation.\\n\\nFor example, the note Do# (C#) is called Ka (K) because it shares the same position as La (A) (ie. both notes are above a line).\\n\\nFollowing this logic, the 12 notes can be written as:\\nDo / Ka / Ré / To(l) / Mi / Fa / Hu / So(l) / Pi / La / Vé / Si.\\n\\nIn English, we only use the first letters, which gives us the following sequence:\\nC / K / D / T / E / F / H / G / P / A / V / B.\\n","frontmatter":{"title":"Solmization","description":"Systems of attributing a distinct syllable to each note of a musical scale.","date":"2021-08-31T00:00:00.000Z","cover":"/media_files/cover/theory-notes-solmization-The_Hand_of_Guido.jpg"},"url":"/theory/notes/solmization/"},{"src":"---\\ntitle: Nature of sound\\ndescription: The acoustic waves - their sources and mediums.\\n\\ndate: 2021-08-31\\ncover: sound-waves.jpg\\n---\\n\\n\\n## What is sound?\\n\\n![](./Spherical_pressure_waves.gif)\\n\\nAcoustic vibrations propagate as mechanical waves of pressure in a transmission medium such as gas, liquid or solid. The speed of sound in air at 20 ºC is about 343 m/s (1,235 km/h) and complexly depends on density and pressure/stiffness of the medium. Audio range falls between infrasonic (&lt;20 Hz) and ultrasonic (>20 kHz) frequencies.\\n\\n<sound-vibrations class=\\"my-16\\" id=\\"sound-vibrations\\" />\\n\\n## Lindsay's Wheel of Acoustics\\n\\n![](./Lindsays_Wheel_of_Acoustics.svg)\\n\\n![](./atmosphere-speed-of-sound.png)\\n","frontmatter":{"title":"Nature of sound","description":"The acoustic waves - their sources and mediums.","date":"2021-08-31T00:00:00.000Z","cover":"/media_files/cover/theory-sound-nature-sound-waves.jpg"},"url":"/theory/sound/nature/"},{"src":"---\\ntitle: National notation systems of ancient and modern cultures\\ndescription: Greece, Korea and others\\ndate: 2021-08-30\\n\\ncover: Bhat_notation1.jpg\\nsvaras:\\n  - name: ṣaḍja (षड्ज)\\n    trans: Giving birth to the six\\n    variants: shuddha sa (sa)\\n    color: Green\\n    planet: Mercury\\n    mnem: Sa\\n    solfege: Do\\n    chakra: Mūlādhāra\\n\\n  - name: ṛṣabha (ऋषभ)\\n    variants: komal re (ra), shuddha re (ri)\\n    trans: Bull\\n    color: Red\\n    planet: Mars\\n    mnem: Re\\n    solfege: Re\\n    chakra: Svādhiṣṭhāna\\n\\n  - name: gāndhāra (गान्धार)\\n    variants: komal ga (ga), shuddha ma (gi)\\n    trans: Minium\\n    color: Gold\\n    planet: Sun\\n    mnem: Ga\\n    solfege: Mi\\n    chakra: Maṇipūra\\n\\n  - name: madhyama (मध्यम)\\n    variants: shuddha ma (mi), tivra ma (mu)\\n    trans: Middlemost\\n    color: White\\n    planet: Moon\\n    mnem: Ma\\n    solfege: Fa\\n    chakra: Anāhata\\n\\n  - name: pañcama (पंचम)\\n    trans: Fifth\\n    variants: shuddha pa (pa)\\n    color: Black\\n    planet: Saturn\\n    mnem: Pa\\n    solfege: Sol\\n    chakra: Viśuddha\\n\\n  - name: dhaivata (धैवत)\\n    variants: komal dha (dha), shuddha dha (dhi)\\n    trans: Steady\\n    color: Yellow\\n    planet: Jupiter\\n    mnem: Dha\\n    solfege: La\\n    chakra: Ājñā\\n\\n  - name: niṣāda (निषाद)\\n    variants: komal ni (na), shuddha ni (ni)\\n    trans: Sitting\\n    color: Multi\\n    planet: Venus\\n    mnem: Ni\\n    solfege: Si\\n    chakra: Sahasrāra\\n---\\n\\n## Indian notation\\n\\n### The seven varnas of a saptak.\\n\\nThe Samaveda text (1200 BC – 1000 BC) contains notated melodies, and these are probably the world's oldest surviving ones.\\n\\nhttps://en.wikipedia.org/wiki/Vedic_accent\\n\\nThe musical notation is written usually immediately above, sometimes within, the line of Samaveda text, either in syllabic or a numerical form depending on the Samavedic Sakha (school). The Indian scholar and musical theorist Pingala (c. 200 BC), in his Chanda Sutra, used marks indicating long and short syllables.\\n\\n![](./Bhat_notation1.jpg)\\n\\n## Saptak - सप्तक - 7 svaras - Octave\\n\\n<table class=\\"text-center text-sm\\">\\n<tr>\\n  <th>Solfege</th>\\n  <th>Syllable</th>\\n  <th>Name</th>\\n  <th>Meaning</th>\\n  <th>Variants</th>\\n  <th>Color</th>\\n  <th>Planet</th>\\n  <th>Chakra</th>\\n</tr>\\n<tr v-for=\\"svara in $frontmatter.svaras\\" :key=\\"svara.name\\">\\n  <td> {{svara.solfege}}</td>\\n  <td class=\\"font-bold\\"> {{svara.mnem}}</td>\\n  <td> {{svara.name}}</td>\\n  <td> {{svara.trans}}</td>\\n  <td> {{svara.variants}}</td>\\n  <td :style=\\"{backgroundColor: svara.color}\\"> {{svara.color}}</td>\\n  <td> {{svara.planet}}</td>\\n  <td> {{svara.chakra}}</td>\\n</tr>\\n</table>\\n\\nhttps://en.wikipedia.org/wiki/Svara\\n\\nhttp://sanskritdictionary.com/%E1%B9%A3a%E1%B8%8Dja/242242/1\\n\\n## Hurrian songs - the worlds oldest music notation artefact\\n\\n![](./images/Hurritische_hymne.gif)\\n\\nThe Hurrian songs are a collection of music inscribed in cuneiform on clay tablets excavated from the ancient Amorite-Canaanite city of Ugarit, a headland in northern Syria, which date to approximately 1400 BCE. One of these tablets, which is nearly complete, contains the Hurrian Hymn to Nikkal (also known as the Hurrian cult hymn or A Zaluzi to the Gods, or simply h.6), making it the oldest surviving substantially complete work of notated music in the world.\\n\\nThe complete song is one of about 36 such hymns in cuneiform writing, found on fragments of clay tablets excavated in the 1950s from the Royal Palace at Ugarit (present-day Ras Shamra, Syria), in a stratum dating from the fourteenth century BC, but is the only one surviving in substantially complete form.\\n\\n## Ancient Greece\\n\\nHymn to Applo in Delphi\\n\\n![](./images/Delphichymn.jpg)\\n\\n## China\\n\\n### Gongche - 'mi re'\\n\\n1. 上 - [sɑ̄ːŋ] - shàng - do\\n2. 尺 - [tsʰɛ́ː] - chě - re\\n3. 工 - [kʊ́ŋ] - gōng - mi\\n4. 凡 - [fɑ́ːn] - fán - fa\\n5. 六 - [líːu] - liù - sol\\n6. 五 - [wúː] - wǔ - la\\n7. 乙 - [jìː] - yǐ - si\\n\\n![](./images/gongche.jpg)\\n\\n![](./images/Kam_Hok_Yap_Mun-Yeung_Kwan_Sam_Tip.jpg)\\n\\n## Korea\\n\\n**Jeongganbo** musical notation system\\n\\n![](./images/Jeongganbo.jpg)\\n\\n## Japan\\n\\n**Kunkunshi** (工工四 (Okinawan) pronounced [kuŋkunɕiː]) is the traditional notation system by which music is recorded in the Ryukyu Islands. The term kunkunshi originally referred to the first three notes of a widely known Chinese melody, although today it is used almost exclusively in reference to the sheet music.\\n\\nKunkunshi is believed to have been first developed by Mongaku Terukina or by his student Choki Yakabi in the early to mid-1700s. However, it was not until the end of the 19th century that the form became standardized for writing sanshin music.\\n\\n![](./images/Kunkunshi.jpg)\\n\\n![](./images/Kunkunshi_for_Tinsagu_nu_Hana.png)\\n\\n<youtube-embed video=\\"O7DR4kjWG_c\\" />\\n","frontmatter":{"title":"National notation systems of ancient and modern cultures","description":"Greece, Korea and others","date":"2021-08-30T00:00:00.000Z","cover":"/media_files/cover/theory-notes-national-Bhat_notation1.jpg","svaras":[{"name":"ṣaḍja (षड्ज)","trans":"Giving birth to the six","variants":"shuddha sa (sa)","color":"Green","planet":"Mercury","mnem":"Sa","solfege":"Do","chakra":"Mūlādhāra"},{"name":"ṛṣabha (ऋषभ)","variants":"komal re (ra), shuddha re (ri)","trans":"Bull","color":"Red","planet":"Mars","mnem":"Re","solfege":"Re","chakra":"Svādhiṣṭhāna"},{"name":"gāndhāra (गान्धार)","variants":"komal ga (ga), shuddha ma (gi)","trans":"Minium","color":"Gold","planet":"Sun","mnem":"Ga","solfege":"Mi","chakra":"Maṇipūra"},{"name":"madhyama (मध्यम)","variants":"shuddha ma (mi), tivra ma (mu)","trans":"Middlemost","color":"White","planet":"Moon","mnem":"Ma","solfege":"Fa","chakra":"Anāhata"},{"name":"pañcama (पंचम)","trans":"Fifth","variants":"shuddha pa (pa)","color":"Black","planet":"Saturn","mnem":"Pa","solfege":"Sol","chakra":"Viśuddha"},{"name":"dhaivata (धैवत)","variants":"komal dha (dha), shuddha dha (dhi)","trans":"Steady","color":"Yellow","planet":"Jupiter","mnem":"Dha","solfege":"La","chakra":"Ājñā"},{"name":"niṣāda (निषाद)","variants":"komal ni (na), shuddha ni (ni)","trans":"Sitting","color":"Multi","planet":"Venus","mnem":"Ni","solfege":"Si","chakra":"Sahasrāra"}]},"url":"/theory/notes/national/"},{"src":"---\\ntitle: Human auditory system\\ndescription: Explore the intricate and inredibly complicated mechanism of converting acoustic vibrations to electrical nerve signals.\\n\\ndate: 2021-08-30\\ncover: auditory-system.png\\n---\\n\\n## Tonal perception\\n\\nSound is amplified and transformed into nerve signals by mechanically activated hair cells emitting glutamate neurotransmitter in a basilar membrane in the cochlea of the human inner ear. It happens in a spiral organ with 2.5 coils of tonotopically organized bone tissue resonating with different frequencies in its different locations.\\n\\n![](./auditory-system.png)\\n\\n![](./auditory-system-2.jpg)\\n\\n![](./basilar-membrane.jpg)\\n\\n<youtube-embed video=\\"XsXIOBx6cwI\\" />\\n\\nHearing is a crucial aspect of human communication, as the ear transforms sound vibrations from the environment into nerve impulses that are interpreted as sounds by the brain. The cochlea, a part of the inner ear, is responsible for frequency analysis, with different sections resonating at different frequencies. The place theory of hearing suggests that each place in the cochlea corresponds to the perception of a given frequency.\\n\\nThe just noticeable difference in frequency is about 1 Hz for frequencies lower than 1000 Hz for most people. However, the resonance curves of the cochlea are broad and overlap, making it difficult for the ear to pick out frequencies that are close together. The place theory of hearing cannot fully explain how we perceive different frequencies, as it does not account for the ability to hear sudden changes in frequency.\\n\\nThe place theory of hearing is one of the two opposing theories that attempt to explain the perceptual processing of sound sensation, alongside the frequency theory explorable.com. The place theory suggests that each part of the cochlea resonates at a different frequency, with the stapes end resonating at high frequencies and the end furthest from the ossicles resonating at low frequencies. When a given frequency is presented to the cochlea, it causes motion in only one part, which sends a nerve impulse to the brain, enabling the perception of that frequency. However, the place theory has limitations, as the resonance curves are broad and overlap, making it difficult for the ear to distinguish frequencies that are close together.\\n\\nThe temporal theory of hearing is another overlapping theory that aims to explain the richness of auditory phenomena experienced by humans. Unlike the place theory, the temporal theory focuses on the timing of neural activity, suggesting that the brain processes temporal information to perceive sound. This theory posits that the brain uses the timing of neural activity to distinguish between different frequencies, even when the resonance curves of the cochlea overlap. Combining the place theory and the temporal theory can help explain the complexity of human auditory perception and provide a more comprehensive understanding of how we perceive sound.\\n","frontmatter":{"title":"Human auditory system","description":"Explore the intricate and inredibly complicated mechanism of converting acoustic vibrations to electrical nerve signals.","date":"2021-08-30T00:00:00.000Z","cover":"/media_files/cover/theory-sound-hearing-auditory-system.png"},"url":"/theory/sound/hearing/"},{"src":"---\\ntitle: Psychoacoustics\\ndescription: The science of percieved sound\\n\\ndate: 2021-08-29\\ncover: hearing.svg\\n---\\n\\n## Equal-loudness contour\\n\\nThe human auditory system is sensitive to frequencies from about 20 Hz to a maximum of around 20,000 Hz, although the upper hearing limit decreases with age. Within this range, the human ear is most sensitive between 2 and 5 kHz, largely due to the resonance of the ear canal and the transfer function of the ossicles of the middle ear.\\n\\n![](./equal-loudness.svg)\\n\\nFletcher and Munson first measured equal-loudness contours using headphones (1933). In their study, test subjects listened to pure tones at various frequencies and over 10 dB increments in stimulus intensity. For each frequency and intensity, the listener also listened to a reference tone at 1000 Hz. Fletcher and Munson adjusted the reference tone until the listener perceived that it was the same loudness as the test tone. Loudness, being a psychological quantity, is difficult to measure, so Fletcher and Munson averaged their results over many test subjects to derive reasonable averages. The lowest equal-loudness contour represents the quietest audible tone—the absolute threshold of hearing. The highest contour is the threshold of pain.\\n\\n![](./Audible.jpg)\\n\\nIn 1956 Robinson and Dadson produced a new experimental determination that they believed was more accurate. It became the basis for a standard (ISO 226) that was considered definitive until 2003 when ISO revised the standard on the basis of recent assessments by research groups worldwide.\\n\\n[Audial illusions](./illusions/index.md)\\n\\nhttps://en.wikipedia.org/wiki/Interaural_time_difference\\n","frontmatter":{"title":"Psychoacoustics","description":"The science of percieved sound","date":"2021-08-29T00:00:00.000Z","cover":"/media_files/cover/theory-sound-psychoacoustics-hearing.svg"},"url":"/theory/sound/psychoacoustics/"},{"src":"---\\ntitle: Scales\\ndescription: A scale is a subset of 12 chromatic pitches\\n\\ncover: gray-notes.svg\\ndate: 2021-08-28\\nlinks:\\n  - https://williamzeitler.com/index.php\\n  - https://ianring.com/musictheory/scales/finder/#689\\n  - https://www.flutopedia.com/csc_3tone_12tet.htm\\n---\\n\\nScales are collections of pitch classes to play together. There's a plenty of such known and used [Note combinations](./study/index.md).\\n\\nFive notes is enough to construct the most simple and pleasant sounding [Pentatonic scales](./pentatonic/index.md). The most common scales nowadays are the 2 sets of 7 notes patterns: the [diatonic](./diatonic/index.md) and the [jazz/melodic](./melodic/index.md) families of scales. Every note in such a scale has it's own distinct role as a [Scale degree](./degrees/index.md).\\n\\nBreaking the diatonic rule the modernism era has discovered all the strange [Symmetrical scales](./symmetrical/index.md) that bring us more complex emotional effects.\\n\\nLet's not focus only on Western music theory, especially when it comes to scales. [Indian Raga](./raga/index.md) school has a much wider scope on note collections to be played and improvised over.\\n","frontmatter":{"title":"Scales","description":"A scale is a subset of 12 chromatic pitches","cover":"/media_files/cover/theory-scales-gray-notes.svg","date":"2021-08-28T00:00:00.000Z","links":["https://williamzeitler.com/index.php","https://ianring.com/musictheory/scales/finder/#689","https://www.flutopedia.com/csc_3tone_12tet.htm"]},"url":"/theory/scales/"},{"src":"---\\ntitle: Frequency and pitch\\ndescription: The human perception of sound frequency as a place of it at a scale\\ncover: jacek-ulinski.jpg\\ndate: 2021-08-28\\n---\\n\\nPitch is a perceptual property of sounds that allows their ordering on a frequency-related scale, or more commonly, pitch is the quality that makes it possible to judge sounds as \\"higher\\" and \\"lower\\" in the sense associated with musical melodies. Pitch is a major auditory attribute of musical tones, along with duration, loudness, and timbre.\\n\\nPitch may be quantified as a frequency, but pitch is not a purely objective physical property; it is a subjective psychoacoustical attribute of sound. Historically, the study of pitch and pitch perception has been a central problem in psychoacoustics, and has been instrumental in forming and testing theories of sound representation, processing, and perception in the auditory system.\\n\\n## Perception\\n\\n### Pitch and frequency\\n\\nPitch is an auditory sensation in which a listener assigns musical tones to relative positions on a musical scale based primarily on their perception of the frequency of vibration. Pitch is closely related to frequency, but the two are not equivalent. Frequency is an objective, scientific attribute that can be measured. Pitch is each person's subjective perception of a sound wave, which cannot be directly measured. However, this does not necessarily mean that most people won't agree on which notes are higher and lower.\\n\\nThe oscillations of sound waves can often be characterized in terms of frequency. Pitches are usually associated with, and thus quantified as, frequencies (in cycles per second, or hertz), by comparing the sounds being assessed against sounds with pure tones (ones with periodic, sinusoidal waveforms). Complex and aperiodic sound waves can often be assigned a pitch by this method.\\n\\nAccording to the American National Standards Institute, pitch is the auditory attribute of sound according to which sounds can be ordered on a scale from low to high. Since pitch is such a close proxy for frequency, it is almost entirely determined by how quickly the sound wave is making the air vibrate and has almost nothing to do with the intensity, or amplitude, of the wave. That is, \\"high\\" pitch means very rapid oscillation, and \\"low\\" pitch corresponds to slower oscillation. Despite that, the idiom relating vertical height to sound pitch is shared by most languages. At least in English, it is just one of many deep conceptual metaphors that involve up/down. The exact etymological history of the musical sense of high and low pitch is still unclear. There is evidence that humans do actually perceive that the source of a sound is slightly higher or lower in vertical space when the sound frequency is increased or reduced.\\n\\nIn most cases, the pitch of complex sounds such as speech and musical notes corresponds very nearly to the repetition rate of periodic or nearly-periodic sounds, or to the reciprocal of the time interval between repeating similar events in the sound waveform.\\n\\nThe pitch of complex tones can be ambiguous, meaning that two or more different pitches can be perceived, depending upon the observer. When the actual fundamental frequency can be precisely determined through physical measurement, it may differ from the perceived pitch because of overtones, also known as upper partials, harmonic or otherwise. A complex tone composed of two sine waves of 1000 and 1200 Hz may sometimes be heard as up to three pitches: two spectral pitches at 1000 and 1200 Hz, derived from the physical frequencies of the pure tones, and the combination tone at 200 Hz, corresponding to the repetition rate of the waveform. In a situation like this, the percept at 200 Hz is commonly referred to as the missing fundamental, which is often the greatest common divisor of the frequencies present.\\n\\nPitch depends to a lesser degree on the sound pressure level (loudness, volume) of the tone, especially at frequencies below 1,000 Hz and above 2,000 Hz. The pitch of lower tones gets lower as sound pressure increases. For instance, a tone of 200 Hz that is very loud seems one semitone lower in pitch than if it is just barely audible. Above 2,000 Hz, the pitch gets higher as the sound gets louder. These results were obtained in the pioneering works by S. Stevens and W. Snow. Later investigations, i.e. by A. Cohen, had shown that in most cases the apparent pitch shifts were not significantly different from pitch‐matching errors. When averaged, the remaining shifts followed the directions of Stevens' curves but were small (2% or less by frequency, i.e. not more than a semitone).\\n\\n### Theories of pitch perception\\n\\nTheories of pitch perception try to explain how the physical sound and specific physiology of the auditory system work together to yield the experience of pitch. In general, pitch perception theories can be divided into place coding and temporal coding. Place theory holds that the perception of pitch is determined by the place of maximum excitation on the basilar membrane.\\n\\nA place code, taking advantage of the tonotopy in the auditory system, must be in effect for the perception of high frequencies, since neurons have an upper limit on how fast they can phase-lock their action potentials. However, a purely place-based theory cannot account for the accuracy of pitch perception in the low and middle frequency ranges. Moreover, there is some evidence that some non-human primates lack auditory cortex responses to pitch despite having clear tonotopic maps in auditory cortex, showing that tonotopic place codes are not sufficient for pitch responses.\\n\\nTemporal theories offer an alternative that appeals to the temporal structure of action potentials, mostly the phase-locking and mode-locking of action potentials to frequencies in a stimulus. The precise way this temporal structure helps code for pitch at higher levels is still debated, but the processing seems to be based on an autocorrelation of action potentials in the auditory nerve. However, it has long been noted that a neural mechanism that may accomplish a delay—a necessary operation of a true autocorrelation—has not been found. At least one model shows that a temporal delay is unnecessary to produce an autocorrelation model of pitch perception, appealing to phase shifts between cochlear filters; however, earlier work has shown that certain sounds with a prominent peak in their autocorrelation function do not elicit a corresponding pitch percept, and that certain sounds without a peak in their autocorrelation function nevertheless elicit a pitch. To be a more complete model, autocorrelation must therefore apply to signals that represent the output of the cochlea, as via auditory-nerve interspike-interval histograms. Some theories of pitch perception hold that pitch has inherent octave ambiguities, and therefore is best decomposed into a pitch chroma, a periodic value around the octave, like the note names in western music—and a pitch height, which may be ambiguous, that indicates the octave the pitch is in.\\n\\n### Just-noticeable difference\\n\\nThe just-noticeable difference (jnd) (the threshold at which a change is perceived) depends on the tone's frequency content. Below 500 Hz, the jnd is about 3 Hz for sine waves, and 1 Hz for complex tones; above 1000 Hz, the jnd for sine waves is about 0.6% (about 10 cents). The jnd is typically tested by playing two tones in quick succession with the listener asked if there was a difference in their pitches. The jnd becomes smaller if the two tones are played simultaneously as the listener is then able to discern beat frequencies. The total number of perceptible pitch steps in the range of human hearing is about 1,400; the total number of notes in the equal-tempered scale, from 16 to 16,000 Hz, is 120.\\n\\n### Aural illusions\\n\\nThe relative perception of pitch can be fooled, resulting in aural illusions. There are several of these, such as the tritone paradox, but most notably the Shepard scale, where a continuous or discrete sequence of specially formed tones can be made to sound as if the sequence continues ascending or descending forever.\\n\\n## Definite and indefinite pitch\\n\\nNot all musical instruments make notes with a clear pitch. The unpitched percussion instrument (a class of percussion instrument) does not produce particular pitches. A sound or note of definite pitch is one where a listener can possibly (or relatively easily) discern the pitch. Sounds with definite pitch have harmonic frequency spectra or close to harmonic spectra.\\n\\nA sound generated on any instrument produces many modes of vibration that occur simultaneously. A listener hears numerous frequencies at once. The vibration with the lowest frequency is called the fundamental frequency; the other frequencies are overtones. Harmonics are an important class of overtones with frequencies that are integer multiples of the fundamental. Whether or not the higher frequencies are integer multiples, they are collectively called the partials, referring to the different parts that make up the total spectrum.\\n\\nA sound or note of indefinite pitch is one that a listener finds impossible or relatively difficult to identify as to pitch. Sounds with indefinite pitch do not have harmonic spectra or have altered harmonic spectra—a characteristic known as inharmonicity.\\n\\nIt is still possible for two sounds of indefinite pitch to clearly be higher or lower than one another. For instance, a snare drum sounds higher pitched than a bass drum though both have indefinite pitch, because its sound contains higher frequencies. In other words, it is possible and often easy to roughly discern the relative pitches of two sounds of indefinite pitch, but sounds of indefinite pitch do not neatly correspond to any specific pitch.\\n\\n## Labeling pitches\\n\\nPitches are labeled using:\\n\\n- Letters, as in Helmholtz pitch notation\\n- A combination of letters and numbers—as in scientific pitch notation, where notes are labelled upwards from C0, the 16 Hz C\\n- Numbers that represent the frequency in hertz (Hz), the number of cycles per second\\n\\nFor example, one might refer to the A above middle C as a′, A4, or 440 Hz. In standard Western equal temperament, the notion of pitch is insensitive to \\"spelling\\": the description \\"G4 double sharp\\" refers to the same pitch as A4; in other temperaments, these may be distinct pitches. Human perception of musical intervals is approximately logarithmic with respect to fundamental frequency: the perceived interval between the pitches \\"A220\\" and \\"A440\\" is the same as the perceived interval between the pitches A440 and A880. Motivated by this logarithmic perception, music theorists sometimes represent pitches using a numerical scale based on the logarithm of fundamental frequency. For example, one can adopt the widely used MIDI standard to map fundamental frequency, f, to a real number, p, as follows\\n\\n> p = 69 + 12 × log 2 ⁡ ( f 440 Hz )\\n\\nThis creates a linear pitch space in which octaves have size 12, semitones (the distance between adjacent keys on the piano keyboard) have size 1, and A440 is assigned the number 69. Distance in this space corresponds to musical intervals as understood by musicians. An equal-tempered semitone is subdivided into 100 cents. The system is flexible enough to include \\"microtones\\" not found on standard piano keyboards. For example, the pitch halfway between C (60) and C♯ (61) can be labeled 60.5.\\n\\n<youtube-embed video=\\"Y7TesKMSE74\\" />\\n\\n## Pitch standards and standard pitch\\n\\nA pitch standard (also concert pitch) is the conventional pitch reference a group of musical instruments are tuned to for a performance. Concert pitch may vary from ensemble to ensemble, and has varied widely over musical history.\\n\\nStandard pitch is a more widely accepted convention. The A above middle C is usually set at 440 Hz (often written as \\"A = 440 Hz\\" or sometimes \\"A440\\"), although other frequencies, such as 442 Hz, are also often used as variants. Another standard pitch, the so-called Baroque pitch, has been set in the 20th century as A = 415 Hz—approximately an equal-tempered semitone lower than A440 to facilitate transposition. The Classical pitch can be set to either 427 Hz (about halfway between A415 and A440) or 430 Hz (also between A415 and A440 but slightly sharper than the quarter tone). And ensembles specializing in authentic performance set the A above middle C to 432 Hz or 435 Hz when performing repertoire from the Romantic era.\\n\\nTransposing instruments have their origin in the variety of pitch standards. In modern times, they conventionally have their parts transposed into different keys from voices and other instruments (and even from each other). As a result, musicians need a way to refer to a particular pitch in an unambiguous manner when talking to each other.\\n\\nFor example, the most common type of clarinet or trumpet, when playing a note written in their part as C, sounds a pitch that is called B♭ on a non-transposing instrument like a violin (which indicates that at one time these wind instruments played at a standard pitch a tone lower than violin pitch). To refer to that pitch unambiguously, a musician calls it concert B♭, meaning, \\"...the pitch that someone playing a non-transposing instrument like a violin calls B♭.\\"\\n\\n## A440 (pitch standard)\\n\\nA440 (also known as Stuttgart pitch) is the musical pitch corresponding to an audio frequency of 440 Hz, which serves as a tuning standard for the musical note of A above middle C, or A4 in scientific pitch notation. It is standardized by the International Organization for Standardization as ISO 16. While other frequencies have been (and occasionally still are) used to tune the first A above middle C, A440 is now commonly used as a reference frequency to calibrate acoustic equipment and to tune pianos, violins, and other musical instruments.\\n\\n### History and use\\n\\nBefore standardization on 440 Hz, many countries and organizations followed the French standard since the 1860s of 435 Hz, which had also been the Austrian government's 1885 recommendation. Johann Heinrich Scheibler recommended A440 as a standard in 1834 after inventing the \\"tonometer\\" to measure pitch, and it was approved by the Society of German Natural Scientists and Physicians the same year.\\n\\nThe American music industry reached an informal standard of 440 Hz in 1926, and some began using it in instrument manufacturing.\\n\\nIn 1936, the American Standards Association recommended that the A above middle C be tuned to 440 Hz. This standard was taken up by the International Organization for Standardization in 1955 (reaffirmed by them in 1975) as ISO 16.\\n\\nIt is designated A4 in scientific pitch notation because it occurs in the octave that starts with the fourth C key on a standard 88-key piano keyboard. On MIDI, A440 is note 69 (0x45 hexadecimal).\\n\\n### Modern practices\\n\\nA440 is widely used as concert pitch in the United Kingdom and the United States. In continental Europe the frequency of A4 commonly varies between 440 Hz and 444 Hz. In the period instrument movement, a consensus has arisen around a modern baroque pitch of 415 Hz (with 440 Hz corresponding to A♯), a 'baroque' pitch for some special church music (in particular, some German church music, e.g. the pre-Leipzig period cantatas of Bach) known as Chorton pitch at 466 Hz (with 440 Hz corresponding to A♭), and classical pitch at 427–430 Hz.\\n\\nThe US time and frequency station WWV broadcasts a 440 Hz signal at two minutes past every hour, with WWVH broadcasting the same tone at the first minute past every hour. This was added in 1936 to aid orchestras in tuning their instruments.\\n\\n## History of pitch standards in Western music\\n\\nHistorically, various standards have been used to fix the pitch of notes at certain frequencies. Various systems of musical tuning have also been used to determine the relative frequency of notes in a scale.\\n\\n### Pre-19th century\\n\\nUntil the 19th century, there was no coordinated effort to standardize musical pitch, and the levels across Europe varied widely. Pitches did not just vary from place to place, or over time—pitch levels could vary even within the same city. The pitch used for an English cathedral organ in the 17th century, for example, could be as much as five semitones lower than that used for a domestic keyboard instrument in the same city.\\n\\nEven within one church, the pitch used could vary over time because of the way organs were tuned. Generally, the end of an organ pipe would be hammered inwards to a cone, or flared outwards, to raise or lower the pitch. When the pipe ends became frayed by this constant process they were all trimmed down, thus raising the overall pitch of the organ.\\n\\nFrom the early 18th century, pitch could also be controlled with the use of tuning forks (invented in 1711), although again there was variation. For example, a tuning fork associated with Handel, dating from 1740, is pitched at A = 422.5 Hz, while a later one from 1780 is pitched at A = 409 Hz, about a quarter-tone lower. A tuning fork that belonged to Ludwig van Beethoven around 1800, now in the British Library, is pitched at A = 455.4 Hz, well over a half-tone higher.\\n\\nOverall, there was a tendency towards the end of the 18th century for the frequency of the A above middle C to be in the range of 400 to 450 Hz.\\n\\nThe frequencies quoted here are based on modern measurements and would not have been precisely known to musicians of the day. Although Mersenne had made a rough determination of sound frequencies as early as the 17th century, such measurements did not become scientifically accurate until the 19th century, beginning with the work of German physicist Johann Scheibler in the 1830s. The term formerly used for the unit of pitch, cycle per second (CPS) was renamed the hertz (Hz) in the 20th century in honor of Heinrich Hertz.\\n\\n### Pitch inflation\\n\\nDuring historical periods when instrumental music rose in prominence (relative to the voice), there was a continuous tendency for pitch levels to rise. This \\"pitch inflation\\" seemed largely a product of instrumentalists competing with each other, each attempting to produce a brighter, more \\"brilliant\\", sound than that of their rivals. On at least two occasions, pitch inflation had become so severe that reform became needed. At the beginning of the 17th century, Michael Praetorius reported in his encyclopedic Syntagma musicum that pitch levels had become so high that singers were experiencing severe throat strain and lutenists and viol players were complaining of snapped strings. The standard voice ranges he cites show that the pitch level of his time, at least in the part of Germany where he lived, was at least a minor third higher than today's. Solutions to this problem were sporadic and local, but generally involved the establishment of separate standards for voice and organ (German: Chorton, lit. 'choir tone') and for chamber ensembles (German: Kammerton, lit. 'chamber tone'). Where the two were combined, as for example in a cantata, the singers and instrumentalists might perform from music written in different keys. This system kept pitch inflation at bay for some two centuries.\\n\\nConcert pitch rose further in the 19th century as may be seen reflected in the tuning forks of France. The pipe organ tuning fork in Versailles Chapel in 1795 is 390 Hz, but in the Paris Opera an 1810 tuning fork gives A = 423 Hz, an 1822 fork gives A = 432 Hz, and an 1855 fork gives A = 449 Hz. At La Scala in Milan, the A above middle C rose as high as 451 Hz.\\n\\n### 19th- and 20th-century standards\\n\\nThe strongest opponents of the upward tendency in pitch were singers, who complained that it was putting a strain on their voices. Largely due to their protests, the French government passed a law on February 16, 1859, which set the A above middle C at 435 Hz. This was the first attempt to standardize pitch on such a scale, and was known as the diapason normal. It became quite a popular pitch standard outside France as well, and has also been known at various times as French pitch, continental pitch or international pitch (the last of these not to be confused with the 1939 \\"international standard pitch\\" described below). An 1885 conference in Vienna established this value among Italy, Austria, Hungary, Russia, Prussia, Saxony, Sweden and Württemberg. This was included as \\"Convention of 16 and 19 November 1885 regarding the establishment of a concert pitch\\" in the Treaty of Versailles in 1919 which formally ended World War I. The diapason normal resulted in middle C being tuned at about 258.65 Hz.\\n\\nAn alternative pitch standard known as philosophical or scientific pitch fixes middle C at 256 Hz (that is, 28 Hz), which results the A above it being approximately 430.54 Hz in equal temperament tuning. The appeal of this system is its mathematical idealism (the frequencies of all the Cs being powers of two). This system never received the same official recognition as the French A = 435 Hz and has not been widely used. This tuning has been promoted unsuccessfully by the LaRouche movement's Schiller Institute under the name Verdi tuning since Italian composer Giuseppe Verdi had proposed a slight lowering of the French tuning system. However, the Schiller Institute's recommended tuning for A of 432 Hz is for the Pythagorean ratio of 27:16, rather than the logarithmic ratio of equal temperament tuning.\\n\\nBritish attempts at standardisation in the 19th century gave rise to the old philharmonic pitch standard of about A = 452 Hz (different sources quote slightly different values), replaced in 1896 by the considerably \\"deflated\\" new philharmonic pitch at A = 439 Hz. The high pitch was maintained by Sir Michael Costa for the Crystal Palace Handel Festivals, causing the withdrawal of the principal tenor Sims Reeves in 1877, though at singers' insistence the Birmingham Festival pitch was lowered (and the organ retuned) at that time. At the Queen's Hall in London, the establishment of the diapason normal for the Promenade Concerts in 1895 (and retuning of the organ to A = 435.5 at 15 °C (59 °F), to be in tune with A = 439 in a heated hall) caused the Royal Philharmonic Society and others (including the Bach Choir, and the Felix Mottl and Arthur Nikisch concerts) to adopt the continental pitch thereafter.\\n\\nIn England the term low pitch was used from 1896 onward to refer to the new Philharmonic Society tuning standard of A = 439 Hz at 68 °F, while \\"high pitch\\" was used for the older tuning of A = 452.4 Hz at 60 °F. Although the larger London orchestras were quick to conform to the new, low pitch, provincial orchestras continued using the high pitch until at least the 1920s, and most brass bands were still using the high pitch in the mid-1960s. Highland pipe bands continue to use an even sharper tuning, around A = 470–480 Hz, over a semitone higher than A440. As a result, bagpipes are often perceived as playing in B♭ despite being notated in A (as if they were transposing instruments in D-flat), and are often tuned to match B♭ brass instruments when the two are required to play together.\\n\\nThe Stuttgart Conference of 1834 recommended C264 (A440) as the standard pitch based on Scheibler's studies with his Tonometer. For this reason A440 has been referred to as Stuttgart pitch or Scheibler pitch.\\n\\nIn 1939, an international conference recommended that the A above middle C be tuned to 440 Hz, now known as concert pitch. As a technical standard this was taken up by the International Organization for Standardization in 1955 and reaffirmed by them in 1975 as ISO 16. The difference between this and the diapason normal is due to confusion over the temperature at which the French standard should be measured. The initial standard was A = 439 Hz, but this was superseded by A = 440 Hz, possibly because 439 Hz was difficult to reproduce in a laboratory since 439 is a prime number.\\n","frontmatter":{"title":"Frequency and pitch","description":"The human perception of sound frequency as a place of it at a scale","cover":"/media_files/cover/theory-sound-pitch-jacek-ulinski.jpg","date":"2021-08-28T00:00:00.000Z"},"url":"/theory/sound/pitch/"},{"src":"---\\ntitle: Timbre and overtones\\ndescription: The character of sound\\n\\ndate: 2021-08-26\\ncover: overtones.svg\\n---\\n\\n## Timbre\\n\\nIn music, timbre, also known as tone color or tone quality (from psychoacoustics), is the perceived sound quality of a musical note, sound or tone. Timbre distinguishes different types of sound production, such as choir voices and musical instruments. It also enables listeners to distinguish different instruments in the same category (e.g., an oboe and a clarinet, both woodwind instruments).\\n\\nThe physical characteristics of sound that determine the perception of timbre include frequency spectrum and envelope. Singers and instrumental musicians can change the timbre of the music they are singing/playing by using different singing or playing techniques. For example, a violinist can use different bowing styles or play on different parts of the string to obtain different timbres (e.g., playing sul tasto produces a light, airy timbre, whereas playing sul ponticello produces a harsh, even and aggressive tone).\\n\\n## Attributes of timbre\\n\\nMany commentators have attempted to decompose timbre into component attributes. For example, J. F. Schouten (1968, 42) describes the \\"elusive attributes of timbre\\" as \\"determined by at least five major acoustic parameters\\", which Robert Erickson finds, \\"scaled to the concerns of much contemporary music\\":\\n\\n- Range between tonal and noiselike character\\n- Spectral envelope\\n- Time envelope in terms of rise, duration, and decay (ADSR, which stands for \\"attack, decay, sustain, release\\")\\n- Changes both of spectral envelope (formant-glide) and fundamental frequency (micro-intonation)\\n- Prefix, or onset of a sound, quite dissimilar to the ensuing lasting vibration\\n\\n## Amplitude envelope\\n\\n![](./adsr.svg)\\n\\n- **Attack**: time from silence to the loudest level\\n- **Decay**: time from loudest level to sustain level\\n- **Sustain**: level of volume while the sound is holded\\n- **Release**: time to return to silence after releasing the hold\\n\\n## Helmholz resonance\\n\\nHelmholtz resonance or wind throb is the phenomenon of air resonance in a cavity, such as when one blows across the top of an empty bottle. The name comes from a device created in the 1850s by Hermann von Helmholtz, the Helmholtz resonator, which he used to identify the various frequencies or musical pitches present in music and other complex sounds.\\n\\nWhen air is forced into a cavity, the pressure inside increases. When the external force pushing the air into the cavity is removed, the higher-pressure air inside will flow out. Due to the inertia of the moving air the cavity will be left at a pressure slightly lower than the outside, causing air to be drawn back in. This process repeats, with the magnitude of the pressure oscillations increasing and decreasing asymptotically after the sound starts and stops.\\n\\n![](./Helmholtz_resonator.jpg)\\n\\nWhen the resonator's 'nipple' is placed inside one's ear, a specific frequency of the complex sound can be picked out and heard clearly. In his book Helmholtz’ explains: When we \\"apply a resonator to the ear, most of the tones produced in the surrounding air will be considerably damped; but if the proper tone of the resonator is sounded, it brays into the ear most powerfully…. The proper tone of the resonator may even be sometimes heard cropping up in the whistling of the wind, the rattling of carriage wheels, the splashing of water.\\"\\n\\n## Harmonics – the natural resonances\\n\\n<img src=\\"./Bowed_violin_string_helholz_corner.gif\\" >\\n\\n<youtube-embed video=\\"9O3VEXzuOKI\\" />\\n\\nA note isn't just a wave, it's a mix of resonating modes of oscillations.\\n\\n### Tristimulus timbre model\\n\\nThe concept of tristimulus originates in the world of color, describing the way three primary colors can be mixed together to create a given color. By analogy, the musical tristimulus measures the mixture of harmonics in a given sound, grouped into three sections. It is basically a proposal of reducing a huge number of sound partials, that can amount to dozens or hundreds in some cases, down to only three values. The first tristimulus measures the relative weight of the first harmonic; the second tristimulus measures the relative weight of the second, third, and fourth harmonics taken together; and the third tristimulus measures the relative weight of all the remaining harmonics.\\n\\n<youtube-embed video=\\"Wpt3lmSFW3k\\" />\\n\\n\\n<iframe class=\\"m-auto\\" title=\\"vimeo-player\\" src=\\"https://player.vimeo.com/video/164848028?h=68deef5350\\" width=\\"640\\" height=\\"360\\" frameborder=\\"0\\" allowfullscreen></iframe>","frontmatter":{"title":"Timbre and overtones","description":"The character of sound","date":"2021-08-26T00:00:00.000Z","cover":"/media_files/cover/theory-sound-timbre-overtones.svg"},"url":"/theory/sound/timbre/"},{"src":"---\\ntitle: Just intonation\\ndescription: 5-limit and other rational fraction based tunings\\ndate: 2021-08-20\\n\\ncover: intervals.svg\\n---\\n\\n**Just intonation** or pure intonation is the tuning of musical intervals as whole number ratios (such as 3:2 or 4:3) of frequencies. An interval tuned in this way is said to be pure, and is called a just interval. Just intervals (and chords created by combining them) consist of tones from a single harmonic series of an implied fundamental. For example, if the notes G3 and C4 are tuned as members of the harmonic series of the lowest C, their frequencies will be 3 and 4 times the fundamental frequency. The interval ratio between C4 and G3 is therefore 4:3, a just fourth.\\n\\nIn Western musical practice, instruments are rarely tuned using only pure intervals — the desire for different keys to have identical intervals in Western music makes this impractical. Some instruments of fixed pitch, such as electric pianos, are commonly tuned using equal temperament, in which all intervals other than octaves consist of irrational-number frequency ratios. Acoustic pianos are usually tuned with the octaves slightly widened, and thus with no pure intervals at all. \\n\\n### Terminology\\n\\n[Pythagorean tuning](../pythagorean/index.md), or 3-limit tuning, allows ratios including the numbers 2 and 3 and their powers, such as 3:2, a perfect fifth, and 9:4, a major ninth. Although the interval from C to G is called a perfect fifth for purposes of music analysis regardless of its tuning method, for purposes of discussing tuning systems musicologists may distinguish between a perfect fifth created using the 3:2 ratio and a tempered fifth using some other system, such as meantone or equal temperament.\\n\\n**5-limit tuning** encompasses ratios additionally using the number 5 and its powers, such as 5:4, a major third, and 15:8, a major seventh. The specialized term perfect third is occasionally used to distinguish the 5:4 ratio from major thirds created using other tuning methods. **7-limit** and higher systems use higher partials in the overtone series.\\n\\n**Commas** are very small intervals that result from minute differences between pairs of just intervals. For example, the 5:4 ratio is different from the Pythagorean (3-limit) major third (81:64) by a difference of 81:80, called the syntonic comma.\\n\\n\\n![svg](./intervals.svg)\\n\\nA twelve-tone scale can also be created by compounding harmonics up to the fifth: namely, by multiplying the frequency of a given reference note (the base note) by powers of 2, 3, or 5, or a combination of them. This method is called five-limit tuning.\\n\\n![svg](./pentactys.svg)\\n\\n5-limit tuning encompasses ratios additionally using the number 5 and its powers, such as 5:4, a major third, and 15:8, a major seventh. 7-limit and higher systems use higher partials in the overtone series.\\n","frontmatter":{"title":"Just intonation","description":"5-limit and other rational fraction based tunings","date":"2021-08-20T00:00:00.000Z","cover":"/media_files/cover/theory-notes-temperaments-just-intervals.svg"},"url":"/theory/notes/temperaments/just/"},{"src":"---\\ntitle: Pythagorean tuning\\ndescription: 3-limit tuning based on the 3:2 ratio\\n\\ndate: 2021-08-20\\ncover: Tetractys.svg\\n---\\n\\n## Pythagorean tuning\\n\\nPythagorean tuning, or 3-limit tuning, also allows ratios including the number 3 and its powers, such as 3:2, a perfect fifth, and 9:4, a major ninth. 12-tone Pythagorean temperament is based on a stack of intervals called perfect fifths, each tuned in the ratio 3:2, the next simplest ratio after 2:1. Starting from D for example (D-based tuning), six other notes are produced by moving six times a ratio 3:2 up, and the remaining ones by moving the same ratio down:\\n\\n> E♭–B♭–F–C–G–D–A–E–B–F♯–C♯–G♯\\n\\nThis succession of eleven 3:2 intervals spans across a wide range of frequency (on a piano keyboard, it encompasses 77 keys). Since notes differing in frequency by a factor of 2 are given the same name, it is customary to divide or multiply the frequencies of some of these notes by 2 or by a power of 2. The purpose of this adjustment is to move the 12 notes within a smaller range of frequency, namely within the interval between the base note D and the D above it (a note with twice its frequency). This interval is typically called the basic octave (on a piano keyboard, an octave has only 12 keys).\\n\\n![svg](./Tetractys.svg)\\n\\nThe tetractys (Greek: τετρακτύς) is a triangular figure consisting of ten points arranged in four rows: one, two, three, and four points in each row, which is the geometrical representation of the fourth triangular number. As a mystical symbol, it was very important to the secret worship of Pythagoreanism.\\n","frontmatter":{"title":"Pythagorean tuning","description":"3-limit tuning based on the 3:2 ratio","date":"2021-08-20T00:00:00.000Z","cover":"/media_files/cover/theory-notes-temperaments-pythagorean-Tetractys.svg"},"url":"/theory/notes/temperaments/pythagorean/"},{"src":"---\\ntitle: Evolution of european notation systems\\ndescription: From neumes to staves\\ndate: 2021-08-19\\n\\ncover: hooks_and_banners.png\\n---\\n\\n## Medieval neumes c. 500–1400\\n\\n<youtube-embed video=\\"2OBB5-bP6qs\\" />\\n\\n![](./images/Dies_irae_ms_fragm.jpg)\\n![](./images/Dies_irae.gif)\\n\\nEarly Western medieval notation was written with neumes, which did not specify exact pitches but only the shape of the melodies, i.e. indicating when the musical line went up or down; presumably these were intended as mnemonics for melodies which had been taught by rote.\\n\\n![](./images/adiastemic.jpg)\\n\\nDuring the 9th through 11th centuries a number of systems were developed to specify pitch more precisely, including diastematic neumes whose height on the page corresponded with their absolute pitch level (Longobardian and Beneventan manuscripts from Italy show this technique around AD 1000). Digraphic notation, using letter names similar to modern note names in conjunction with the neumes, made a brief appearance in a few manuscripts, but a number of manuscripts used one or more horizontal lines to indicate particular pitches.\\n\\n![](./images/Digraphic_neumes.png)\\n\\n### Diastemic neumes\\n\\n![](./images/Beneventan_music_manuscript.jpg)\\n\\n![](./images/diastemic.jpg)\\n\\nIn the early 11th century, Beneventan neumes (from the churches of Benevento in southern Italy) were written at varying distances from the text to indicate the overall shape of the melody; such neumes are called \\"heightened\\" or \\"diastematic\\" neumes, which showed the relative pitches between neumes. A few manuscripts from the same period use \\"digraphic\\" notation in which note names are included below the neumes. Shortly after this, one to four staff lines—an innovation traditionally ascribed to Guido d'Arezzo—clarified the exact relationship between pitches. One line was marked as representing a particular pitch, usually C or F. These neumes resembled the same thin, scripty style of the chironomic notation. By the 11th century, chironomic neumes had evolved into square notation; in Germany, a variant called Gothic neumes continued to be used until the 16th century. This variant is also known as Hufnagel notation, as the used neumes resemble the nails (hufnagels) one uses to attach horseshoes.\\n\\n![](./images/Goth002-web.jpg)\\n\\n## Russian neumes\\n\\nZnamenny Chant is a singing tradition used in the Russian Orthodox Church which uses a \\"hook and banner\\" notation. Znamenny Chant is unison, melismatic liturgical singing that has its own specific notation, called the stolp notation. The symbols used in the stolp notation are called kryuki (Russian: крюки, 'hooks') or znamena (Russian: знамёна, 'signs'). Often the names of the signs are used to refer to the stolp notation. Znamenny melodies are part of a system, consisting of Eight Modes (intonation structures; called glasy); the melodies are characterized by fluency and well-balancedness (Kholopov 2003, 192). There exist several types of Znamenny Chant: the so-called Stolpovoy, Malyj (Little) and Bolshoy (Great) Znamenny Chant. Ruthenian Chant (Prostopinije) is sometimes considered a sub-division of the Znamenny Chant tradition, with the Muscovite Chant (Znamenny Chant proper) being the second branch of the same musical continuum.\\n\\n![](./hooks_and_banners.png)\\n\\nZnamenny Chants are not written with notes (the so-called linear notation), but with special signs, called Znamëna (Russian for \\"marks\\", \\"banners\\") or Kryuki (\\"hooks\\"), as some shapes of these signs resemble hooks. Each sign may include the following components: a large black hook or a black stroke, several smaller black 'points' and 'commas' and lines near the hook or crossing the hook. Some signs may mean only one note, some 2 to 4 notes, and some a whole melody of more than 10 notes with a complicated rhythmic structure. The stolp notation was developed in Kievan Rus' as an East Slavic refinement of the Byzantine neumatic musical notation.\\n\\n![](./images/Old_Believers_Octoechos_2.jpg)\\n\\nThe most notable feature of this notation system is that it records transitions of the melody, rather than notes. The signs also represent a mood and a gradation of how this part of melody is to be sung (tempo, strength, devotion, meekness, etc.) Every sign has its own name and also features as a spiritual symbol. For example, there is a specific sign, called \\"little dove\\" (Russian: голубчик (golubchik)), which represents two rising sounds, but which is also a symbol of the Holy Ghost. Gradually the system became more and more complicated. This system was also ambiguous, so that almost no one, except the most trained and educated singers, could sing an unknown melody at sight. The signs only helped to reproduce the melody, not coding it in an unambiguous way.\\n\\n![](./images/Kryuki.jpg)\\n\\n> ![A musical manuscript of 1433 (Pantokratoros monastery, code 214)](./images/Musical_manuscript.jpg)\\n> A musical manuscript of 1433 (Pantokratoros monastery, code 214)\\n\\n> ![](./images/Easter_koinonikon_of_the_Kievan_Rus_with_Kondakarian_notation.jpg)\\n> Easter koinonikon тҍло христово / σῶμα χριστοῦ (\\"The body of Christ\\") in echos plagios protos notated with kondakarian notation in 2 rows: great (red names) and small signs (blue names)\\n\\n---\\n\\n## Guido d'Arezzo\\n\\nGuido of Arezzo or Guido d'Arezzo (c. 991–992 – after 1033) was an Italian music theorist and pedagogue of High medieval music. A Benedictine monk, he is regarded as the inventor—or by some, developer—of the modern staff notation that replaced the predominant neumatic notation and was thus massively influential to the development of Western musical notation and practice.\\n\\n> ![](./images/Guido_e_Teodaldo.jpg)\\n> Guido (left) showing Tedald the monochord, depicted in an 11th-century medieval manuscript\\n\\nBy around 1013 he began teaching at Pomposa Abbey, but his antiphonary Prologus in antiphonarium and novel teaching methods based on staff notation brought considerable resentment from his colleagues. He thus moved to Arezzo in 1025 and under the patronage of Bishop Tedald of Arezzo he taught singers at the Arezzo Cathedral. Using staff notation, he was able to teach large amounts of music quickly and he wrote the multifaceted Micrologus, attracting attention from around Italy. Interested in his innovations, Pope John XIX called him to Rome. After arriving and beginning to explain his methods to the clergy, sickness sent him away in the summer. The rest of his life is largely unclear, but he settled in a monastery near Arezzo, probably one of the Avellana of the Camaldolese order.\\n\\n![](./images/UtQueantLaxis-Arezzo.png)\\n\\nGuido developed new techniques for teaching, such as staff notation and the use of the \\"ut–re–mi–fa–sol–la\\" (do–re–mi–fa–so–la) mnemonic (solmization). The ut–re–mi-fa-sol-la syllables are taken from the initial syllables of each of the first six half-lines of the first stanza of the hymn Ut queant laxis, whose text is attributed to the Italian monk and scholar Paulus Diaconus (though the musical line either shares a common ancestor with the earlier setting of Horace's \\"Ode to Phyllis\\" (Odes 4.11), recorded in the Montpellier manuscript H425, or may have been taken from it).[23] Giovanni Battista Doni is known for having changed the name of note \\"Ut\\" (C), renaming it \\"Do\\" (in the \\"Do Re Mi ...\\" sequence known as solfège).[24] A seventh note, \\"Si\\" (from the initials for \\"Sancte Iohannes,\\" Latin for Saint John the Baptist) was added shortly after to complete the diatonic scale.[25] In anglophone countries, \\"Si\\" was changed to \\"Ti\\" by Sarah Glover in the nineteenth century so that every syllable might begin with a different letter (this also freed up Si for later use as Sol-sharp). \\"Ti\\" is used in tonic sol-fa and in the song \\"Do-Re-Mi\\".\\n\\n![](./images/Guidonian_scale2.png)\\n\\n### Guidonian hand\\n\\nGuido is somewhat erroneously credited with the invention of the Guidonian hand, a widely used mnemonic system where note names are mapped to parts of the human hand. Only a rudimentary form of the Guidonian hand is actually described by Guido, and the fully elaborated system of natural, hard, and soft hexachords cannot be securely attributed to him.\\n\\n![](./images/Guidonian_hand.jpg)\\n\\nIn the 12th century, a development in teaching and learning music in a more efficient manner had arisen. Guido of Arezzo's alleged development of the Guidonian hand, more than a hundred years after his death, allowed for musicians to label a specific joint or fingertip with the gamut (also referred to as the hexachord in the modern era).[citation needed] Using specific joints of the hand and fingertips transformed the way one would learn and memorize solmization syllables. Not only did the Guidonian hand become a standard use in preparing music in the 12th century, its popularity grew more widespread well into the 17th and 18th century. The knowledge and use of the Guidonian hand would allow a musician to simply transpose, identify intervals, and aid in use of notation and the creation of new music. Musicians were able to sing and memorize longer sections of music and counterpoint during performances and the amount of time spent diminished dramatically.\\n\\n![](./images/Guidonischehand.gif)\\n\\n<youtube-embed video=\\"veJNu1fi8p4\\" />\\n\\n> **Ut** queant laxis  \\n>  **Re**sonare fibris,  \\n>  **Mi**ra gestorum  \\n>  **Fa**muli tuorum,  \\n>  **So**lve polluti  \\n>  **La**bii reatum,  \\n>  **S**ancte **J**ohannes.\\n\\n![](./images/Ut_Queant_Laxis_MT.png)\\n\\n---\\n\\n## Square notation\\n\\n![](./images/gregorian.jpg)\\n\\nBy the 13th century, the neumes of Gregorian chant were usually written in square notation on a staff with four lines and three spaces and a clef marker, as in the 14th–15th century Graduale Aboense shown here. In square notation, small groups of ascending notes on a syllable are shown as stacked squares, read from bottom to top, while descending notes are written with diamonds read from left to right. In melismatic chants, in which a syllable may be sung to a large number of notes, a series of smaller such groups of neumes are written in succession, read from left to right. A special symbol called the custos, placed at the end of a system, showed which pitch came next at the start of the following system. Special neumes such as the oriscus, quilisma, and liquescent neumes, indicate particular vocal treatments for these notes. This system of square notation is standard in modern chantbooks.\\n\\n![](./images/Graduale_Aboense.jpg)\\n\\n---\\n\\n## Mensural notation of Renaissance c. 1400–1600\\n\\nMensural notation is the musical notation system used for European vocal polyphonic music from the later part of the 13th century until about 1600. The term \\"mensural\\" refers to the ability of this system to describe precisely measured rhythmic durations in terms of numerical proportions between note values. Its modern name is inspired by the terminology of medieval theorists, who used terms like musica mensurata (\\"measured music\\") or cantus mensurabilis (\\"measurable song\\") to refer to the rhythmically defined polyphonic music of their age, as opposed to musica plana or musica choralis, i.e., Gregorian plainchant.\\n\\n![Early 16th-century manuscript in mensural notation, containing a Kyrie by J. Barbireau.](./images/Barbireau_illum.jpg)\\n\\nMensural notation grew out of an earlier, more limited method of notating rhythms in terms of fixed repetitive patterns, the so-called rhythmic modes, which were developed in France around 1200. An early form of mensural notation was first described and codified in the treatise Ars cantus mensurabilis (\\"The art of measured chant\\") by Franco of Cologne (c. 1280). A much expanded system allowing for greater rhythmic complexity was introduced in France with the stylistic movement of the Ars nova in the 14th century, while Italian 14th-century music developed its own, somewhat different variant. Around 1400, the French system was adopted across Europe, and became the standard form of notation of the Renaissance music of the 15th and 16th centuries. After around 1600, mensural notation gradually evolved into modern measure (or bar) notation.\\n\\n![](./images/CordierColor.jpg)\\n\\nThe decisive innovation of mensural notation was the systematic use of different note shapes to denote rhythmic durations that stood in well-defined, hierarchical numerical relations to each other. While less context dependent than notation in rhythmic modes, mensural notation differed from the modern system in that the values of notes were still somewhat context-dependent.\\n\\n![](./images/medieval.jpg)\\n\\n---\\n\\n## Baroque music c. 1580–1750\\n\\nBaroque music forms a major portion of the \\"classical music\\" canon, and is now widely studied, performed, and listened to. The term \\"baroque\\" comes from the Portuguese word barroco, meaning \\"misshapen pearl\\". Key composers of the Baroque era include Johann Sebastian Bach, Antonio Vivaldi, George Frideric Handel, Claudio Monteverdi, Domenico Scarlatti, Alessandro Scarlatti, Henry Purcell, Georg Philipp Telemann, Jean-Baptiste Lully, Jean-Philippe Rameau, Marc-Antoine Charpentier, Arcangelo Corelli, François Couperin, Giuseppe Tartini, Heinrich Schütz, Jan Pieterszoon Sweelinck, Dieterich Buxtehude, and others.\\n\\n![](./images/baroque.jpg)\\n\\n![A music piece for lute by Robert II Ballard, 1612](./images/ballard.jpg)\\n\\n> ![](./images/Bachlut1.png)\\n>\\n> ![](./images/bach2.png)\\n> J.S. Bach\\n\\n## Galant music c. 1720–1770\\n\\nIn music, galant refers to the style which was fashionable from the 1720s to the 1770s. This movement featured a return to simplicity and immediacy of appeal after the complexity of the late Baroque era. This meant simpler, more song-like melodies, decreased use of polyphony, short, periodic phrases, a reduced harmonic vocabulary emphasizing tonic and dominant, and a clear distinction between soloist and accompaniment. C. P. E. Bach and Daniel Gottlob Türk, who were among the most significant theorists of the late 18th century, contrasted the galant with the \\"learned\\" or \\"strict\\" styles.\\n\\n![](./images/1698_Campra_L-Europe_Galante.jpg)\\n\\n---\\n\\n## Classical period c. 1750–1820\\n\\nClassical music has a lighter, clearer texture than Baroque music, but a more sophisticated use of form. It is mainly homophonic, using a clear melody line over a subordinate chordal accompaniment, but counterpoint was by no means forgotten, especially in liturgical vocal music and, later in the period, secular instrumental music. Variety and contrast within a piece became more pronounced than before and the orchestra increased in size, range, and power.\\n\\n> ![](./images/Phantasie_fur_eine_Orgelwalze.jpg)\\n> W.A. Mozart\\n\\nThe harpsichord was replaced as the main keyboard instrument by the piano (or fortepiano). Unlike the harpsichord, which plucks strings with quills, pianos strike the strings with leather-covered hammers when the keys are pressed, which enables the performer to play louder or softer (hence the original name \\"fortepiano,\\" literally \\"loud soft\\") and play with more expression; in contrast, the force with which a performer plays the harpsichord keys does not change the sound. Instrumental music was considered important by Classical period composers. The main kinds of instrumental music were the sonata, trio, string quartet, quintet, symphony (performed by an orchestra) and the solo concerto, which featured a virtuoso solo performer playing a solo work for violin, piano, flute, or another instrument, accompanied by an orchestra. Vocal music, such as songs for a singer and piano (notably the work of Schubert), choral works, and opera (a staged dramatic work for singers and orchestra) were also important during this period.\\n\\nThe best-known composers from this period are Joseph Haydn, Wolfgang Amadeus Mozart, Ludwig van Beethoven, and Franz Schubert; other notable names include Carl Philipp Emanuel Bach, Johann Christian Bach, Luigi Boccherini, Domenico Cimarosa, Joseph Martin Kraus, Muzio Clementi, Christoph Willibald Gluck, Carl Ditters von Dittersdorf, André Grétry, Pierre-Alexandre Monsigny, Leopold Mozart, Michael Haydn, Giovanni Paisiello, Johann Baptist Wanhal, François-André Danican Philidor, Niccolò Piccinni, Antonio Salieri, Georg Christoph Wagenseil, Georg Matthias Monn, Johann Georg Albrechtsberger, Mauro Giuliani, Christian Cannabich and the Chevalier de Saint-Georges. Beethoven is regarded either as a Romantic composer or a Classical period composer who was part of the transition to the Romantic era. Schubert is also a transitional figure, as were Johann Nepomuk Hummel, Luigi Cherubini, Gaspare Spontini, Gioachino Rossini, Carl Maria von Weber, Jan Ladislav Dussek and Niccolò Paganini. The period is sometimes referred to as the era of Viennese Classicism (German: Wiener Klassik), since Gluck, Haydn, Salieri, Mozart, Beethoven, and Schubert all worked in Vienna.\\n\\n![](./images/alt-cover-2.jpg)\\n\\n---\\n\\n## Romantic period c. 1800–1910\\n\\nRomantic music is a stylistic movement in Western Classical music associated with the period of the 19th century commonly referred to as the Romantic era (or Romantic period). It is closely related to the broader concept of Romanticism—the intellectual, artistic and literary movement that became prominent in Europe from approximately 1800 until 1910.\\n\\nRomantic composers sought to create music that was individualistic, emotional, dramatic and often programmatic; reflecting broader trends within the movements of Romantic literature, poetry, art, and philosophy. Romantic music was often ostensibly inspired by (or else sought to evoke) non-musical stimuli, such as nature, literature, poetry, or the fine arts.\\n\\n> ![](./images/beethoven.jpg)\\n> L.V. Beethoven\\n\\nInfluential composers of the early Romantic era include Adolphe Adam, Daniel Auber, Ludwig van Beethoven, Hector Berlioz, François-Adrien Boieldieu, Frédéric Chopin, Sophia Dussek, Ferdinand Hérold, Mikhail Glinka, Fanny Mendelssohn, Felix Mendelssohn, John Field, Ignaz Moscheles, Otto Nicolai, Gioachino Rossini, Ferdinand Ries, Vincenzo Bellini, Franz Berwald, Luigi Cherubini, Carl Czerny, Gaetano Donizetti, Johann Nepomuk Hummel, Carl Loewe, Niccolò Paganini, Giacomo Meyerbeer, Anton Reicha, Franz Schubert, Clara Schumann, Robert Schumann, Louis Spohr, Gaspare Spontini, Ambroise Thomas and Carl Maria von Weber. Later nineteenth-century composers would appear to build upon certain early Romantic ideas and musical techniques, such as the use of extended chromatic harmony and expanded orchestration. Such later Romantic composers include Albéniz, Bruckner, Granados, Smetana, Brahms, MacDowell, Tchaikovsky, Parker, Mussorgsky, Dvořák, Borodin, Delius, Liszt, Wagner, Mahler, Goldmark, Richard Strauss, Verdi, Puccini, Bizet, Lalo, Rimsky-Korsakov, Schoenberg, Sibelius, Stanford, Parry, Scriabin, Elgar, Grieg, Saint-Saëns, Fauré, Rachmaninoff, Glazunov, Chausson and Franck.\\n\\n> ![](./images/chopin.jpg)\\n> F. Chopin\\n\\n---\\n\\n## Modernism c. 1890–1975\\n\\nmodernism is an aesthetic stance underlying the period of change and development in musical language that occurred around the turn of the 20th century, a period of diverse reactions in challenging and reinterpreting older categories of music, innovations that led to new ways of organizing and approaching harmonic, melodic, sonic, and rhythmic aspects of music, and changes in aesthetic worldviews in close relation to the larger identifiable period of modernism in the arts of the time. The operative word most associated with it is \\"innovation\\". Its leading feature is a \\"linguistic plurality\\", which is to say that no one music genre ever assumed a dominant position.\\n\\n![](./images/satie.png)\\n\\n> Inherent within musical modernism is the conviction that music is not a static phenomenon defined by timeless truths and classical principles, but rather something which is intrinsically historical and developmental. While belief in musical progress or in the principle of innovation is not new or unique to modernism, such values are particularly important within modernist aesthetic stances.\\n> — Edward Campbell (2010, p. 37)\\n\\nExamples include the celebration of Arnold Schoenberg's rejection of tonality in chromatic post-tonal and twelve-tone works and Igor Stravinsky's move away from metrical rhythm.\\n\\n![](./images/Stravinsky-Piano-Rag-Music-1.jpg)\\n\\n### Serialism and dodecaphony\\n\\nIn music, serialism is a method of composition using series of pitches, rhythms, dynamics, timbres or other musical elements. Serialism began primarily with Arnold Schoenberg's twelve-tone technique, though some of his contemporaries were also working to establish serialism as a form of post-tonal thinking.\\n\\n![](./images/schoenberg.png)\\n\\nTwelve-tone technique orders the twelve notes of the chromatic scale, forming a row or series and providing a unifying basis for a composition's melody, harmony, structural progressions, and variations. Other types of serialism also work with sets, collections of objects, but not necessarily with fixed-order series, and extend the technique to other musical dimensions (often called \\"parameters\\"), such as duration, dynamics, and timbre.\\n\\n> ![](./images/messian.jpg)\\n> Olivier Messiaen: „La Ville d'En-Haut“, für Klavier und kleines Orchester (1987), Manuskriptseite.\\n\\nSerialism of the first type is most specifically defined as a structural principle according to which a recurring series of ordered elements (normally a set—or row—of pitches or pitch classes) is used in order or manipulated in particular ways to give a piece unity. \\"Serial\\" is often broadly used to describe all music written in what Schoenberg called \\"The Method of Composing with Twelve Notes related only to one another\\", or dodecaphony, and methods that evolved from his methods. It is sometimes used more specifically to apply only to music in which at least one element other than pitch is treated as a row or series.\\n\\n> ![](./images/xenakis.jpg)\\n> I. Xenakis\\n\\nThe twelve-tone technique—also known as dodecaphony, twelve-tone serialism, is a method of musical composition first devised by Austrian composer Josef Matthias Hauer, who published his \\"law of the twelve tones\\" in 1919. In 1923, Arnold Schoenberg (1874–1951) developed his own, better-known version of 12-tone technique, which became associated with the \\"Second Viennese School\\" composers, who were the primary users of the technique in the first decades of its existence. The technique is a means of ensuring that all 12 notes of the chromatic scale are sounded as often as one another in a piece of music while preventing the emphasis of any one note through the use of tone rows, orderings of the 12 pitch classes. All 12 notes are thus given more or less equal importance, and the music avoids being in a key. Over time, the technique increased greatly in popularity and eventually became widely influential on 20th-century composers. Many important composers who had originally not subscribed to or actively opposed the technique, such as Aaron Copland and Igor Stravinsky, eventually adopted it in their music.\\n\\n### Aleatoric music\\n\\nAleatoric music (also aleatory music or chance music; from the Latin word alea, meaning \\"dice\\") is music in which some element of the composition is left to chance, and/or some primary element of a composed work's realization is left to the determination of its performer(s). The term is most often associated with procedures in which the chance element involves a relatively limited number of possibilities.\\n\\n> ![](./images/visconti_example.jpg)\\n> L. Visconti\\n\\nSome writers do not make a distinction between aleatory, chance, and indeterminancy in music, and use the terms interchangeably. From this point of view, indeterminate or chance music can be divided into three groups: (1) the use of random procedures to produce a determinate, fixed score, (2) mobile form, and (3) indeterminate notation, including graphic notation and texts.\\n\\n> ![](./images/Stockhausen.jpg)\\n> Karlheinz Stockhausen’s Helicopter String Quartet. Watch an excerpt of the work performed live (in helicopters) from the 2003 Salzberg Festival.\\n\\nThe first group includes scores in which the chance element is involved only in the process of composition, so that every parameter is fixed before their performance. In John Cage's Music of Changes (1951), for example, the composer selected duration, tempo, and dynamics by using the I Ching, an ancient Chinese book which prescribes methods for arriving at random numbers. Because this work is absolutely fixed from performance to performance, Cage regarded it as an entirely determinate work made using chance procedures. On the level of detail, Iannis Xenakis used probability theories to define some microscopic aspects of Pithoprakta (1955–56), which is Greek for \\"actions by means of probability\\". This work contains four sections, characterized by textural and timbral attributes, such as glissandi and pizzicati. At the macroscopic level, the sections are designed and controlled by the composer while the single components of sound are controlled by mathematical theories.\\n\\n> ![](./images/xenakis-1.jpg)\\n> Pithoprakta by I. Xenakis\\n\\nIn the second type of indeterminate music, chance elements involve the performance. Notated events are provided by the composer, but their arrangement is left to the determination of the performer. Karlheinz Stockhausen's Klavierstück XI (1956) presents nineteen events which are composed and notated in a traditional way, but the arrangement of these events is determined by the performer spontaneously during the performance. In Earle Brown's Available forms II (1962), the conductor is asked to decide the order of the events at the very moment of the performance.\\n\\n![](./images/available-forms.png)\\n\\n![](./images/Karlheinz-Stockhausens-Klavierstueck-XI.png)\\n\\n<youtube-embed video=\\"NxLMtP8ejKA\\" />\\n\\n> ![](./images/lutoslawski.gif)\\n> Witold Roman Lutosławski (25 January 1913 – 7 February 1994) was a Polish composer and conductor.\\n\\nThe greatest degree of indeterminacy is reached by the third type of indeterminate music, where traditional musical notation is replaced by visual or verbal signs suggesting how a work can be performed, for example in graphic score pieces.\\n\\n> ![](./images/brown-dec.jpg)\\n> Earle Brown's December 1952\\n\\nEarle Brown's December 1952 (1952) shows lines and rectangles of various lengths and thicknesses that can read as loudness, duration, or pitch. The performer chooses how to read them. Another example is Morton Feldman's Intersection No. 2 (1951) for piano solo, written on coordinate paper.\\n\\n![](./images/feldman-proj.jpg)\\n\\nTime units are represented by the squares viewed horizontally, while relative pitch levels of high, middle, and low are indicated by three vertical squares in each row. The performer determines what particular pitches and rhythms to play.\\n\\n> ![](./images/drawing-xenakis.png)\\n> I. Xenakis\\n\\n### John Cage\\n\\nJohn Milton Cage Jr. (September 5, 1912 – August 12, 1992) was an American composer, music theorist, artist, and philosopher. A pioneer of indeterminacy in music, electroacoustic music, and non-standard use of musical instruments, Cage was one of the leading figures of the post-war avant-garde.\\n\\n![](./images/john-cage-1.jpg)\\n\\n![](./images/john-cage-2.jpeg)\\n\\n![](./images/john-cage-3.jpg)\\n\\n### Earle Brown\\n\\nEarle Brown (December 26, 1926 – July 2, 2002) was an American composer who established his own formal and notational systems. Brown was the creator of \\"open form,\\" a style of musical construction.\\n\\n![](./images/earle-brown-oh-k.jpg)\\n\\nAlthough Brown precisely notated compositions throughout his career using traditional notation, he also was an inventor and early practitioner of various innovative notations.\\n\\n![](./images/cover-Folio_II_c_1980.png)\\n\\nIn Twenty-Five Pages, and in other works, Brown used what he called \\"time notation\\" or \\"proportional notation\\" where rhythms were indicated by their horizontal length and placement in relation to each other and were to be interpreted flexibly. However, by Modules I and II (1966), Brown more often used stemless note heads which could be interpreted with even greater flexibility.\\n\\nIn 1959, with Hodograph I, Brown sketched the contour and character abstractly in what he called \\"implicit areas\\" of the piece. This graphic style was more gestural and calligraphic than the geometric abstraction of December 1952. Beginning with Available Forms I, Brown used this graphic notation on the staff in some sections of the score.\\n\\n![](./images/parallels.jpg)\\n","frontmatter":{"title":"Evolution of european notation systems","description":"From neumes to staves","date":"2021-08-19T00:00:00.000Z","cover":"/media_files/cover/theory-notes-staff-evolution-hooks_and_banners.png"},"url":"/theory/notes/staff/evolution/"},{"src":"---\\ntitle: Classic European music staff notation\\ndescription: How the sheet notes are written and read from classic era till today\\ndate: 2021-08-12\\ncover: kvintcirklen.png\\nlinks:\\n  - https://en.wikibooks.org/wiki/Music_Theory/Music_Notation_Systems\\n  - https://www.vexflow.com/\\n---\\n\\n<script setup>\\nimport { state } from '../../../../components/abc/state'\\n\\nconst minuet = \`\\nX:409\\nT:Minuet in G Major\\nT:BWV Anhang 114\\nC:Christian Petzold (1677-1733)\\nC:Formerly attributed to J. S. Bach\\nC:(Guitar chords added)\\nZ:ClassicMan at musescore.com\\nZ:abc-edited-by: AW\\nL:1/4\\nM:3/4\\nI:linebreak $\\nK:G\\nV:1 treble %nm=\\"Piano\\"\\nV:2 treble\\nV:3 bass\\nV:4 bass\\nV:1\\n\\"G\\"d G/A/\\"D7/a\\"B/c/ | \\"G/b\\"d .G .G | \\"C\\"e Mc/d/e/f/ | \\"G/b\\"g .G .G | \\\\\\n\\"Am\\"Mc d/c/\\"\\"B/A/ | \\"G\\"B c/B/A/G/ | \\"D\\"F \\"G\\"G/A/B/G/ |\\"D    D7\\"{B} A3 |$\\n\\"G\\"d G/A/\\"D7/a\\"B/c/ | \\"G/b\\"d .G .G | \\"C\\"e Mc/d/e/f/ | \\"G/b\\"g .G .G | \\\\\\n\\"Am\\"Mc d/c/\\"D/f#\\"B/A/ | \\"G\\"B c/B/\\"G/b\\"A/G/ | \\"Am/c\\"A \\"G/d\\"B/A/\\"D\\"G/F/ | \\"G\\"G3 ::$\\n%\\n\\"G\\"b g/a/b/g/ | \\"D/f#\\"a d/e/f/d/ | \\"Em\\"g e/f/g/d/ | \\"A\\"^c B/c/ A | \\\\\\n\\"A\\"A/B/^c/d/e/f/ | \\"G/b\\"g \\"D\\"f \\"A/c#\\"e | \\"D\\"f \\"D/f#\\"A \\"A\\"^c | \\"D       D7\\"d3 |$\\n\\"G/b\\"d G/F/ G | \\"C\\"e G/F/ G | \\"G/b\\"d \\"D/a\\"c \\"G\\"B | \\"D\\"A/G/F/G/ A | \\\\\\n\\"D\\"D/E/F/G/A/B/ | \\"C/e\\"c \\"G\\"PB \\"D/f#\\"A | \\"G\\"B/d/ \\"G/b\\"G \\"D\\"F | \\"G\\"G3 :|\\nV:2\\nx3 | x3 | x3 | x3 | x3 | x3 | x3 | x3 |$ x3 | x3 | x3 | x3 | x3 | x3 | x3 | x3 ::$ x3 | x3 | x3 |\\nx3 | x3 | x3 | x3 | x3 |$ x3 | x3 | x3 | x3 | x3 | x3 | x3 | [B,D]3 :|\\nV:3\\n[B,D]2 A, | B,3 | C3 | B,3 | A,3 | G,3 | D B, G, | D D,/C/B,/A,/ |$ B,2 A, | G, .B, .G, | C3 |\\nB, C/B,/A,/G,/ | A,2 F, | G,2 B, | C D D, | G,2 G,, ::$ G,3 | F,3 | E, G, E, | A,2 A,, | A,3 |\\nB, D ^C | D F, A, | D D, =C |$ z D2 | z E2 | B, A, G, | D2 z | z z F, | E, G, F, | G, B,, D, |\\nG, D, G,, :|\\nV:4\\nG,2 x | x3 | x3 | x3 | x3 | x3 | x3 | x3 |$ x3 | x3 | x3 | x3 | x3 | x3 | x3 | x3 ::$ x3 | x3 |\\nx3 | x3 | x3 | x3 | x3 | x3 |$ B,2 B, | C2 C | x3 | x3 | D,3 | x3 | x3 | x3 :|\\n\`\\n<\/script>\\n\\n<button :style=\\"{background: state.colorize ? 'linear-gradient(#e66465, #9198e5)': ''}\\" class=\\"button fixed right-16 bottom-4 z-20000 p-2 bg-light-400 dark-bg-dark-400 rounded-xl shadow active_bg-red-100\\"\\n@click=\\"state.colorize = !state.colorize\\">Colorize notes</button>\\n\\n![](./kvintcirklen.png)\\n\\nStandard notation is used to demonstrate how a piece is played. Unlike tablature, it applies to any instrument. It indicates key signatures, time signatures, rhythms, tempo, dynamics (how loud each instrument should be), and so on. A highly trained musician can sometimes take a piece of sheet music written in standard notation, look it over once or twice, and then play the song as though he or she had been playing it his or her whole life.\\n\\nFor instance, below is the C major scale, including a C at the end, in standard notation.\\n\\nThe standard notation staff has five lines and four spaces. From bottom to top the five lines are E G B D F, which is commonly memorized as an acrostic such as:\\n\\n- **E**very\\n- **G**ood\\n- **B**oy\\n- **D**oes\\n- **F**ine\\n\\nThe four spaces between the five lines are F, A, C, and E, which should surely be easy for an English speaker to remember, because together they spell \\"face\\".\\n\\nBut what about the first two notes, which are below the staff? Well, the second note is just below the E, so it must be D. The first is below that, so it must be C. It also has a line through it to indicate it is placed on an \\"invisible\\" line. This line is called a ledger line. A note could be placed below this ledger line, which would be B. Or a note could be placed below that, on another ledger line, and it would be A. Notes can continue to be placed on ledger lines above and below the staff infinitely, but extending too far from the staff is impractical, because the pitches will become very hard to read.\\n\\n## Clefs\\n\\n1. Treble (G) <abc-render :abc=\\"'K:treble\\\\nG8'\\" />\\n2. Bass (F) <abc-render :abc=\\"'K:bass\\\\nF,8'\\" />\\n3. Baritone (F) <abc-render :abc=\\"'K:bass3\\\\nF,8'\\" />\\n4. Tenor (C) <abc-render :abc=\\"'K:tenor\\\\nc,8'\\" />\\n5. Alto (C) <abc-render :abc=\\"'K:alto\\\\nc,8'\\" />\\n6. Mezzosoprano (C) <abc-render :abc=\\"'K:alto2\\\\nc,8'\\" />\\n7. Soprano (C) <abc-render :abc=\\"'K:alto1\\\\nc,8'\\" />\\n\\n## Note pitch\\n\\n### Natural (G)\\n\\n<abc-render :abc=\\"'G8'\\" />\\n\\n<abc-render :abc=\\"'K:Gb\\\\n=G8'\\" />\\n\\n### Sharp (G#)\\n\\n<abc-render :abc=\\"'^G8'\\" />\\n\\n<abc-render :abc=\\"'K:Gb\\\\n^^G8'\\" />\\n\\n### Flat (Gb)\\n\\n<abc-render :abc=\\"'_G8'\\" />\\n\\n<abc-render :abc=\\"'K:C#\\\\n__G8'\\" />\\n\\n### Ascending\\n\\nA A# B C C# D D# E F F# G G# A\\n\\n<abc-render responsive :abc=\\"'A,^A,B,C^CD^DEF^FG^GA'\\" />\\n\\n### Descending\\n\\nA Ab G Gb F E Eb D Db C B Bb A\\n\\n<abc-render responsive :abc=\\"\`a,_a,G_GFE_ED_DCB,_B,A,\`\\" />\\n\\n![](./chromatic-c.jpg)\\n![](./chromatic-Eb.jpg)\\n\\n## Note values (durations)\\n\\nWhole note = 2 half notes = 4 quarter notes = 8 eighth notes = 16 sixteenth notes\\n\\n<abc-render responsive :abc=\\"\`M:4/4\\\\n|G8|G4A4|G2A2B2c2|GDGDGDGD|G/D/G/D/G/D/G/D/G/D/G/D/G/D/G/D/|\`\\" />\\n\\n### Dotted notes\\n\\n<abc-render responsive :abc=\\"\`M:4/4\\\\n|(G12|G4)|G5G2|G3GG3G|G3/2G/2G3/2G/2G3/2G/2G3/2G/2|\`\\" />\\n\\n### Triplets\\n\\n<abc-render responsive :abc=\\"\`M:4/4\\\\n|(3G4A4B4|(3G2A2B2 (3G2A2B2| (3GAB (3GAB (3GAB (3GAB|\`\\" />\\n\\n### Other tuplets\\n\\n<abc-render responsive :abc=\\"\`M:4/4\\\\n|(5G2A2B2c2d2|(7CDEFGAB|\`\\" />\\n\\n### Rests\\n\\n<abc-render responsive :abc=\\"\`M:4/4\\\\n|z8|z4z4|z2z2z2z2|zzzzzzzz|z/z/z/z/z/z/z/z/z/z/z/z/z/z/z/z/|\`\\" />\\n\\n![](./note-values-and-rests.png)\\n\\n> ![](./Bachlut1.png)\\n> J.S.Bach Prelude\\n\\n### Alexander Scriabin - Piano Concerto in F sharp minor, Op. 20\\n\\n<youtube-embed video=\\"F734PyD3NAw\\" />\\n\\n## Vector render of staff notation by ABCjs\\n\\nNote colorization is very useful to build connections between classic and Chromatone music theory visualizations.\\n<abc-render responsive :abc=\\"minuet\\" />\\n\\n[Play with the ABC notations editor](../computer/abc/index.md)\\n\\n[Sight reading](./sight-reading/index.md)\\n\\n[European tradition](./evolution/index.md)\\n","frontmatter":{"title":"Classic European music staff notation","description":"How the sheet notes are written and read from classic era till today","date":"2021-08-12T00:00:00.000Z","cover":"/media_files/cover/theory-notes-staff-kvintcirklen.png","links":["https://en.wikibooks.org/wiki/Music_Theory/Music_Notation_Systems","https://www.vexflow.com/"]},"url":"/theory/notes/staff/"},{"src":"---\\ntitle: Equal temperament\\ndescription: 12-TET and other equal divisions of an octave\\ndate: 2021-08-10\\n\\ncover: zhu-zaiyu-1154.jpg\\n---\\n\\nIn classical music and Western music in general, the most common tuning system since the 18th century has been twelve-tone equal temperament (also known as 12 equal temperament, 12-TET or 12-ET; informally abbreviated to twelve equal), which divides the octave into 12 parts, all of which are equal on a logarithmic scale, with a ratio equal to the 12th root of 2 (12√2 ≈ 1.05946). That resulting smallest interval, 1⁄12 the width of an octave, is called a semitone or half step. In Western countries the term equal temperament, without qualification, generally means [12-TET](https://en.wikipedia.org/wiki/Equal_temperament).\\n\\n### Zhu Zaiyu\\n\\nZhu Zaiyu (朱載堉), a prince of the Ming court, spent thirty years on research based on the equal temperament idea originally postulated by his father. He described his new pitch theory in his Fusion of Music and Calendar 律暦融通 published in 1580. This was followed by the publication of a detailed account of the new theory of the equal temperament with a precise numerical specification for 12-TET in his 5,000-page work Complete Compendium of Music and Pitch (Yuelü quan shu 樂律全書) in 1584.\\n\\n![](./zhu-zaiyu-1154.jpg)\\n\\nZhu obtained his result mathematically by dividing the length of string and pipe successively by 12√2 ≈ 1.059463, and for pipe length by 24√2, such that after twelve divisions (an octave) the length was divided by a factor of 2:\\n\\n![svg](./12-equation.svg)\\n\\nSimilarly, after 84 divisions (7 octaves) the length was divided by a factor of 128.\\n\\n![svg](./128-equation.svg)\\n\\nZhu Zaiyu has been credited as the first person to solve the equal temperament problem mathematically.\\n\\n![](./zhu-zaiyu-strings.jpg)\\n\\n### Mathematics of 12-TET\\n\\n![svg](./tet-equation.svg)\\n\\n![svg](./tet-fifth-equation.svg)\\n\\n![svg](./oct-equation.svg)\\n\\n![](./Monochord_ET.png)\\n\\n### Tuning to the beats\\n\\nA precise equal temperament is possible using the 17th-century Sabbatini method of splitting the octave first into three tempered major thirds. This was also proposed by several writers during the Classical era. Tuning without beat rates but employing several checks, achieving virtually modern accuracy, was already done in the first decades of the 19th century. Using beat rates, first proposed in 1749, became common after their diffusion by Helmholtz and Ellis in the second half of the 19th century. The ultimate precision was available with 2-decimal tables published by White in 1917\\n\\n![](./piano-tuning.png)\\n","frontmatter":{"title":"Equal temperament","description":"12-TET and other equal divisions of an octave","date":"2021-08-10T00:00:00.000Z","cover":"/media_files/cover/theory-notes-temperaments-equal-zhu-zaiyu-1154.jpg"},"url":"/theory/notes/temperaments/equal/"},{"src":"---\\ntitle: Tunings comparison\\ndescription: Ways to juxtapose and compare different tuning methods side by side\\ndate: 2021-08-05\\ncover: tuning-circle.svg\\n---\\n\\n<img src=\\"./et-limits.svg\\" />\\n\\n## Circle of tunings\\n\\nSee and hear the slight differences between Pythagorean tunings, Just intonation and 12-TET. Click on the circle to start the note. Click again to stop it. You can hear the beatings between the same notes in various tunings and also hear the quality of the intervals in each of them.\\n\\n<tuning-circle />\\n","frontmatter":{"title":"Tunings comparison","description":"Ways to juxtapose and compare different tuning methods side by side","date":"2021-08-05T00:00:00.000Z","cover":"/media_files/cover/theory-notes-temperaments-tunings-tuning-circle.svg"},"url":"/theory/notes/temperaments/tunings/"},{"src":"---\\ntitle: Melody\\ndescription: Combinations of pitch and rhythm\\ndate: 2021-08-04\\ncover: ani-adigyozalyan.jpg\\n---\\n\\n[Melody](./study/index.md) as a linear succession of tones brings [Motion](./motion/index.md) to music and it originates from [singing](./singing/index.md). The basis for the singer is created with a [Drone](./drone/index.md) and the brightest colors of the voice are discovered through [Articulation and ornamentation](./articulation/index.md).\\n","frontmatter":{"title":"Melody","description":"Combinations of pitch and rhythm","date":"2021-08-04T00:00:00.000Z","cover":"/media_files/cover/theory-melody-ani-adigyozalyan.jpg"},"url":"/theory/melody/"},{"src":"---\\ntitle: Tutorship\\ndescription: Personal guidance through complexities of music with easy to grasp visual examples and web apps by the author and developer of Chromatone\\nlayout: iframe\\ndate: 2021-07-05\\ncover: wes-hicks.jpg\\ntopContent: true\\niframe: https://tutor.chromatone.center\\nbuttons:\\n  - url: \\"https://tutor.chromatone.center/\\"\\n    text: \\"tutor.chromatone.center\\"\\n---\\n\\n","frontmatter":{"title":"Tutorship","description":"Personal guidance through complexities of music with easy to grasp visual examples and web apps by the author and developer of Chromatone","layout":"iframe","date":"2021-07-05T00:00:00.000Z","cover":"/media_files/cover/tutor-wes-hicks.jpg","topContent":true,"iframe":"https://tutor.chromatone.center","buttons":[{"url":"https://tutor.chromatone.center/","text":"tutor.chromatone.center"}]},"url":"/tutor/"},{"src":"---\\ntitle: Drum rudiments\\ndescription: Basic patterns played with drum sticks\\ncover: josh-sorenson.jpg\\ndate: 2021-06-30\\n---\\n\\n<youtube-embed video=\\"WSC7iujjg_o\\" />\\n\\n### [Practice drum rudiments online](../../../practice/rhythm/rudiments/index.md)\\n\\n## Historical organization\\n\\n(NARD Standard 26 American Drum Rudiments of 1933)\\n\\n### Thirteen \\"essential\\" rudiments\\n\\n- The double stroke open roll\\n- The five stroke roll\\n- The seven stroke roll\\n- The flam\\n- The flam accent\\n- The flam paradiddle\\n- The flamacue\\n- The drag (half drag or ruff)\\n- The single drag tap\\n- The double drag tap\\n- The double paradiddle\\n- The single ratamacue\\n- The triple ratamacue\\n\\n### Second thirteen rudiments\\n\\n- The single stroke roll\\n- The nine stroke roll\\n- The ten stroke roll\\n- The eleven stroke roll\\n- The thirteen stroke roll\\n- The fifteen stroke roll\\n- The flam tap\\n- The single paradiddle\\n- The drag paradiddle No. 1\\n- The drag paradiddle No. 2\\n- The flam paradiddle-diddle\\n- The lesson 25\\n- The double ratamacue\\n\\n### Last fourteen rudiments\\n\\nIn 1984, the Percussive Arts Society added 14 more rudiments to extend the list to the current 40 International Snare Drum Rudiments. The ordering was completely changed during this last re-organization.\\n\\n- The single stroke four\\n- The single stroke seven\\n- The multiple bounce roll\\n- The triple stroke roll\\n- The six stroke roll\\n- The seventeen stroke roll\\n- The triple paradiddle\\n- The single paradiddle-diddle\\n- The single flammed mill\\n- The pataflafla\\n- The Swiss Army triplet\\n- The inverted flam tap\\n- The flam drag\\n- The single dragadiddle\\n\\n<youtube-embed video=\\"roT6Imp7lSg\\" />\\n\\n## Terminology\\n\\n### Single stroke\\n\\nA stroke performs a single percussive note. There are four basic single strokes.\\n\\n### Double stroke\\n\\nA double stroke consists of two single strokes played by the same hand (either RR or LL).\\n\\n### Diddle\\n\\nA diddle is a double stroke played at the current prevailing speed of the piece. For example, if a sixteenth-note passage is being played then any diddles in that passage would consist of sixteenth notes.\\n\\n### Paradiddle\\n\\nA paradiddle consists of two single strokes followed by a double stroke, i.e., RLRR or LRLL. When multiple paradiddles are played in succession, the first note always alternates between right and left. Therefore, a single paradiddle is often used to switch the \\"lead hand\\" in drumming music.\\nMill Stroke\\n\\nA mill stroke is essentially a reversed paradiddle with the sticking RRLR or LLRL with an accent on the first note. The single flammed mill is the most common mill stroke variant in American playing.\\n\\n### Drag\\n\\nA drag is a double stroke played at twice the speed of the context in which it is placed. For example, if a sixteenth-note passage is being played then any drags in that passage would consist of thirty-second notes. Drags can also be notated as grace notes, in which case the spacing between the notes can be interpreted by the player. On timpani, drags are often played with alternating sticking (lrL or rlR).\\n\\nIn Scottish pipe band snare drumming, a drag consists of a flam where the gracenote is played as a \\"deadstick\\" (staccato note).[citation needed]\\n\\n### Ruff\\n\\nHistorically, the modern Drag was known as a Ruff (or Rough) if played closed and a Half Drag when played open. Ruff can also refer to a single stroked set of grace notes preceding a regular note. In American playing the 3 Stroke Ruff has 2 single stroked grace notes before the primary or full note and a 4 Stroke Ruff has 3 singles before the primary note. Other rudimental systems have differing sticking methods and names for similar notation figures. Though still used and taught by drummers and drum teachers in practice, the 3 Stroke Ruff and 4 Stroke Ruff are not officially listed on the NARD or PAS rudiment sheets and the term Drag has eclipsed Ruff (or Rough) for the double stroked rudiments, in both open or closed execution, according to the current PAS standard terminology.\\n\\n### Flam\\n\\nA flam consists of two single strokes played by alternating hands (rL or lR). The first stroke is a quieter grace note followed by a louder primary stroke on the opposite hand. The two notes are played almost simultaneously, and are intended to sound like a single, broader note. The temporal distance between the grace note and the primary note can vary depending on the style and context of the piece being played. In the past, or in some European systems, open flams and closed flams were listed as separate rudiments.\\n\\n### Charge Stroke\\n\\nA charge stroke is a special variation on an open flam in which one or both of the notes are accented to provide a driving feel that can create the illusion that the downbeat has moved earlier in time. The two major types are French  Lr or Rl and Swiss LR or RL with the first note preceding the downbeat, which falls on the second note, in both types. Charge strokes can be combined with flams or drags to create complex grace note figures preceding a downbeat.\\n\\n### Roll\\n\\nDrum rolls are various techniques employed to produce a sustained, continuous sound.\\n\\nhttps://en.wikipedia.org/wiki/Drum_rudiment\\n\\nhttps://www.drumeo.com/beat/rudiments/\\n\\n### [Practice drum rudiments online](../../../practice/rhythm/rudiments/index.md)\\n","frontmatter":{"title":"Drum rudiments","description":"Basic patterns played with drum sticks","cover":"/media_files/cover/theory-rhythm-rudiments-josh-sorenson.jpg","date":"2021-06-30T00:00:00.000Z"},"url":"/theory/rhythm/rudiments/"},{"src":"---\\ntitle: Alternative notation systems\\ndescription: There's a plenty of proposed and actually used ways of writing down and communicating music information\\ndate: 2021-06-04\\ncover: kelly-sikkema.jpg\\n---\\n\\nHere's the growing list of all the known alternative approaches to notation systems:\\n\\n- [Tabulature](./tabulature/index.md)\\n- [Numbered notation](./numbered/index.md)\\n- [Bilinear notation](./bilinear/index.md)\\n- [Chromatic staff](./chromatic-staff/index.md)\\n- [Klavarscribo](./klavar/index.md)\\n- [Dodeka](./dodeka/index.md)\\n- [Parsons code](./parsons/index.md)\\n- [Standard pitch notation](./scientific/index.md)\\n- [Integer notation](./integer/index.md)\\n","frontmatter":{"title":"Alternative notation systems","description":"There's a plenty of proposed and actually used ways of writing down and communicating music information","date":"2021-06-04T00:00:00.000Z","cover":"/media_files/cover/theory-notes-alternative-kelly-sikkema.jpg"},"url":"/theory/notes/alternative/"},{"src":"---\\ntitle: Computer notation\\ndescription: Ways to describe, store and communicate musical notes in digital realm\\ndate: 2021-03-12\\ncover: FL.png\\n---\\n\\nComputers opened up the diverse methods for describing, reproducing, and communicating music in the digital era. This includes MIDI, Piano Roll, ABC notation, and other digital notation systems. As we continue to innovate and experiment with technology, these tools are not only used to transcribe traditional music but also to create new forms of sonic expression.\\n\\nOne of the most commonly used computer notations is MIDI (Musical Instrument Digital Interface). [MIDI](./midi/index.md) is a protocol that allows computers, synthesizers, MIDI controllers, sound cards, samplers and drum machines to control one another and exchange system data. It does not contain any sounds, but instructions that tell a device what to do.\\n\\nAnother important computer notation is the [Piano roll](./piano-roll/index.md). In modern digital audio workstations, the piano roll is a virtual grid representing time on the horizontal axis and MIDI notes on the vertical axis. This interface allows for precise control over the pitch, duration, and timing of notes. It has become a fundamental tool in digital music production, enabling composers to write, edit, and arrange their work in a visual interface.\\n\\n[ABC-notation](./abc/index.md) is a simple yet powerful ASCII musical notation for folk and traditional music. It was designed as a language for notating music in plain text files. The simplicity of ABC notation makes it ideal for sharing tunes through email and over the internet. [Ring Tone Text Transfer Language](./ring-tone/index.md) is another example of compact ASCII-based computer notation.\\n\\nAs we delve into the world of digital music notation, we also encounter innovative ways to represent music, such as colorizing staff notation or piano rolls. These methods provide a visual way to understand the tonal relationships and structures within a piece of music. For instance, the Chromatone system uses colors to denote different pitches, creating a vibrant and intuitive musical landscape.\\n\\nIn conclusion, computer notation is a vast and evolving field, opening up new possibilities for how we create, interact with, and understand music. As technology continues to advance, we can only imagine the future innovations that will further revolutionize the way we notate and perceive music.\\n","frontmatter":{"title":"Computer notation","description":"Ways to describe, store and communicate musical notes in digital realm","date":"2021-03-12T00:00:00.000Z","cover":"/media_files/cover/theory-notes-computer-FL.png"},"url":"/theory/notes/computer/"},{"src":"---\\ntitle: Emancipation of dissonance\\ndescription: The process of gradual acceptance of the more dissonant intervals as consonant and musical\\n\\ndate: 2021-03-04\\n---\\n\\nSchoenberg [believed](https://digital.library.unt.edu/ark:/67531/metadc9855/m2/1/high_res_d/dissertation.pdf) that the modern major and minor modes were artificial, produced by historical evolution rather than by or through nature. His first definition of the minor mode revolves around the notion of this mode as \\"synthetic\\" or \\"a product of art.\\"\\n\\nThough Schoenberg believed that the major-minor system had evolved historically, it was not present in nature but rather had undergone a transformation to last with it. The major mode, especially, had evolved to include all of the nondiatonic notes of the seven church modes that were “constructed on the seven diatonic tones of our major scale”. Here, Schoenberg defends his notion that each bass note can impose its own overtones, thus becoming the root of each chord; though they may be construed as “artificial,” they are not because they imitate a “prototype” in nature, the overtone series.\\n\\nThe major and minor modes are the simplification of an earlier modal system, with the addition of “nondiatonic phenomena.” In Harmonielehre, Schoenberg wrote of this central premise:\\n\\n> If we sum up the characteristics of the church modes, we get major and minor plus a number of nondiatonic phenomena. And the way in which the nondiatonic events of one church mode were carried over to the other modes I conceive as the process by which our two present-day modes (major and minor) crystallized out of the church modes. Accordingly, major and minor contain all those nondiatonic possibilities inherently, by virtue of this historical synthesis\\n\\nSchoenberg characterized nondiatonic phenomena in the alteration of chords as a continuation of the major-minor system, and eventually taught that there is no difference between consonance and dissonance. This argument resulted in his famous theory of the ‘emancipation of the dissonance,’ a concept Schoenberg borrowed from Rudolph Louis’s Der Widerspruch in der Musik, which addresses historical connotations not intrinsic in the original meanings of consonance and dissonance. When working out the ‘emancipation of the dissonance,’ Schoenberg was “attacking a structural-ornamental distinction that claims to be valid for all music, not distinctions appropriate to individual pieces, styles or composers.”\\n\\n> There are, then, no non-harmonic tones, no tones foreign to harmony, but merely tones foreign to the harmonic system. Passing tones, changing tones, suspensions, etc., are, like sevenths and ninths, nothing else but attempts to include in the possibilities of tones sounding together – these are of course, by definition, harmonies – something that sounds similar to the more remote overtones. Whoever gives rules for their use is describing, at best, the ways in which they are most generally used. He does not have the right, though, to claim that he has then precisely separated those possibilities in which they sound good from those in which they sound bad.\\n>\\n> \\"Harmonielehre\\"\\n\\nTurning points, pivot tones, neutralization, chromatic substitutes, and nondiatonic phenomena are concepts Schoenberg began teaching to address the changing context of dissonance in late nineteenth-century harmonic theory. In his chapter titled “At the Frontiers of Tonality,” Schoenberg began to illustrate what he called “vagrant harmonies,” defining the diminished triad, diminished seventh chords, and the augmented sixth chord and explaining how each of these chords functions in harmony.\\n\\nJust as the harmonic series was and is used as a justification for consonance, such as by Rameau, among others, the harmonic series is often used as physical or psychoacoustic justification for the gradual emancipation of intervals and chords found further and further up the harmonic series over time, such as is argued by Henry Cowell in defense of his tone clusters. Some argue further that they are not dissonances, but consonances higher up the harmonic series and thus more complex. Chailley (1951, 12); cited in Nattiez 1990 gives the following diagram, a specific timeline he proposes:\\n\\n![](./Chailley_harmonic_series_emancipationt.png)\\n\\n### Cooper timeline\\n\\n![](./Overtone_series_and_Western_music_development.png)\\n\\nCooper (1973, 6-7) proposes the following timeline:\\n\\n- A. unison and octave singing (magadizing) in Greek music and Ambrosian and Greek chant,\\n- B. parallel fourths and fifths in organum, from c. 850\\n- C. triadic music; from c. 1400\\n- D. chordal seventh, from c. 1600\\n- E. chordal ninth, from c. 1750\\n- F. whole-tone scale, from c. 1880\\n- G. total chromaticism, twelve-tone technique, and microtones in the early 20th-century.\\n","frontmatter":{"title":"Emancipation of dissonance","description":"The process of gradual acceptance of the more dissonant intervals as consonant and musical","date":"2021-03-04T00:00:00.000Z"},"url":"/theory/intervals/emancipation/"},{"src":"---\\ntitle: Sensory dissonance\\ndescription: The rather objective approach to pitch interval consonance and dissonance measure to model, calculate and extract\\ndate: 2021-02-15\\n---\\n\\n<youtube-embed video=\\"wg5QcF2akzQ\\" />\\n\\n## Research\\n\\n### [The pleasantness of sensory dissonance is mediated by musical style and expertise](https://www.nature.com/articles/s41598-018-35873-8)\\n\\nWestern musical styles use a large variety of chords and vertical sonorities. Based on objective acoustical properties, chords can be situated on a dissonant-consonant continuum. While this might to some extent converge with the unpleasant-pleasant continuum, subjective liking might diverge for various chord forms from music across different styles. Our study aimed to investigate how well appraisals of the roughness and pleasantness dimensions of isolated chords taken from real-world music are predicted by Parncutt’s established model of sensory dissonance. Furthermore, we related these subjective ratings to style of origin and acoustical features of the chords as well as musical sophistication of the raters. Ratings were obtained for chords deemed representative of the harmonic language of three different musical styles (classical, jazz and avant-garde music), plus randomly generated chords. Results indicate that pleasantness and roughness ratings were, on average, mirror opposites; however, their relative distribution differed greatly across styles, reflecting different underlying aesthetic ideals. Parncutt’s model only weakly predicted ratings for all but Classical chords, suggesting that listeners’ appraisal of the dissonance and pleasantness of chords bears not only on stimulus-side but also on listener-side factors. Indeed, we found that levels of musical sophistication negatively predicted listeners’ tendency to rate the consonance and pleasantness of any one chord as coupled measures, suggesting that musical education and expertise may serve to individuate how these musical dimensions are apprehended.\\n\\n[Download the PDF article](/public/media/pdf/sensory%20dissonance.pdf)\\n\\n### [An article by Naithan Bosse](https://www.naithan.com/sensory-dissonance/)\\n  \\nWhile completing my doctoral studies at the University of Calgary, I wrote a Max external, nb.dissonance, to estimate the amount of “sensory dissonance” created for any input chord. The external is based on Sean Ferguson’s method for estimating sensory dissonance detailed in the document portion of his doctoral thesis, Concerto for Piano and Orchestra (2000), as well as Richard Parncutt’s descriptions in Harmony: A Psychoacoustical Approach (1989). This post summarizes Ferguson’s method for estimating sensory dissonance and includes examples of how I experimented with the concept of sensory dissonance during the early stages of composing my dissertation composition Through a Window. My intention in writing this post is mainly to solidify my understanding of the methods described by Ferguson and Parncutt and to recommend these sources to anyone interested in the topics described below.\\n\\n### [Sensory Dissonance feature extraction: a case study](https://easychair.org/publications/open/qSM8) by Anna Terzaroli\\n\\nAn audio feature can become relevant as a musical feature. This paper focuses on the “Sensory\\nDissonance” audio feature and its use as a musical parameter useful to analyze and compose music of\\nall genres. It is possible by developing a software tool able to detect the presence of dissonance\\nunderstood as Sensory Dissonance, to quantify the dissonance and then to draw a graphic function of\\nthe traced dissonance. This function is placed under the sound which it relates, while the music signal\\nmay be written according to the western notation system. The obtained curve does not only provide\\ninformation concerning the degree of dissonance: it also allows a deeper reading of the entire\\nanalyzed musical work.\\n\\n[Download PDF article](/public/media/pdf/Sensory_Dissonance_feature_extraction_a_case_study.pdf)\\n\\n### [Relating Tuning and Timbre](https://sethares.engr.wisc.edu/consemi.html)  by William A. Sethares\\n\\nIf you've ever attempted to play music in weird tunings (where \\"weird\\" means anything other than 12 tone equal temperament), then you've probably noticed that certain timbres (or tones) sound good in some scales and not in others. 17 and 19 tone equal temperament are easy to play in, for instance, because many of the standard timbres in synthesizers sound fine in these tunings. I remember when I first played in 16 tone. I had to audition hundreds of sounds before I found a few good timbres. When I tried to play in 10 tone, though, none of the timbres in my synthesizers sounded good. This article explains why this happens, and shows how to design timbres and scales that complement each other. This suggests a way to design new musical instruments with unusual timbres that can play consonantly in unusual scales.\\n\\n[Download the book \\"Tuning, Timbre, Spectrum, Scale\\"](/public/media/pdf/tuning-timbre-spectrum-scale.pdf)\\n\\n### [Sensory Perceptions of Harmony, Dissonance, Color and Timbre: Creative Insights in the Fine Arts and Daily Communication](https://www.amazon.com/Sensory-Perceptions-Harmony-Dissonance-Timbre-ebook/dp/B07JYLY6W2) by Ellen Gilmer\\n\\nAlthough no two people see colors, hear sounds or express thoughts, feelings, desires or realizations in exactly the same way, by sharing our unique perceptions of these sensory stimuli, we can communicate and appreciate the perceptions and viewpoints of others. Even the most dissonant musical chords, painterly strokes or written and spoken words gain values of harmony and acceptance as their rhythms, hues and tonalities grow familiar and vital to us all.","frontmatter":{"title":"Sensory dissonance","description":"The rather objective approach to pitch interval consonance and dissonance measure to model, calculate and extract","date":"2021-02-15T00:00:00.000Z"},"url":"/theory/intervals/dissonance/"},{"src":"---\\ntitle: Interval cycles\\ndescription: Collection of pitch classes created from a sequence of the same interval class\\ndate: 2021-02-03\\n---\\n\\nIn music, an [interval cycle](https://en.wikipedia.org/wiki/Interval_cycle) is a collection of pitch classes created from a sequence of the same interval class. In other words, a collection of pitches by starting with a certain note and going up by a certain interval until the original note is reached (e.g. starting from C, going up by 3 semitones repeatedly until eventually C is again reached - the cycle is the collection of all the notes met on the way). In other words, interval cycles \\"unfold a single recurrent interval in a series that closes with a return to the initial pitch class\\". See: wikt:cycle.\\n\\nInterval cycles are notated by George Perle using the letter \\"C\\" (for cycle), with an interval class integer to distinguish the interval. Thus the diminished seventh chord would be C3 and the augmented triad would be C4. A superscript may be added to distinguish between transpositions, using 0–11 to indicate the lowest pitch class in the cycle. \\"These interval cycles play a fundamental role in the harmonic organization of post-diatonic music and can easily be identified by naming the cycle.\\"\\n\\nInterval cycles assume the use of equal temperament and may not work in other systems such as just intonation. For example, if the C4 interval cycle used justly-tuned major thirds it would fall flat of an octave return by an interval known as the diesis. Put another way, a major third above G♯ is B♯, which is only enharmonically the same as C in systems such as equal temperament, in which the diesis has been tempered out.\\n\\nInterval cycles are symmetrical and thus non-diatonic. However, a seven-pitch segment of C7 will produce the diatonic major scale.\\n\\nThis is known also known as a generated collection. A minimum of three pitches are needed to represent an interval cycle.\\n\\nCyclic tonal progressions in the works of Romantic composers such as Gustav Mahler and Richard Wagner form a link with the cyclic pitch successions in the atonal music of Modernists such as Béla Bartók, Alexander Scriabin, Edgard Varèse, and the Second Viennese School (Arnold Schoenberg, Alban Berg, and Anton Webern). At the same time, these progressions signal the end of tonality.\\n\\nInterval cycles are also important in jazz, such as in Coltrane changes.\\n\\n\\"Similarly,\\" to any pair of transpositionally related sets being reducible to two transpositionally related representations of the chromatic scale, \\"the pitch-class relations between any pair of inversionally related sets is reducible to the pitch-class relations between two inversionally related representations of the semitonal scale.\\" Thus an interval cycle or pair of cycles may be reducible to a representation of the chromatic scale.\\n\\nAs such, interval cycles may be differentiated as ascending or descending, with, \\"the ascending form of the semitonal scale [called] a 'P cycle' and the descending form [called] an 'I cycle',\\" while, \\"inversionally related dyads [are called] 'P/I' dyads.\\" P/I dyads will always share a sum of complementation. Cyclic sets are those \\"sets whose alternate elements unfold complementary cycles of a single interval,\\" that is an ascending and descending cycle:\\nCyclic set (sum 9) from Berg's Lyric Suite\\n\\nIn 1920 Berg discovered/created a \\"master array\\" of all twelve interval cycles:\\n\\n    Berg's Master Array of Interval Cycles\\n\\n    Cycles P 0 11 10  9  8  7  6  5  4  3  2  1  0\\n    P  I  I 0  1  2  3  4  5  6  7  8  9 10 11  0\\n          _______________________________________\\n    0  0  | 0  0  0  0  0  0  0  0  0  0  0  0  0\\n    11  1  | 0 11 10  9  8  7  6  5  4  3  2  1  0\\n    10  2  | 0 10  8  6  4  2  0 10  8  6  4  2  0\\n    9  3  | 0  9  6  3  0  9  6  3  0  9  6  3  0\\n    8  4  | 0  8  4  0  8  4  0  8  4  0  8  4  0\\n    7  5  | 0  7  2  9  4 11  6  1  8  3 10  5  0\\n    6  6  | 0  6  0  6  0  6  0  6  0  6  0  6  0\\n    5  7  | 0  5 10  3  8  1  6 11  4  9  2  7  0\\n    4  8  | 0  4  8  0  4  8  0  4  8  0  4  8  0\\n    3  9  | 0  3  6  9  0  3  6  9  0  3  6  9  0\\n    2 10  | 0  2  4  6  8 10  0  2  4  6  8 10  0\\n    1 11  | 0  1  2  3  4  5  6  7  8  9 10 11  0\\n    0  0  | 0  0  0  0  0  0  0  0  0  0  0  0  0\\n\\n## Generated collection\\n\\nIn diatonic set theory, [a generated collection](https://en.wikipedia.org/wiki/Generated_collection) is a collection or scale formed by repeatedly adding a constant interval in integer notation, the generator, also known as an interval cycle, around the chromatic circle until a complete collection or scale is formed. All scales with the deep scale property can be generated by any interval coprime with (in twelve-tone equal temperament) twelve. (Johnson, 2003, p. 83)\\n\\nThe C major diatonic collection can be generated by adding a cycle of perfect fifths (C7) starting at F: F-C-G-D-A-E-B = C-D-E-F-G-A-B. Using integer notation and modulo 12: 5 + 7 = 0, 0 + 7 = 7, 7 + 7 = 2, 2 + 7 = 9, 9 + 7 = 4, 4 + 7 = 11.\\n7-note segment of C5: the C major scale as a generated collection\\n\\nThe C major scale could also be generated using cycle of perfect fourths (C5), as 12 minus any coprime of twelve is also coprime with twelve: 12 − 7 = 5. B-E-A-D-G-C-F.\\n\\nA generated collection for which a single generic interval corresponds to the single generator or interval cycle used is a MOS (for \\"moment of symmetry\\") or well formed generated collection. For example, the diatonic collection is well formed, for the perfect fifth (the generic interval 4) corresponds to the generator 7. Though not all fifths in the diatonic collection are perfect (B-F is a diminished fifth, tritone, or 6), a well formed generated collection has only one specific interval between scale members (in this case 6)—which corresponds to the generic interval (4, a fifth) but to not the generator (7). The major and minor pentatonic scales are also well formed. (Johnson, 2003, p. 83)\\n\\nThe properties of generated and well-formedness were described by Norman Carey and David Clampitt in \\"Aspects of Well-Formed Scales\\" (1989), (Johnson, 2003, p. 151.) In earlier (1975) work, theoretician Erv Wilson defined the properties of the idea, and called such a scale a MOS, an acronym for \\"Moment of Symmetry\\". While unpublished, this terminology became widely known and used in the microtonal music community. For instance, the three-gap theorem implies that every generated collection has at most three different steps, the intervals between adjacent tones in the collection (Carey 2007).\\n\\nA degenerate well-formed collection is a scale in which the generator and the interval required to complete the circle or return to the initial note are equivalent and include all scales with equal notes, such as the whole-tone scale. (Johnson, 2003, p. 158, n. 14)\\n\\nA [bisector](<https://en.wikipedia.org/wiki/Bisector_(music)>) is a more general concept used to create collections that cannot be generated but includes all collections which can be generated.\\n","frontmatter":{"title":"Interval cycles","description":"Collection of pitch classes created from a sequence of the same interval class","date":"2021-02-03T00:00:00.000Z"},"url":"/theory/intervals/cycles/"},{"src":"---\\ntitle: Chromatone color notation\\ndescription: Different ways to implementing the color-frequency equations for writing and reading music\\n\\ndate: 2021-02-01\\ncover: midi-roll.png\\n---\\n\\nThere's a plenty of possible ways to make the Chromatone system work for written music communication. This whole web site is one big experiment to find the most useful implications of the simple equations. But there's more to explore!\\n\\n## Colorize the staff notation\\n\\nFirst and the most obvious use of color in music is a simple coloring the regular staff notation. You can use 12 markers to denote any pitch on paper and we can modify existing apps and scripts to produce colored sheet music.\\n\\n<img src=\\"./chromatic-scale.svg\\">\\n\\n## Chromatic hand\\n\\nThe extension of the ancient method of linking finger phalanges and musical notes. We can make it consistent enough to use intuitively after a little practice.\\n\\n![Chromatic hand](./note-hand.svg)\\n\\n## Interval hand\\n\\nThe 12 phalanges of fingers are ideal to reason not only about notes, but intervals too. Assume the tip of your index finger as a tonic note and build any interval, chord, or even scale just with your thumb. It enables you to practice melodies, progressions and more in any moment, at any place.\\n\\n![Interval hand](./hand.svg)\\n\\n## Colorful piano rolls\\n\\nTry the [MIDI-roll](../../../practice/midi/roll/index.md) to look at incoming MIDI visualization.\\n\\nTry the [Pitch-roll](../../../practice/pitch/roll/index.md) to see the main note graph of incoming audio on an endless roll.\\n\\n## Colorful spectrogram\\n\\nAdding the colors to a regular spectrogram makes you see much more about the musical contents of any sound. You can easily see the fundamental pitch and the colors of all the main overtones for simple sounds.\\n\\nTry the [Colorful spectrogram](../../../practice/pitch/spectrogram/index.md) online now.\\n\\n![Both hands](./hands.svg)\\n","frontmatter":{"title":"Chromatone color notation","description":"Different ways to implementing the color-frequency equations for writing and reading music","date":"2021-02-01T00:00:00.000Z","cover":"/media_files/cover/theory-notes-color-midi-roll.png"},"url":"/theory/notes/color/"},{"src":"---\\ntitle: Synthesis\\ndescription: Ways to generate musical sounds out of electric oscillations\\ndate: 2020-10-10\\ncover: 35-54d35.jpg\\n---\\n\\n<youtube-embed video=\\"Y7TesKMSE74\\" />\\n\\n<youtube-embed video=\\"F1RsE4J9k9w\\" />\\n\\n## Types of synthesis\\n\\n- Additive\\n- Subtractive\\n- Wavetable\\n- Amplitude modulation (Ring modulation)\\n- Frequency modulation\\n- Waveshaping\\n  - Saturation\\n  - Wave folding\\n  - Phase inversion\\n- Hard sync\\n- Granular\\n\\n<youtube-embed video=\\"Gn5yixqjmN8\\" />\\n\\n## DSP\\n\\nhttps://github.com/olilarkin/awesome-musicdsp\\n","frontmatter":{"title":"Synthesis","description":"Ways to generate musical sounds out of electric oscillations","date":"2020-10-10T00:00:00.000Z","cover":"/media_files/cover/theory-synthesis-35-54d35.jpg"},"url":"/theory/synthesis/"},{"src":"---\\ntitle: The Real Book\\ndescription: History of 20th century modern jazz notation developments\\ndate: 2020-09-13\\ncover: images/Screen-Shot-2021-04-06-at-11.46.19-AM-600x273.png\\n---\\n\\n>Quotes from the deep into the topic podcast by [99% Invisible](https://99percentinvisible.org/episode/the-real-book/)\\n\\nSince the mid-1970s, almost every jazz musician has owned a copy of the same book. It has a peach-colored cover, a\\nchunky, 1970s-style logo, and a black plastic binding. It’s delightfully homemade-looking—like it was printed by a bunch\\nof teenagers at a Kinkos. And inside is the sheet music for hundreds of common jazz tunes—also known as jazz\\n“standards”—all meticulously notated by hand. It’s called the Real Book.\\n\\n![](./images/history_page_1.jpeg)\\n\\nBut if you were going to music school in the 1970s, you couldn’t just buy a copy of the Real Book at the campus\\nbookstore. Because the Real Book… was _illegal_. The world’s most popular collection of jazz music was a totally\\nunlicensed publication. It was a self-published book created without permission from music publishers or songwriters. It\\nwas duplicated at photocopy shops and sold on street corners, out of the trunks of cars, and under the table at music\\nstores where people used secret code words to make the exchange. The full story of how the Real Book came to be this\\nbootleg bible of jazz is a complicated one. It’s a story about what happens when an insurgent, improvisational art form\\nlike jazz gets codified and becomes something that you can learn from a book.\\n\\nThe History of Fake Books\\n-------------------------\\n\\n![](./images/image011.png)\\n[Barry Kernfeld](https://www.barnesandnoble.com/w/the-story-of-fake-books-barry-kernfeld/1111519327) is a musicologist\\nwho has written a lot about the history of jazz and music piracy. Kernfeld says that long before the Real Book ever came\\nout, jazz musicians were relying on collections of music they called fake books. Kernfeld says that the story of the\\nfirst fake book began in the 1940s. “A man named George Goodwin in New York City, involved in radio in the early 1940s,\\nwas getting a little frustrated with all the intricacies of tracking licensing. And so he invented this thing that he\\ncalled the Tune-Dex,” explains Kernfeld.\\n\\n![](./images/TuneDex-600x733.jpeg)\\n\\nTuneDex card via [Georgia State University\\nLibrary](https://blog.library.gsu.edu/2010/10/13/popular-music-tune-dex-cards/)\\n\\nThe Tune-Dex was an index card catalog designed for radio station employees to keep track of the songs they were playing\\non air. On one side the cards had information about a particular song, such as the composer, the publisher, and anything\\nthat one would need to know for payment rights. On the other side of the card were a few lines of bite-sized sheet\\nmusic—just the song’s melody, lyrics, and chords so that radio station employees could glance at it and quickly recall\\nthe song. This abbreviated musical notation also made the cards useful to another group of people: working jazz\\nmusicians.\\n\\n![](./images/s-l1600-600x450.jpeg)\\n\\nAs a Black art form, jazz had developed out of a mix of other Black music traditions including spirituals and the blues.\\nBy the 1940s, a lot of “jazz” was popular dance music, and many jazz musicians were making their money playing live gigs\\nin small clubs and bars. The standard jazz repertoire was mostly well-known pop songs from Broadway, or New York’s\\nsongwriting factory: “Tin Pan Alley.”\\n\\n<YoutubeEmbed video=\\"5WX_fKVWX2s\\" />\\n\\nJazz musicians would riff and freestyle over these songs. The art of improvisation has always been a key art form of\\njazz music. But what made the average gigging trumpeter or sax player truly valuable was their ability to play any one\\nof hundreds of songs right there on the spot.\\n\\nTo be prepared for any request, musicians would bring stacks and stacks of sheet music to every gig. But lugging around\\na giant pile of paper could be really cumbersome—this is where the Tune-Dex came in. Someone figured out that you could\\ngather together a bunch of Tune-Dex cards, print copies of them on sheets of paper, add a table of contents and a simple\\nbinding, and then sell the finished product directly to musicians in the form of a book. They called them “fake books”\\nbecause they helped musicians fake their way through unfamiliar songs. These first fake books were cheaper than regular\\nsheet music, and a lot more organized. They became an essential tool for this entire class of working musicians.\\n\\nBootleggers\\n-----------\\n\\nMusicians loved these new fake books, but the music publishers hated them. They wanted musicians to buy legal sheet\\nmusic, and so the publishing companies started cracking down on fake book bootleggers. That, of course, didn’t stop the\\nbootleggers and by the 1950s, there were countless illegal fake books in existence, which were being used in nightclubs\\nall across the country.\\n\\n<YoutubeEmbed video=\\"LLDELtfUsaQ\\" />\\n\\nAs helpful as fake books were, they had a lot of problems. They were notoriously illegible and confusingly laid out. The\\nother big problem with these fake books at this point was that the music inside felt really out of date. The fake books\\nhadn’t changed since the mid-40s, but jazz had. Disillusioned by commercial jazz that appealed to mainstream white\\naudiences, a new generation of Black musicians took jazz improvisation to a new level. They experimented with more\\nangular harmonies, technically demanding melodies and blindingly fast tempos. Their new style was called bebop.\\n\\n<YoutubeEmbed video=\\"09BB1pci8_o\\" />\\n\\nBebop was just the beginning. Over several decades, jazz exploded into this constellation of different styles.\\nMeanwhile, the economics of jazz shifted too. There were fewer clubs, smaller paychecks, and more university jazz\\nprograms with steady teaching gigs. The ivory tower, not the nightclub, increasingly became a place for young musicians\\nto learn, and for established musicians to earn a living. And if you’re going to jazz school, you need jazz books.\\n\\n![](./images/1599px-WTB_Berklee_3-600x400.jpeg)\\n\\nBerklee College of Music. Photo by [Cryptic C62](https://commons.wikimedia.org/wiki/User:Cryptic_C62 \\"User:Cryptic C62\\")\\n\\nThe fake books at the time hadn’t kept up with the music. They still contained the same old-fashioned collection of\\nstandards with the same old-fashioned collection of chord changes. If a young jazz musician wanted to try and play like\\nCharles Mingus or Sonny Rollins, they weren’t going to learn from a book. That is… until two college kids invented the Real Book.\\n\\nThe Two Guys\\n------------\\n\\nIn the mid-70s, Steve Swallow began teaching at Boston’s Berklee College of Music, an elite private music school that\\nboasted one of the first jazz performance programs in the country. Swallow had only been teaching at Berklee for a few\\nmonths when two students approached him about a secret project. “I keep referring them to them as ‘the two guys who\\nwrote the book,’ because…they swore me to secrecy. They made me agree that I would not divulge their names,” explains\\nSwallow. The “two guys” wanted to make a new fake book, one that actually catered to the needs of contemporary jazz\\nmusicians and reflected the current state of jazz. And they needed Swallow’s help.\\n\\nFrom the very beginning, the students envisioned the Real Book as a cooler and more contemporary fake book than the\\nstodgy, outdated ones they’d grown up with. They wanted it to include new songs from jazz fusion artists like Herbie\\nHancock, and free jazz pioneers like Ornette Coleman who were pushing the boundaries of the genre. They also wanted to\\ninclude the old jazz standards from Broadway and Tin Pan Alley, but they wanted to update those classics with alternate\\nchord changes that reflected the way modern musicians, like Miles Davis, were actually playing them.\\n\\n<YoutubeEmbed video=\\"jy1ICphDYTQ\\" />\\n\\nModern jazz musicians had altered a lot of classic standards over the years, with new harmonies and more complex chord\\nchanges. And to capture these new sounds, the students spent hours listening to recordings and transcribing what they\\nheard, as best they could. It was a huge undertaking because most of these chord changes had never actually been written\\ndown. They weren’t necessarily thinking about it like this at the time, but the students were effectively establishing a\\nnew set of standardized harmonies for a handful of classic songs.\\n\\n![](./images/0af38b0aa71f96f108ae83a243e5de8d.jpeg)\\n\\n![](./images/history_page_1_002.jpeg)\\n\\nThe music wasn’t the only part of their new fake book that the students wanted to improve. They also wanted to fix the aesthetic problems with the old fake books, and make something that was nice to look at and easy to read. One of “the two guys” notated all of the music by hand in this very distinctive and expressive script. He also designed and silk-screened the logo on the front cover: “The Real Book,” written in chunky, SchoolHouse Rock-style block letters.\\n\\n![](./images/Screen-Shot-2021-04-06-at-11.46.19-AM-600x273.png)\\n\\nBy the summer of 1975, the book was done, and the students took it to local photocopying shops where they cranked out hundreds of copies to sell directly to other students and a few local businesses near Berklee. Overnight, almost everyone had to have one. As the Real Book’s notoriety grew, so did the demand. The two students hadn’t printed enough copies to keep up, but it turns out, they didn’t need to. Not long after they created a few hundred copies of the book, bootleg versions began popping up all over the world. The Real Book had taken on a life of its own, and the students\\nironically found themselves in the same position as the music publishers and songwriters they’d originally cut out of the process, as they watched unlicensed copies of their work get duplicated and sold. After they released the first edition of the Real Book, the students put out two more editions to correct mistakes, and then their work was done. But the Real Book lived on, copied over and over again by new generations of bootleggers. And as the number of students in elite conservatory jazz programs continued to swell over the next few decades, the Real Book, with its modern repertoire, reharmonized standards, and beautiful handwriting, became the de-facto textbook for this new legion of jazz students. The unofficial official handbook of jazz.\\n\\n![](./images/Screen-Shot-2021-04-06-at-11.45.30-AM-600x772.png)\\n\\nThe Real Real Book\\n------------------\\n\\nJust like with old fake books, the success of the Real Book was a major problem for music publishers. Some companies\\nreleased their own fake books, but they never managed to compete with the Real Book. The popularity of the Real Book\\nmeant that lots of people weren’t getting paid for their work. But in the mid-2000s, music executive Jeff Schroedl and\\nthe publisher Hal Leonard decided, if you can’t beat ’em, join ’em. They went through the Real Book page by page,\\nsecured the rights to almost every song, and published a completely legal version. You don’t need to buy the Real Book\\nout of the back of someone’s car anymore. It’s available at your local music shop. They even wanted the same\\nhandwriting. Hal Leonard actually hired a copyist to mimic the old Real Book’s iconic script and turn it into a digital\\nfont, which means a digital copy of a physical copy of one anonymous Berklee student’s handwriting from the mid-70s will\\ncontinue to live on for as long as new editions of the book are published.\\n\\n![](./images/00240221FCz-600x776.jpeg)\\n\\nThe Hal Leonard version of the Real Book\\n\\nWhen Hal Leonard finally published the legal version of the Real Book in 2004, it was great news if you were a composer\\nwith a song in there. You’d finally be getting royalties from the sale of the most popular jazz fake book of all time.\\nBut that didn’t totally solve the intellectual property problems with the Real Book. While the legalization of the Real\\nBook did resolve most of its flagrant copyright violations, it didn’t clear up authorship disputes that go back to the\\nearly days of jazz. Many jazz songs arise out of collective tinkering and improvising in jam sessions. It’s sometimes\\nquite hard to say who exactly wrote a given song, and power dynamics often impacted whose name actually got listed as an\\nofficial songwriter. And so there are likely many musicians whose names will never appear on the songs they helped\\nwrite, even if those songs appear in the legal Real Book.\\n\\nUseful Tool, or Reductive Cheat Sheet?\\n----------------------------------\\n\\nEven if we put the intellectual property questions aside for a second, fake books like the Real Book still have plenty\\nof critics. Nicholas Payton is a musician and record label owner, and he compares the Real Book to a study guide or a\\ncheat sheet—a way to distill this complicated art form into a manageable packet of digestible information. To Payton,\\njazz isn’t just information to be learned. It’s a way of thinking and a form of expression. And it’s fundamentally a\\nBlack cultural phenomenon that can’t be taken out of its historical context. Payton says that reading books like the\\nReal Book, even going to music school, can really only get you so far. If you want to learn to play, at some point\\nyou’re going to have to immerse yourself in the culture of the music. For Payton (and many musicians) learning directly\\nfrom elders, in person, is a crucial part of what it means to really know the art form.\\n\\nThere’s also the question of codification, and whether it’s useful to have one songbook filled with definitive versions\\nof all these jazz tunes. Carolyn Wilkins has taught ensembles at Berklee College of Music, and she says that the chords\\nthat are written down in the Real Book sometimes get treated like the _right_ way to play a particular song. But even\\nthough jazz has all of these “standards,” they’re not supposed to be played in one standard way. As you listen to\\ndifferent recordings of the same song by different jazz artists, it becomes obvious that there’s no one right way to\\nplay it. Wilkins says that the Real Book does have its place in jazz education. Over her years at Berklee, she’s seen\\nhow it can be a useful starting place as a tool to bring young jazz musicians together. The key, she says, is to treat\\nthe Real Book as a starting place. From there you need to go out and explore all the other ways people have played a\\nparticular song. “And then ultimately you must find your own way.”\\n\\n<YoutubeEmbed video=\\"1eRNRzyX3ac\\" />\\n\\n-------\\n\\n- Listen to the podcast at [99percentinvisible.org](https://99percentinvisible.org/episode/the-real-book/)\\n- [Download The Real Book (5th edition) [PDF]](http://biblio3.url.edu.gt/Libros/Real-Book/The_Real_Vol_1.pdf)\\n\\nWe see the Chromatone web-site as The Real Book for 21st century. As the old one enabled a whole class of professional jazz musicians, the new one enables the whole majority of casual visual musicians. It's a toolbox for everyone to study, explore and compose music themselves and with friends, at any place. And the more open and accessive it is - the more fun it will be for the world to start seeing music.\\n","frontmatter":{"title":"The Real Book","description":"History of 20th century modern jazz notation developments","date":"2020-09-13T00:00:00.000Z","cover":"/media_files/cover/theory-notes-staff-real-book-images-Screen-Shot-2021-04-06-at-11.46.19-AM-600x273.png"},"url":"/theory/notes/staff/real-book/"},{"src":"---\\ntitle: Tabulature\\ndescription: Explicit note playing instructions for the instrument\\ncover: capirola2.png\\ndate: 2020-03-30\\n---\\n\\nTablature (or tabulature, or tab for short) is a form of musical notation indicating instrument fingering rather than musical pitches. The word tablature originates from the Latin word tabulatura. Tabula is a table or slate, in Latin. To tabulate something means to put it into a table or chart.\\n\\nTablature is common for fretted stringed instruments such as the lute, vihuela, or guitar, as well as many free reed aerophones such as the harmonica. Tablature was common during the Renaissance and Baroque eras, and is commonly used today in notating many forms of music. Three types of organ tablature were used in Europe: German, Spanish and Italian.\\n\\n> ![](./Vihuela-Tab_Fuenllana_1554.jpg)\\n> Example of numeric vihuela tablature from the book \\"Orphenica Lyra\\" by Miguel de Fuenllana (1554). Red numerals (original) mark the vocal part.\\n\\nWhile standard notation represents the rhythm and duration of each note and its pitch relative to the scale based on a twelve tone division of the octave, tablature is instead operationally based, indicating where and when a finger should be placed to generate a note, so pitch is denoted implicitly rather than explicitly.\\n\\n![](./Tuning-chr.png)\\n\\nTablature for plucked strings is based upon a diagrammatic representation of the strings and frets of the instrument, keyboard tablature represents the keys of the instrument, and woodwind tablature shows whether each of the fingerholes is to be closed or left open.\\n\\n![](./capirola2.png)\\n\\n![](./guitar-tabs.svg)\\n\\n![](./Star-Wars-Ukulele-The-Imperial-March.jpg)\\n\\n### Drum tabs\\n\\nInstead of the durational notes normally seen on a piece of sheet music, drum tab uses proportional horizontal placement to indicate rhythm and vertical placement on a series of lines to represent which drum from the drum kit to stroke. Drum tabs frequently depict drum patterns.\\n\\n\`\`\`\\nHH|x-x-x-x-x-x-x-x-||\\n S|----o-------o---||\\n B|o-------o-------||\\n   1 + 2 + 3 + 4 +\\n\`\`\`\\n\\n### Keyboard tabulature\\n\\nThe modern keyboard tabs are built using any monospaced font. THey show each octave of the piano on a separate lane (with \\"R\\" and \\"L\\" for the hand). Letters show the note played. \\">\\" symbols show note durations in the fixed time periods, divided by \\"|\\" symbols. The actual chords are placed above the tabs.\\n\\n\`\`\`\\nPenny Lane - The Beatles\\nTabbed By: Ebon-Ivor\\n\\n             C          Am7          Dm7        Gsus7\\n   +  1  +   1  +  2  +  3  +  4  +   1  +  2  +  3  +  4  +\\nR5|---c-d-e-|e>>d>>c---c>>>>---------|------------------c-d-e>|\\nR4|g>>------|--------b------b>>a>>---|a-----------------a>>>>>|\\nR4|---------|g>>>>>g>>>>>g>>>>>---g>>|--g-f>>>>>>>>>>g>>f>>>>>|\\nR4|---------|e>>>>>e>>>>>e>>>>>e>>>>>|------------------------|\\nR4|---------|------------------c>>>>>|c>>>>>c>>>>>c>>>>>------|\\nR3|---------|------------------------|a>>>>>a>>>>>a>>>>>------|\\nL3|---------|c>>>>>------------------|------------------------|\\nL2|---------|------b>>>>>a>>>>>g>>>>>|f>>>>>d>>>>>g>>>>>g>>>>>|\\n\\n   C          Am7          Cm7                     Am7b5\\n\\n\`\`\`\\n\\n[tabnabber.com](https://tabnabber.com/view_Tab.asp?tabID=11885&sArtist=Beatles%2C%20The&sName=Penny%20Lane)\\n","frontmatter":{"title":"Tabulature","description":"Explicit note playing instructions for the instrument","cover":"/media_files/cover/theory-notes-alternative-tabulature-capirola2.png","date":"2020-03-30T00:00:00.000Z"},"url":"/theory/notes/alternative/tabulature/"},{"src":"---\\ntitle: External resources\\ndescription: Links to some valuable information on music and color theory and more\\ncover: ugur-akdemir.jpg\\ndate: 2019-02-02\\n---\\n\\n\\n<script setup>\\nimport { data } from '#/data/resources.data'\\n<\/script>\\n\\n<ToolsList  :data=\\"data\\" />\\n","frontmatter":{"title":"External resources","description":"Links to some valuable information on music and color theory and more","cover":"/media_files/cover/theory-resources-ugur-akdemir.jpg","date":"2019-02-02T00:00:00.000Z"},"url":"/theory/resources/"},{"src":"---\\ntitle: Audio Programming\\ndescription: List of most notable audio programming languages\\ndate: 2014-06-02\\n---\\n\\n* [ABC notation](https://en.wikipedia.org/wiki/ABC_notation \\"ABC notation\\"), a language for notating music using the ASCII character set\\n* [Bol Processor](https://bolprocessor.org/), a model of [formal grammars](https://en.wikipedia.org/wiki/Formal_grammar \\"Formal grammar\\") enriched with polymetric expressions for the representation of time structures\\n* [ChucK](https://en.wikipedia.org/wiki/ChucK \\"ChucK\\"), strongly timed, concurrent, and on-the-fly audio programming language\\n* [Real-time Cmix](https://en.wikipedia.org/wiki/Real-time_Cmix \\"Real-time Cmix\\"), a [MUSIC-N](https://en.wikipedia.org/wiki/MUSIC-N \\"MUSIC-N\\") synthesis language somewhat similar to Csound\\n* [Cmajor](https://cmajor.dev/), a high-performance JIT-compiled C-style language for DSP\\n* [Common Lisp Music](https://en.wikipedia.org/wiki/Common_Lisp_Music \\"Common Lisp Music\\") (CLM), a music synthesis and signal processing package in the Music V family\\n* [Csound](https://en.wikipedia.org/wiki/Csound \\"Csound\\"), a [MUSIC-N](https://en.wikipedia.org/wiki/MUSIC-N \\"MUSIC-N\\") synthesis language released under the [LGPL](https://en.wikipedia.org/wiki/GNU_Lesser_General_Public_License \\"GNU Lesser General Public License\\") with many available [unit generators](https://en.wikipedia.org/wiki/Unit_generator \\"Unit generator\\")\\n* [Elementary audio](https://elementary.audio), a JavaScript library for digital audio signal processing. Generate and transform sound, both natively and in the browser with a functional, declarative API.\\n* [Extempore](https://en.wikipedia.org/wiki/Extempore_(software) \\"Extempore (software)\\"), a live-coding environment that borrows a core foundation from the [Impromptu](https://en.wikipedia.org/wiki/Impromptu_(programming_environment) \\"Impromptu (programming environment)\\") environment\\n* [FAUST](https://en.wikipedia.org/wiki/FAUST_(programming_language) \\"FAUST (programming language)\\"), Functional Audio Stream, a functional compiled language for efficient real-time audio signal processing\\n* [GLICOL](https://glicol.org), a graph-oriented live coding language written in Rust\\n* [Hierarchical Music Specification Language](https://en.wikipedia.org/wiki/Hierarchical_Music_Specification_Language \\"Hierarchical Music Specification Language\\") (HMSL), optimized more for music than synthesis, developed in the 1980s in [Forth](https://en.wikipedia.org/wiki/Forth_(programming_language) \\"Forth (programming language)\\")\\n* [Impromptu](https://en.wikipedia.org/wiki/Impromptu_(programming_environment) \\"Impromptu (programming environment)\\"), a [Scheme](https://en.wikipedia.org/wiki/Scheme_(programming_language) \\"Scheme (programming language)\\") language environment for [Mac OS X](https://en.wikipedia.org/wiki/Mac_OS_X \\"Mac OS X\\") capable of sound and video synthesis, algorithmic composition, and 2D and 3D graphics programming\\n* [Ixi lang](https://en.wikipedia.org/wiki/Ixi_lang \\"Ixi lang\\"), a programming language for live coding musical expression.\\n* [JFugue](https://en.wikipedia.org/wiki/JFugue \\"JFugue\\"), a Java and JVM library for programming music that outputs to MIDI and has the ability to convert to formats including ABC Notation, Lilypond, and MusicXML\\n* [jMusic](https://en.wikipedia.org/wiki/JMusic \\"JMusic\\")\\n* [JSyn](https://en.wikipedia.org/wiki/JSyn \\"JSyn\\")\\n* [Keykit](https://en.wikipedia.org/wiki/Keykit \\"Keykit\\"), a programming language and portable graphical environment for MIDI music composition\\n* [Kyma (sound design language)](https://en.wikipedia.org/wiki/Kyma_(sound_design_language) \\"Kyma (sound design language)\\")\\n* [LilyPond](https://en.wikipedia.org/wiki/LilyPond \\"LilyPond\\"), a computer program and file format for music engraving.\\n* [Max/MSP](https://en.wikipedia.org/wiki/Max/MSP \\"Max/MSP\\"), a proprietary, modular visual programming language aimed at sound synthesis for music\\n* [Music Macro Language](https://en.wikipedia.org/wiki/Music_Macro_Language \\"Music Macro Language\\") (MML), often used to produce [chiptune](https://en.wikipedia.org/wiki/Chiptune \\"Chiptune\\") music in Japan\\n* [MUSIC-N](https://en.wikipedia.org/wiki/MUSIC-N \\"MUSIC-N\\"), includes versions I, II, III, IV, IV-B, IV-BF, V, 11, and 360\\n* [Nyquist](https://en.wikipedia.org/wiki/Nyquist_(programming_language) \\"Nyquist (programming language)\\")\\n* [OpenMusic](https://en.wikipedia.org/wiki/OpenMusic \\"OpenMusic\\")\\n* [Orca (music programming language)](https://100r.co/site/orca.html \\"Orca (music programming language)\\"), a two-dimensional esoteric programming language in which every letter of the alphabet is an operator, where lowercase letters operate on bang, uppercase letters operate each frame\\n* [Pure Data](https://en.wikipedia.org/wiki/Pure_Data \\"Pure Data\\"), a modular visual programming language for signal processing aimed at music creation\\n* [Tidal Cycles](https://tidalcycles.org/ \\"Tidal Cycles (page does not exist)\\"), a live coding environment for algorithmic patterns, written in Haskell and using Supercollider for synthesis\\n* [Reaktor](https://en.wikipedia.org/wiki/Reaktor \\"Reaktor\\")\\n* [Sonic Pi](https://en.wikipedia.org/wiki/Sonic_Pi \\"Sonic Pi\\")\\n* [Structured Audio Orchestra Language](https://en.wikipedia.org/wiki/Structured_Audio_Orchestra_Language \\"Structured Audio Orchestra Language\\") (SAOL), part of the [MPEG-4 Structured Audio](https://en.wikipedia.org/wiki/MPEG-4_Structured_Audio \\"MPEG-4 Structured Audio\\") standard\\n* [SuperCollider](https://en.wikipedia.org/wiki/SuperCollider \\"SuperCollider\\")\\n* [SynthEdit](https://en.wikipedia.org/wiki/SynthEdit \\"SynthEdit\\"), a modular visual programming language for signal processing aimed at creating [audio plug-ins](https://en.wikipedia.org/wiki/Audio_plug-in \\"Audio plug-in\\")\\n* [melo](https://github.com/dy/melo) - Micro language for floatbeats and audio, it has smooth operator and organic sugar. Compiles to compact 0-runtime WASM with linear memory. \\n* [topos](https://github.com/Bubobubobubobubo/topos?) - A Web-Based Algorithmic Sequencer. Topos is a web based live coding environment designed to be installation-free, independant and fun. ","frontmatter":{"title":"Audio Programming","description":"List of most notable audio programming languages","date":"2014-06-02T00:00:00.000Z"},"url":"/theory/synthesis/audio-programming/"}]`),Ny=n=>(mt("data-v-73fcc3ab"),n=n(),pt(),n),w3=["href"],_3={class:"info flex-1"},k3={class:"flex items-center w-full"},T3={key:0,class:"mr-2 text-2xl"},x3={class:"mt-1"},S3={class:"text-2xl"},A3={key:0,class:"text-xl px-2 mt-2"},C3=Ny(()=>v("div",{class:"i-radix-icons-text-align-left"},null,-1)),M3=[C3],I3=Ny(()=>v("div",{class:"flex-1"},null,-1)),E3={key:0,class:"text-md mt-4 mb-2 font-normal w-full"},D3={__name:"RowBlock",props:{item:Object,color:{type:String,default:"currentColor"}},setup(n){var a;const e=n;Ta(),Dy({path:(a=e.item)==null?void 0:a.url},ni);const t=H(()=>{var i,o;return`url(${(o=(i=e.item)==null?void 0:i.frontmatter)==null?void 0:o.cover})`});return(i,o)=>{var l,c,h,d,u,m,p,g,y,b,x,S,k,w,C,M,A,I;const s=v3,r=Py;return _(),T("div",{class:"row",style:se({borderColor:n.color})},[v("a",{class:ae(["header no-underline",{"pt-70":(c=(l=n.item)==null?void 0:l.frontmatter)==null?void 0:c.cover}]),href:f(Ce)(n.item.url)},[v("div",{class:"cover bg-center",style:se({backgroundImage:t.value})},null,4),v("div",_3,[v("div",k3,[(d=(h=n.item)==null?void 0:h.frontmatter)!=null&&d.emoji?(_(),T("div",T3,K((m=(u=n.item)==null?void 0:u.frontmatter)==null?void 0:m.emoji),1)):U("",!0),v("div",x3,[v("span",S3,K((g=(p=n.item)==null?void 0:p.frontmatter)==null?void 0:g.title),1),(b=(y=n.item)==null?void 0:y.frontmatter)!=null&&b.more?(_(),T("span",A3,M3)):U("",!0)]),I3,(S=(x=n.item)==null?void 0:x.frontmatter)!=null&&S.product?U("",!0):(_(),At(s,{key:1,date:n.item.lastModified},null,8,["date"]))]),(w=(k=n.item)==null?void 0:k.frontmatter)!=null&&w.description?(_(),T("div",E3,K((M=(C=n.item)==null?void 0:C.frontmatter)==null?void 0:M.description),1)):U("",!0),Q(r,{buttons:(I=(A=n.item)==null?void 0:A.frontmatter)==null?void 0:I.buttons,color:n.color},null,8,["buttons","color"])])],10,w3)],4)}}},P3=Fe(D3,[["__scopeId","data-v-73fcc3ab"]]),N3={key:0,class:"flex flex-wrap max-w-full mx-1 md-mx-2 gap-8 mt-12"},B3=["id","i","total"],j3={__name:"RowList",props:["children"],setup(n){return(e,t)=>{const a=P3;return n.children?(_(),T("div",N3,[(_(!0),T(ke,null,Me(n.children,(i,o)=>(_(),T("div",{class:"my-0 flex items-stretch",style:{flex:"1 1 300px"},key:i.url,id:f(Ce)(i.url),i:o,total:n.children.length},[Q(a,{item:i,color:f(vt)(o,n.children.length)},null,8,["item","color"])],8,B3))),128))])):U("",!0)}}},z3=n=>(mt("data-v-b19e6eb5"),n=n(),pt(),n),R3=["src"],O3={class:"mr-0"},q3=z3(()=>v("div",{class:"flex-1"},null,-1)),F3={key:0,class:"mx-2 my-0 text-6xl"},L3={key:1,class:"mt-0 mb-0"},G3={__name:"PageHeadline",props:["pageColor","lightColor","page","cover"],setup(n){const e=n,t=H(()=>{var i,o,s,r;if((i=e.page)!=null&&i.buttons)return(o=e.page)==null?void 0:o.buttons;const a=[];return(s=e.page)!=null&&s.url&&a.push({url:e.page.url,text:e.page.url,type:"primary"}),(r=e.page)!=null&&r.github&&a.push({url:e.page.github,text:e.page.github,type:"github"}),a});return(a,i)=>{var s,r,l,c,h,d,u,m,p,g;const o=Py;return a.$frontmatter.misc?U("",!0):(_(),T("div",{key:0,class:ae(["header",{"has-cover":((s=n.page)==null?void 0:s.cover)||((r=n.page)==null?void 0:r.icon)}]),style:se({backgroundColor:n.pageColor})},[n.cover?(_(),T("div",{key:0,class:"cover",style:se({backgroundImage:`url(${n.cover})`,backgroundColor:n.pageColor})},null,4)):U("",!0),(l=n.page)!=null&&l.icon?(_(),T("img",{key:1,class:"icon",src:(c=n.page)==null?void 0:c.icon},null,8,R3)):U("",!0),En(a.$slots,"default",{},void 0,!0),v("div",{class:"meta",style:se({borderColor:n.pageColor})},[(h=n.page)!=null&&h.title?(_(),T("div",{class:"text-2xl md-text-3xl font-bold flex flex-wrap items-center",key:n.page.url},[v("div",O3,K((d=n.page)==null?void 0:d.title),1),q3,(u=n.page)!=null&&u.emoji?(_(),T("div",F3,K((m=n.page)==null?void 0:m.emoji),1)):U("",!0)])):U("",!0),(p=n.page)!=null&&p.description?(_(),T("div",L3,K((g=n.page)==null?void 0:g.description),1)):U("",!0),Q(o,{buttons:t.value},null,8,["buttons"])],4)],6))}}},$3=Fe(G3,[["__scopeId","data-v-b19e6eb5"]]),V3={class:"w-full max-w-60ch flex flex-wrap items-stretch justify-start gap-2"},H3=["href"],W3={class:"font-normal"},U3={__name:"PageParents",props:["parents"],setup(n){return(e,t)=>(_(),T("div",V3,[(_(!0),T(ke,null,Me(n.parents,a=>{var i;return _(),T("a",{class:"text-xl transition rounded-lg no-underline flex items-center p-3 bg-light-300 bg-opacity-70 dark-bg-dark-100 dark-bg-opacity-70 hover-bg-light-100 hover-dark-bg-dark-100 opacity-60 hover-opacity-85",key:a.url,href:f(Ce)(a.url)},[v("span",W3,K((i=a==null?void 0:a.frontmatter)==null?void 0:i.title),1)],8,H3)}),128))]))}},K3="2.6.4",J3={class:"bg-dark-100 bg-op-30 dark-bg-dark-800 p-4 md-p-8 w-full flex items-end gap-4 dark-text-light-900"},Z3={class:"no-underline flex items-center gap-4",href:"/"},Y3=["src"],X3=v("div",{class:"flex flex-col"},[v("div",{class:"text-2xl font-bold"},"Chromatone "),v("div",{class:"text-lg"},"Visual Music Language ")],-1),Q3=v("div",{class:"flex-1"},null,-1),eN={class:"no-underline text-sm",href:"https://github.com/chromatone/chromatone.center/releases",target:"_blank"},tN=v("div",{class:"text-md"},"2017-Present",-1),nN={__name:"PageFooter",setup(n){const{isDark:e,theme:t}=Ka();return(a,i)=>(_(),T("div",J3,[v("a",Z3,[f(t).logo?(_(),T("img",{key:0,class:"w-16",src:f(t).logo,alt:"Chromatone logo",title:"Chromatone"},null,8,Y3)):U("",!0),X3]),Q3,v("a",eN,"v."+K(f(K3)),1),tN]))}},aN=["i","total"],iN=["href"],oN={class:"text-4xl",style:{flex:"0 1 30px"}},sN={key:0,class:"i-la-book"},rN={key:1,class:"i-la-hand-point-up"},lN={key:2,class:"i-la-chalkboard-teacher"},cN={key:3,class:"i-la-shopping-bag"},hN={key:4,class:"i-la-star"},dN={key:5,class:"i-la-at"},uN={key:6,class:"i-la-chalkboard-teacher"},mN={class:"p-0 flex flex-col gap-2 flex-1"},pN={class:"text-4xl"},fN={class:"font-normal"},gN={key:0,class:"flex flex-wrap py-2 gap-2 mt-2"},yN=["href"],bN=["i","total"],vN={__name:"HomeTile",props:{item:Object,i:Number,total:Number},setup(n){const e=n;Ta();const t=Dy({path:e.item.url},ni);return H(()=>vt(e.i,e.total)),(a,i)=>{var o,s,r,l,c,h,d,u,m,p,g,y,b,x,S,k,w,C,M;return _(),T("div",{class:"flex p-4 flex-col tile border-2",i:n.i,total:n.total,style:se({borderColor:f(vt)(n.i,n.total)})},[v("a",{class:"flex flex-col p-2 no-underline",href:f(Ce)(n.item.url)},[v("div",{class:"flex items-start gap-2 mb-4",style:se({color:f(vt)(n.i,n.total)})},[v("div",oN,[((s=(o=n.item)==null?void 0:o.frontmatter)==null?void 0:s.title)=="Theory"?(_(),T("div",sN)):U("",!0),((l=(r=n.item)==null?void 0:r.frontmatter)==null?void 0:l.title)=="Practice"?(_(),T("div",rN)):U("",!0),((h=(c=n.item)==null?void 0:c.frontmatter)==null?void 0:h.title)=="Academy"?(_(),T("div",lN)):U("",!0),((u=(d=n.item)==null?void 0:d.frontmatter)==null?void 0:u.title)=="Shop"?(_(),T("div",cN)):U("",!0),((p=(m=n.item)==null?void 0:m.frontmatter)==null?void 0:p.title)=="Support"?(_(),T("div",hN)):U("",!0),((y=(g=n.item)==null?void 0:g.frontmatter)==null?void 0:y.title)=="Contacts"?(_(),T("div",dN)):U("",!0),((x=(b=n.item)==null?void 0:b.frontmatter)==null?void 0:x.title)=="Tutorship"?(_(),T("div",uN)):U("",!0)]),v("div",mN,[v("div",pN,K((k=(S=n.item)==null?void 0:S.frontmatter)==null?void 0:k.title),1)])],4),v("div",fN,K((C=(w=n.item)==null?void 0:w.frontmatter)==null?void 0:C.description),1)],8,iN),((M=f(t))==null?void 0:M.length)>0?(_(),T("div",gN,[(_(!0),T(ke,null,Me(f(t),(A,I)=>{var D;return _(),T("a",{class:"cursor-pointer shadow-md rounded border-1 no-underline hover-shadow-lg dark-bg-dark-700 bg-light-100",style:se({borderColor:f(vt)(I,f(t).length)}),href:f(Ce)(A.url),key:A.url},[v("div",{class:"m-2",i:I,total:f(t).length},K((D=A==null?void 0:A.frontmatter)==null?void 0:D.title),9,bN)],12,yN)}),128))])):U("",!0)],12,aN)}}},wN=Fe(vN,[["__scopeId","data-v-2d35b3cb"]]),_N={key:0,class:"pwa-toast",role:"alertdialog","aria-labelledby":"pwa-message"},kN=v("div",{id:"pwa-message",class:"mb-3"}," App ready to work offline ",-1),TN={__name:"RegisterSW",setup(n){const e=ee(!1);function t(){e.value=!0}async function a(){e.value=!1}return db(async()=>{const{registerSW:i}=await Ua(async()=>{const{registerSW:o}=await import("./virtual_pwa-register.BehibTvg.js");return{registerSW:o}},__vite__mapDeps([0,1]));i({immediate:!0,onOfflineReady:t,onRegistered(){console.info("Service Worker registered")},onRegisterError(o){console.error("Service Worker registration error!",o)}})}),(i,o)=>e.value?(_(),T("div",_N,[kN,v("button",{type:"button",class:"pwa-cancel",onClick:a}," Close ")])):U("",!0)}};function Yn(n){return Array.isArray?Array.isArray(n):zy(n)==="[object Array]"}const xN=1/0;function SN(n){if(typeof n=="string")return n;let e=n+"";return e=="0"&&1/n==-xN?"-0":e}function AN(n){return n==null?"":SN(n)}function An(n){return typeof n=="string"}function By(n){return typeof n=="number"}function CN(n){return n===!0||n===!1||MN(n)&&zy(n)=="[object Boolean]"}function jy(n){return typeof n=="object"}function MN(n){return jy(n)&&n!==null}function qt(n){return n!=null}function hc(n){return!n.trim().length}function zy(n){return n==null?n===void 0?"[object Undefined]":"[object Null]":Object.prototype.toString.call(n)}const IN="Incorrect 'index' type",EN=n=>`Invalid value for key ${n}`,DN=n=>`Pattern length exceeds max of ${n}.`,PN=n=>`Missing ${n} property in key`,NN=n=>`Property 'weight' in key '${n}' must be a positive integer`,zm=Object.prototype.hasOwnProperty;class BN{constructor(e){this._keys=[],this._keyMap={};let t=0;e.forEach(a=>{let i=Ry(a);this._keys.push(i),this._keyMap[i.id]=i,t+=i.weight}),this._keys.forEach(a=>{a.weight/=t})}get(e){return this._keyMap[e]}keys(){return this._keys}toJSON(){return JSON.stringify(this._keys)}}function Ry(n){let e=null,t=null,a=null,i=1,o=null;if(An(n)||Yn(n))a=n,e=Rm(n),t=Hc(n);else{if(!zm.call(n,"name"))throw new Error(PN("name"));const s=n.name;if(a=s,zm.call(n,"weight")&&(i=n.weight,i<=0))throw new Error(NN(s));e=Rm(s),t=Hc(s),o=n.getFn}return{path:e,id:t,weight:i,src:a,getFn:o}}function Rm(n){return Yn(n)?n:n.split(".")}function Hc(n){return Yn(n)?n.join("."):n}function jN(n,e){let t=[],a=!1;const i=(o,s,r)=>{if(qt(o))if(!s[r])t.push(o);else{let l=s[r];const c=o[l];if(!qt(c))return;if(r===s.length-1&&(An(c)||By(c)||CN(c)))t.push(AN(c));else if(Yn(c)){a=!0;for(let h=0,d=c.length;h<d;h+=1)i(c[h],s,r+1)}else s.length&&i(c,s,r+1)}};return i(n,An(e)?e.split("."):e,0),a?t:t[0]}const zN={includeMatches:!1,findAllMatches:!1,minMatchCharLength:1},RN={isCaseSensitive:!1,includeScore:!1,keys:[],shouldSort:!0,sortFn:(n,e)=>n.score===e.score?n.idx<e.idx?-1:1:n.score<e.score?-1:1},ON={location:0,threshold:.6,distance:100},qN={useExtendedSearch:!1,getFn:jN,ignoreLocation:!1,ignoreFieldNorm:!1,fieldNormWeight:1};var he={...RN,...zN,...ON,...qN};const FN=/[^ ]+/g;function LN(n=1,e=3){const t=new Map,a=Math.pow(10,e);return{get(i){const o=i.match(FN).length;if(t.has(o))return t.get(o);const s=1/Math.pow(o,.5*n),r=parseFloat(Math.round(s*a)/a);return t.set(o,r),r},clear(){t.clear()}}}class zd{constructor({getFn:e=he.getFn,fieldNormWeight:t=he.fieldNormWeight}={}){this.norm=LN(t,3),this.getFn=e,this.isCreated=!1,this.setIndexRecords()}setSources(e=[]){this.docs=e}setIndexRecords(e=[]){this.records=e}setKeys(e=[]){this.keys=e,this._keysMap={},e.forEach((t,a)=>{this._keysMap[t.id]=a})}create(){this.isCreated||!this.docs.length||(this.isCreated=!0,An(this.docs[0])?this.docs.forEach((e,t)=>{this._addString(e,t)}):this.docs.forEach((e,t)=>{this._addObject(e,t)}),this.norm.clear())}add(e){const t=this.size();An(e)?this._addString(e,t):this._addObject(e,t)}removeAt(e){this.records.splice(e,1);for(let t=e,a=this.size();t<a;t+=1)this.records[t].i-=1}getValueForItemAtKeyId(e,t){return e[this._keysMap[t]]}size(){return this.records.length}_addString(e,t){if(!qt(e)||hc(e))return;let a={v:e,i:t,n:this.norm.get(e)};this.records.push(a)}_addObject(e,t){let a={i:t,$:{}};this.keys.forEach((i,o)=>{let s=i.getFn?i.getFn(e):this.getFn(e,i.path);if(qt(s)){if(Yn(s)){let r=[];const l=[{nestedArrIndex:-1,value:s}];for(;l.length;){const{nestedArrIndex:c,value:h}=l.pop();if(qt(h))if(An(h)&&!hc(h)){let d={v:h,i:c,n:this.norm.get(h)};r.push(d)}else Yn(h)&&h.forEach((d,u)=>{l.push({nestedArrIndex:u,value:d})})}a.$[o]=r}else if(An(s)&&!hc(s)){let r={v:s,n:this.norm.get(s)};a.$[o]=r}}}),this.records.push(a)}toJSON(){return{keys:this.keys,records:this.records}}}function Oy(n,e,{getFn:t=he.getFn,fieldNormWeight:a=he.fieldNormWeight}={}){const i=new zd({getFn:t,fieldNormWeight:a});return i.setKeys(n.map(Ry)),i.setSources(e),i.create(),i}function GN(n,{getFn:e=he.getFn,fieldNormWeight:t=he.fieldNormWeight}={}){const{keys:a,records:i}=n,o=new zd({getFn:e,fieldNormWeight:t});return o.setKeys(a),o.setIndexRecords(i),o}function Us(n,{errors:e=0,currentLocation:t=0,expectedLocation:a=0,distance:i=he.distance,ignoreLocation:o=he.ignoreLocation}={}){const s=e/n.length;if(o)return s;const r=Math.abs(a-t);return i?s+r/i:r?1:s}function $N(n=[],e=he.minMatchCharLength){let t=[],a=-1,i=-1,o=0;for(let s=n.length;o<s;o+=1){let r=n[o];r&&a===-1?a=o:!r&&a!==-1&&(i=o-1,i-a+1>=e&&t.push([a,i]),a=-1)}return n[o-1]&&o-a>=e&&t.push([a,o-1]),t}const za=32;function VN(n,e,t,{location:a=he.location,distance:i=he.distance,threshold:o=he.threshold,findAllMatches:s=he.findAllMatches,minMatchCharLength:r=he.minMatchCharLength,includeMatches:l=he.includeMatches,ignoreLocation:c=he.ignoreLocation}={}){if(e.length>za)throw new Error(DN(za));const h=e.length,d=n.length,u=Math.max(0,Math.min(a,d));let m=o,p=u;const g=r>1||l,y=g?Array(d):[];let b;for(;(b=n.indexOf(e,p))>-1;){let M=Us(e,{currentLocation:b,expectedLocation:u,distance:i,ignoreLocation:c});if(m=Math.min(M,m),p=b+h,g){let A=0;for(;A<h;)y[b+A]=1,A+=1}}p=-1;let x=[],S=1,k=h+d;const w=1<<h-1;for(let M=0;M<h;M+=1){let A=0,I=k;for(;A<I;)Us(e,{errors:M,currentLocation:u+I,expectedLocation:u,distance:i,ignoreLocation:c})<=m?A=I:k=I,I=Math.floor((k-A)/2+A);k=I;let D=Math.max(1,u-I+1),P=s?d:Math.min(u+I,d)+h,E=Array(P+2);E[P+1]=(1<<M)-1;for(let j=P;j>=D;j-=1){let W=j-1,L=t[n.charAt(W)];if(g&&(y[W]=+!!L),E[j]=(E[j+1]<<1|1)&L,M&&(E[j]|=(x[j+1]|x[j])<<1|1|x[j+1]),E[j]&w&&(S=Us(e,{errors:M,currentLocation:W,expectedLocation:u,distance:i,ignoreLocation:c}),S<=m)){if(m=S,p=W,p<=u)break;D=Math.max(1,2*u-p)}}if(Us(e,{errors:M+1,currentLocation:u,expectedLocation:u,distance:i,ignoreLocation:c})>m)break;x=E}const C={isMatch:p>=0,score:Math.max(.001,S)};if(g){const M=$N(y,r);M.length?l&&(C.indices=M):C.isMatch=!1}return C}function HN(n){let e={};for(let t=0,a=n.length;t<a;t+=1){const i=n.charAt(t);e[i]=(e[i]||0)|1<<a-t-1}return e}class qy{constructor(e,{location:t=he.location,threshold:a=he.threshold,distance:i=he.distance,includeMatches:o=he.includeMatches,findAllMatches:s=he.findAllMatches,minMatchCharLength:r=he.minMatchCharLength,isCaseSensitive:l=he.isCaseSensitive,ignoreLocation:c=he.ignoreLocation}={}){if(this.options={location:t,threshold:a,distance:i,includeMatches:o,findAllMatches:s,minMatchCharLength:r,isCaseSensitive:l,ignoreLocation:c},this.pattern=l?e:e.toLowerCase(),this.chunks=[],!this.pattern.length)return;const h=(u,m)=>{this.chunks.push({pattern:u,alphabet:HN(u),startIndex:m})},d=this.pattern.length;if(d>za){let u=0;const m=d%za,p=d-m;for(;u<p;)h(this.pattern.substr(u,za),u),u+=za;if(m){const g=d-za;h(this.pattern.substr(g),g)}}else h(this.pattern,0)}searchIn(e){const{isCaseSensitive:t,includeMatches:a}=this.options;if(t||(e=e.toLowerCase()),this.pattern===e){let p={isMatch:!0,score:0};return a&&(p.indices=[[0,e.length-1]]),p}const{location:i,distance:o,threshold:s,findAllMatches:r,minMatchCharLength:l,ignoreLocation:c}=this.options;let h=[],d=0,u=!1;this.chunks.forEach(({pattern:p,alphabet:g,startIndex:y})=>{const{isMatch:b,score:x,indices:S}=VN(e,p,g,{location:i+y,distance:o,threshold:s,findAllMatches:r,minMatchCharLength:l,includeMatches:a,ignoreLocation:c});b&&(u=!0),d+=x,b&&S&&(h=[...h,...S])});let m={isMatch:u,score:u?d/this.chunks.length:1};return u&&a&&(m.indices=h),m}}class Da{constructor(e){this.pattern=e}static isMultiMatch(e){return Om(e,this.multiRegex)}static isSingleMatch(e){return Om(e,this.singleRegex)}search(){}}function Om(n,e){const t=n.match(e);return t?t[1]:null}class WN extends Da{constructor(e){super(e)}static get type(){return"exact"}static get multiRegex(){return/^="(.*)"$/}static get singleRegex(){return/^=(.*)$/}search(e){const t=e===this.pattern;return{isMatch:t,score:t?0:1,indices:[0,this.pattern.length-1]}}}class UN extends Da{constructor(e){super(e)}static get type(){return"inverse-exact"}static get multiRegex(){return/^!"(.*)"$/}static get singleRegex(){return/^!(.*)$/}search(e){const a=e.indexOf(this.pattern)===-1;return{isMatch:a,score:a?0:1,indices:[0,e.length-1]}}}class KN extends Da{constructor(e){super(e)}static get type(){return"prefix-exact"}static get multiRegex(){return/^\^"(.*)"$/}static get singleRegex(){return/^\^(.*)$/}search(e){const t=e.startsWith(this.pattern);return{isMatch:t,score:t?0:1,indices:[0,this.pattern.length-1]}}}class JN extends Da{constructor(e){super(e)}static get type(){return"inverse-prefix-exact"}static get multiRegex(){return/^!\^"(.*)"$/}static get singleRegex(){return/^!\^(.*)$/}search(e){const t=!e.startsWith(this.pattern);return{isMatch:t,score:t?0:1,indices:[0,e.length-1]}}}class ZN extends Da{constructor(e){super(e)}static get type(){return"suffix-exact"}static get multiRegex(){return/^"(.*)"\$$/}static get singleRegex(){return/^(.*)\$$/}search(e){const t=e.endsWith(this.pattern);return{isMatch:t,score:t?0:1,indices:[e.length-this.pattern.length,e.length-1]}}}class YN extends Da{constructor(e){super(e)}static get type(){return"inverse-suffix-exact"}static get multiRegex(){return/^!"(.*)"\$$/}static get singleRegex(){return/^!(.*)\$$/}search(e){const t=!e.endsWith(this.pattern);return{isMatch:t,score:t?0:1,indices:[0,e.length-1]}}}class Fy extends Da{constructor(e,{location:t=he.location,threshold:a=he.threshold,distance:i=he.distance,includeMatches:o=he.includeMatches,findAllMatches:s=he.findAllMatches,minMatchCharLength:r=he.minMatchCharLength,isCaseSensitive:l=he.isCaseSensitive,ignoreLocation:c=he.ignoreLocation}={}){super(e),this._bitapSearch=new qy(e,{location:t,threshold:a,distance:i,includeMatches:o,findAllMatches:s,minMatchCharLength:r,isCaseSensitive:l,ignoreLocation:c})}static get type(){return"fuzzy"}static get multiRegex(){return/^"(.*)"$/}static get singleRegex(){return/^(.*)$/}search(e){return this._bitapSearch.searchIn(e)}}class Ly extends Da{constructor(e){super(e)}static get type(){return"include"}static get multiRegex(){return/^'"(.*)"$/}static get singleRegex(){return/^'(.*)$/}search(e){let t=0,a;const i=[],o=this.pattern.length;for(;(a=e.indexOf(this.pattern,t))>-1;)t=a+o,i.push([a,t-1]);const s=!!i.length;return{isMatch:s,score:s?0:1,indices:i}}}const Wc=[WN,Ly,KN,JN,YN,ZN,UN,Fy],qm=Wc.length,XN=/ +(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)/,QN="|";function e4(n,e={}){return n.split(QN).map(t=>{let a=t.trim().split(XN).filter(o=>o&&!!o.trim()),i=[];for(let o=0,s=a.length;o<s;o+=1){const r=a[o];let l=!1,c=-1;for(;!l&&++c<qm;){const h=Wc[c];let d=h.isMultiMatch(r);d&&(i.push(new h(d,e)),l=!0)}if(!l)for(c=-1;++c<qm;){const h=Wc[c];let d=h.isSingleMatch(r);if(d){i.push(new h(d,e));break}}}return i})}const t4=new Set([Fy.type,Ly.type]);class n4{constructor(e,{isCaseSensitive:t=he.isCaseSensitive,includeMatches:a=he.includeMatches,minMatchCharLength:i=he.minMatchCharLength,ignoreLocation:o=he.ignoreLocation,findAllMatches:s=he.findAllMatches,location:r=he.location,threshold:l=he.threshold,distance:c=he.distance}={}){this.query=null,this.options={isCaseSensitive:t,includeMatches:a,minMatchCharLength:i,findAllMatches:s,ignoreLocation:o,location:r,threshold:l,distance:c},this.pattern=t?e:e.toLowerCase(),this.query=e4(this.pattern,this.options)}static condition(e,t){return t.useExtendedSearch}searchIn(e){const t=this.query;if(!t)return{isMatch:!1,score:1};const{includeMatches:a,isCaseSensitive:i}=this.options;e=i?e:e.toLowerCase();let o=0,s=[],r=0;for(let l=0,c=t.length;l<c;l+=1){const h=t[l];s.length=0,o=0;for(let d=0,u=h.length;d<u;d+=1){const m=h[d],{isMatch:p,indices:g,score:y}=m.search(e);if(p){if(o+=1,r+=y,a){const b=m.constructor.type;t4.has(b)?s=[...s,...g]:s.push(g)}}else{r=0,o=0,s.length=0;break}}if(o){let d={isMatch:!0,score:r/o};return a&&(d.indices=s),d}}return{isMatch:!1,score:1}}}const Uc=[];function a4(...n){Uc.push(...n)}function Kc(n,e){for(let t=0,a=Uc.length;t<a;t+=1){let i=Uc[t];if(i.condition(n,e))return new i(n,e)}return new qy(n,e)}const Or={AND:"$and",OR:"$or"},Jc={PATH:"$path",PATTERN:"$val"},Zc=n=>!!(n[Or.AND]||n[Or.OR]),i4=n=>!!n[Jc.PATH],o4=n=>!Yn(n)&&jy(n)&&!Zc(n),Fm=n=>({[Or.AND]:Object.keys(n).map(e=>({[e]:n[e]}))});function Gy(n,e,{auto:t=!0}={}){const a=i=>{let o=Object.keys(i);const s=i4(i);if(!s&&o.length>1&&!Zc(i))return a(Fm(i));if(o4(i)){const l=s?i[Jc.PATH]:o[0],c=s?i[Jc.PATTERN]:i[l];if(!An(c))throw new Error(EN(l));const h={keyId:Hc(l),pattern:c};return t&&(h.searcher=Kc(c,e)),h}let r={children:[],operator:o[0]};return o.forEach(l=>{const c=i[l];Yn(c)&&c.forEach(h=>{r.children.push(a(h))})}),r};return Zc(n)||(n=Fm(n)),a(n)}function s4(n,{ignoreFieldNorm:e=he.ignoreFieldNorm}){n.forEach(t=>{let a=1;t.matches.forEach(({key:i,norm:o,score:s})=>{const r=i?i.weight:null;a*=Math.pow(s===0&&r?Number.EPSILON:s,(r||1)*(e?1:o))}),t.score=a})}function r4(n,e){const t=n.matches;e.matches=[],qt(t)&&t.forEach(a=>{if(!qt(a.indices)||!a.indices.length)return;const{indices:i,value:o}=a;let s={indices:i,value:o};a.key&&(s.key=a.key.src),a.idx>-1&&(s.refIndex=a.idx),e.matches.push(s)})}function l4(n,e){e.score=n.score}function c4(n,e,{includeMatches:t=he.includeMatches,includeScore:a=he.includeScore}={}){const i=[];return t&&i.push(r4),a&&i.push(l4),n.map(o=>{const{idx:s}=o,r={item:e[s],refIndex:s};return i.length&&i.forEach(l=>{l(o,r)}),r})}class ro{constructor(e,t={},a){this.options={...he,...t},this.options.useExtendedSearch,this._keyStore=new BN(this.options.keys),this.setCollection(e,a)}setCollection(e,t){if(this._docs=e,t&&!(t instanceof zd))throw new Error(IN);this._myIndex=t||Oy(this.options.keys,this._docs,{getFn:this.options.getFn,fieldNormWeight:this.options.fieldNormWeight})}add(e){qt(e)&&(this._docs.push(e),this._myIndex.add(e))}remove(e=()=>!1){const t=[];for(let a=0,i=this._docs.length;a<i;a+=1){const o=this._docs[a];e(o,a)&&(this.removeAt(a),a-=1,i-=1,t.push(o))}return t}removeAt(e){this._docs.splice(e,1),this._myIndex.removeAt(e)}getIndex(){return this._myIndex}search(e,{limit:t=-1}={}){const{includeMatches:a,includeScore:i,shouldSort:o,sortFn:s,ignoreFieldNorm:r}=this.options;let l=An(e)?An(this._docs[0])?this._searchStringList(e):this._searchObjectList(e):this._searchLogical(e);return s4(l,{ignoreFieldNorm:r}),o&&l.sort(s),By(t)&&t>-1&&(l=l.slice(0,t)),c4(l,this._docs,{includeMatches:a,includeScore:i})}_searchStringList(e){const t=Kc(e,this.options),{records:a}=this._myIndex,i=[];return a.forEach(({v:o,i:s,n:r})=>{if(!qt(o))return;const{isMatch:l,score:c,indices:h}=t.searchIn(o);l&&i.push({item:o,idx:s,matches:[{score:c,value:o,norm:r,indices:h}]})}),i}_searchLogical(e){const t=Gy(e,this.options),a=(r,l,c)=>{if(!r.children){const{keyId:d,searcher:u}=r,m=this._findMatches({key:this._keyStore.get(d),value:this._myIndex.getValueForItemAtKeyId(l,d),searcher:u});return m&&m.length?[{idx:c,item:l,matches:m}]:[]}const h=[];for(let d=0,u=r.children.length;d<u;d+=1){const m=r.children[d],p=a(m,l,c);if(p.length)h.push(...p);else if(r.operator===Or.AND)return[]}return h},i=this._myIndex.records,o={},s=[];return i.forEach(({$:r,i:l})=>{if(qt(r)){let c=a(t,r,l);c.length&&(o[l]||(o[l]={idx:l,item:r,matches:[]},s.push(o[l])),c.forEach(({matches:h})=>{o[l].matches.push(...h)}))}}),s}_searchObjectList(e){const t=Kc(e,this.options),{keys:a,records:i}=this._myIndex,o=[];return i.forEach(({$:s,i:r})=>{if(!qt(s))return;let l=[];a.forEach((c,h)=>{l.push(...this._findMatches({key:c,value:s[h],searcher:t}))}),l.length&&o.push({idx:r,item:s,matches:l})}),o}_findMatches({key:e,value:t,searcher:a}){if(!qt(t))return[];let i=[];if(Yn(t))t.forEach(({v:o,i:s,n:r})=>{if(!qt(o))return;const{isMatch:l,score:c,indices:h}=a.searchIn(o);l&&i.push({score:c,key:e,value:o,idx:s,norm:r,indices:h})});else{const{v:o,n:s}=t,{isMatch:r,score:l,indices:c}=a.searchIn(o);r&&i.push({score:l,key:e,value:o,norm:s,indices:c})}return i}}ro.version="7.0.0";ro.createIndex=Oy;ro.parseIndex=GN;ro.config=he;ro.parseQuery=Gy;a4(n4);const h4={class:"flex flex-col w-full gap-2"},d4={class:"flex items-center gap-2 relative"},u4=v("div",{class:"i-la-search text-xl absolute z-400 left-2"},null,-1),m4=v("div",{class:"i-la-times text-lg"},null,-1),p4=[m4],f4={class:"flex flex-col w-full gap-2 max-h-80dvh overflow-y-scroll"},g4=["onKeyup","href"],y4={class:"font-bold"},b4={class:"text-sm font-normal"},v4={key:0,class:"text-sm inline-flex"},w4={class:"font-bold whitespace-nowrap"},_4={class:"ml-2"},$y={__name:"NavSearch",props:{focus:{type:Boolean}},emits:["close"],setup(n,{emit:e}){const t=ub(),a=new ro(ni,{includeScore:!0,ignoreLocation:!0,keys:["frontmatter.title","frontmatter.description","frontmatter.city","frontmatter.place"]}),i=n,o=ee(""),s=H(()=>a.search(o.value)),r=ee(),{focused:l}=mb(r);return de(()=>i.focus,c=>{c&&setTimeout(()=>{l.value=!0},200)},{immediate:!0}),Um(r,()=>o.value=""),Ro("Escape",()=>{o.value="",l.value=!1}),(c,h)=>(_(),T("div",h4,[v("div",d4,[u4,F(v("input",{class:"w-full p-2 rounded-lg z-20 bg-light-100 dark-bg-dark-100 shadow pl-10",ref_key:"inputEl",ref:r,id:"search","onUpdate:modelValue":h[0]||(h[0]=d=>o.value=d),placeholder:"Search"},null,512),[[ar,o.value]]),o.value?(_(),T("button",{key:0,class:"z-400 absolute right-2",onClick:h[1]||(h[1]=d=>{o.value="",c.$emit("close")})},p4)):U("",!0)]),v("div",f4,[(_(!0),T(ke,null,Me(s.value.filter(d=>d.score<.3),d=>{var u,m,p,g,y,b,x,S,k,w,C,M;return _(),T("a",{class:"px-3 py-3 bg-light-600 rounded shadow dark-bg-dark-300 hover-bg-light-100 dark-hover-bg-dark-600 border-1 dark-border-dark-50 border-opacity-20 no-underline",tabindex:"0",onKeyup:Vm(A=>f(t).go(f(Ce)(d.item.url)),["enter"]),href:f(Ce)(d.item.url),onClick:h[2]||(h[2]=A=>{o.value="",c.$emit("close")}),key:d,style:se({opacity:1-d.score/2})},[v("div",y4,K((m=(u=d.item)==null?void 0:u.frontmatter)==null?void 0:m.title),1),v("div",b4,K((g=(p=d.item)==null?void 0:p.frontmatter)==null?void 0:g.description),1),(b=(y=d.item)==null?void 0:y.frontmatter)!=null&&b.city||(S=(x=d.item)==null?void 0:x.frontmatter)!=null&&S.place?(_(),T("div",v4,[v("div",w4,K((w=(k=d.item)==null?void 0:k.frontmatter)==null?void 0:w.city),1),v("div",_4,K((M=(C=d.item)==null?void 0:C.frontmatter)==null?void 0:M.place),1)])):U("",!0)],44,g4)}),128))])]))}},k4=n=>(mt("data-v-9a2dc1ef"),n=n(),pt(),n),T4=["aria-current"],x4=["href","id"],S4=k4(()=>v("div",{class:"flex-1"},null,-1)),A4={key:0,class:"px-1 flex items-center"},C4={class:"flex flex-col"},M4={__name:"SideBarLevel",props:{path:{type:String,default:""},level:{type:Number,default:0}},setup(n){const e=Ta(),t=n,{pages:a,children:i}=Pd({path:t.path},ni);return(o,s)=>{const r=Jn("SideBarLevel",!0);return _(),At(Oo,{name:"fade"},{default:Ge(()=>[F(v("div",{class:"flex flex-col",style:se({gap:n.level==0?"1em":"0"})},[(_(!0),T(ke,null,Me(f(i),(l,c)=>{var h,d,u,m,p;return _(),T("div",{class:"level",key:l.url,"aria-current":f(e).path.includes(f(Ce)(l.url))?"page":!1,style:se({borderColor:f(vt)(c,f(i).length)})},[v("a",{href:f(Ce)(l.url),id:(h=l==null?void 0:l.frontmatter)==null?void 0:h.title,style:se({color:n.level==0?f(vt)(c,f(i).length):"currentColor"})},[v("div",{class:ae(["flex-auto",{"text-xl font-bold":n.level==0}])},K((d=l==null?void 0:l.frontmatter)==null?void 0:d.title),3),S4,(u=f(a))!=null&&u[f(Ce)(l.url)]?(_(),T("div",A4,K((p=(m=f(a))==null?void 0:m[f(Ce)(l.url)])==null?void 0:p.length),1)):U("",!0)],12,x4),F(v("div",C4,[Q(r,{path:l.url,level:n.level+1},null,8,["path","level"])],512),[[bt,f(e).path.includes(f(Ce)(l.url))]])],12,T4)}),128))],4),[[bt,f(i)&&f(i).length>0]])]),_:1})}}},Vy=Fe(M4,[["__scopeId","data-v-9a2dc1ef"]]),Rd=n=>(mt("data-v-7c099f07"),n=n(),pt(),n),I4={class:"mt-17px ml-52px text-xl mb-4"},E4=["aria-label"],D4=Rd(()=>v("div",{class:"flex-1"},null,-1)),P4={key:0,class:"opacity-20 p-4 mt-1 hover-opacity-80 flex items-center gap-2",href:"/"},N4=Rd(()=>v("div",{class:"i-la-home"},null,-1)),B4=Rd(()=>v("div",{class:"p-0"},"Back to main",-1)),j4=[N4,B4],z4={__name:"SideBar",props:{open:{type:Boolean,required:!0}},emits:["close"],setup(n){const{site:e}=Ka(),t=Ta(),a=ee(!1);return(i,o)=>{const s=$y;return _(),T(ke,null,[Q(Oo,{name:"fade"},{default:Ge(()=>[F(v("div",{class:"sidebar-mask z-499 overscroll-contain",onClick:o[0]||(o[0]=r=>i.$emit("close"))},null,512),[[bt,n.open]])]),_:1}),v("div",{class:ae(["panel",{open:n.open}])},[v("div",I4,[v("a",{class:"no-underline",href:"/","aria-label":`${f(e).title}, go to main page`},K(f(e).title),9,E4)]),Q(s,{onClose:o[1]||(o[1]=r=>a.value=!1),focus:a.value},null,8,["focus"]),Q(Vy,{path:"/",level:0}),D4,f(t).path!="/"?(_(),T("a",P4,j4)):U("",!0)],2)],64)}}},R4=Fe(z4,[["__scopeId","data-v-7c099f07"]]),O4={class:"fixed z-1800 bottom-0 flex left-0 right-0 pointer-events-none px-4 pb-1"},q4={__name:"MidiNotes",setup(n){const{midi:e}=cd();return(t,a)=>(_(),T("div",O4,[(_(!0),T(ke,null,Me(f(e).activeChromaMidi,(i,o)=>(_(),T("div",{class:"flex-1 rounded-lg h-2 transition-all duration-100ms ease-out opacity-100",key:o,style:se({backgroundColor:i?f(Ve)(i-9-24):"#eee2"})},null,4))),128))]))}},F4=n=>(mt("data-v-f364d960"),n=n(),pt(),n),L4={class:"flex flex-col"},G4=["aria-current"],$4=["href","id"],V4=F4(()=>v("div",{class:"flex-1 min-w-10"},null,-1)),H4={key:0,class:"px-1 flex items-center"},W4={class:"flex flex-col"},U4={__name:"BarLevel",props:{path:{type:String,default:""},level:{type:Number,default:0}},setup(n){const e=Ta(),t=n,{pages:a,children:i}=Pd({path:t.path},ni);return(o,s)=>{const r=Vy;return _(),At(Oo,{name:"fade"},{default:Ge(()=>[F(v("div",L4,[(_(!0),T(ke,null,Me(f(i),(l,c)=>{var h,d,u,m,p;return _(),T("div",{class:"level",key:l.url,"aria-current":f(e).path.includes(f(Ce)(l.url))?"page":!1,style:se({borderColor:f(vt)(c,f(i).length)})},[v("a",{href:f(Ce)(l.url),id:(h=l==null?void 0:l.frontmatter)==null?void 0:h.title,style:se({color:n.level==0?f(vt)(c,f(i).length):"currentColor"})},[v("div",{class:ae(["flex-auto",{"text-lg font-bold":n.level==0}])},K((d=l==null?void 0:l.frontmatter)==null?void 0:d.title),3),V4,(u=f(a))!=null&&u[f(Ce)(l.url)]?(_(),T("div",H4,K((p=(m=f(a))==null?void 0:m[f(Ce)(l.url)])==null?void 0:p.length),1)):U("",!0)],12,$4),F(v("div",W4,[Q(r,{path:l.url,level:n.level+1},null,8,["path","level"])],512),[[bt,f(e).path.includes(f(Ce)(l.url))]])],12,G4)}),128))],512),[[bt,f(i)&&f(i).length>0]])]),_:1})}}},K4=Fe(U4,[["__scopeId","data-v-f364d960"]]),J4={class:"flex flex-wrap gap-2 text-sm"},Z4=["value"],Y4=["value"],X4=["value"],Q4={__name:"CastDevices",setup(n){const e=H(()=>[{value:"none",display:"None"},...Ic.value.map(i=>({value:i.deviceId,display:i.label}))]),t=H(()=>[{value:"none",display:"None"},...Ec.value.map(i=>({value:i.deviceId,display:i.label}))]),a=e2().map(i=>({value:i,display:dd[i].toUpperCase()}));return Dc(),(i,o)=>(_(),T("div",J4,[F(v("select",{"onUpdate:modelValue":o[0]||(o[0]=s=>So(Wt)?Wt.value=s:null),title:"Camera"},[(_(!0),T(ke,null,Me(e.value,s=>(_(),T("option",{key:s,value:s.value},K(s.display||s.value.substring(0,10)),9,Z4))),128))],512),[[xo,f(Wt)]]),F(v("select",{"onUpdate:modelValue":o[1]||(o[1]=s=>So(Kn)?Kn.value=s:null),title:"Microphone"},[(_(!0),T(ke,null,Me(t.value,s=>(_(),T("option",{key:s,value:s.value},K(s.display||s.value.substring(0,10)),9,Y4))),128))],512),[[xo,f(Kn)]]),f(a).length?F((_(),T("select",{key:0,"onUpdate:modelValue":o[2]||(o[2]=s=>So(Ha)?Ha.value=s:null),title:"mimeType"},[(_(!0),T(ke,null,Me(f(a),s=>(_(),T("option",{key:s,value:s.value},K(s.display),9,X4))),128))],512)),[[xo,f(Ha)]]):U("",!0)]))}},eB=Fe(Q4,[["__scopeId","data-v-a40e3db1"]]),tB={class:"flex flex-col gap-2 w-full"},nB={class:"flex flex-wrap gap-2"},aB={class:"is-group flex flex-wrap"},iB=v("div",{class:"i-mdi-checkbox-blank-circle-outline"},null,-1),oB=v("div",{class:"m-0"},"Record audio",-1),sB=[iB,oB],rB=v("div",{class:"i-mdi-checkbox-blank-circle animate-pulse"},null,-1),lB={class:"p-1"},cB={key:0,class:"i-carbon-stop-outline"},hB={key:1,class:"i-carbon-video"},dB={class:"m-0"},uB={key:2,class:"p-1"},mB={class:"is-group flex flex-wrap"},pB=v("div",{class:"i-carbon-user-avatar"},null,-1),fB=v("div",{class:"ml-0"},"Camera avatar",-1),gB=[pB,fB],yB=v("div",{class:"i-la-cog"},null,-1),bB=v("div",{class:"ml-0"},"Settings",-1),vB=[yB,bB],wB={key:0,class:"flex gap-2"},_B={class:"flex flex-col gap-2 py-2",style:{flex:"1 1 100px"}},kB={class:"form-check"},TB={class:"form-text"},xB={class:"text-xs w-full opacity-50"},SB=v("div",{class:"mt-2 opacity-50"},"Resulting filenames",-1),AB={class:"font-mono"},CB={key:0,class:"font-mono"},MB={__name:"CastPanel",setup(n){const{streamCamera:e,showAvatar:t,recordingTime:a,currentCamera:i,toggleAvatar:o,toggleRecording:s,recording:r,startRecording:l}=ng,c=ee(),{record:h,recording:d,toggled:u,duration:m}=Al(),{width:p,height:g}=pb();return(y,b)=>{const x=eB,S=pn("tooltip");return _(),T("div",tB,[v("div",nB,[v("div",aB,[f(d)?(_(),T("button",{key:1,class:"flex-button text-red-500",onClick:b[1]||(b[1]=k=>f(h).stop())},[rB,v("div",lB,K((f(m)/1e3).toFixed())+" s",1)])):F((_(),T("button",{key:0,class:"flex-button",onClick:b[0]||(b[0]=k=>f(h).start())},sB)),[[S,"Start audio recording",void 0,{top:!0}]]),F((_(),T("button",{class:ae(["flex-button",{"text-red-500":f(r)}]),title:"Recording",onClick:b[2]||(b[2]=(...k)=>f(s)&&f(s)(...k))},[f(r)?(_(),T("div",cB)):(_(),T("div",hB)),v("div",dB,"Record screen "+K(f(p))+"x"+K(f(g)),1),f(a)?(_(),T("div",uB,K((f(a)/1e3).toFixed())+"s",1)):U("",!0)],2)),[[S,"Start screen recording",void 0,{top:!0}]])]),v("div",mB,[f(i)!=="none"?F((_(),T("button",{key:0,class:ae(["flex-button",{"text-green-500":!!(f(t)&&f(e))}]),title:"Show camera view",onClick:b[3]||(b[3]=(...k)=>f(o)&&f(o)(...k))},gB,2)),[[S,"Enable circular camera avatar",void 0,{top:!0}]]):U("",!0),F((_(),T("button",{class:"flex-button",onClick:b[4]||(b[4]=k=>c.value=!c.value),"aria-label":"Screencast options"},vB)),[[S,"Open screencast options",void 0,{top:!0}]])])]),c.value?(_(),T("div",wB,[v("div",_B,[v("div",kB,[F(v("input",{class:"mr-2","onUpdate:modelValue":b[5]||(b[5]=k=>So(ha)?ha.value=k:null),name:"record-camera",type:"checkbox"},null,512),[[fb,f(ha)]]),v("label",{for:"record-camera",onClick:b[6]||(b[6]=k=>ha.value=!f(ha))},"Record camera separately")]),v("div",TB,[F(v("input",{class:"bg-transparent text-current","onUpdate:modelValue":b[7]||(b[7]=k=>So(Ys)?Ys.value=k:null),name:"title",type:"text",placeholder:"Enter recording title"},null,512),[[ar,f(Ys)]])]),v("div",xB,[SB,v("div",AB,K(f(Su).screen),1),f(ha)?(_(),T("div",CB,K(f(Su).camera),1)):U("",!0)])]),Q(x,{style:{flex:"10 1 300px"}})])):U("",!0)])}}},IB={class:"rounded-xl overflow-hidden w-4 relative my-1 bg-light-800 dark-bg-dark-800"},EB={__name:"ControlLevel",props:{meter:Number},setup(n){return(e,t)=>(_(),T("div",IB,[v("div",{class:"absolute bottom-0 left-0 w-full transition-all duration-50ms",style:se({height:n.meter*100+"%",backgroundColor:`hsl(${180-n.meter*180},90%,50%)`})},null,4)]))}},DB={class:"flex flex-wrap w-full gap-2"},PB={class:"is-group flex flex-wrap p-2 gap-2"},NB={key:0,class:"i-ph-microphone z-10 relative"},BB={key:1,class:"i-ph-microphone-fill z-10 relative"},jB=v("div",{class:"m-0"},"Mic",-1),zB=v("div",{class:"i-ph-ear"},null,-1),RB=v("div",{class:"m-0"},"Monitoring",-1),OB=[zB,RB],qB={class:"flex flex-wrap is-group items-center p-2 gap-2"},FB=v("div",{class:"p-1 font-bold"},"Master",-1),LB={key:0,class:"i-bi-volume-up"},GB={key:1,class:"i-bi-volume-mute"},$B={key:0,class:"flex flex-wrap items-center is-group p-2 gap-2"},VB=v("div",{class:"p-1 font-bold"},"Channels",-1),HB={__name:"StateSound",setup(n){const{audio:e,channels:t}=ud(),{mic:a,input:i}=lA();return(o,s)=>{const r=Jg,l=EB,c=MB,h=pn("tooltip");return _(),T("div",DB,[v("div",PB,[F((_(),T("button",{class:ae(["flex-button relative overflow-hidden",{active:f(a).open}]),onClick:s[0]||(s[0]=d=>f(a).open=!f(a).open)},[f(a).opened?(_(),T("div",BB)):(_(),T("div",NB)),jB],2)),[[h,"Enable microphone",void 0,{top:!0}]]),F((_(),T("button",{class:ae(["flex-button",{active:f(a).monitor}]),onClick:s[1]||(s[1]=d=>f(a).monitor=!f(a).monitor)},OB,2)),[[h,"Connect microphone to output",void 0,{top:!0}]]),F(Q(r,{modelValue:f(a).volume,"onUpdate:modelValue":s[2]||(s[2]=d=>f(a).volume=d),min:0,max:5,step:.001,param:"GAIN"},null,8,["modelValue"]),[[h,"Microphone volume",void 0,{bottom:!0}]]),F(Q(r,{modelValue:f(a).gate,"onUpdate:modelValue":s[3]||(s[3]=d=>f(a).gate=d),min:-100,max:-40,step:1,param:"GATE",unit:"dB",fixed:0},null,8,["modelValue"]),[[h,"Noise gate",void 0,{bottom:!0}]]),Q(l,{class:"mr-1",meter:f(a).meter},null,8,["meter"])]),v("div",qB,[FB,F(Q(r,{param:"Vol",modelValue:f(e).volume,"onUpdate:modelValue":s[4]||(s[4]=d=>f(e).volume=d),min:0,max:2,step:.001},null,8,["modelValue"]),[[h,"Master volume",void 0,{bottom:!0}]]),F((_(),T("button",{class:ae(["text-button border mute mt-24",{active:!f(e).mute}]),onClick:s[5]||(s[5]=d=>f(e).mute=!f(e).mute),"aria-label":"Toggle mute"},[f(e).mute?(_(),T("div",GB)):(_(),T("div",LB))],2)),[[h,"Toggle mute",void 0,{top:!0}]]),Q(l,{class:"mr-1",meter:f(e).meter},null,8,["meter"])]),Object.keys(f(t)).length>0?(_(),T("div",$B,[VB,(_(!0),T(ke,null,Me(f(t),(d,u)=>(_(),T("div",{class:"p-1 text-sm",key:u},K(u),1))),128))])):U("",!0),Q(c)])}}},WB={class:"flex flex-wrap justify-center max-w-max"},UB=v("div",{class:"flex-auto w-full text-sm text-center border-b-1 border-dark-300 dark-border-light-300"},"OSC",-1),KB=["modelValue","onInput","id","value","aria-label"],JB=["for","value"],ZB={key:0,class:"i-ph-wave-sine-duotone"},YB={key:1,class:"i-ph-wave-triangle-duotone"},XB={key:2,class:"i-ph-wave-square-duotone"},QB={key:3,class:"i-ph-wave-sawtooth-duotone"},ej={__name:"SynthOscillators",props:{modelValue:{type:String,default:"sawtooth8"},types:{type:Object,default:{sine:"SIN",triangle:"TRI",square8:"SQR",sawtooth8:"SAW"}}},emits:["update:modelValue"],setup(n,{emit:e}){return(t,a)=>(_(),T("div",WB,[UB,(_(!0),T(ke,null,Me(n.types,(i,o)=>(_(),T("div",{class:"flex relative flex-auto",key:o},[v("input",{class:"absolute right-1 top-1",type:"radio",modelValue:n.modelValue,onInput:s=>t.$emit("update:modelValue",o),id:o,value:o,name:"OSC","aria-label":`Select ${o} oscillator`},null,40,KB),v("label",{class:ae(["text-button flex-auto flex justify-center",{active:n.modelValue==o}]),for:o,value:o},[o=="sine"?(_(),T("div",ZB)):U("",!0),o=="triangle"?(_(),T("div",YB)):U("",!0),o=="square8"?(_(),T("div",XB)):U("",!0),o=="sawtooth8"?(_(),T("div",QB)):U("",!0)],10,JB)]))),128))]))}},lo=n=>(mt("data-v-8eeb1d96"),n=n(),pt(),n),tj={class:"flex flex-col w-full gap-2"},nj={class:"flex flex-wrap"},aj=lo(()=>v("div",{class:"i-la-wave-square text-xl"},null,-1)),ij=lo(()=>v("div",{class:"m-0"},"Play synth",-1)),oj=[aj,ij],sj=lo(()=>v("div",{class:"i-la-ban text-xl"},null,-1)),rj=lo(()=>v("div",{class:"m-0"},"Stop synth",-1)),lj=[sj,rj],cj={key:0,class:"i-bi-volume-up"},hj={key:1,class:"i-bi-volume-off"},dj=lo(()=>v("div",{class:"m-0"},"MIDI Synth",-1)),uj={class:"flex flex-wrap gap-2"},mj={class:"flex flex-wrap"},pj={class:"is-group flex relative"},fj=lo(()=>v("div",{class:"text-sm absolute -top-4 bg-light-300 px-1 rounded dark-bg-dark-400"},"Delay",-1)),gj={class:"flex is-group"},yj={class:"font-bold"},bj={class:"font-bold"},vj={__name:"SynthPanel",setup(n){const{synth:e,once:t,releaseAll:a}=r2(),i=De([1,.2,1,0,0,1,.2,.2]),o=Yc([-3,-2,-1,0,1,2,3],{initialValue:B.offset});de(i,()=>{e.poly.set({oscillator:{partials:[...i]}}),console.log("set")});const s=H(()=>c2(B.note.pitch,B.note.octA));return(r,l)=>{const c=Jg,h=ej,d=Zg,u=pn("tooltip");return _(),T("div",tj,[v("div",nj,[F((_(),T("button",{class:ae(["flex-button",{active:f(e).state.initiated}]),onClick:l[0]||(l[0]=m=>f(t)()),"aria-label":"Test synth sound"},oj,2)),[[u,"Test synth sound",void 0,{top:!0}]]),F((_(),T("button",{class:"flex-button",onClick:l[1]||(l[1]=m=>f(a)()),"aria-label":"Panic synth release"},lj)),[[u,"Panic synth release",void 0,{top:!0}]]),F((_(),T("button",{class:ae(["flex-button border opacity-30",{active:f(e).state.midi}]),onClick:l[2]||(l[2]=m=>f(e).state.midi=!f(e).state.midi)},[f(e).state.midi?(_(),T("div",cj)):(_(),T("div",hj)),dj],2)),[[u,"Play synth on MIDI input",void 0,{bottom:!0}]])]),v("div",uj,[F(Q(c,{min:0,max:2,step:.001,modelValue:f(e).state.volume,"onUpdate:modelValue":l[3]||(l[3]=m=>f(e).state.volume=m),param:"VOL"},null,8,["modelValue"]),[[u,"Synth volume",void 0,{top:!0}]]),F(Q(h,{class:"is-group",modelValue:f(e).params.oscillator.type,"onUpdate:modelValue":l[4]||(l[4]=m=>f(e).params.oscillator.type=m)},null,8,["modelValue"]),[[u,"Select oscillator type",void 0,{top:!0}]])]),v("div",mj,[(_(!0),T(ke,null,Me(i,(m,p)=>(_(),T("div",{class:"p-1",key:p},[Q(d,{class:"transition",min:0,max:1,step:.01,modelValue:i[p],"onUpdate:modelValue":g=>i[p]=g,param:p+"",style:se({color:f(h2)(s.value*(p+1))})},null,8,["modelValue","onUpdate:modelValue","param","style"])]))),128))]),v("div",pj,[fj,F(Q(c,{min:0,max:1,step:.001,modelValue:f(e).delayParams.feedback,"onUpdate:modelValue":l[5]||(l[5]=m=>f(e).delayParams.feedback=m),param:"Feedback"},null,8,["modelValue"]),[[u,"Synth delay feedback ratio",void 0,{top:!0}]]),F(Q(c,{min:0,max:1,step:.001,modelValue:f(e).delayParams.wet,"onUpdate:modelValue":l[6]||(l[6]=m=>f(e).delayParams.wet=m),param:"Wet"},null,8,["modelValue"]),[[u,"Synth delay wet",void 0,{top:!0}]])]),v("div",gj,[F((_(),T("button",{class:"flex-button",onClick:l[7]||(l[7]=m=>f(e).state.quantize.next()),"aria-label":"Synth panel"},[uc("Quantize "),v("div",yj,K(f(e).state.quantize.state),1)])),[[u,"Synth quantization",void 0,{bottom:!0}]]),F((_(),T("button",{class:"flex-button",onClick:l[8]||(l[8]=m=>f(B).offset=f(o).next())},[uc("Octave"),v("div",bj,K(f(B).offset>0?"+":"")+K(f(B).offset),1)])),[[u,"Octave offset",void 0,{bottom:!0}]])])])}}},wj=Fe(vj,[["__scopeId","data-v-8eeb1d96"]]),_j={class:"i-carbon-moon"},kj={class:"i-ion-ios-sunny"},Tj={__name:"StateDark",setup(n){const{isDark:e}=Ka();return(t,a)=>{const i=pn("tooltip");return F((_(),T("button",{class:"p-2 text-xl",onClick:a[0]||(a[0]=o=>e.value=!f(e)),"aria-label":"Toggle dark mode"},[F(v("div",_j,null,512),[[bt,f(e)]]),F(v("div",kj,null,512),[[bt,!f(e)]])])),[[i,"Toggle dark mode",void 0,{right:!0}]])}}},xj=v("div",{class:"i-la-expand"},null,-1),Sj=[xj],Aj={__name:"FullScreen",props:{el:{type:Object,default:null}},setup(n){const e=n,t=ee(),a=ee();bn(()=>{rn(o)});function i(){o(),a.value.toggle()}H(()=>{var s;return(s=a.value)==null?void 0:s.isSupported});function o(){e.el?t.value=e.el:t.value=document.getElementById("screen"),t.value||(t.value=document.getElementById("content")),a.value=gb(t.value)}return(s,r)=>{const l=pn("tooltip");return F((_(),T("button",{"aria-label":"Fullscreen toggle",onClick:r[0]||(r[0]=c=>i())},Sj)),[[l,"Toggle fullscreen",void 0,{left:!0}]])}}},Cj=n=>(mt("data-v-116b5a6a"),n=n(),pt(),n),Mj={class:"cursor-pointer bg-op-70 backdrop-blur dark-bg-op-70 fixed bg-light-900 dark-bg-dark-200 p-3 z-1000",key:"arrow"},Ij=Cj(()=>v("div",{class:"i-la-angle-left text-2xl"},null,-1)),Ej=[Ij],Dj={__name:"BarPanel",props:{modelValue:{},modelModifiers:{}},emits:["update:modelValue"],setup(n){const e=yb(n,"modelValue"),t=ee();return Um(t,()=>{e.value=!1}),$m("Escape",()=>{e.value=!1}),(a,i)=>(_(),At(dc,{name:"slide"},{default:Ge(()=>[F(v("button",Mj,Ej,512),[[bt,e.value]]),F(v("div",{class:"panel",ref_key:"panel",ref:t,key:"panel"},[En(a.$slots,"default",{},void 0,!0)],512),[[bt,e.value]])]),_:3}))}},ki=Fe(Dj,[["__scopeId","data-v-116b5a6a"]]),gt=n=>(mt("data-v-1b029fc0"),n=n(),pt(),n),Pj={class:"bar"},Nj={href:"/","aria-label":"Back to main page"},Bj=["src"],jj=gt(()=>v("div",{class:"i-la-book"},null,-1)),zj=[jj],Rj=gt(()=>v("div",{class:"i-la-hand-point-up"},null,-1)),Oj=[Rj],qj=gt(()=>v("div",{class:"i-la-chalkboard-teacher"},null,-1)),Fj=[qj],Lj=gt(()=>v("div",{class:"i-la-shopping-bag"},null,-1)),Gj=[Lj],$j=gt(()=>v("div",{class:"i-cil-education"},null,-1)),Vj=[$j],Hj=gt(()=>v("div",{class:"i-la-at"},null,-1)),Wj=[Hj],Uj=gt(()=>v("div",{class:"spacer"},null,-1)),Kj=gt(()=>v("div",{class:"i-la-search"},null,-1)),Jj=[Kj],Zj=gt(()=>v("div",{class:"flex-auto"},null,-1)),Yj=gt(()=>v("div",{class:"spacer"},null,-1)),Xj=gt(()=>v("div",{class:"i-mdi-piano"},null,-1)),Qj=[Xj],ez=gt(()=>v("div",{class:"i-mdi-metronome"},null,-1)),tz=[ez],nz=gt(()=>v("div",{class:"i-la-microphone"},null,-1)),az=[nz],iz=gt(()=>v("div",{class:"spacer"},null,-1)),oz=gt(()=>v("div",{class:"i-carbon-pen"},null,-1)),sz=[oz],rz=gt(()=>v("a",{class:"text-xl p-2 my-2 block",href:"/theory/"},"Theory",-1)),lz=gt(()=>v("a",{class:"text-xl p-2 my-2 block",href:"/practice/"},"Practice",-1)),cz={__name:"BarBar",setup(n){const e=Ta(),{theme:t}=Ka(),a=ee(),i=ee(),o=ee(),s=ee(),r=ee(),l=ee();return(c,h)=>{const d=Tj,u=bS,m=wj,p=EM,g=SE,y=HB,b=$y,x=K4,S=Jn("client-only"),k=pn("tooltip");return _(),T(ke,null,[v("nav",Pj,[F((_(),T("a",Nj,[f(t).logo?(_(),T("img",{key:0,class:"cursor-pointer mt-4 mx-2 mb-2",src:f(t).logo,alt:"Chromatone logo",title:"Chromatone"},null,8,Bj)):U("",!0)])),[[k,"Chromatone",void 0,{right:!0}]]),F((_(),T("button",{onClick:h[0]||(h[0]=w=>o.value=!o.value),class:ae({active:o.value||f(e).path.includes("theory")}),title:"Theory","aria-label":"Toggle theory navigation panel"},zj,2)),[[k,"Theory",void 0,{right:!0}]]),F((_(),T("button",{onClick:h[1]||(h[1]=w=>i.value=!i.value),class:ae({active:i.value||f(e).path.includes("practice")}),title:"Practice","aria-label":"Toggle practice navigation panel"},Oj,2)),[[k,"Practice",void 0,{right:!0}]]),F((_(),T("a",{class:ae(["button",{active:f(e).path.includes("tutor")}]),title:"tutor",href:"/tutor/","aria-label":"Tutorship"},Fj,2)),[[k,"Tutorship",void 0,{right:!0}]]),F((_(),T("a",{class:ae(["button",{active:f(e).path.includes("shop")}]),title:"Shop",href:"/shop/","aria-label":"Shop"},Gj,2)),[[k,"Shop",void 0,{right:!0}]]),F((_(),T("a",{class:ae(["button",{active:f(e).path.includes("academy")}]),title:"Academy",href:"/academy/","aria-label":"Academy"},Vj,2)),[[k,"Academy",void 0,{right:!0}]]),F((_(),T("a",{class:ae(["button",{active:f(e).path.includes("contacts")}]),title:"Contacts",href:"/contacts/","aria-label":"Contacts"},Wj,2)),[[k,"Contacts",void 0,{right:!0}]]),Uj,F((_(),T("button",{title:"Search",onClick:h[2]||(h[2]=w=>a.value=!a.value),class:ae({active:a.value}),"aria-label":"Toggle search panel"},Jj,2)),[[k,"Search",void 0,{right:!0}]]),Zj,Yj,F((_(),T("button",{onClick:h[3]||(h[3]=w=>l.value=!l.value),class:ae({active:l.value}),"aria-label":"Toggle synth panel",style:se({color:f(Ve)(f(qe).tonic)})},Qj,6)),[[k,"Synth settings",void 0,{right:!0}]]),F((_(),T("button",{onClick:h[4]||(h[4]=w=>r.value=!r.value),class:ae({active:r.value}),"aria-label":"Toggle transport panel",style:se({color:f(X).blink?f(X).color:""})},tz,6)),[[k,"Transport",void 0,{right:!0}]]),F((_(),T("button",{onClick:h[5]||(h[5]=w=>s.value=!s.value),class:ae({active:s.value}),"aria-label":"Toggle audio input/output panel",style:se({color:f(xn).opened?"red":""})},az,6)),[[k,"Audio input/output",void 0,{right:!0}]]),iz,F((_(),T("button",{onClick:h[6]||(h[6]=w=>va.value=!f(va)),class:ae({active:f(va)}),"aria-label":"Toggle screen drawing"},sz,2)),[[k,"Draw on the screen",void 0,{right:!0}]]),Q(d),Q(Aj)]),Q(S,null,{default:Ge(()=>[Q(ki,{modelValue:l.value,"onUpdate:modelValue":h[7]||(h[7]=w=>l.value=w)},{default:Ge(()=>[Q(u,{class:"w-full"}),Q(m)]),_:1},8,["modelValue"]),Q(ki,{modelValue:r.value,"onUpdate:modelValue":h[8]||(h[8]=w=>r.value=w)},{default:Ge(()=>[Q(p),Q(g)]),_:1},8,["modelValue"]),Q(ki,{modelValue:s.value,"onUpdate:modelValue":h[9]||(h[9]=w=>s.value=w)},{default:Ge(()=>[Q(y)]),_:1},8,["modelValue"]),Q(ki,{modelValue:a.value,"onUpdate:modelValue":h[11]||(h[11]=w=>a.value=w)},{default:Ge(()=>[Q(b,{class:"mt-4",onClose:h[10]||(h[10]=w=>a.value=!1),focus:a.value},null,8,["focus"])]),_:1},8,["modelValue"]),Q(ki,{modelValue:o.value,"onUpdate:modelValue":h[12]||(h[12]=w=>o.value=w)},{default:Ge(()=>[rz,Q(x,{path:"/theory/",level:0})]),_:1},8,["modelValue"]),Q(ki,{modelValue:i.value,"onUpdate:modelValue":h[13]||(h[13]=w=>i.value=w)},{default:Ge(()=>[lz,Q(x,{path:"/practice/",level:0})]),_:1},8,["modelValue"])]),_:1})],64)}}},hz=Fe(cz,[["__scopeId","data-v-1b029fc0"]]),dz=["src"],uz={class:"main"},mz=["src"],pz={key:1,class:"home items-center justify-center overflow-clip","aria-labelledby":"main-title"},fz=v("div",{class:"flex-1 p-8 gap-1 flex flex-col lg-scale-120 origin-left",style:{flex:"1 1 400px"}},[v("div",{class:"text-3rem md-text-4rem font-bold"},"Chromatone"),v("div",{class:"text-2rem md-ml-1"},"Visual Music Language"),v("div",{class:"text-xl md-ml-1"},"to learn, explore and communicate with ")],-1),gz={class:"flex flex-wrap items-start px-4 gap-4"},yz={class:"flex flex-wrap gap-4 items-stretch",style:{flex:"1 1 280px"}},bz={class:"flex flex-col gap-4",style:{flex:"1 1 280px"}},vz={key:0,class:"p-0"},wz={key:2,class:"w-full relative flex flex-col",id:"content"},_z={class:"font-bold select-none pointer-events-none"},kz={class:"p-0 select-none pointer-events-none flex-1"},Tz=["src"],xz={__name:"layout",setup(n){const{x:e,y:t}=bb(),a=vb("history"),{isDark:i,theme:o}=Ka(),s=Ta(),{frontmatter:r}=Ka(),l=ee(!1),{pages:c,children:h,siblings:d,parents:u}=Pd(s,ni),m=OP(s,ni),p=H(()=>{let b=i.value?40:60;return vt(d.value.index,d.value.total,1,20,b)}),g=H(()=>vt(d.value.index,d.value.total,1,40,60));function y(){t.value=0}return(b,x)=>{var J,ie,ge,ot;const S=hz,k=q4,w=R4,C=TN,M=CI,A=wN,I=IE,D=Jn("content"),P=nN,E=U3,O=$3,j=j3,W=i3,L=RP,z=zP,Y=jP,V=Jn("client-only");return _(),T(ke,null,[f(o).logo?(_(),T("img",{key:0,class:"top-16px left-2 fixed z-1000 cursor-pointer mr-3 h-30px",src:f(o).logo,alt:"Chromatone logo",onClick:x[0]||(x[0]=Ee=>l.value=!l.value)},null,8,dz)):U("",!0),Q(S),Q(k),v("div",uz,[Q(w,{open:l.value,onClose:x[1]||(x[1]=Ee=>l.value=!1)},null,8,["open"]),Q(C),f(r).layout=="iframe"?(_(),T(ke,{key:0},[(J=f(r))!=null&&J.iframe?(_(),T("iframe",{key:0,class:"min-h-80svh w-full max-w-100svw",src:f(r).iframe},null,8,mz)):U("",!0)],64)):f(r).layout=="home"?(_(),T("main",pz,[Q(M,{class:"mt-8 flex justify-center",style:{flex:"1 1 420px"}}),fz,v("div",gz,[v("div",yz,[(_(!0),T(ke,null,Me(f(h),(Ee,le)=>(_(),At(A,{style:{flex:"1 1 280px"},key:Ee.url,item:Ee,i:le,total:f(h).length},null,8,["item","i","total"]))),128))]),v("div",bz,[(ie=f(r))!=null&&ie.youtube?(_(),T("div",vz,[Q(I,{video:(ge=f(r))==null?void 0:ge.youtube},null,8,["video"])])):U("",!0),Q(D,{class:"content z-2 flex-auto"})])]),Q(P)])):(_(),T("main",wz,[Q(Oo,{name:"fade"},{default:Ge(()=>{var Ee,le,Te,Je,te,Ot;return[f(r).layout!="app"?(_(),At(O,{key:0,pageColor:p.value,lightColor:g.value,page:f(r),cover:f(r).dynamic?((Ee=f(r))==null?void 0:Ee.cover)||((le=f(r))==null?void 0:le.poster)||"":(Je=(Te=f(m))==null?void 0:Te.frontmatter)==null?void 0:Je.cover},{default:Ge(()=>[Q(E,{parents:f(r).dynamic?f(u):f(u).slice(0,-1)},null,8,["parents"])]),_:1},8,["pageColor","lightColor","page","cover"])):f(t)>100?(_(),T("div",{key:1,class:"fixed top-0 left-12 right-0 z-100 text-md p-2 flex gap-2 items-center bg-light-200 bg-opacity-20 dark-bg-dark-200 dark-bg-opacity-10 backdrop-blur-lg pt-2 pl-4 min-h-15 border-t-4 op-90 transition",style:se({borderColor:p.value})},[v("h2",_z,K((te=f(r))==null?void 0:te.title),1),v("div",kz,K((Ot=f(r))==null?void 0:Ot.description),1),v("div",{class:"i-la-angle-up w-6",onClick:x[2]||(x[2]=dt=>y())})],4)):U("",!0)]}),_:1}),(ot=f(r))!=null&&ot.iframe?(_(),T("iframe",{key:0,class:"min-h-80svh w-full max-w-100svw",src:f(r).iframe},null,8,Tz)):U("",!0),Q(Oo,{name:"fade"},{default:Ge(()=>{var Ee,le;return[(_(),T("div",{class:"pb-8 relative flex flex-col items-stretch w-full flex-auto",key:f(s).path},[(Ee=f(r))!=null&&Ee.topContent?(_(),At(D,{key:0,class:"content flex-auto z-10"})):U("",!0),Q(j,{class:"px-2 my-2 max-w-200",children:f(h)},null,8,["children"]),(le=f(r))!=null&&le.topContent?U("",!0):(_(),At(D,{key:1,class:"content flex-auto z-10"}))]))]}),_:1}),f(a).nonextprev?U("",!0):(_(),At(W,{key:1,siblings:f(d),parents:f(u)},null,8,["siblings","parents"])),Q(P)])),Q(V,null,{default:Ge(()=>[Q(L,{class:"z-100"}),Q(z),f(va)||f(Ay)?(_(),At(Y,{key:0,class:"fixed bottom-4 left-4 right-16 z-100"})):U("",!0)]),_:1})])],64)}}},Sz={class:"theme flex flex-col items-center"},Az=v("h1",{class:"text-6xl"},"404",-1),Cz=["href"],Mz={__name:"not-found",setup(n){const{site:e}=Ka(),t=["There's nothing here.","How did we get here?","That's a Four-Oh-Four.","Looks like we've got some broken links."];function a(){return t[Math.floor(Math.random()*t.length)]}return(i,o)=>(_(),T("div",Sz,[Az,v("p",null,K(a()),1),v("a",{href:f(e).base,"aria-label":"go to home"},"Take me home.",8,Cz)]))}},IR={Layout:xz,NotFound:Mz,async enhanceApp({app:n}){n.use(ED),n.use(MC);{const e=await Ua(()=>import("./index.DqdnRQKP.js"),__vite__mapDeps([2,1]));n.use(e.default)}}};export{Fa as $,Tu as A,cR as B,md as C,pS as D,Uh as E,pr as F,pi as G,dx as H,uA as I,AR as J,Ji as K,X as L,Jg as M,d2 as N,Cg as O,rf as P,yt as Q,kR as R,vt as S,TR as T,EM as U,Hg as V,_r as W,Xf as X,hd as Y,r2 as Z,bS as _,fR as a,_k as a0,nT as a1,Yo as a2,lR as a3,h2 as a4,yR as a5,gC as a6,bR as a7,rg as a8,MR as a9,Qe as aA,Dh as aB,oR as aC,vR as aD,CR as aE,_R as aF,Sg as aG,Xs as aH,Zg as aI,pl as aJ,ul as aK,nf as aL,qh as aM,Ph as aN,Lh as aO,sf as aP,xR as aQ,IE as aR,oe as aS,SR as aT,IR as aU,sg as aV,vg as aa,br as ab,wg as ac,CI as ad,sR as ae,G as af,uR as ag,SE as ah,kk as ai,ud as aj,iR as ak,hl as al,Xa as am,tg as an,dR as ao,og as ap,ci as aq,re as ar,Vo as as,Jf as at,_s as au,ks as av,ea as aw,Mh as ax,lA as ay,o2 as az,Tr as b,xr as c,Sl as d,ua as e,B as f,qe as g,u2 as h,tx as i,hR as j,Ac as k,wu as l,As as m,Ve as n,Ko as o,c2 as p,wR as q,Zn as r,gR as s,p2 as t,cd as u,zs as v,Re as w,Qf as x,l2 as y,pR as z};
