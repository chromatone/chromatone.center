const __vite__mapDeps=(i,m=__vite__mapDeps,d=(m.f||(m.f=["assets/chunks/HydraSynth.D2vfcsfD.js","assets/chunks/framework.C3LH_Uf3.js","assets/chunks/theme.DRfkbxnY.js","assets/chunks/index.h_hPpPpY.js","assets/chunks/meyda.min.1E7FA6VY.js"])))=>i.map(i=>d[i]);
import{D as a,a0 as r,K as s,F as e,a2 as o,C as n,au as i,_ as d}from"./chunks/framework.C3LH_Uf3.js";const l=e("h2",{id:"hydra",tabindex:"-1"},[o("Hydra "),e("a",{class:"header-anchor",href:"#hydra","aria-label":'Permalink to "Hydra"'},"â€‹")],-1),h=e("p",null,"Set of tools for livecoding networked visuals. Inspired by analog modular synthesizers, these tools are an exploration into using streaming over the web for routing video sources and outputs in realtime.",-1),c=e("p",null,"Hydra uses multiple framebuffers to allow dynamically mixing, compositing, and collaborating between connected browser-visual-streams. Coordinate and color transforms can be applied to each output via chained functions.",-1),p=e("p",null,[e("a",{href:"https://hydra.ojack.xyz",target:"_blank",rel:"noreferrer"},"https://hydra.ojack.xyz")],-1),v=JSON.parse('{"title":"Hydra synth","description":"","frontmatter":{"title":"Hydra synth","subtitle":"Experiment with visual synth","cover":"cover.png","layout":"app","date":"2020-02-02T00:00:00.000Z","links":["https://github.com/hydra-synth/hydra-synth","https://github.com/hydra-synth/hydra","https://github.com/hydra-synth/hydra-examples"]},"headers":[],"relativePath":"practice/visual/hydra/index.md","filePath":"practice/visual/hydra/index.md","lastUpdated":1720375267000}'),u={name:"practice/visual/hydra/index.md"},b=Object.assign(u,{setup(y){const t=i(()=>d(()=>import("./chunks/HydraSynth.D2vfcsfD.js"),__vite__mapDeps([0,1,2,3,4])));return(_,m)=>(n(),a("div",null,[r(s(t)),l,h,c,p]))}});export{v as __pageData,b as default};
